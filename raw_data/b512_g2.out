I0811 16:02:11.941331 26953 caffe.cpp:217] Using GPUs 0, 1
I0811 16:02:16.509601 26953 caffe.cpp:222] GPU 0: Tesla K80
I0811 16:02:16.511466 26953 caffe.cpp:222] GPU 1: Tesla K80
I0811 16:02:16.891360 26953 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.01
display: 10
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "caffe_alexnet_train"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0811 16:02:16.891824 26953 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0811 16:02:16.893519 26953 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0811 16:02:16.893586 26953 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0811 16:02:16.894182 26953 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "imagenet_mean.binaryproto"
  }
  data_param {
    source: "/data/ilsvrc10_train_lmdb"
    batch_size: 512
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0811 16:02:16.894451 26953 layer_factory.hpp:77] Creating layer data
I0811 16:02:16.896061 26953 net.cpp:100] Creating Layer data
I0811 16:02:16.896097 26953 net.cpp:408] data -> data
I0811 16:02:16.896147 26953 net.cpp:408] data -> label
I0811 16:02:16.896180 26953 data_transformer.cpp:25] Loading mean file from: imagenet_mean.binaryproto
I0811 16:02:16.897573 26963 db_lmdb.cpp:35] Opened lmdb /data/ilsvrc10_train_lmdb
I0811 16:02:16.918926 26953 data_layer.cpp:41] output data size: 512,3,227,227
I0811 16:02:17.685544 26953 net.cpp:150] Setting up data
I0811 16:02:17.685619 26953 net.cpp:157] Top shape: 512 3 227 227 (79148544)
I0811 16:02:17.685642 26953 net.cpp:157] Top shape: 512 (512)
I0811 16:02:17.685648 26953 net.cpp:165] Memory required for data: 316596224
I0811 16:02:17.685668 26953 layer_factory.hpp:77] Creating layer conv1
I0811 16:02:17.685725 26953 net.cpp:100] Creating Layer conv1
I0811 16:02:17.685734 26953 net.cpp:434] conv1 <- data
I0811 16:02:17.685757 26953 net.cpp:408] conv1 -> conv1
I0811 16:02:17.730484 26980 blocking_queue.cpp:50] Waiting for data
I0811 16:02:18.009141 26953 net.cpp:150] Setting up conv1
I0811 16:02:18.009202 26953 net.cpp:157] Top shape: 512 96 55 55 (148684800)
I0811 16:02:18.009210 26953 net.cpp:165] Memory required for data: 911335424
I0811 16:02:18.009239 26953 layer_factory.hpp:77] Creating layer relu1
I0811 16:02:18.009264 26953 net.cpp:100] Creating Layer relu1
I0811 16:02:18.009289 26953 net.cpp:434] relu1 <- conv1
I0811 16:02:18.009305 26953 net.cpp:395] relu1 -> conv1 (in-place)
I0811 16:02:18.009696 26953 net.cpp:150] Setting up relu1
I0811 16:02:18.009717 26953 net.cpp:157] Top shape: 512 96 55 55 (148684800)
I0811 16:02:18.009728 26953 net.cpp:165] Memory required for data: 1506074624
I0811 16:02:18.009738 26953 layer_factory.hpp:77] Creating layer norm1
I0811 16:02:18.009765 26953 net.cpp:100] Creating Layer norm1
I0811 16:02:18.009775 26953 net.cpp:434] norm1 <- conv1
I0811 16:02:18.009789 26953 net.cpp:408] norm1 -> norm1
I0811 16:02:18.010628 26953 net.cpp:150] Setting up norm1
I0811 16:02:18.010663 26953 net.cpp:157] Top shape: 512 96 55 55 (148684800)
I0811 16:02:18.010673 26953 net.cpp:165] Memory required for data: 2100813824
I0811 16:02:18.010684 26953 layer_factory.hpp:77] Creating layer pool1
I0811 16:02:18.010718 26953 net.cpp:100] Creating Layer pool1
I0811 16:02:18.010757 26953 net.cpp:434] pool1 <- norm1
I0811 16:02:18.010772 26953 net.cpp:408] pool1 -> pool1
I0811 16:02:18.010886 26953 net.cpp:150] Setting up pool1
I0811 16:02:18.010905 26953 net.cpp:157] Top shape: 512 96 27 27 (35831808)
I0811 16:02:18.010913 26953 net.cpp:165] Memory required for data: 2244141056
I0811 16:02:18.010922 26953 layer_factory.hpp:77] Creating layer conv2
I0811 16:02:18.010952 26953 net.cpp:100] Creating Layer conv2
I0811 16:02:18.010963 26953 net.cpp:434] conv2 <- pool1
I0811 16:02:18.010982 26953 net.cpp:408] conv2 -> conv2
I0811 16:02:18.033689 26953 net.cpp:150] Setting up conv2
I0811 16:02:18.033723 26953 net.cpp:157] Top shape: 512 256 27 27 (95551488)
I0811 16:02:18.033733 26953 net.cpp:165] Memory required for data: 2626347008
I0811 16:02:18.033756 26953 layer_factory.hpp:77] Creating layer relu2
I0811 16:02:18.033773 26953 net.cpp:100] Creating Layer relu2
I0811 16:02:18.033782 26953 net.cpp:434] relu2 <- conv2
I0811 16:02:18.033794 26953 net.cpp:395] relu2 -> conv2 (in-place)
I0811 16:02:18.034128 26953 net.cpp:150] Setting up relu2
I0811 16:02:18.034147 26953 net.cpp:157] Top shape: 512 256 27 27 (95551488)
I0811 16:02:18.034155 26953 net.cpp:165] Memory required for data: 3008552960
I0811 16:02:18.034164 26953 layer_factory.hpp:77] Creating layer norm2
I0811 16:02:18.034181 26953 net.cpp:100] Creating Layer norm2
I0811 16:02:18.034189 26953 net.cpp:434] norm2 <- conv2
I0811 16:02:18.034201 26953 net.cpp:408] norm2 -> norm2
I0811 16:02:18.034809 26953 net.cpp:150] Setting up norm2
I0811 16:02:18.034834 26953 net.cpp:157] Top shape: 512 256 27 27 (95551488)
I0811 16:02:18.034842 26953 net.cpp:165] Memory required for data: 3390758912
I0811 16:02:18.034853 26953 layer_factory.hpp:77] Creating layer pool2
I0811 16:02:18.034870 26953 net.cpp:100] Creating Layer pool2
I0811 16:02:18.034879 26953 net.cpp:434] pool2 <- norm2
I0811 16:02:18.034896 26953 net.cpp:408] pool2 -> pool2
I0811 16:02:18.034970 26953 net.cpp:150] Setting up pool2
I0811 16:02:18.034983 26953 net.cpp:157] Top shape: 512 256 13 13 (22151168)
I0811 16:02:18.034991 26953 net.cpp:165] Memory required for data: 3479363584
I0811 16:02:18.034998 26953 layer_factory.hpp:77] Creating layer conv3
I0811 16:02:18.035025 26953 net.cpp:100] Creating Layer conv3
I0811 16:02:18.035035 26953 net.cpp:434] conv3 <- pool2
I0811 16:02:18.035048 26953 net.cpp:408] conv3 -> conv3
I0811 16:02:18.080739 26953 net.cpp:150] Setting up conv3
I0811 16:02:18.080767 26953 net.cpp:157] Top shape: 512 384 13 13 (33226752)
I0811 16:02:18.080775 26953 net.cpp:165] Memory required for data: 3612270592
I0811 16:02:18.080793 26953 layer_factory.hpp:77] Creating layer relu3
I0811 16:02:18.080811 26953 net.cpp:100] Creating Layer relu3
I0811 16:02:18.080818 26953 net.cpp:434] relu3 <- conv3
I0811 16:02:18.080828 26953 net.cpp:395] relu3 -> conv3 (in-place)
I0811 16:02:18.081348 26953 net.cpp:150] Setting up relu3
I0811 16:02:18.081372 26953 net.cpp:157] Top shape: 512 384 13 13 (33226752)
I0811 16:02:18.081379 26953 net.cpp:165] Memory required for data: 3745177600
I0811 16:02:18.081387 26953 layer_factory.hpp:77] Creating layer conv4
I0811 16:02:18.081408 26953 net.cpp:100] Creating Layer conv4
I0811 16:02:18.081418 26953 net.cpp:434] conv4 <- conv3
I0811 16:02:18.081432 26953 net.cpp:408] conv4 -> conv4
I0811 16:02:18.111758 26953 net.cpp:150] Setting up conv4
I0811 16:02:18.111783 26953 net.cpp:157] Top shape: 512 384 13 13 (33226752)
I0811 16:02:18.111788 26953 net.cpp:165] Memory required for data: 3878084608
I0811 16:02:18.111799 26953 layer_factory.hpp:77] Creating layer relu4
I0811 16:02:18.111814 26953 net.cpp:100] Creating Layer relu4
I0811 16:02:18.111820 26953 net.cpp:434] relu4 <- conv4
I0811 16:02:18.111829 26953 net.cpp:395] relu4 -> conv4 (in-place)
I0811 16:02:18.112073 26953 net.cpp:150] Setting up relu4
I0811 16:02:18.112088 26953 net.cpp:157] Top shape: 512 384 13 13 (33226752)
I0811 16:02:18.112093 26953 net.cpp:165] Memory required for data: 4010991616
I0811 16:02:18.112107 26953 layer_factory.hpp:77] Creating layer conv5
I0811 16:02:18.112141 26953 net.cpp:100] Creating Layer conv5
I0811 16:02:18.112149 26953 net.cpp:434] conv5 <- conv4
I0811 16:02:18.112159 26953 net.cpp:408] conv5 -> conv5
I0811 16:02:18.132356 26953 net.cpp:150] Setting up conv5
I0811 16:02:18.132377 26953 net.cpp:157] Top shape: 512 256 13 13 (22151168)
I0811 16:02:18.132383 26953 net.cpp:165] Memory required for data: 4099596288
I0811 16:02:18.132397 26953 layer_factory.hpp:77] Creating layer relu5
I0811 16:02:18.132408 26953 net.cpp:100] Creating Layer relu5
I0811 16:02:18.132414 26953 net.cpp:434] relu5 <- conv5
I0811 16:02:18.132426 26953 net.cpp:395] relu5 -> conv5 (in-place)
I0811 16:02:18.132642 26953 net.cpp:150] Setting up relu5
I0811 16:02:18.132658 26953 net.cpp:157] Top shape: 512 256 13 13 (22151168)
I0811 16:02:18.132663 26953 net.cpp:165] Memory required for data: 4188200960
I0811 16:02:18.132668 26953 layer_factory.hpp:77] Creating layer pool5
I0811 16:02:18.132679 26953 net.cpp:100] Creating Layer pool5
I0811 16:02:18.132684 26953 net.cpp:434] pool5 <- conv5
I0811 16:02:18.132693 26953 net.cpp:408] pool5 -> pool5
I0811 16:02:18.132753 26953 net.cpp:150] Setting up pool5
I0811 16:02:18.132762 26953 net.cpp:157] Top shape: 512 256 6 6 (4718592)
I0811 16:02:18.132767 26953 net.cpp:165] Memory required for data: 4207075328
I0811 16:02:18.132772 26953 layer_factory.hpp:77] Creating layer fc6
I0811 16:02:18.132791 26953 net.cpp:100] Creating Layer fc6
I0811 16:02:18.132797 26953 net.cpp:434] fc6 <- pool5
I0811 16:02:18.132807 26953 net.cpp:408] fc6 -> fc6
I0811 16:02:19.303170 26953 net.cpp:150] Setting up fc6
I0811 16:02:19.303210 26953 net.cpp:157] Top shape: 512 4096 (2097152)
I0811 16:02:19.303215 26953 net.cpp:165] Memory required for data: 4215463936
I0811 16:02:19.303227 26953 layer_factory.hpp:77] Creating layer relu6
I0811 16:02:19.303242 26953 net.cpp:100] Creating Layer relu6
I0811 16:02:19.303248 26953 net.cpp:434] relu6 <- fc6
I0811 16:02:19.303256 26953 net.cpp:395] relu6 -> fc6 (in-place)
I0811 16:02:19.303797 26953 net.cpp:150] Setting up relu6
I0811 16:02:19.303809 26953 net.cpp:157] Top shape: 512 4096 (2097152)
I0811 16:02:19.303813 26953 net.cpp:165] Memory required for data: 4223852544
I0811 16:02:19.303818 26953 layer_factory.hpp:77] Creating layer drop6
I0811 16:02:19.303828 26953 net.cpp:100] Creating Layer drop6
I0811 16:02:19.303833 26953 net.cpp:434] drop6 <- fc6
I0811 16:02:19.303841 26953 net.cpp:395] drop6 -> fc6 (in-place)
I0811 16:02:19.303874 26953 net.cpp:150] Setting up drop6
I0811 16:02:19.303882 26953 net.cpp:157] Top shape: 512 4096 (2097152)
I0811 16:02:19.303886 26953 net.cpp:165] Memory required for data: 4232241152
I0811 16:02:19.303891 26953 layer_factory.hpp:77] Creating layer fc7
I0811 16:02:19.303900 26953 net.cpp:100] Creating Layer fc7
I0811 16:02:19.303905 26953 net.cpp:434] fc7 <- fc6
I0811 16:02:19.303921 26953 net.cpp:408] fc7 -> fc7
I0811 16:02:19.768165 26953 net.cpp:150] Setting up fc7
I0811 16:02:19.768203 26953 net.cpp:157] Top shape: 512 4096 (2097152)
I0811 16:02:19.768208 26953 net.cpp:165] Memory required for data: 4240629760
I0811 16:02:19.768225 26953 layer_factory.hpp:77] Creating layer relu7
I0811 16:02:19.768247 26953 net.cpp:100] Creating Layer relu7
I0811 16:02:19.768254 26953 net.cpp:434] relu7 <- fc7
I0811 16:02:19.768265 26953 net.cpp:395] relu7 -> fc7 (in-place)
I0811 16:02:19.768667 26953 net.cpp:150] Setting up relu7
I0811 16:02:19.768677 26953 net.cpp:157] Top shape: 512 4096 (2097152)
I0811 16:02:19.768682 26953 net.cpp:165] Memory required for data: 4249018368
I0811 16:02:19.768687 26953 layer_factory.hpp:77] Creating layer drop7
I0811 16:02:19.768695 26953 net.cpp:100] Creating Layer drop7
I0811 16:02:19.768700 26953 net.cpp:434] drop7 <- fc7
I0811 16:02:19.768707 26953 net.cpp:395] drop7 -> fc7 (in-place)
I0811 16:02:19.768734 26953 net.cpp:150] Setting up drop7
I0811 16:02:19.768743 26953 net.cpp:157] Top shape: 512 4096 (2097152)
I0811 16:02:19.768748 26953 net.cpp:165] Memory required for data: 4257406976
I0811 16:02:19.768760 26953 layer_factory.hpp:77] Creating layer fc8
I0811 16:02:19.768781 26953 net.cpp:100] Creating Layer fc8
I0811 16:02:19.768785 26953 net.cpp:434] fc8 <- fc7
I0811 16:02:19.768795 26953 net.cpp:408] fc8 -> fc8
I0811 16:02:19.879863 26953 net.cpp:150] Setting up fc8
I0811 16:02:19.879887 26953 net.cpp:157] Top shape: 512 1000 (512000)
I0811 16:02:19.879891 26953 net.cpp:165] Memory required for data: 4259454976
I0811 16:02:19.879901 26953 layer_factory.hpp:77] Creating layer loss
I0811 16:02:19.879914 26953 net.cpp:100] Creating Layer loss
I0811 16:02:19.879917 26953 net.cpp:434] loss <- fc8
I0811 16:02:19.879923 26953 net.cpp:434] loss <- label
I0811 16:02:19.879938 26953 net.cpp:408] loss -> loss
I0811 16:02:19.879956 26953 layer_factory.hpp:77] Creating layer loss
I0811 16:02:19.893808 26953 net.cpp:150] Setting up loss
I0811 16:02:19.893823 26953 net.cpp:157] Top shape: (1)
I0811 16:02:19.893827 26953 net.cpp:160]     with loss weight 1
I0811 16:02:19.893852 26953 net.cpp:165] Memory required for data: 4259454980
I0811 16:02:19.893857 26953 net.cpp:226] loss needs backward computation.
I0811 16:02:19.893862 26953 net.cpp:226] fc8 needs backward computation.
I0811 16:02:19.893867 26953 net.cpp:226] drop7 needs backward computation.
I0811 16:02:19.893869 26953 net.cpp:226] relu7 needs backward computation.
I0811 16:02:19.893873 26953 net.cpp:226] fc7 needs backward computation.
I0811 16:02:19.893877 26953 net.cpp:226] drop6 needs backward computation.
I0811 16:02:19.893882 26953 net.cpp:226] relu6 needs backward computation.
I0811 16:02:19.893885 26953 net.cpp:226] fc6 needs backward computation.
I0811 16:02:19.893890 26953 net.cpp:226] pool5 needs backward computation.
I0811 16:02:19.893894 26953 net.cpp:226] relu5 needs backward computation.
I0811 16:02:19.893901 26953 net.cpp:226] conv5 needs backward computation.
I0811 16:02:19.893908 26953 net.cpp:226] relu4 needs backward computation.
I0811 16:02:19.893911 26953 net.cpp:226] conv4 needs backward computation.
I0811 16:02:19.893918 26953 net.cpp:226] relu3 needs backward computation.
I0811 16:02:19.893923 26953 net.cpp:226] conv3 needs backward computation.
I0811 16:02:19.893928 26953 net.cpp:226] pool2 needs backward computation.
I0811 16:02:19.893935 26953 net.cpp:226] norm2 needs backward computation.
I0811 16:02:19.893940 26953 net.cpp:226] relu2 needs backward computation.
I0811 16:02:19.893944 26953 net.cpp:226] conv2 needs backward computation.
I0811 16:02:19.893949 26953 net.cpp:226] pool1 needs backward computation.
I0811 16:02:19.893955 26953 net.cpp:226] norm1 needs backward computation.
I0811 16:02:19.893960 26953 net.cpp:226] relu1 needs backward computation.
I0811 16:02:19.893964 26953 net.cpp:226] conv1 needs backward computation.
I0811 16:02:19.893970 26953 net.cpp:228] data does not need backward computation.
I0811 16:02:19.893973 26953 net.cpp:270] This network produces output loss
I0811 16:02:19.893991 26953 net.cpp:283] Network initialization done.
I0811 16:02:19.894783 26953 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0811 16:02:19.894830 26953 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0811 16:02:19.895119 26953 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "imagenet_mean.binaryproto"
  }
  data_param {
    source: "/data/ilsvrc10_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0811 16:02:19.895270 26953 layer_factory.hpp:77] Creating layer data
I0811 16:02:19.895380 26953 net.cpp:100] Creating Layer data
I0811 16:02:19.895390 26953 net.cpp:408] data -> data
I0811 16:02:19.895402 26953 net.cpp:408] data -> label
I0811 16:02:19.895412 26953 data_transformer.cpp:25] Loading mean file from: imagenet_mean.binaryproto
I0811 16:02:19.905288 27020 db_lmdb.cpp:35] Opened lmdb /data/ilsvrc10_val_lmdb
I0811 16:02:19.905832 26953 data_layer.cpp:41] output data size: 50,3,227,227
I0811 16:02:19.970938 26953 net.cpp:150] Setting up data
I0811 16:02:19.970979 26953 net.cpp:157] Top shape: 50 3 227 227 (7729350)
I0811 16:02:19.970986 26953 net.cpp:157] Top shape: 50 (50)
I0811 16:02:19.970990 26953 net.cpp:165] Memory required for data: 30917600
I0811 16:02:19.970999 26953 layer_factory.hpp:77] Creating layer label_data_1_split
I0811 16:02:19.971017 26953 net.cpp:100] Creating Layer label_data_1_split
I0811 16:02:19.971024 26953 net.cpp:434] label_data_1_split <- label
I0811 16:02:19.971035 26953 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0811 16:02:19.971048 26953 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0811 16:02:19.971112 26953 net.cpp:150] Setting up label_data_1_split
I0811 16:02:19.971120 26953 net.cpp:157] Top shape: 50 (50)
I0811 16:02:19.971125 26953 net.cpp:157] Top shape: 50 (50)
I0811 16:02:19.971128 26953 net.cpp:165] Memory required for data: 30918000
I0811 16:02:19.971133 26953 layer_factory.hpp:77] Creating layer conv1
I0811 16:02:19.971150 26953 net.cpp:100] Creating Layer conv1
I0811 16:02:19.971155 26953 net.cpp:434] conv1 <- data
I0811 16:02:19.971163 26953 net.cpp:408] conv1 -> conv1
I0811 16:02:19.978273 26953 net.cpp:150] Setting up conv1
I0811 16:02:19.978292 26953 net.cpp:157] Top shape: 50 96 55 55 (14520000)
I0811 16:02:19.978297 26953 net.cpp:165] Memory required for data: 88998000
I0811 16:02:19.978310 26953 layer_factory.hpp:77] Creating layer relu1
I0811 16:02:19.978322 26953 net.cpp:100] Creating Layer relu1
I0811 16:02:19.978325 26953 net.cpp:434] relu1 <- conv1
I0811 16:02:19.978333 26953 net.cpp:395] relu1 -> conv1 (in-place)
I0811 16:02:19.978509 26953 net.cpp:150] Setting up relu1
I0811 16:02:19.978519 26953 net.cpp:157] Top shape: 50 96 55 55 (14520000)
I0811 16:02:19.978523 26953 net.cpp:165] Memory required for data: 147078000
I0811 16:02:19.978528 26953 layer_factory.hpp:77] Creating layer norm1
I0811 16:02:19.978539 26953 net.cpp:100] Creating Layer norm1
I0811 16:02:19.978544 26953 net.cpp:434] norm1 <- conv1
I0811 16:02:19.978551 26953 net.cpp:408] norm1 -> norm1
I0811 16:02:19.978935 26953 net.cpp:150] Setting up norm1
I0811 16:02:19.978948 26953 net.cpp:157] Top shape: 50 96 55 55 (14520000)
I0811 16:02:19.978953 26953 net.cpp:165] Memory required for data: 205158000
I0811 16:02:19.978957 26953 layer_factory.hpp:77] Creating layer pool1
I0811 16:02:19.978967 26953 net.cpp:100] Creating Layer pool1
I0811 16:02:19.978971 26953 net.cpp:434] pool1 <- norm1
I0811 16:02:19.978978 26953 net.cpp:408] pool1 -> pool1
I0811 16:02:19.979020 26953 net.cpp:150] Setting up pool1
I0811 16:02:19.979027 26953 net.cpp:157] Top shape: 50 96 27 27 (3499200)
I0811 16:02:19.979030 26953 net.cpp:165] Memory required for data: 219154800
I0811 16:02:19.979034 26953 layer_factory.hpp:77] Creating layer conv2
I0811 16:02:19.979046 26953 net.cpp:100] Creating Layer conv2
I0811 16:02:19.979050 26953 net.cpp:434] conv2 <- pool1
I0811 16:02:19.979059 26953 net.cpp:408] conv2 -> conv2
I0811 16:02:19.989246 26953 net.cpp:150] Setting up conv2
I0811 16:02:19.989262 26953 net.cpp:157] Top shape: 50 256 27 27 (9331200)
I0811 16:02:19.989266 26953 net.cpp:165] Memory required for data: 256479600
I0811 16:02:19.989277 26953 layer_factory.hpp:77] Creating layer relu2
I0811 16:02:19.989286 26953 net.cpp:100] Creating Layer relu2
I0811 16:02:19.989291 26953 net.cpp:434] relu2 <- conv2
I0811 16:02:19.989298 26953 net.cpp:395] relu2 -> conv2 (in-place)
I0811 16:02:19.989648 26953 net.cpp:150] Setting up relu2
I0811 16:02:19.989671 26953 net.cpp:157] Top shape: 50 256 27 27 (9331200)
I0811 16:02:19.989675 26953 net.cpp:165] Memory required for data: 293804400
I0811 16:02:19.989681 26953 layer_factory.hpp:77] Creating layer norm2
I0811 16:02:19.989691 26953 net.cpp:100] Creating Layer norm2
I0811 16:02:19.989696 26953 net.cpp:434] norm2 <- conv2
I0811 16:02:19.989702 26953 net.cpp:408] norm2 -> norm2
I0811 16:02:19.989899 26953 net.cpp:150] Setting up norm2
I0811 16:02:19.989909 26953 net.cpp:157] Top shape: 50 256 27 27 (9331200)
I0811 16:02:19.989913 26953 net.cpp:165] Memory required for data: 331129200
I0811 16:02:19.989918 26953 layer_factory.hpp:77] Creating layer pool2
I0811 16:02:19.989926 26953 net.cpp:100] Creating Layer pool2
I0811 16:02:19.989930 26953 net.cpp:434] pool2 <- norm2
I0811 16:02:19.989938 26953 net.cpp:408] pool2 -> pool2
I0811 16:02:19.989977 26953 net.cpp:150] Setting up pool2
I0811 16:02:19.989984 26953 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I0811 16:02:19.989987 26953 net.cpp:165] Memory required for data: 339782000
I0811 16:02:19.989991 26953 layer_factory.hpp:77] Creating layer conv3
I0811 16:02:19.990002 26953 net.cpp:100] Creating Layer conv3
I0811 16:02:19.990006 26953 net.cpp:434] conv3 <- pool2
I0811 16:02:19.990015 26953 net.cpp:408] conv3 -> conv3
I0811 16:02:20.015521 26953 net.cpp:150] Setting up conv3
I0811 16:02:20.015537 26953 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I0811 16:02:20.015542 26953 net.cpp:165] Memory required for data: 352761200
I0811 16:02:20.015552 26953 layer_factory.hpp:77] Creating layer relu3
I0811 16:02:20.015561 26953 net.cpp:100] Creating Layer relu3
I0811 16:02:20.015566 26953 net.cpp:434] relu3 <- conv3
I0811 16:02:20.015573 26953 net.cpp:395] relu3 -> conv3 (in-place)
I0811 16:02:20.016070 26953 net.cpp:150] Setting up relu3
I0811 16:02:20.016083 26953 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I0811 16:02:20.016088 26953 net.cpp:165] Memory required for data: 365740400
I0811 16:02:20.016093 26953 layer_factory.hpp:77] Creating layer conv4
I0811 16:02:20.016106 26953 net.cpp:100] Creating Layer conv4
I0811 16:02:20.016111 26953 net.cpp:434] conv4 <- conv3
I0811 16:02:20.016120 26953 net.cpp:408] conv4 -> conv4
I0811 16:02:20.037758 26953 net.cpp:150] Setting up conv4
I0811 16:02:20.037784 26953 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I0811 16:02:20.037788 26953 net.cpp:165] Memory required for data: 378719600
I0811 16:02:20.037797 26953 layer_factory.hpp:77] Creating layer relu4
I0811 16:02:20.037809 26953 net.cpp:100] Creating Layer relu4
I0811 16:02:20.037814 26953 net.cpp:434] relu4 <- conv4
I0811 16:02:20.037822 26953 net.cpp:395] relu4 -> conv4 (in-place)
I0811 16:02:20.038306 26953 net.cpp:150] Setting up relu4
I0811 16:02:20.038321 26953 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I0811 16:02:20.038324 26953 net.cpp:165] Memory required for data: 391698800
I0811 16:02:20.038329 26953 layer_factory.hpp:77] Creating layer conv5
I0811 16:02:20.038343 26953 net.cpp:100] Creating Layer conv5
I0811 16:02:20.038348 26953 net.cpp:434] conv5 <- conv4
I0811 16:02:20.038357 26953 net.cpp:408] conv5 -> conv5
I0811 16:02:20.081691 26953 net.cpp:150] Setting up conv5
I0811 16:02:20.081720 26953 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I0811 16:02:20.081725 26953 net.cpp:165] Memory required for data: 400351600
I0811 16:02:20.081743 26953 layer_factory.hpp:77] Creating layer relu5
I0811 16:02:20.081756 26953 net.cpp:100] Creating Layer relu5
I0811 16:02:20.081763 26953 net.cpp:434] relu5 <- conv5
I0811 16:02:20.081771 26953 net.cpp:395] relu5 -> conv5 (in-place)
I0811 16:02:20.081946 26953 net.cpp:150] Setting up relu5
I0811 16:02:20.081956 26953 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I0811 16:02:20.081960 26953 net.cpp:165] Memory required for data: 409004400
I0811 16:02:20.081965 26953 layer_factory.hpp:77] Creating layer pool5
I0811 16:02:20.081979 26953 net.cpp:100] Creating Layer pool5
I0811 16:02:20.081982 26953 net.cpp:434] pool5 <- conv5
I0811 16:02:20.081990 26953 net.cpp:408] pool5 -> pool5
I0811 16:02:20.082057 26953 net.cpp:150] Setting up pool5
I0811 16:02:20.082075 26953 net.cpp:157] Top shape: 50 256 6 6 (460800)
I0811 16:02:20.082079 26953 net.cpp:165] Memory required for data: 410847600
I0811 16:02:20.082083 26953 layer_factory.hpp:77] Creating layer fc6
I0811 16:02:20.082094 26953 net.cpp:100] Creating Layer fc6
I0811 16:02:20.082098 26953 net.cpp:434] fc6 <- pool5
I0811 16:02:20.082108 26953 net.cpp:408] fc6 -> fc6
I0811 16:02:21.149547 26953 net.cpp:150] Setting up fc6
I0811 16:02:21.149608 26953 net.cpp:157] Top shape: 50 4096 (204800)
I0811 16:02:21.149615 26953 net.cpp:165] Memory required for data: 411666800
I0811 16:02:21.149631 26953 layer_factory.hpp:77] Creating layer relu6
I0811 16:02:21.149657 26953 net.cpp:100] Creating Layer relu6
I0811 16:02:21.149667 26953 net.cpp:434] relu6 <- fc6
I0811 16:02:21.149675 26953 net.cpp:395] relu6 -> fc6 (in-place)
I0811 16:02:21.150477 26953 net.cpp:150] Setting up relu6
I0811 16:02:21.150506 26953 net.cpp:157] Top shape: 50 4096 (204800)
I0811 16:02:21.150511 26953 net.cpp:165] Memory required for data: 412486000
I0811 16:02:21.150516 26953 layer_factory.hpp:77] Creating layer drop6
I0811 16:02:21.150529 26953 net.cpp:100] Creating Layer drop6
I0811 16:02:21.150534 26953 net.cpp:434] drop6 <- fc6
I0811 16:02:21.150542 26953 net.cpp:395] drop6 -> fc6 (in-place)
I0811 16:02:21.150591 26953 net.cpp:150] Setting up drop6
I0811 16:02:21.150599 26953 net.cpp:157] Top shape: 50 4096 (204800)
I0811 16:02:21.150604 26953 net.cpp:165] Memory required for data: 413305200
I0811 16:02:21.150609 26953 layer_factory.hpp:77] Creating layer fc7
I0811 16:02:21.150621 26953 net.cpp:100] Creating Layer fc7
I0811 16:02:21.150626 26953 net.cpp:434] fc7 <- fc6
I0811 16:02:21.150635 26953 net.cpp:408] fc7 -> fc7
I0811 16:02:21.610841 26953 net.cpp:150] Setting up fc7
I0811 16:02:21.610903 26953 net.cpp:157] Top shape: 50 4096 (204800)
I0811 16:02:21.610908 26953 net.cpp:165] Memory required for data: 414124400
I0811 16:02:21.610930 26953 layer_factory.hpp:77] Creating layer relu7
I0811 16:02:21.610954 26953 net.cpp:100] Creating Layer relu7
I0811 16:02:21.610963 26953 net.cpp:434] relu7 <- fc7
I0811 16:02:21.610975 26953 net.cpp:395] relu7 -> fc7 (in-place)
I0811 16:02:21.611426 26953 net.cpp:150] Setting up relu7
I0811 16:02:21.611451 26953 net.cpp:157] Top shape: 50 4096 (204800)
I0811 16:02:21.611456 26953 net.cpp:165] Memory required for data: 414943600
I0811 16:02:21.611461 26953 layer_factory.hpp:77] Creating layer drop7
I0811 16:02:21.611472 26953 net.cpp:100] Creating Layer drop7
I0811 16:02:21.611479 26953 net.cpp:434] drop7 <- fc7
I0811 16:02:21.611486 26953 net.cpp:395] drop7 -> fc7 (in-place)
I0811 16:02:21.611536 26953 net.cpp:150] Setting up drop7
I0811 16:02:21.611543 26953 net.cpp:157] Top shape: 50 4096 (204800)
I0811 16:02:21.611547 26953 net.cpp:165] Memory required for data: 415762800
I0811 16:02:21.611552 26953 layer_factory.hpp:77] Creating layer fc8
I0811 16:02:21.611564 26953 net.cpp:100] Creating Layer fc8
I0811 16:02:21.611569 26953 net.cpp:434] fc8 <- fc7
I0811 16:02:21.611578 26953 net.cpp:408] fc8 -> fc8
I0811 16:02:21.726784 26953 net.cpp:150] Setting up fc8
I0811 16:02:21.726824 26953 net.cpp:157] Top shape: 50 1000 (50000)
I0811 16:02:21.726829 26953 net.cpp:165] Memory required for data: 415962800
I0811 16:02:21.726840 26953 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0811 16:02:21.726851 26953 net.cpp:100] Creating Layer fc8_fc8_0_split
I0811 16:02:21.726858 26953 net.cpp:434] fc8_fc8_0_split <- fc8
I0811 16:02:21.726866 26953 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0811 16:02:21.726877 26953 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0811 16:02:21.726929 26953 net.cpp:150] Setting up fc8_fc8_0_split
I0811 16:02:21.726938 26953 net.cpp:157] Top shape: 50 1000 (50000)
I0811 16:02:21.726943 26953 net.cpp:157] Top shape: 50 1000 (50000)
I0811 16:02:21.726946 26953 net.cpp:165] Memory required for data: 416362800
I0811 16:02:21.726951 26953 layer_factory.hpp:77] Creating layer accuracy
I0811 16:02:21.726985 26953 net.cpp:100] Creating Layer accuracy
I0811 16:02:21.727001 26953 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0811 16:02:21.727007 26953 net.cpp:434] accuracy <- label_data_1_split_0
I0811 16:02:21.727015 26953 net.cpp:408] accuracy -> accuracy
I0811 16:02:21.727025 26953 net.cpp:150] Setting up accuracy
I0811 16:02:21.727030 26953 net.cpp:157] Top shape: (1)
I0811 16:02:21.727033 26953 net.cpp:165] Memory required for data: 416362804
I0811 16:02:21.727038 26953 layer_factory.hpp:77] Creating layer loss
I0811 16:02:21.727046 26953 net.cpp:100] Creating Layer loss
I0811 16:02:21.727051 26953 net.cpp:434] loss <- fc8_fc8_0_split_1
I0811 16:02:21.727056 26953 net.cpp:434] loss <- label_data_1_split_1
I0811 16:02:21.727061 26953 net.cpp:408] loss -> loss
I0811 16:02:21.727072 26953 layer_factory.hpp:77] Creating layer loss
I0811 16:02:21.727741 26953 net.cpp:150] Setting up loss
I0811 16:02:21.727771 26953 net.cpp:157] Top shape: (1)
I0811 16:02:21.727776 26953 net.cpp:160]     with loss weight 1
I0811 16:02:21.727795 26953 net.cpp:165] Memory required for data: 416362808
I0811 16:02:21.727799 26953 net.cpp:226] loss needs backward computation.
I0811 16:02:21.727816 26953 net.cpp:228] accuracy does not need backward computation.
I0811 16:02:21.727821 26953 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0811 16:02:21.727825 26953 net.cpp:226] fc8 needs backward computation.
I0811 16:02:21.727830 26953 net.cpp:226] drop7 needs backward computation.
I0811 16:02:21.727834 26953 net.cpp:226] relu7 needs backward computation.
I0811 16:02:21.727838 26953 net.cpp:226] fc7 needs backward computation.
I0811 16:02:21.727843 26953 net.cpp:226] drop6 needs backward computation.
I0811 16:02:21.727846 26953 net.cpp:226] relu6 needs backward computation.
I0811 16:02:21.727850 26953 net.cpp:226] fc6 needs backward computation.
I0811 16:02:21.727855 26953 net.cpp:226] pool5 needs backward computation.
I0811 16:02:21.727859 26953 net.cpp:226] relu5 needs backward computation.
I0811 16:02:21.727866 26953 net.cpp:226] conv5 needs backward computation.
I0811 16:02:21.727870 26953 net.cpp:226] relu4 needs backward computation.
I0811 16:02:21.727875 26953 net.cpp:226] conv4 needs backward computation.
I0811 16:02:21.727880 26953 net.cpp:226] relu3 needs backward computation.
I0811 16:02:21.727885 26953 net.cpp:226] conv3 needs backward computation.
I0811 16:02:21.727890 26953 net.cpp:226] pool2 needs backward computation.
I0811 16:02:21.727895 26953 net.cpp:226] norm2 needs backward computation.
I0811 16:02:21.727900 26953 net.cpp:226] relu2 needs backward computation.
I0811 16:02:21.727905 26953 net.cpp:226] conv2 needs backward computation.
I0811 16:02:21.727910 26953 net.cpp:226] pool1 needs backward computation.
I0811 16:02:21.727915 26953 net.cpp:226] norm1 needs backward computation.
I0811 16:02:21.727919 26953 net.cpp:226] relu1 needs backward computation.
I0811 16:02:21.727923 26953 net.cpp:226] conv1 needs backward computation.
I0811 16:02:21.727928 26953 net.cpp:228] label_data_1_split does not need backward computation.
I0811 16:02:21.727933 26953 net.cpp:228] data does not need backward computation.
I0811 16:02:21.727938 26953 net.cpp:270] This network produces output accuracy
I0811 16:02:21.727942 26953 net.cpp:270] This network produces output loss
I0811 16:02:21.727962 26953 net.cpp:283] Network initialization done.
I0811 16:02:21.728123 26953 solver.cpp:60] Solver scaffolding done.
I0811 16:02:21.798951 26953 parallel.cpp:392] GPUs pairs 0:1
I0811 16:02:22.300287 26953 data_layer.cpp:41] output data size: 512,3,227,227
I0811 16:02:25.781343 26953 parallel.cpp:425] Starting Optimization
I0811 16:02:25.781440 26953 solver.cpp:279] Solving AlexNet
I0811 16:02:25.781450 26953 solver.cpp:280] Learning Rate Policy: step
I0811 16:02:25.781553 26953 solver.cpp:337] Iteration 0, Testing net (#0)
I0811 16:02:26.516196 26953 solver.cpp:404]     Test net output #0: accuracy = 0
I0811 16:02:26.516309 26953 solver.cpp:404]     Test net output #1: loss = 6.90858 (* 1 = 6.90858 loss)
I0811 16:02:28.670871 26953 solver.cpp:228] Iteration 0, loss = 6.91046
I0811 16:02:28.671022 26953 solver.cpp:244]     Train net output #0: loss = 6.91046 (* 1 = 6.91046 loss)
I0811 16:02:28.671139 26953 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0811 16:02:48.578862 26953 solver.cpp:228] Iteration 10, loss = 6.90705
I0811 16:02:48.578997 26953 solver.cpp:244]     Train net output #0: loss = 6.90705 (* 1 = 6.90705 loss)
I0811 16:02:50.011360 26953 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I0811 16:03:08.652765 26953 solver.cpp:228] Iteration 20, loss = 6.91065
I0811 16:03:08.652843 26953 solver.cpp:244]     Train net output #0: loss = 6.91065 (* 1 = 6.91065 loss)
I0811 16:03:10.079035 26953 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0811 16:03:28.725438 26953 solver.cpp:228] Iteration 30, loss = 6.90781
I0811 16:03:28.725698 26953 solver.cpp:244]     Train net output #0: loss = 6.90781 (* 1 = 6.90781 loss)
I0811 16:03:30.152228 26953 sgd_solver.cpp:106] Iteration 30, lr = 0.01
I0811 16:03:48.822998 26953 solver.cpp:228] Iteration 40, loss = 6.88951
I0811 16:03:48.823073 26953 solver.cpp:244]     Train net output #0: loss = 6.88951 (* 1 = 6.88951 loss)
I0811 16:03:50.255094 26953 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0811 16:04:08.859205 26953 solver.cpp:228] Iteration 50, loss = 6.8911
I0811 16:04:08.859449 26953 solver.cpp:244]     Train net output #0: loss = 6.8911 (* 1 = 6.8911 loss)
I0811 16:04:10.291363 26953 sgd_solver.cpp:106] Iteration 50, lr = 0.01
I0811 16:04:28.926524 26953 solver.cpp:228] Iteration 60, loss = 6.88808
I0811 16:04:28.926621 26953 solver.cpp:244]     Train net output #0: loss = 6.88808 (* 1 = 6.88808 loss)
I0811 16:04:30.366936 26953 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0811 16:04:48.988798 26953 solver.cpp:228] Iteration 70, loss = 6.88717
I0811 16:04:48.989058 26953 solver.cpp:244]     Train net output #0: loss = 6.88717 (* 1 = 6.88717 loss)
I0811 16:04:50.418928 26953 sgd_solver.cpp:106] Iteration 70, lr = 0.01
I0811 16:05:09.021348 26953 solver.cpp:228] Iteration 80, loss = 6.88819
I0811 16:05:09.021426 26953 solver.cpp:244]     Train net output #0: loss = 6.88819 (* 1 = 6.88819 loss)
I0811 16:05:10.443825 26953 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0811 16:05:29.100275 26953 solver.cpp:228] Iteration 90, loss = 6.88157
I0811 16:05:29.100462 26953 solver.cpp:244]     Train net output #0: loss = 6.88157 (* 1 = 6.88157 loss)
I0811 16:05:30.516222 26953 sgd_solver.cpp:106] Iteration 90, lr = 0.01
I0811 16:05:48.560159 26953 solver.cpp:337] Iteration 100, Testing net (#0)
I0811 16:05:49.160751 26953 solver.cpp:404]     Test net output #0: accuracy = 0.002
I0811 16:05:49.160836 26953 solver.cpp:404]     Test net output #1: loss = 6.92314 (* 1 = 6.92314 loss)
I0811 16:05:49.744707 26953 solver.cpp:228] Iteration 100, loss = 6.87237
I0811 16:05:49.744812 26953 solver.cpp:244]     Train net output #0: loss = 6.87237 (* 1 = 6.87237 loss)
I0811 16:05:51.151366 26953 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0811 16:06:09.822394 26953 solver.cpp:228] Iteration 110, loss = 6.87458
I0811 16:06:09.822656 26953 solver.cpp:244]     Train net output #0: loss = 6.87458 (* 1 = 6.87458 loss)
I0811 16:06:11.239775 26953 sgd_solver.cpp:106] Iteration 110, lr = 0.01
I0811 16:06:29.919718 26953 solver.cpp:228] Iteration 120, loss = 6.86907
I0811 16:06:29.919806 26953 solver.cpp:244]     Train net output #0: loss = 6.86907 (* 1 = 6.86907 loss)
I0811 16:06:31.343189 26953 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0811 16:06:49.989094 26953 solver.cpp:228] Iteration 130, loss = 6.86089
I0811 16:06:49.989374 26953 solver.cpp:244]     Train net output #0: loss = 6.86089 (* 1 = 6.86089 loss)
I0811 16:06:51.418367 26953 sgd_solver.cpp:106] Iteration 130, lr = 0.01
I0811 16:07:10.037345 26953 solver.cpp:228] Iteration 140, loss = 6.85176
I0811 16:07:10.037420 26953 solver.cpp:244]     Train net output #0: loss = 6.85176 (* 1 = 6.85176 loss)
I0811 16:07:11.460397 26953 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0811 16:07:30.124761 26953 solver.cpp:228] Iteration 150, loss = 6.84383
I0811 16:07:30.125010 26953 solver.cpp:244]     Train net output #0: loss = 6.84383 (* 1 = 6.84383 loss)
I0811 16:07:31.545819 26953 sgd_solver.cpp:106] Iteration 150, lr = 0.01
I0811 16:07:50.172726 26953 solver.cpp:228] Iteration 160, loss = 6.84298
I0811 16:07:50.172797 26953 solver.cpp:244]     Train net output #0: loss = 6.84298 (* 1 = 6.84298 loss)
I0811 16:07:51.595974 26953 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0811 16:08:10.258718 26953 solver.cpp:228] Iteration 170, loss = 6.78543
I0811 16:08:10.258971 26953 solver.cpp:244]     Train net output #0: loss = 6.78543 (* 1 = 6.78543 loss)
I0811 16:08:11.672355 26953 sgd_solver.cpp:106] Iteration 170, lr = 0.01
I0811 16:08:30.320221 26953 solver.cpp:228] Iteration 180, loss = 6.79187
I0811 16:08:30.320307 26953 solver.cpp:244]     Train net output #0: loss = 6.79187 (* 1 = 6.79187 loss)
I0811 16:08:31.744864 26953 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0811 16:08:50.342680 26953 solver.cpp:228] Iteration 190, loss = 6.73739
I0811 16:08:50.342860 26953 solver.cpp:244]     Train net output #0: loss = 6.73739 (* 1 = 6.73739 loss)
I0811 16:08:51.762374 26953 sgd_solver.cpp:106] Iteration 190, lr = 0.01
I0811 16:09:09.844595 26953 solver.cpp:337] Iteration 200, Testing net (#0)
I0811 16:09:10.453498 26953 solver.cpp:404]     Test net output #0: accuracy = 0.004
I0811 16:09:10.453622 26953 solver.cpp:404]     Test net output #1: loss = 6.74575 (* 1 = 6.74575 loss)
I0811 16:09:11.025439 26953 solver.cpp:228] Iteration 200, loss = 6.73368
I0811 16:09:11.025524 26953 solver.cpp:244]     Train net output #0: loss = 6.73368 (* 1 = 6.73368 loss)
I0811 16:09:12.434784 26953 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0811 16:09:31.136314 26953 solver.cpp:228] Iteration 210, loss = 6.77855
I0811 16:09:31.136523 26953 solver.cpp:244]     Train net output #0: loss = 6.77855 (* 1 = 6.77855 loss)
I0811 16:09:32.561096 26953 sgd_solver.cpp:106] Iteration 210, lr = 0.01
I0811 16:09:51.191429 26953 solver.cpp:228] Iteration 220, loss = 6.74329
I0811 16:09:51.191514 26953 solver.cpp:244]     Train net output #0: loss = 6.74329 (* 1 = 6.74329 loss)
I0811 16:09:52.621301 26953 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0811 16:10:11.255760 26953 solver.cpp:228] Iteration 230, loss = 6.70064
I0811 16:10:11.256016 26953 solver.cpp:244]     Train net output #0: loss = 6.70064 (* 1 = 6.70064 loss)
I0811 16:10:12.683585 26953 sgd_solver.cpp:106] Iteration 230, lr = 0.01
I0811 16:10:31.315064 26953 solver.cpp:228] Iteration 240, loss = 6.75739
I0811 16:10:31.315132 26953 solver.cpp:244]     Train net output #0: loss = 6.75739 (* 1 = 6.75739 loss)
I0811 16:10:32.745818 26953 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0811 16:10:51.373189 26953 solver.cpp:228] Iteration 250, loss = 6.6887
I0811 16:10:51.373466 26953 solver.cpp:244]     Train net output #0: loss = 6.6887 (* 1 = 6.6887 loss)
I0811 16:10:52.794800 26953 sgd_solver.cpp:106] Iteration 250, lr = 0.01
I0811 16:11:11.440093 26953 solver.cpp:228] Iteration 260, loss = 6.6583
I0811 16:11:11.440155 26953 solver.cpp:244]     Train net output #0: loss = 6.6583 (* 1 = 6.6583 loss)
I0811 16:11:12.865682 26953 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0811 16:11:31.496918 26953 solver.cpp:228] Iteration 270, loss = 6.59124
I0811 16:11:31.497131 26953 solver.cpp:244]     Train net output #0: loss = 6.59124 (* 1 = 6.59124 loss)
I0811 16:11:32.930093 26953 sgd_solver.cpp:106] Iteration 270, lr = 0.01
I0811 16:11:51.563665 26953 solver.cpp:228] Iteration 280, loss = 6.645
I0811 16:11:51.563743 26953 solver.cpp:244]     Train net output #0: loss = 6.645 (* 1 = 6.645 loss)
I0811 16:11:52.987797 26953 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0811 16:12:11.633643 26953 solver.cpp:228] Iteration 290, loss = 6.5722
I0811 16:12:11.633857 26953 solver.cpp:244]     Train net output #0: loss = 6.5722 (* 1 = 6.5722 loss)
I0811 16:12:13.055111 26953 sgd_solver.cpp:106] Iteration 290, lr = 0.01
I0811 16:12:31.099671 26953 solver.cpp:337] Iteration 300, Testing net (#0)
I0811 16:12:31.706758 26953 solver.cpp:404]     Test net output #0: accuracy = 0.014
I0811 16:12:31.706881 26953 solver.cpp:404]     Test net output #1: loss = 6.57591 (* 1 = 6.57591 loss)
I0811 16:12:32.300947 26953 solver.cpp:228] Iteration 300, loss = 6.50622
I0811 16:12:32.301036 26953 solver.cpp:244]     Train net output #0: loss = 6.50622 (* 1 = 6.50622 loss)
I0811 16:12:33.699152 26953 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0811 16:12:52.303443 26953 solver.cpp:228] Iteration 310, loss = 6.54613
I0811 16:12:52.303694 26953 solver.cpp:244]     Train net output #0: loss = 6.54613 (* 1 = 6.54613 loss)
I0811 16:12:53.724707 26953 sgd_solver.cpp:106] Iteration 310, lr = 0.01
I0811 16:13:12.302217 26953 solver.cpp:228] Iteration 320, loss = 6.53298
I0811 16:13:12.302279 26953 solver.cpp:244]     Train net output #0: loss = 6.53298 (* 1 = 6.53298 loss)
I0811 16:13:13.725270 26953 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0811 16:13:32.340052 26953 solver.cpp:228] Iteration 330, loss = 6.53331
I0811 16:13:32.340245 26953 solver.cpp:244]     Train net output #0: loss = 6.53331 (* 1 = 6.53331 loss)
I0811 16:13:33.772985 26953 sgd_solver.cpp:106] Iteration 330, lr = 0.01
I0811 16:13:52.416369 26953 solver.cpp:228] Iteration 340, loss = 6.43184
I0811 16:13:52.416429 26953 solver.cpp:244]     Train net output #0: loss = 6.43184 (* 1 = 6.43184 loss)
I0811 16:13:53.841593 26953 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0811 16:14:12.486711 26953 solver.cpp:228] Iteration 350, loss = 6.39348
I0811 16:14:12.486985 26953 solver.cpp:244]     Train net output #0: loss = 6.39348 (* 1 = 6.39348 loss)
I0811 16:14:13.901602 26953 sgd_solver.cpp:106] Iteration 350, lr = 0.01
I0811 16:14:32.547174 26953 solver.cpp:228] Iteration 360, loss = 6.44895
I0811 16:14:32.547236 26953 solver.cpp:244]     Train net output #0: loss = 6.44895 (* 1 = 6.44895 loss)
I0811 16:14:33.971230 26953 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0811 16:14:52.573271 26953 solver.cpp:228] Iteration 370, loss = 6.40185
I0811 16:14:52.573422 26953 solver.cpp:244]     Train net output #0: loss = 6.40185 (* 1 = 6.40185 loss)
I0811 16:14:53.997475 26953 sgd_solver.cpp:106] Iteration 370, lr = 0.01
I0811 16:15:12.632416 26953 solver.cpp:228] Iteration 380, loss = 6.52314
I0811 16:15:12.632485 26953 solver.cpp:244]     Train net output #0: loss = 6.52314 (* 1 = 6.52314 loss)
I0811 16:15:14.062767 26953 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0811 16:15:32.690410 26953 solver.cpp:228] Iteration 390, loss = 6.38116
I0811 16:15:32.690649 26953 solver.cpp:244]     Train net output #0: loss = 6.38116 (* 1 = 6.38116 loss)
I0811 16:15:34.124196 26953 sgd_solver.cpp:106] Iteration 390, lr = 0.01
I0811 16:15:52.111295 26953 solver.cpp:337] Iteration 400, Testing net (#0)
I0811 16:15:52.724969 26953 solver.cpp:404]     Test net output #0: accuracy = 0.008
I0811 16:15:52.725090 26953 solver.cpp:404]     Test net output #1: loss = 6.26607 (* 1 = 6.26607 loss)
I0811 16:15:53.293579 26953 solver.cpp:228] Iteration 400, loss = 6.37243
I0811 16:15:53.293670 26953 solver.cpp:244]     Train net output #0: loss = 6.37243 (* 1 = 6.37243 loss)
I0811 16:15:54.691215 26953 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0811 16:16:13.313899 26953 solver.cpp:228] Iteration 410, loss = 6.36365
I0811 16:16:13.314136 26953 solver.cpp:244]     Train net output #0: loss = 6.36365 (* 1 = 6.36365 loss)
I0811 16:16:14.736842 26953 sgd_solver.cpp:106] Iteration 410, lr = 0.01
I0811 16:16:33.358228 26953 solver.cpp:228] Iteration 420, loss = 6.33258
I0811 16:16:33.358288 26953 solver.cpp:244]     Train net output #0: loss = 6.33258 (* 1 = 6.33258 loss)
I0811 16:16:34.776335 26953 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0811 16:16:53.321485 26953 solver.cpp:228] Iteration 430, loss = 6.2544
I0811 16:16:53.321722 26953 solver.cpp:244]     Train net output #0: loss = 6.2544 (* 1 = 6.2544 loss)
I0811 16:16:54.730970 26953 sgd_solver.cpp:106] Iteration 430, lr = 0.01
I0811 16:17:13.327088 26953 solver.cpp:228] Iteration 440, loss = 6.24467
I0811 16:17:13.327164 26953 solver.cpp:244]     Train net output #0: loss = 6.24467 (* 1 = 6.24467 loss)
I0811 16:17:14.754595 26953 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0811 16:17:33.380581 26953 solver.cpp:228] Iteration 450, loss = 6.22124
I0811 16:17:33.380765 26953 solver.cpp:244]     Train net output #0: loss = 6.22124 (* 1 = 6.22124 loss)
I0811 16:17:34.808426 26953 sgd_solver.cpp:106] Iteration 450, lr = 0.01
I0811 16:17:53.393340 26953 solver.cpp:228] Iteration 460, loss = 6.17456
I0811 16:17:53.393404 26953 solver.cpp:244]     Train net output #0: loss = 6.17456 (* 1 = 6.17456 loss)
I0811 16:17:54.816443 26953 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0811 16:18:13.370020 26953 solver.cpp:228] Iteration 470, loss = 6.2395
I0811 16:18:13.370218 26953 solver.cpp:244]     Train net output #0: loss = 6.2395 (* 1 = 6.2395 loss)
I0811 16:18:14.786350 26953 sgd_solver.cpp:106] Iteration 470, lr = 0.01
I0811 16:18:33.389188 26953 solver.cpp:228] Iteration 480, loss = 6.18816
I0811 16:18:33.389256 26953 solver.cpp:244]     Train net output #0: loss = 6.18816 (* 1 = 6.18816 loss)
I0811 16:18:34.798573 26953 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0811 16:18:53.402175 26953 solver.cpp:228] Iteration 490, loss = 6.15334
I0811 16:18:53.402402 26953 solver.cpp:244]     Train net output #0: loss = 6.15334 (* 1 = 6.15334 loss)
I0811 16:18:54.821843 26953 sgd_solver.cpp:106] Iteration 490, lr = 0.01
I0811 16:19:12.889075 26953 solver.cpp:337] Iteration 500, Testing net (#0)
I0811 16:19:13.496526 26953 solver.cpp:404]     Test net output #0: accuracy = 0.02
I0811 16:19:13.496625 26953 solver.cpp:404]     Test net output #1: loss = 6.06972 (* 1 = 6.06972 loss)
I0811 16:19:14.076863 26953 solver.cpp:228] Iteration 500, loss = 6.07838
I0811 16:19:14.076946 26953 solver.cpp:244]     Train net output #0: loss = 6.07838 (* 1 = 6.07838 loss)
I0811 16:19:15.454712 26953 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0811 16:19:33.958715 26953 solver.cpp:228] Iteration 510, loss = 6.22967
I0811 16:19:33.958916 26953 solver.cpp:244]     Train net output #0: loss = 6.22967 (* 1 = 6.22967 loss)
I0811 16:19:35.374596 26953 sgd_solver.cpp:106] Iteration 510, lr = 0.01
I0811 16:19:53.930850 26953 solver.cpp:228] Iteration 520, loss = 6.11525
I0811 16:19:53.930923 26953 solver.cpp:244]     Train net output #0: loss = 6.11525 (* 1 = 6.11525 loss)
I0811 16:19:55.339889 26953 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0811 16:20:13.877724 26953 solver.cpp:228] Iteration 530, loss = 6.12306
I0811 16:20:13.877977 26953 solver.cpp:244]     Train net output #0: loss = 6.12306 (* 1 = 6.12306 loss)
I0811 16:20:15.300772 26953 sgd_solver.cpp:106] Iteration 530, lr = 0.01
I0811 16:20:33.829596 26953 solver.cpp:228] Iteration 540, loss = 6.09457
I0811 16:20:33.829668 26953 solver.cpp:244]     Train net output #0: loss = 6.09457 (* 1 = 6.09457 loss)
I0811 16:20:35.257019 26953 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0811 16:20:53.800153 26953 solver.cpp:228] Iteration 550, loss = 6.01661
I0811 16:20:53.800376 26953 solver.cpp:244]     Train net output #0: loss = 6.01661 (* 1 = 6.01661 loss)
I0811 16:20:55.218946 26953 sgd_solver.cpp:106] Iteration 550, lr = 0.01
I0811 16:21:13.783525 26953 solver.cpp:228] Iteration 560, loss = 6.08248
I0811 16:21:13.783597 26953 solver.cpp:244]     Train net output #0: loss = 6.08248 (* 1 = 6.08248 loss)
I0811 16:21:15.194413 26953 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0811 16:21:33.740027 26953 solver.cpp:228] Iteration 570, loss = 5.98016
I0811 16:21:33.740288 26953 solver.cpp:244]     Train net output #0: loss = 5.98016 (* 1 = 5.98016 loss)
I0811 16:21:35.142885 26953 sgd_solver.cpp:106] Iteration 570, lr = 0.01
I0811 16:21:53.695492 26953 solver.cpp:228] Iteration 580, loss = 5.98083
I0811 16:21:53.695570 26953 solver.cpp:244]     Train net output #0: loss = 5.98083 (* 1 = 5.98083 loss)
I0811 16:21:55.113852 26953 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0811 16:22:13.644263 26953 solver.cpp:228] Iteration 590, loss = 5.91702
I0811 16:22:13.644472 26953 solver.cpp:244]     Train net output #0: loss = 5.91702 (* 1 = 5.91702 loss)
I0811 16:22:15.066870 26953 sgd_solver.cpp:106] Iteration 590, lr = 0.01
I0811 16:22:33.031914 26953 solver.cpp:337] Iteration 600, Testing net (#0)
I0811 16:22:33.640486 26953 solver.cpp:404]     Test net output #0: accuracy = 0.046
I0811 16:22:33.640581 26953 solver.cpp:404]     Test net output #1: loss = 5.80301 (* 1 = 5.80301 loss)
I0811 16:22:34.219945 26953 solver.cpp:228] Iteration 600, loss = 6.02795
I0811 16:22:34.220033 26953 solver.cpp:244]     Train net output #0: loss = 6.02795 (* 1 = 6.02795 loss)
I0811 16:22:35.615931 26953 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0811 16:22:54.279623 26953 solver.cpp:228] Iteration 610, loss = 5.89168
I0811 16:22:54.279881 26953 solver.cpp:244]     Train net output #0: loss = 5.89168 (* 1 = 5.89168 loss)
I0811 16:22:55.699618 26953 sgd_solver.cpp:106] Iteration 610, lr = 0.01
I0811 16:23:14.264812 26953 solver.cpp:228] Iteration 620, loss = 5.83834
I0811 16:23:14.264881 26953 solver.cpp:244]     Train net output #0: loss = 5.83834 (* 1 = 5.83834 loss)
I0811 16:23:15.679347 26953 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0811 16:23:34.238018 26953 solver.cpp:228] Iteration 630, loss = 5.9079
I0811 16:23:34.238293 26953 solver.cpp:244]     Train net output #0: loss = 5.9079 (* 1 = 5.9079 loss)
I0811 16:23:35.650039 26953 sgd_solver.cpp:106] Iteration 630, lr = 0.01
I0811 16:23:54.178678 26953 solver.cpp:228] Iteration 640, loss = 5.88624
I0811 16:23:54.178740 26953 solver.cpp:244]     Train net output #0: loss = 5.88624 (* 1 = 5.88624 loss)
I0811 16:23:55.586227 26953 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0811 16:24:14.186429 26953 solver.cpp:228] Iteration 650, loss = 5.89057
I0811 16:24:14.186697 26953 solver.cpp:244]     Train net output #0: loss = 5.89057 (* 1 = 5.89057 loss)
I0811 16:24:15.609568 26953 sgd_solver.cpp:106] Iteration 650, lr = 0.01
I0811 16:24:34.218448 26953 solver.cpp:228] Iteration 660, loss = 5.80845
I0811 16:24:34.218511 26953 solver.cpp:244]     Train net output #0: loss = 5.80845 (* 1 = 5.80845 loss)
I0811 16:24:35.646755 26953 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0811 16:24:54.305027 26953 solver.cpp:228] Iteration 670, loss = 5.83258
I0811 16:24:54.305261 26953 solver.cpp:244]     Train net output #0: loss = 5.83258 (* 1 = 5.83258 loss)
I0811 16:24:55.738497 26953 sgd_solver.cpp:106] Iteration 670, lr = 0.01
I0811 16:25:14.299372 26953 solver.cpp:228] Iteration 680, loss = 5.77123
I0811 16:25:14.299446 26953 solver.cpp:244]     Train net output #0: loss = 5.77123 (* 1 = 5.77123 loss)
I0811 16:25:15.699811 26953 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0811 16:25:34.242841 26953 solver.cpp:228] Iteration 690, loss = 5.72436
I0811 16:25:34.242995 26953 solver.cpp:244]     Train net output #0: loss = 5.72436 (* 1 = 5.72436 loss)
I0811 16:25:35.657291 26953 sgd_solver.cpp:106] Iteration 690, lr = 0.01
I0811 16:25:53.616946 26953 solver.cpp:337] Iteration 700, Testing net (#0)
I0811 16:25:54.223332 26953 solver.cpp:404]     Test net output #0: accuracy = 0.028
I0811 16:25:54.223441 26953 solver.cpp:404]     Test net output #1: loss = 5.61714 (* 1 = 5.61714 loss)
I0811 16:25:54.819456 26953 solver.cpp:228] Iteration 700, loss = 5.73842
I0811 16:25:54.819530 26953 solver.cpp:244]     Train net output #0: loss = 5.73842 (* 1 = 5.73842 loss)
I0811 16:25:56.194340 26953 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0811 16:26:14.864035 26953 solver.cpp:228] Iteration 710, loss = 5.67809
I0811 16:26:14.864254 26953 solver.cpp:244]     Train net output #0: loss = 5.67809 (* 1 = 5.67809 loss)
I0811 16:26:16.289860 26953 sgd_solver.cpp:106] Iteration 710, lr = 0.01
I0811 16:26:34.881860 26953 solver.cpp:228] Iteration 720, loss = 5.77783
I0811 16:26:34.881922 26953 solver.cpp:244]     Train net output #0: loss = 5.77783 (* 1 = 5.77783 loss)
I0811 16:26:36.304015 26953 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0811 16:26:54.847520 26953 solver.cpp:228] Iteration 730, loss = 5.69572
I0811 16:26:54.847735 26953 solver.cpp:244]     Train net output #0: loss = 5.69572 (* 1 = 5.69572 loss)
I0811 16:26:56.264004 26953 sgd_solver.cpp:106] Iteration 730, lr = 0.01
I0811 16:27:14.797993 26953 solver.cpp:228] Iteration 740, loss = 5.68599
I0811 16:27:14.798063 26953 solver.cpp:244]     Train net output #0: loss = 5.68599 (* 1 = 5.68599 loss)
I0811 16:27:16.209771 26953 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0811 16:27:34.758667 26953 solver.cpp:228] Iteration 750, loss = 5.59368
I0811 16:27:34.758962 26953 solver.cpp:244]     Train net output #0: loss = 5.59368 (* 1 = 5.59368 loss)
I0811 16:27:36.166571 26953 sgd_solver.cpp:106] Iteration 750, lr = 0.01
I0811 16:27:54.703630 26953 solver.cpp:228] Iteration 760, loss = 5.72985
I0811 16:27:54.703712 26953 solver.cpp:244]     Train net output #0: loss = 5.72985 (* 1 = 5.72985 loss)
I0811 16:27:56.119822 26953 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0811 16:28:14.676667 26953 solver.cpp:228] Iteration 770, loss = 5.62192
I0811 16:28:14.676901 26953 solver.cpp:244]     Train net output #0: loss = 5.62192 (* 1 = 5.62192 loss)
I0811 16:28:16.101533 26953 sgd_solver.cpp:106] Iteration 770, lr = 0.01
I0811 16:28:34.636147 26953 solver.cpp:228] Iteration 780, loss = 5.82542
I0811 16:28:34.636217 26953 solver.cpp:244]     Train net output #0: loss = 5.82542 (* 1 = 5.82542 loss)
I0811 16:28:36.048569 26953 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0811 16:28:54.571523 26953 solver.cpp:228] Iteration 790, loss = 5.65029
I0811 16:28:54.571770 26953 solver.cpp:244]     Train net output #0: loss = 5.65029 (* 1 = 5.65029 loss)
I0811 16:28:55.987769 26953 sgd_solver.cpp:106] Iteration 790, lr = 0.01
I0811 16:29:13.946018 26953 solver.cpp:337] Iteration 800, Testing net (#0)
I0811 16:29:14.556602 26953 solver.cpp:404]     Test net output #0: accuracy = 0.064
I0811 16:29:14.556700 26953 solver.cpp:404]     Test net output #1: loss = 5.46005 (* 1 = 5.46005 loss)
I0811 16:29:15.130177 26953 solver.cpp:228] Iteration 800, loss = 5.59753
I0811 16:29:15.130239 26953 solver.cpp:244]     Train net output #0: loss = 5.59753 (* 1 = 5.59753 loss)
I0811 16:29:16.518368 26953 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0811 16:29:35.028172 26953 solver.cpp:228] Iteration 810, loss = 5.48258
I0811 16:29:35.028373 26953 solver.cpp:244]     Train net output #0: loss = 5.48258 (* 1 = 5.48258 loss)
I0811 16:29:36.444809 26953 sgd_solver.cpp:106] Iteration 810, lr = 0.01
I0811 16:29:54.966583 26953 solver.cpp:228] Iteration 820, loss = 5.54277
I0811 16:29:54.966640 26953 solver.cpp:244]     Train net output #0: loss = 5.54277 (* 1 = 5.54277 loss)
I0811 16:29:56.387249 26953 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0811 16:30:14.920454 26953 solver.cpp:228] Iteration 830, loss = 5.39536
I0811 16:30:14.920671 26953 solver.cpp:244]     Train net output #0: loss = 5.39536 (* 1 = 5.39536 loss)
I0811 16:30:16.343909 26953 sgd_solver.cpp:106] Iteration 830, lr = 0.01
I0811 16:30:34.906615 26953 solver.cpp:228] Iteration 840, loss = 5.51701
I0811 16:30:34.906687 26953 solver.cpp:244]     Train net output #0: loss = 5.51701 (* 1 = 5.51701 loss)
I0811 16:30:36.312829 26953 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0811 16:30:54.832703 26953 solver.cpp:228] Iteration 850, loss = 5.5009
I0811 16:30:54.832857 26953 solver.cpp:244]     Train net output #0: loss = 5.5009 (* 1 = 5.5009 loss)
I0811 16:30:56.248653 26953 sgd_solver.cpp:106] Iteration 850, lr = 0.01
I0811 16:31:14.803540 26953 solver.cpp:228] Iteration 860, loss = 5.52314
I0811 16:31:14.803617 26953 solver.cpp:244]     Train net output #0: loss = 5.52314 (* 1 = 5.52314 loss)
I0811 16:31:16.215224 26953 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0811 16:31:34.757866 26953 solver.cpp:228] Iteration 870, loss = 5.54286
I0811 16:31:34.758005 26953 solver.cpp:244]     Train net output #0: loss = 5.54286 (* 1 = 5.54286 loss)
I0811 16:31:36.189736 26953 sgd_solver.cpp:106] Iteration 870, lr = 0.01
I0811 16:31:54.715136 26953 solver.cpp:228] Iteration 880, loss = 5.35946
I0811 16:31:54.715206 26953 solver.cpp:244]     Train net output #0: loss = 5.35946 (* 1 = 5.35946 loss)
I0811 16:31:56.128233 26953 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0811 16:32:14.685987 26953 solver.cpp:228] Iteration 890, loss = 5.45736
I0811 16:32:14.686168 26953 solver.cpp:244]     Train net output #0: loss = 5.45736 (* 1 = 5.45736 loss)
I0811 16:32:16.117254 26953 sgd_solver.cpp:106] Iteration 890, lr = 0.01
I0811 16:32:34.072389 26953 solver.cpp:337] Iteration 900, Testing net (#0)
I0811 16:32:34.678504 26953 solver.cpp:404]     Test net output #0: accuracy = 0.074
I0811 16:32:34.678588 26953 solver.cpp:404]     Test net output #1: loss = 5.23999 (* 1 = 5.23999 loss)
I0811 16:32:35.261000 26953 solver.cpp:228] Iteration 900, loss = 5.40558
I0811 16:32:35.261101 26953 solver.cpp:244]     Train net output #0: loss = 5.40558 (* 1 = 5.40558 loss)
I0811 16:32:36.635804 26953 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0811 16:32:55.170150 26953 solver.cpp:228] Iteration 910, loss = 5.64014
I0811 16:32:55.170404 26953 solver.cpp:244]     Train net output #0: loss = 5.64014 (* 1 = 5.64014 loss)
I0811 16:32:56.569159 26953 sgd_solver.cpp:106] Iteration 910, lr = 0.01
I0811 16:33:15.084589 26953 solver.cpp:228] Iteration 920, loss = 5.48263
I0811 16:33:15.084658 26953 solver.cpp:244]     Train net output #0: loss = 5.48263 (* 1 = 5.48263 loss)
I0811 16:33:16.493276 26953 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0811 16:33:35.011935 26953 solver.cpp:228] Iteration 930, loss = 5.41011
I0811 16:33:35.012171 26953 solver.cpp:244]     Train net output #0: loss = 5.41011 (* 1 = 5.41011 loss)
I0811 16:33:36.423427 26953 sgd_solver.cpp:106] Iteration 930, lr = 0.01
I0811 16:33:54.982913 26953 solver.cpp:228] Iteration 940, loss = 5.36947
I0811 16:33:54.982971 26953 solver.cpp:244]     Train net output #0: loss = 5.36947 (* 1 = 5.36947 loss)
I0811 16:33:56.407194 26953 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0811 16:34:14.935099 26953 solver.cpp:228] Iteration 950, loss = 5.46875
I0811 16:34:14.935326 26953 solver.cpp:244]     Train net output #0: loss = 5.46875 (* 1 = 5.46875 loss)
I0811 16:34:16.362627 26953 sgd_solver.cpp:106] Iteration 950, lr = 0.01
I0811 16:34:34.900885 26953 solver.cpp:228] Iteration 960, loss = 5.30678
I0811 16:34:34.900946 26953 solver.cpp:244]     Train net output #0: loss = 5.30678 (* 1 = 5.30678 loss)
I0811 16:34:36.306516 26953 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0811 16:34:54.855482 26953 solver.cpp:228] Iteration 970, loss = 5.34375
I0811 16:34:54.855720 26953 solver.cpp:244]     Train net output #0: loss = 5.34375 (* 1 = 5.34375 loss)
I0811 16:34:56.274406 26953 sgd_solver.cpp:106] Iteration 970, lr = 0.01
I0811 16:35:14.831843 26953 solver.cpp:228] Iteration 980, loss = 5.27358
I0811 16:35:14.831913 26953 solver.cpp:244]     Train net output #0: loss = 5.27358 (* 1 = 5.27358 loss)
I0811 16:35:16.240309 26953 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0811 16:35:34.795419 26953 solver.cpp:228] Iteration 990, loss = 5.41802
I0811 16:35:34.795645 26953 solver.cpp:244]     Train net output #0: loss = 5.41802 (* 1 = 5.41802 loss)
I0811 16:35:36.219184 26953 sgd_solver.cpp:106] Iteration 990, lr = 0.01
I0811 16:35:54.155588 26953 solver.cpp:337] Iteration 1000, Testing net (#0)
I0811 16:35:54.758199 26953 solver.cpp:404]     Test net output #0: accuracy = 0.058
I0811 16:35:54.758311 26953 solver.cpp:404]     Test net output #1: loss = 5.15002 (* 1 = 5.15002 loss)
I0811 16:35:55.329918 26953 solver.cpp:228] Iteration 1000, loss = 5.15445
I0811 16:35:55.329993 26953 solver.cpp:244]     Train net output #0: loss = 5.15445 (* 1 = 5.15445 loss)
I0811 16:35:56.718619 26953 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0811 16:36:15.227624 26953 solver.cpp:228] Iteration 1010, loss = 5.21959
I0811 16:36:15.227849 26953 solver.cpp:244]     Train net output #0: loss = 5.21959 (* 1 = 5.21959 loss)
I0811 16:36:16.634383 26953 sgd_solver.cpp:106] Iteration 1010, lr = 0.01
I0811 16:36:35.177428 26953 solver.cpp:228] Iteration 1020, loss = 5.20874
I0811 16:36:35.177492 26953 solver.cpp:244]     Train net output #0: loss = 5.20874 (* 1 = 5.20874 loss)
I0811 16:36:36.597750 26953 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0811 16:36:55.130420 26953 solver.cpp:228] Iteration 1030, loss = 5.18149
I0811 16:36:55.130712 26953 solver.cpp:244]     Train net output #0: loss = 5.18149 (* 1 = 5.18149 loss)
I0811 16:36:56.546742 26953 sgd_solver.cpp:106] Iteration 1030, lr = 0.01
I0811 16:37:15.091987 26953 solver.cpp:228] Iteration 1040, loss = 5.3474
I0811 16:37:15.092047 26953 solver.cpp:244]     Train net output #0: loss = 5.3474 (* 1 = 5.3474 loss)
I0811 16:37:16.502060 26953 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0811 16:37:35.019050 26953 solver.cpp:228] Iteration 1050, loss = 5.38715
I0811 16:37:35.019372 26953 solver.cpp:244]     Train net output #0: loss = 5.38715 (* 1 = 5.38715 loss)
I0811 16:37:36.439647 26953 sgd_solver.cpp:106] Iteration 1050, lr = 0.01
I0811 16:37:55.026928 26953 solver.cpp:228] Iteration 1060, loss = 5.2794
I0811 16:37:55.027001 26953 solver.cpp:244]     Train net output #0: loss = 5.2794 (* 1 = 5.2794 loss)
I0811 16:37:56.446599 26953 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0811 16:38:14.955718 26953 solver.cpp:228] Iteration 1070, loss = 5.27775
I0811 16:38:14.955932 26953 solver.cpp:244]     Train net output #0: loss = 5.27775 (* 1 = 5.27775 loss)
I0811 16:38:16.363788 26953 sgd_solver.cpp:106] Iteration 1070, lr = 0.01
I0811 16:38:34.900568 26953 solver.cpp:228] Iteration 1080, loss = 5.21072
I0811 16:38:34.900629 26953 solver.cpp:244]     Train net output #0: loss = 5.21072 (* 1 = 5.21072 loss)
I0811 16:38:36.316299 26953 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0811 16:38:54.890388 26953 solver.cpp:228] Iteration 1090, loss = 5.06894
I0811 16:38:54.890628 26953 solver.cpp:244]     Train net output #0: loss = 5.06894 (* 1 = 5.06894 loss)
I0811 16:38:56.312748 26953 sgd_solver.cpp:106] Iteration 1090, lr = 0.01
I0811 16:39:14.267994 26953 solver.cpp:337] Iteration 1100, Testing net (#0)
I0811 16:39:14.874713 26953 solver.cpp:404]     Test net output #0: accuracy = 0.074
I0811 16:39:14.874827 26953 solver.cpp:404]     Test net output #1: loss = 4.90872 (* 1 = 4.90872 loss)
I0811 16:39:15.443830 26953 solver.cpp:228] Iteration 1100, loss = 5.19388
I0811 16:39:15.443907 26953 solver.cpp:244]     Train net output #0: loss = 5.19388 (* 1 = 5.19388 loss)
I0811 16:39:16.830443 26953 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0811 16:39:35.322013 26953 solver.cpp:228] Iteration 1110, loss = 5.00079
I0811 16:39:35.322281 26953 solver.cpp:244]     Train net output #0: loss = 5.00079 (* 1 = 5.00079 loss)
I0811 16:39:36.738631 26953 sgd_solver.cpp:106] Iteration 1110, lr = 0.01
I0811 16:39:55.257203 26953 solver.cpp:228] Iteration 1120, loss = 5.02286
I0811 16:39:55.257277 26953 solver.cpp:244]     Train net output #0: loss = 5.02286 (* 1 = 5.02286 loss)
I0811 16:39:56.688948 26953 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0811 16:40:15.227004 26953 solver.cpp:228] Iteration 1130, loss = 5.00074
I0811 16:40:15.227244 26953 solver.cpp:244]     Train net output #0: loss = 5.00074 (* 1 = 5.00074 loss)
I0811 16:40:16.634584 26953 sgd_solver.cpp:106] Iteration 1130, lr = 0.01
I0811 16:40:35.183521 26953 solver.cpp:228] Iteration 1140, loss = 4.94897
I0811 16:40:35.183584 26953 solver.cpp:244]     Train net output #0: loss = 4.94897 (* 1 = 4.94897 loss)
I0811 16:40:36.603337 26953 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0811 16:40:55.153877 26953 solver.cpp:228] Iteration 1150, loss = 5.19857
I0811 16:40:55.154093 26953 solver.cpp:244]     Train net output #0: loss = 5.19857 (* 1 = 5.19857 loss)
I0811 16:40:56.570607 26953 sgd_solver.cpp:106] Iteration 1150, lr = 0.01
I0811 16:41:15.110941 26953 solver.cpp:228] Iteration 1160, loss = 4.95963
I0811 16:41:15.111013 26953 solver.cpp:244]     Train net output #0: loss = 4.95963 (* 1 = 4.95963 loss)
I0811 16:41:16.533675 26953 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0811 16:41:35.045583 26953 solver.cpp:228] Iteration 1170, loss = 5.08492
I0811 16:41:35.045774 26953 solver.cpp:244]     Train net output #0: loss = 5.08492 (* 1 = 5.08492 loss)
I0811 16:41:36.473496 26953 sgd_solver.cpp:106] Iteration 1170, lr = 0.01
I0811 16:41:55.043809 26953 solver.cpp:228] Iteration 1180, loss = 5.07974
I0811 16:41:55.043892 26953 solver.cpp:244]     Train net output #0: loss = 5.07974 (* 1 = 5.07974 loss)
I0811 16:41:56.444738 26953 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0811 16:42:14.980253 26953 solver.cpp:228] Iteration 1190, loss = 5.06767
I0811 16:42:14.980515 26953 solver.cpp:244]     Train net output #0: loss = 5.06767 (* 1 = 5.06767 loss)
I0811 16:42:16.398398 26953 sgd_solver.cpp:106] Iteration 1190, lr = 0.01
I0811 16:42:34.349383 26953 solver.cpp:337] Iteration 1200, Testing net (#0)
I0811 16:42:34.952520 26953 solver.cpp:404]     Test net output #0: accuracy = 0.102
I0811 16:42:34.952625 26953 solver.cpp:404]     Test net output #1: loss = 4.85427 (* 1 = 4.85427 loss)
I0811 16:42:35.524889 26953 solver.cpp:228] Iteration 1200, loss = 4.89655
I0811 16:42:35.524974 26953 solver.cpp:244]     Train net output #0: loss = 4.89655 (* 1 = 4.89655 loss)
I0811 16:42:36.904355 26953 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0811 16:42:55.400665 26953 solver.cpp:228] Iteration 1210, loss = 5.25059
I0811 16:42:55.400894 26953 solver.cpp:244]     Train net output #0: loss = 5.25059 (* 1 = 5.25059 loss)
I0811 16:42:56.825547 26953 sgd_solver.cpp:106] Iteration 1210, lr = 0.01
I0811 16:43:15.341104 26953 solver.cpp:228] Iteration 1220, loss = 5.034
I0811 16:43:15.341182 26953 solver.cpp:244]     Train net output #0: loss = 5.034 (* 1 = 5.034 loss)
I0811 16:43:16.761759 26953 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0811 16:43:35.336419 26953 solver.cpp:228] Iteration 1230, loss = 5.0993
I0811 16:43:35.336616 26953 solver.cpp:244]     Train net output #0: loss = 5.0993 (* 1 = 5.0993 loss)
I0811 16:43:36.754024 26953 sgd_solver.cpp:106] Iteration 1230, lr = 0.01
I0811 16:43:55.302580 26953 solver.cpp:228] Iteration 1240, loss = 4.84676
I0811 16:43:55.302642 26953 solver.cpp:244]     Train net output #0: loss = 4.84676 (* 1 = 4.84676 loss)
I0811 16:43:56.708890 26953 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0811 16:44:15.252894 26953 solver.cpp:228] Iteration 1250, loss = 4.89567
I0811 16:44:15.253139 26953 solver.cpp:244]     Train net output #0: loss = 4.89567 (* 1 = 4.89567 loss)
I0811 16:44:16.656867 26953 sgd_solver.cpp:106] Iteration 1250, lr = 0.01
I0811 16:44:35.216732 26953 solver.cpp:228] Iteration 1260, loss = 4.89685
I0811 16:44:35.216810 26953 solver.cpp:244]     Train net output #0: loss = 4.89685 (* 1 = 4.89685 loss)
I0811 16:44:36.641688 26953 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0811 16:44:55.166976 26953 solver.cpp:228] Iteration 1270, loss = 4.92904
I0811 16:44:55.167212 26953 solver.cpp:244]     Train net output #0: loss = 4.92904 (* 1 = 4.92904 loss)
I0811 16:44:56.586935 26953 sgd_solver.cpp:106] Iteration 1270, lr = 0.01
I0811 16:45:15.120448 26953 solver.cpp:228] Iteration 1280, loss = 4.95138
I0811 16:45:15.120509 26953 solver.cpp:244]     Train net output #0: loss = 4.95138 (* 1 = 4.95138 loss)
I0811 16:45:16.559463 26953 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0811 16:45:35.087608 26953 solver.cpp:228] Iteration 1290, loss = 5.05674
I0811 16:45:35.087842 26953 solver.cpp:244]     Train net output #0: loss = 5.05674 (* 1 = 5.05674 loss)
I0811 16:45:36.511781 26953 sgd_solver.cpp:106] Iteration 1290, lr = 0.01
I0811 16:45:54.455124 26953 solver.cpp:337] Iteration 1300, Testing net (#0)
I0811 16:45:55.062448 26953 solver.cpp:404]     Test net output #0: accuracy = 0.096
I0811 16:45:55.062577 26953 solver.cpp:404]     Test net output #1: loss = 4.90897 (* 1 = 4.90897 loss)
I0811 16:45:55.627076 26953 solver.cpp:228] Iteration 1300, loss = 5.05356
I0811 16:45:55.627151 26953 solver.cpp:244]     Train net output #0: loss = 5.05356 (* 1 = 5.05356 loss)
I0811 16:45:57.000541 26953 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0811 16:46:15.499114 26953 solver.cpp:228] Iteration 1310, loss = 5.01609
I0811 16:46:15.499364 26953 solver.cpp:244]     Train net output #0: loss = 5.01609 (* 1 = 5.01609 loss)
I0811 16:46:16.913703 26953 sgd_solver.cpp:106] Iteration 1310, lr = 0.01
I0811 16:46:35.447036 26953 solver.cpp:228] Iteration 1320, loss = 4.78503
I0811 16:46:35.447090 26953 solver.cpp:244]     Train net output #0: loss = 4.78503 (* 1 = 4.78503 loss)
I0811 16:46:36.866106 26953 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0811 16:46:55.435413 26953 solver.cpp:228] Iteration 1330, loss = 4.73562
I0811 16:46:55.435696 26953 solver.cpp:244]     Train net output #0: loss = 4.73562 (* 1 = 4.73562 loss)
I0811 16:46:56.855469 26953 sgd_solver.cpp:106] Iteration 1330, lr = 0.01
I0811 16:47:15.372416 26953 solver.cpp:228] Iteration 1340, loss = 4.76532
I0811 16:47:15.372476 26953 solver.cpp:244]     Train net output #0: loss = 4.76532 (* 1 = 4.76532 loss)
I0811 16:47:16.794173 26953 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0811 16:47:35.353766 26953 solver.cpp:228] Iteration 1350, loss = 4.84198
I0811 16:47:35.353996 26953 solver.cpp:244]     Train net output #0: loss = 4.84198 (* 1 = 4.84198 loss)
I0811 16:47:36.757774 26953 sgd_solver.cpp:106] Iteration 1350, lr = 0.01
I0811 16:47:55.306247 26953 solver.cpp:228] Iteration 1360, loss = 4.94255
I0811 16:47:55.306313 26953 solver.cpp:244]     Train net output #0: loss = 4.94255 (* 1 = 4.94255 loss)
I0811 16:47:56.718631 26953 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0811 16:48:15.251871 26953 solver.cpp:228] Iteration 1370, loss = 4.84261
I0811 16:48:15.252065 26953 solver.cpp:244]     Train net output #0: loss = 4.84261 (* 1 = 4.84261 loss)
I0811 16:48:16.662606 26953 sgd_solver.cpp:106] Iteration 1370, lr = 0.01
I0811 16:48:35.216879 26953 solver.cpp:228] Iteration 1380, loss = 4.8865
I0811 16:48:35.216938 26953 solver.cpp:244]     Train net output #0: loss = 4.8865 (* 1 = 4.8865 loss)
I0811 16:48:36.637778 26953 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0811 16:48:38.649147 26953 solver.cpp:454] Snapshotting to binary proto file caffe_alexnet_train_iter_1382.caffemodel
I0811 16:48:54.906273 26953 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe_alexnet_train_iter_1382.solverstate
I0811 16:49:13.357969 26953 solver.cpp:228] Iteration 1390, loss = 4.72858
I0811 16:49:13.358036 26953 solver.cpp:244]     Train net output #0: loss = 4.72858 (* 1 = 4.72858 loss)
I0811 16:49:14.776196 26953 sgd_solver.cpp:106] Iteration 1390, lr = 0.01
I0811 16:49:32.762905 26953 solver.cpp:337] Iteration 1400, Testing net (#0)
I0811 16:49:33.377310 26953 solver.cpp:404]     Test net output #0: accuracy = 0.136
I0811 16:49:33.377429 26953 solver.cpp:404]     Test net output #1: loss = 4.59403 (* 1 = 4.59403 loss)
I0811 16:49:33.957002 26953 solver.cpp:228] Iteration 1400, loss = 4.72566
I0811 16:49:33.957063 26953 solver.cpp:244]     Train net output #0: loss = 4.72566 (* 1 = 4.72566 loss)
I0811 16:49:35.329634 26953 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0811 16:49:53.832607 26953 solver.cpp:228] Iteration 1410, loss = 4.73063
I0811 16:49:53.832664 26953 solver.cpp:244]     Train net output #0: loss = 4.73063 (* 1 = 4.73063 loss)
I0811 16:49:55.250934 26953 sgd_solver.cpp:106] Iteration 1410, lr = 0.01
I0811 16:50:13.767696 26953 solver.cpp:228] Iteration 1420, loss = 4.64396
I0811 16:50:13.767918 26953 solver.cpp:244]     Train net output #0: loss = 4.64396 (* 1 = 4.64396 loss)
I0811 16:50:15.185333 26953 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0811 16:50:33.734792 26953 solver.cpp:228] Iteration 1430, loss = 4.72267
I0811 16:50:33.734850 26953 solver.cpp:244]     Train net output #0: loss = 4.72267 (* 1 = 4.72267 loss)
I0811 16:50:35.147537 26953 sgd_solver.cpp:106] Iteration 1430, lr = 0.01
I0811 16:50:53.676107 26953 solver.cpp:228] Iteration 1440, loss = 4.67608
I0811 16:50:53.676355 26953 solver.cpp:244]     Train net output #0: loss = 4.67608 (* 1 = 4.67608 loss)
I0811 16:50:55.090781 26953 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0811 16:51:13.669505 26953 solver.cpp:228] Iteration 1450, loss = 4.7007
I0811 16:51:13.669561 26953 solver.cpp:244]     Train net output #0: loss = 4.7007 (* 1 = 4.7007 loss)
I0811 16:51:15.091445 26953 sgd_solver.cpp:106] Iteration 1450, lr = 0.01
I0811 16:51:33.628020 26953 solver.cpp:228] Iteration 1460, loss = 4.84744
I0811 16:51:33.628265 26953 solver.cpp:244]     Train net output #0: loss = 4.84744 (* 1 = 4.84744 loss)
I0811 16:51:35.053352 26953 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0811 16:51:53.587512 26953 solver.cpp:228] Iteration 1470, loss = 4.82091
I0811 16:51:53.587579 26953 solver.cpp:244]     Train net output #0: loss = 4.82091 (* 1 = 4.82091 loss)
I0811 16:51:54.985074 26953 sgd_solver.cpp:106] Iteration 1470, lr = 0.01
I0811 16:52:13.545732 26953 solver.cpp:228] Iteration 1480, loss = 4.60737
I0811 16:52:13.545975 26953 solver.cpp:244]     Train net output #0: loss = 4.60737 (* 1 = 4.60737 loss)
I0811 16:52:14.971220 26953 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0811 16:52:33.504575 26953 solver.cpp:228] Iteration 1490, loss = 4.68471
I0811 16:52:33.504636 26953 solver.cpp:244]     Train net output #0: loss = 4.68471 (* 1 = 4.68471 loss)
I0811 16:52:34.921478 26953 sgd_solver.cpp:106] Iteration 1490, lr = 0.01
I0811 16:52:52.905472 26953 solver.cpp:337] Iteration 1500, Testing net (#0)
I0811 16:52:53.515094 26953 solver.cpp:404]     Test net output #0: accuracy = 0.128
I0811 16:52:53.515261 26953 solver.cpp:404]     Test net output #1: loss = 4.58209 (* 1 = 4.58209 loss)
I0811 16:52:54.090780 26953 solver.cpp:228] Iteration 1500, loss = 4.70988
I0811 16:52:54.090864 26953 solver.cpp:244]     Train net output #0: loss = 4.70988 (* 1 = 4.70988 loss)
I0811 16:52:55.486507 26953 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0811 16:53:13.937099 26953 solver.cpp:228] Iteration 1510, loss = 5.24812
I0811 16:53:13.937156 26953 solver.cpp:244]     Train net output #0: loss = 5.24812 (* 1 = 5.24812 loss)
I0811 16:53:15.351080 26953 sgd_solver.cpp:106] Iteration 1510, lr = 0.01
I0811 16:53:33.872392 26953 solver.cpp:228] Iteration 1520, loss = 4.79886
I0811 16:53:33.872625 26953 solver.cpp:244]     Train net output #0: loss = 4.79886 (* 1 = 4.79886 loss)
I0811 16:53:35.278754 26953 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0811 16:53:53.819278 26953 solver.cpp:228] Iteration 1530, loss = 4.82365
I0811 16:53:53.819342 26953 solver.cpp:244]     Train net output #0: loss = 4.82365 (* 1 = 4.82365 loss)
I0811 16:53:55.237126 26953 sgd_solver.cpp:106] Iteration 1530, lr = 0.01
I0811 16:54:13.751739 26953 solver.cpp:228] Iteration 1540, loss = 4.55349
I0811 16:54:13.751981 26953 solver.cpp:244]     Train net output #0: loss = 4.55349 (* 1 = 4.55349 loss)
I0811 16:54:15.181077 26953 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0811 16:54:33.761101 26953 solver.cpp:228] Iteration 1550, loss = 4.53263
I0811 16:54:33.761178 26953 solver.cpp:244]     Train net output #0: loss = 4.53263 (* 1 = 4.53263 loss)
I0811 16:54:35.191547 26953 sgd_solver.cpp:106] Iteration 1550, lr = 0.01
I0811 16:54:53.701763 26953 solver.cpp:228] Iteration 1560, loss = 4.66111
I0811 16:54:53.702116 26953 solver.cpp:244]     Train net output #0: loss = 4.66111 (* 1 = 4.66111 loss)
I0811 16:54:55.143466 26953 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0811 16:55:13.705163 26953 solver.cpp:228] Iteration 1570, loss = 4.66253
I0811 16:55:13.705235 26953 solver.cpp:244]     Train net output #0: loss = 4.66253 (* 1 = 4.66253 loss)
I0811 16:55:15.117506 26953 sgd_solver.cpp:106] Iteration 1570, lr = 0.01
I0811 16:55:33.637806 26953 solver.cpp:228] Iteration 1580, loss = 4.61112
I0811 16:55:33.638037 26953 solver.cpp:244]     Train net output #0: loss = 4.61112 (* 1 = 4.61112 loss)
I0811 16:55:35.054307 26953 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0811 16:55:53.607744 26953 solver.cpp:228] Iteration 1590, loss = 4.61096
I0811 16:55:53.607808 26953 solver.cpp:244]     Train net output #0: loss = 4.61096 (* 1 = 4.61096 loss)
I0811 16:55:55.020514 26953 sgd_solver.cpp:106] Iteration 1590, lr = 0.01
I0811 16:56:12.993207 26953 solver.cpp:337] Iteration 1600, Testing net (#0)
I0811 16:56:13.595180 26953 solver.cpp:404]     Test net output #0: accuracy = 0.138
I0811 16:56:13.595253 26953 solver.cpp:404]     Test net output #1: loss = 4.41807 (* 1 = 4.41807 loss)
I0811 16:56:14.171691 26953 solver.cpp:228] Iteration 1600, loss = 4.68875
I0811 16:56:14.171751 26953 solver.cpp:244]     Train net output #0: loss = 4.68875 (* 1 = 4.68875 loss)
I0811 16:56:15.560860 26953 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0811 16:56:34.032415 26953 solver.cpp:228] Iteration 1610, loss = 4.7124
I0811 16:56:34.032474 26953 solver.cpp:244]     Train net output #0: loss = 4.7124 (* 1 = 4.7124 loss)
I0811 16:56:35.438168 26953 sgd_solver.cpp:106] Iteration 1610, lr = 0.01
I0811 16:56:54.005534 26953 solver.cpp:228] Iteration 1620, loss = 4.63068
I0811 16:56:54.005744 26953 solver.cpp:244]     Train net output #0: loss = 4.63068 (* 1 = 4.63068 loss)
I0811 16:56:55.424862 26953 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0811 16:57:13.952792 26953 solver.cpp:228] Iteration 1630, loss = 4.8082
I0811 16:57:13.952862 26953 solver.cpp:244]     Train net output #0: loss = 4.8082 (* 1 = 4.8082 loss)
I0811 16:57:15.354426 26953 sgd_solver.cpp:106] Iteration 1630, lr = 0.01
I0811 16:57:33.920706 26953 solver.cpp:228] Iteration 1640, loss = 4.49057
I0811 16:57:33.920920 26953 solver.cpp:244]     Train net output #0: loss = 4.49057 (* 1 = 4.49057 loss)
I0811 16:57:35.327220 26953 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0811 16:57:53.884179 26953 solver.cpp:228] Iteration 1650, loss = 4.62834
I0811 16:57:53.884238 26953 solver.cpp:244]     Train net output #0: loss = 4.62834 (* 1 = 4.62834 loss)
I0811 16:57:55.297402 26953 sgd_solver.cpp:106] Iteration 1650, lr = 0.01
I0811 16:58:13.811806 26953 solver.cpp:228] Iteration 1660, loss = 4.52635
I0811 16:58:13.812027 26953 solver.cpp:244]     Train net output #0: loss = 4.52635 (* 1 = 4.52635 loss)
I0811 16:58:15.231673 26953 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0811 16:58:33.804956 26953 solver.cpp:228] Iteration 1670, loss = 4.4017
I0811 16:58:33.805044 26953 solver.cpp:244]     Train net output #0: loss = 4.4017 (* 1 = 4.4017 loss)
I0811 16:58:35.219993 26953 sgd_solver.cpp:106] Iteration 1670, lr = 0.01
I0811 16:58:53.744455 26953 solver.cpp:228] Iteration 1680, loss = 4.36282
I0811 16:58:53.744678 26953 solver.cpp:244]     Train net output #0: loss = 4.36282 (* 1 = 4.36282 loss)
I0811 16:58:55.164559 26953 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0811 16:59:13.732482 26953 solver.cpp:228] Iteration 1690, loss = 4.351
I0811 16:59:13.732540 26953 solver.cpp:244]     Train net output #0: loss = 4.351 (* 1 = 4.351 loss)
I0811 16:59:15.143878 26953 sgd_solver.cpp:106] Iteration 1690, lr = 0.01
I0811 16:59:33.087635 26953 solver.cpp:337] Iteration 1700, Testing net (#0)
I0811 16:59:33.687679 26953 solver.cpp:404]     Test net output #0: accuracy = 0.184
I0811 16:59:33.687754 26953 solver.cpp:404]     Test net output #1: loss = 4.374 (* 1 = 4.374 loss)
I0811 16:59:34.259723 26953 solver.cpp:228] Iteration 1700, loss = 4.46731
I0811 16:59:34.259784 26953 solver.cpp:244]     Train net output #0: loss = 4.46731 (* 1 = 4.46731 loss)
I0811 16:59:35.659565 26953 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0811 16:59:54.129084 26953 solver.cpp:228] Iteration 1710, loss = 4.47384
I0811 16:59:54.129150 26953 solver.cpp:244]     Train net output #0: loss = 4.47384 (* 1 = 4.47384 loss)
I0811 16:59:55.548458 26953 sgd_solver.cpp:106] Iteration 1710, lr = 0.01
I0811 17:00:14.085204 26953 solver.cpp:228] Iteration 1720, loss = 4.56223
I0811 17:00:14.085396 26953 solver.cpp:244]     Train net output #0: loss = 4.56223 (* 1 = 4.56223 loss)
I0811 17:00:15.505820 26953 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0811 17:00:34.026901 26953 solver.cpp:228] Iteration 1730, loss = 4.54447
I0811 17:00:34.026968 26953 solver.cpp:244]     Train net output #0: loss = 4.54447 (* 1 = 4.54447 loss)
I0811 17:00:35.453282 26953 sgd_solver.cpp:106] Iteration 1730, lr = 0.01
I0811 17:00:53.996716 26953 solver.cpp:228] Iteration 1740, loss = 4.50582
I0811 17:00:53.996897 26953 solver.cpp:244]     Train net output #0: loss = 4.50582 (* 1 = 4.50582 loss)
I0811 17:00:55.410226 26953 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0811 17:01:13.961808 26953 solver.cpp:228] Iteration 1750, loss = 4.40589
I0811 17:01:13.961866 26953 solver.cpp:244]     Train net output #0: loss = 4.40589 (* 1 = 4.40589 loss)
I0811 17:01:15.378365 26953 sgd_solver.cpp:106] Iteration 1750, lr = 0.01
I0811 17:01:33.906584 26953 solver.cpp:228] Iteration 1760, loss = 4.42938
I0811 17:01:33.906860 26953 solver.cpp:244]     Train net output #0: loss = 4.42938 (* 1 = 4.42938 loss)
I0811 17:01:35.319535 26953 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0811 17:01:53.875051 26953 solver.cpp:228] Iteration 1770, loss = 4.39509
I0811 17:01:53.875107 26953 solver.cpp:244]     Train net output #0: loss = 4.39509 (* 1 = 4.39509 loss)
I0811 17:01:55.290904 26953 sgd_solver.cpp:106] Iteration 1770, lr = 0.01
I0811 17:02:13.816663 26953 solver.cpp:228] Iteration 1780, loss = 4.26193
I0811 17:02:13.816887 26953 solver.cpp:244]     Train net output #0: loss = 4.26193 (* 1 = 4.26193 loss)
I0811 17:02:15.234513 26953 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0811 17:02:33.806362 26953 solver.cpp:228] Iteration 1790, loss = 4.65976
I0811 17:02:33.806422 26953 solver.cpp:244]     Train net output #0: loss = 4.65976 (* 1 = 4.65976 loss)
I0811 17:02:35.232734 26953 sgd_solver.cpp:106] Iteration 1790, lr = 0.01
I0811 17:02:53.185575 26953 solver.cpp:337] Iteration 1800, Testing net (#0)
I0811 17:02:53.787801 26953 solver.cpp:404]     Test net output #0: accuracy = 0.15
I0811 17:02:53.787901 26953 solver.cpp:404]     Test net output #1: loss = 4.39429 (* 1 = 4.39429 loss)
I0811 17:02:54.359417 26953 solver.cpp:228] Iteration 1800, loss = 4.40301
I0811 17:02:54.359513 26953 solver.cpp:244]     Train net output #0: loss = 4.40301 (* 1 = 4.40301 loss)
I0811 17:02:55.756188 26953 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0811 17:03:14.236327 26953 solver.cpp:228] Iteration 1810, loss = 4.43074
I0811 17:03:14.236392 26953 solver.cpp:244]     Train net output #0: loss = 4.43074 (* 1 = 4.43074 loss)
I0811 17:03:15.636772 26953 sgd_solver.cpp:106] Iteration 1810, lr = 0.01
I0811 17:03:34.190690 26953 solver.cpp:228] Iteration 1820, loss = 4.40144
I0811 17:03:34.190871 26953 solver.cpp:244]     Train net output #0: loss = 4.40144 (* 1 = 4.40144 loss)
I0811 17:03:35.604497 26953 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0811 17:03:54.117699 26953 solver.cpp:228] Iteration 1830, loss = 4.54216
I0811 17:03:54.117763 26953 solver.cpp:244]     Train net output #0: loss = 4.54216 (* 1 = 4.54216 loss)
I0811 17:03:55.533815 26953 sgd_solver.cpp:106] Iteration 1830, lr = 0.01
I0811 17:04:14.126664 26953 solver.cpp:228] Iteration 1840, loss = 4.39637
I0811 17:04:14.126860 26953 solver.cpp:244]     Train net output #0: loss = 4.39637 (* 1 = 4.39637 loss)
I0811 17:04:15.553021 26953 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0811 17:04:34.061553 26953 solver.cpp:228] Iteration 1850, loss = 4.1148
I0811 17:04:34.061616 26953 solver.cpp:244]     Train net output #0: loss = 4.1148 (* 1 = 4.1148 loss)
I0811 17:04:35.494313 26953 sgd_solver.cpp:106] Iteration 1850, lr = 0.01
I0811 17:04:54.036690 26953 solver.cpp:228] Iteration 1860, loss = 4.35021
I0811 17:04:54.036926 26953 solver.cpp:244]     Train net output #0: loss = 4.35021 (* 1 = 4.35021 loss)
I0811 17:04:55.438179 26953 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0811 17:05:13.994696 26953 solver.cpp:228] Iteration 1870, loss = 4.16273
I0811 17:05:13.994773 26953 solver.cpp:244]     Train net output #0: loss = 4.16273 (* 1 = 4.16273 loss)
I0811 17:05:15.417498 26953 sgd_solver.cpp:106] Iteration 1870, lr = 0.01
I0811 17:05:33.941226 26953 solver.cpp:228] Iteration 1880, loss = 4.27498
I0811 17:05:33.941474 26953 solver.cpp:244]     Train net output #0: loss = 4.27498 (* 1 = 4.27498 loss)
I0811 17:05:35.350270 26953 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0811 17:05:53.902323 26953 solver.cpp:228] Iteration 1890, loss = 4.34071
I0811 17:05:53.902386 26953 solver.cpp:244]     Train net output #0: loss = 4.34071 (* 1 = 4.34071 loss)
I0811 17:05:55.319902 26953 sgd_solver.cpp:106] Iteration 1890, lr = 0.01
I0811 17:06:13.283437 26953 solver.cpp:337] Iteration 1900, Testing net (#0)
I0811 17:06:13.887393 26953 solver.cpp:404]     Test net output #0: accuracy = 0.182
I0811 17:06:13.887465 26953 solver.cpp:404]     Test net output #1: loss = 4.19455 (* 1 = 4.19455 loss)
I0811 17:06:14.468832 26953 solver.cpp:228] Iteration 1900, loss = 4.41956
I0811 17:06:14.468907 26953 solver.cpp:244]     Train net output #0: loss = 4.41956 (* 1 = 4.41956 loss)
I0811 17:06:15.847417 26953 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0811 17:06:34.352682 26953 solver.cpp:228] Iteration 1910, loss = 4.5204
I0811 17:06:34.352752 26953 solver.cpp:244]     Train net output #0: loss = 4.5204 (* 1 = 4.5204 loss)
I0811 17:06:35.756742 26953 sgd_solver.cpp:106] Iteration 1910, lr = 0.01
I0811 17:06:54.296466 26953 solver.cpp:228] Iteration 1920, loss = 4.15037
I0811 17:06:54.296674 26953 solver.cpp:244]     Train net output #0: loss = 4.15037 (* 1 = 4.15037 loss)
I0811 17:06:55.716611 26953 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0811 17:07:14.259359 26953 solver.cpp:228] Iteration 1930, loss = 4.14095
I0811 17:07:14.259428 26953 solver.cpp:244]     Train net output #0: loss = 4.14095 (* 1 = 4.14095 loss)
I0811 17:07:15.674274 26953 sgd_solver.cpp:106] Iteration 1930, lr = 0.01
I0811 17:07:34.209687 26953 solver.cpp:228] Iteration 1940, loss = 4.42359
I0811 17:07:34.209920 26953 solver.cpp:244]     Train net output #0: loss = 4.42359 (* 1 = 4.42359 loss)
I0811 17:07:35.630781 26953 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0811 17:07:54.171267 26953 solver.cpp:228] Iteration 1950, loss = 4.23358
I0811 17:07:54.171355 26953 solver.cpp:244]     Train net output #0: loss = 4.23358 (* 1 = 4.23358 loss)
I0811 17:07:55.582674 26953 sgd_solver.cpp:106] Iteration 1950, lr = 0.01
I0811 17:08:14.142616 26953 solver.cpp:228] Iteration 1960, loss = 4.38205
I0811 17:08:14.142864 26953 solver.cpp:244]     Train net output #0: loss = 4.38205 (* 1 = 4.38205 loss)
I0811 17:08:15.570793 26953 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0811 17:08:34.111574 26953 solver.cpp:228] Iteration 1970, loss = 4.29701
I0811 17:08:34.111644 26953 solver.cpp:244]     Train net output #0: loss = 4.29701 (* 1 = 4.29701 loss)
I0811 17:08:35.515393 26953 sgd_solver.cpp:106] Iteration 1970, lr = 0.01
I0811 17:08:54.086920 26953 solver.cpp:228] Iteration 1980, loss = 4.25584
I0811 17:08:54.087149 26953 solver.cpp:244]     Train net output #0: loss = 4.25584 (* 1 = 4.25584 loss)
I0811 17:08:55.489714 26953 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0811 17:09:14.019875 26953 solver.cpp:228] Iteration 1990, loss = 4.37012
I0811 17:09:14.019950 26953 solver.cpp:244]     Train net output #0: loss = 4.37012 (* 1 = 4.37012 loss)
I0811 17:09:15.433408 26953 sgd_solver.cpp:106] Iteration 1990, lr = 0.01
I0811 17:09:33.406582 26953 solver.cpp:337] Iteration 2000, Testing net (#0)
I0811 17:09:34.006017 26953 solver.cpp:404]     Test net output #0: accuracy = 0.194
I0811 17:09:34.006094 26953 solver.cpp:404]     Test net output #1: loss = 4.05798 (* 1 = 4.05798 loss)
I0811 17:09:34.570235 26953 solver.cpp:228] Iteration 2000, loss = 4.31071
I0811 17:09:34.570330 26953 solver.cpp:244]     Train net output #0: loss = 4.31071 (* 1 = 4.31071 loss)
I0811 17:09:35.950093 26953 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0811 17:09:54.464597 26953 solver.cpp:228] Iteration 2010, loss = 4.34704
I0811 17:09:54.464664 26953 solver.cpp:244]     Train net output #0: loss = 4.34704 (* 1 = 4.34704 loss)
I0811 17:09:55.885946 26953 sgd_solver.cpp:106] Iteration 2010, lr = 0.01
I0811 17:10:14.389392 26953 solver.cpp:228] Iteration 2020, loss = 4.31068
I0811 17:10:14.389626 26953 solver.cpp:244]     Train net output #0: loss = 4.31068 (* 1 = 4.31068 loss)
I0811 17:10:15.805526 26953 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0811 17:10:34.357035 26953 solver.cpp:228] Iteration 2030, loss = 4.54046
I0811 17:10:34.357102 26953 solver.cpp:244]     Train net output #0: loss = 4.54046 (* 1 = 4.54046 loss)
I0811 17:10:35.761672 26953 sgd_solver.cpp:106] Iteration 2030, lr = 0.01
I0811 17:10:54.310575 26953 solver.cpp:228] Iteration 2040, loss = 4.34061
I0811 17:10:54.310803 26953 solver.cpp:244]     Train net output #0: loss = 4.34061 (* 1 = 4.34061 loss)
I0811 17:10:55.730898 26953 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0811 17:11:14.256539 26953 solver.cpp:228] Iteration 2050, loss = 4.3527
I0811 17:11:14.256613 26953 solver.cpp:244]     Train net output #0: loss = 4.3527 (* 1 = 4.3527 loss)
I0811 17:11:15.674924 26953 sgd_solver.cpp:106] Iteration 2050, lr = 0.01
I0811 17:11:34.231268 26953 solver.cpp:228] Iteration 2060, loss = 4.21444
I0811 17:11:34.231519 26953 solver.cpp:244]     Train net output #0: loss = 4.21444 (* 1 = 4.21444 loss)
I0811 17:11:35.657330 26953 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0811 17:11:54.183540 26953 solver.cpp:228] Iteration 2070, loss = 4.13233
I0811 17:11:54.183609 26953 solver.cpp:244]     Train net output #0: loss = 4.13233 (* 1 = 4.13233 loss)
I0811 17:11:55.612648 26953 sgd_solver.cpp:106] Iteration 2070, lr = 0.01
I0811 17:12:14.183823 26953 solver.cpp:228] Iteration 2080, loss = 4.35196
I0811 17:12:14.183981 26953 solver.cpp:244]     Train net output #0: loss = 4.35196 (* 1 = 4.35196 loss)
I0811 17:12:15.608902 26953 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0811 17:12:34.134040 26953 solver.cpp:228] Iteration 2090, loss = 4.37381
I0811 17:12:34.134104 26953 solver.cpp:244]     Train net output #0: loss = 4.37381 (* 1 = 4.37381 loss)
I0811 17:12:35.555464 26953 sgd_solver.cpp:106] Iteration 2090, lr = 0.01
I0811 17:12:53.489658 26953 solver.cpp:337] Iteration 2100, Testing net (#0)
I0811 17:12:54.083554 26953 solver.cpp:404]     Test net output #0: accuracy = 0.184
I0811 17:12:54.083616 26953 solver.cpp:404]     Test net output #1: loss = 4.1998 (* 1 = 4.1998 loss)
I0811 17:12:54.661463 26953 solver.cpp:228] Iteration 2100, loss = 4.35424
I0811 17:12:54.661526 26953 solver.cpp:244]     Train net output #0: loss = 4.35424 (* 1 = 4.35424 loss)
I0811 17:12:56.038871 26953 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0811 17:13:14.547336 26953 solver.cpp:228] Iteration 2110, loss = 4.17283
I0811 17:13:14.547415 26953 solver.cpp:244]     Train net output #0: loss = 4.17283 (* 1 = 4.17283 loss)
I0811 17:13:15.961086 26953 sgd_solver.cpp:106] Iteration 2110, lr = 0.01
I0811 17:13:34.474333 26953 solver.cpp:228] Iteration 2120, loss = 4.29652
I0811 17:13:34.474483 26953 solver.cpp:244]     Train net output #0: loss = 4.29652 (* 1 = 4.29652 loss)
I0811 17:13:35.889024 26953 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0811 17:13:54.439856 26953 solver.cpp:228] Iteration 2130, loss = 4.21804
I0811 17:13:54.439929 26953 solver.cpp:244]     Train net output #0: loss = 4.21804 (* 1 = 4.21804 loss)
I0811 17:13:55.859542 26953 sgd_solver.cpp:106] Iteration 2130, lr = 0.01
I0811 17:14:14.434433 26953 solver.cpp:228] Iteration 2140, loss = 4.18217
I0811 17:14:14.434646 26953 solver.cpp:244]     Train net output #0: loss = 4.18217 (* 1 = 4.18217 loss)
I0811 17:14:15.851143 26953 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0811 17:14:34.389117 26953 solver.cpp:228] Iteration 2150, loss = 4.22778
I0811 17:14:34.389183 26953 solver.cpp:244]     Train net output #0: loss = 4.22778 (* 1 = 4.22778 loss)
I0811 17:14:35.796803 26953 sgd_solver.cpp:106] Iteration 2150, lr = 0.01
I0811 17:14:54.328066 26953 solver.cpp:228] Iteration 2160, loss = 4.29916
I0811 17:14:54.328321 26953 solver.cpp:244]     Train net output #0: loss = 4.29916 (* 1 = 4.29916 loss)
I0811 17:14:55.750900 26953 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0811 17:15:14.291110 26953 solver.cpp:228] Iteration 2170, loss = 4.10764
I0811 17:15:14.291177 26953 solver.cpp:244]     Train net output #0: loss = 4.10764 (* 1 = 4.10764 loss)
I0811 17:15:15.708603 26953 sgd_solver.cpp:106] Iteration 2170, lr = 0.01
I0811 17:15:34.291509 26953 solver.cpp:228] Iteration 2180, loss = 4.23704
I0811 17:15:34.291765 26953 solver.cpp:244]     Train net output #0: loss = 4.23704 (* 1 = 4.23704 loss)
I0811 17:15:35.713304 26953 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0811 17:15:54.222853 26953 solver.cpp:228] Iteration 2190, loss = 4.2817
I0811 17:15:54.222915 26953 solver.cpp:244]     Train net output #0: loss = 4.2817 (* 1 = 4.2817 loss)
I0811 17:15:55.653431 26953 sgd_solver.cpp:106] Iteration 2190, lr = 0.01
I0811 17:16:13.634707 26953 solver.cpp:337] Iteration 2200, Testing net (#0)
I0811 17:16:14.231612 26953 solver.cpp:404]     Test net output #0: accuracy = 0.192
I0811 17:16:14.231714 26953 solver.cpp:404]     Test net output #1: loss = 3.97907 (* 1 = 3.97907 loss)
I0811 17:16:14.813290 26953 solver.cpp:228] Iteration 2200, loss = 4.13314
I0811 17:16:14.813371 26953 solver.cpp:244]     Train net output #0: loss = 4.13314 (* 1 = 4.13314 loss)
I0811 17:16:16.178092 26953 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0811 17:16:34.657819 26953 solver.cpp:228] Iteration 2210, loss = 4.17124
I0811 17:16:34.657886 26953 solver.cpp:244]     Train net output #0: loss = 4.17124 (* 1 = 4.17124 loss)
I0811 17:16:36.057880 26953 sgd_solver.cpp:106] Iteration 2210, lr = 0.01
I0811 17:16:54.593852 26953 solver.cpp:228] Iteration 2220, loss = 4.50201
I0811 17:16:54.594120 26953 solver.cpp:244]     Train net output #0: loss = 4.50201 (* 1 = 4.50201 loss)
I0811 17:16:56.009719 26953 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0811 17:17:14.558167 26953 solver.cpp:228] Iteration 2230, loss = 4.04833
I0811 17:17:14.558240 26953 solver.cpp:244]     Train net output #0: loss = 4.04833 (* 1 = 4.04833 loss)
I0811 17:17:15.982771 26953 sgd_solver.cpp:106] Iteration 2230, lr = 0.01
I0811 17:17:34.501714 26953 solver.cpp:228] Iteration 2240, loss = 4.10714
I0811 17:17:34.501956 26953 solver.cpp:244]     Train net output #0: loss = 4.10714 (* 1 = 4.10714 loss)
I0811 17:17:35.933202 26953 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0811 17:17:54.493958 26953 solver.cpp:228] Iteration 2250, loss = 4.10091
I0811 17:17:54.494032 26953 solver.cpp:244]     Train net output #0: loss = 4.10091 (* 1 = 4.10091 loss)
I0811 17:17:55.929308 26953 sgd_solver.cpp:106] Iteration 2250, lr = 0.01
I0811 17:18:14.485095 26953 solver.cpp:228] Iteration 2260, loss = 3.92712
I0811 17:18:14.485296 26953 solver.cpp:244]     Train net output #0: loss = 3.92712 (* 1 = 3.92712 loss)
I0811 17:18:15.889279 26953 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0811 17:18:34.421916 26953 solver.cpp:228] Iteration 2270, loss = 4.04469
I0811 17:18:34.421974 26953 solver.cpp:244]     Train net output #0: loss = 4.04469 (* 1 = 4.04469 loss)
I0811 17:18:35.827404 26953 sgd_solver.cpp:106] Iteration 2270, lr = 0.01
I0811 17:18:54.390873 26953 solver.cpp:228] Iteration 2280, loss = 4.01949
I0811 17:18:54.391119 26953 solver.cpp:244]     Train net output #0: loss = 4.01949 (* 1 = 4.01949 loss)
I0811 17:18:55.815778 26953 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0811 17:19:14.321769 26953 solver.cpp:228] Iteration 2290, loss = 4.16643
I0811 17:19:14.321833 26953 solver.cpp:244]     Train net output #0: loss = 4.16643 (* 1 = 4.16643 loss)
I0811 17:19:15.740126 26953 sgd_solver.cpp:106] Iteration 2290, lr = 0.01
I0811 17:19:33.726459 26953 solver.cpp:337] Iteration 2300, Testing net (#0)
I0811 17:19:34.319324 26953 solver.cpp:404]     Test net output #0: accuracy = 0.18
I0811 17:19:34.319399 26953 solver.cpp:404]     Test net output #1: loss = 4.04671 (* 1 = 4.04671 loss)
I0811 17:19:34.925292 26953 solver.cpp:228] Iteration 2300, loss = 4.13088
I0811 17:19:34.925395 26953 solver.cpp:244]     Train net output #0: loss = 4.13088 (* 1 = 4.13088 loss)
I0811 17:19:36.278642 26953 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0811 17:19:54.775529 26953 solver.cpp:228] Iteration 2310, loss = 4.07237
I0811 17:19:54.775614 26953 solver.cpp:244]     Train net output #0: loss = 4.07237 (* 1 = 4.07237 loss)
I0811 17:19:56.186187 26953 sgd_solver.cpp:106] Iteration 2310, lr = 0.01
I0811 17:20:14.686508 26953 solver.cpp:228] Iteration 2320, loss = 3.91978
I0811 17:20:14.686753 26953 solver.cpp:244]     Train net output #0: loss = 3.91978 (* 1 = 3.91978 loss)
I0811 17:20:16.108860 26953 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0811 17:20:34.698915 26953 solver.cpp:228] Iteration 2330, loss = 4.06818
I0811 17:20:34.698982 26953 solver.cpp:244]     Train net output #0: loss = 4.06818 (* 1 = 4.06818 loss)
I0811 17:20:36.104828 26953 sgd_solver.cpp:106] Iteration 2330, lr = 0.01
I0811 17:20:54.630980 26953 solver.cpp:228] Iteration 2340, loss = 4.05494
I0811 17:20:54.631274 26953 solver.cpp:244]     Train net output #0: loss = 4.05494 (* 1 = 4.05494 loss)
I0811 17:20:56.050061 26953 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0811 17:21:14.629453 26953 solver.cpp:228] Iteration 2350, loss = 4.15552
I0811 17:21:14.629534 26953 solver.cpp:244]     Train net output #0: loss = 4.15552 (* 1 = 4.15552 loss)
I0811 17:21:16.058791 26953 sgd_solver.cpp:106] Iteration 2350, lr = 0.01
I0811 17:21:34.545944 26953 solver.cpp:228] Iteration 2360, loss = 4.02641
I0811 17:21:34.546195 26953 solver.cpp:244]     Train net output #0: loss = 4.02641 (* 1 = 4.02641 loss)
I0811 17:21:35.970444 26953 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0811 17:21:54.537601 26953 solver.cpp:228] Iteration 2370, loss = 3.96569
I0811 17:21:54.537664 26953 solver.cpp:244]     Train net output #0: loss = 3.96569 (* 1 = 3.96569 loss)
I0811 17:21:55.940083 26953 sgd_solver.cpp:106] Iteration 2370, lr = 0.01
I0811 17:22:14.493338 26953 solver.cpp:228] Iteration 2380, loss = 3.88702
I0811 17:22:14.493571 26953 solver.cpp:244]     Train net output #0: loss = 3.88702 (* 1 = 3.88702 loss)
I0811 17:22:15.894304 26953 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0811 17:22:34.431269 26953 solver.cpp:228] Iteration 2390, loss = 4.09769
I0811 17:22:34.431334 26953 solver.cpp:244]     Train net output #0: loss = 4.09769 (* 1 = 4.09769 loss)
I0811 17:22:35.843538 26953 sgd_solver.cpp:106] Iteration 2390, lr = 0.01
I0811 17:22:53.819492 26953 solver.cpp:337] Iteration 2400, Testing net (#0)
I0811 17:22:54.419714 26953 solver.cpp:404]     Test net output #0: accuracy = 0.208
I0811 17:22:54.419786 26953 solver.cpp:404]     Test net output #1: loss = 3.94296 (* 1 = 3.94296 loss)
I0811 17:22:54.997689 26953 solver.cpp:228] Iteration 2400, loss = 4.21987
I0811 17:22:54.997782 26953 solver.cpp:244]     Train net output #0: loss = 4.21987 (* 1 = 4.21987 loss)
I0811 17:22:56.369191 26953 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0811 17:23:14.861750 26953 solver.cpp:228] Iteration 2410, loss = 4.00838
I0811 17:23:14.861814 26953 solver.cpp:244]     Train net output #0: loss = 4.00838 (* 1 = 4.00838 loss)
I0811 17:23:16.283205 26953 sgd_solver.cpp:106] Iteration 2410, lr = 0.01
I0811 17:23:34.836325 26953 solver.cpp:228] Iteration 2420, loss = 4.04648
I0811 17:23:34.836575 26953 solver.cpp:244]     Train net output #0: loss = 4.04648 (* 1 = 4.04648 loss)
I0811 17:23:36.257892 26953 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0811 17:23:54.782811 26953 solver.cpp:228] Iteration 2430, loss = 4.00828
I0811 17:23:54.782872 26953 solver.cpp:244]     Train net output #0: loss = 4.00828 (* 1 = 4.00828 loss)
I0811 17:23:56.208812 26953 sgd_solver.cpp:106] Iteration 2430, lr = 0.01
I0811 17:24:14.747805 26953 solver.cpp:228] Iteration 2440, loss = 4.19112
I0811 17:24:14.748059 26953 solver.cpp:244]     Train net output #0: loss = 4.19112 (* 1 = 4.19112 loss)
I0811 17:24:16.150831 26953 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0811 17:24:34.704893 26953 solver.cpp:228] Iteration 2450, loss = 3.90292
I0811 17:24:34.704962 26953 solver.cpp:244]     Train net output #0: loss = 3.90292 (* 1 = 3.90292 loss)
I0811 17:24:36.129638 26953 sgd_solver.cpp:106] Iteration 2450, lr = 0.01
I0811 17:24:54.657083 26953 solver.cpp:228] Iteration 2460, loss = 4.22012
I0811 17:24:54.657357 26953 solver.cpp:244]     Train net output #0: loss = 4.22012 (* 1 = 4.22012 loss)
I0811 17:24:56.074111 26953 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0811 17:25:14.640674 26953 solver.cpp:228] Iteration 2470, loss = 4.05815
I0811 17:25:14.640733 26953 solver.cpp:244]     Train net output #0: loss = 4.05815 (* 1 = 4.05815 loss)
I0811 17:25:16.073864 26953 sgd_solver.cpp:106] Iteration 2470, lr = 0.01
I0811 17:25:34.591331 26953 solver.cpp:228] Iteration 2480, loss = 4.12679
I0811 17:25:34.591545 26953 solver.cpp:244]     Train net output #0: loss = 4.12679 (* 1 = 4.12679 loss)
I0811 17:25:36.010416 26953 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0811 17:25:54.546711 26953 solver.cpp:228] Iteration 2490, loss = 4.07238
I0811 17:25:54.546787 26953 solver.cpp:244]     Train net output #0: loss = 4.07238 (* 1 = 4.07238 loss)
I0811 17:25:55.950060 26953 sgd_solver.cpp:106] Iteration 2490, lr = 0.01
I0811 17:26:13.931093 26953 solver.cpp:337] Iteration 2500, Testing net (#0)
I0811 17:26:14.532455 26953 solver.cpp:404]     Test net output #0: accuracy = 0.224
I0811 17:26:14.532557 26953 solver.cpp:404]     Test net output #1: loss = 3.83397 (* 1 = 3.83397 loss)
I0811 17:26:15.097473 26953 solver.cpp:228] Iteration 2500, loss = 4.20164
I0811 17:26:15.097550 26953 solver.cpp:244]     Train net output #0: loss = 4.20164 (* 1 = 4.20164 loss)
I0811 17:26:16.482591 26953 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0811 17:26:34.965674 26953 solver.cpp:228] Iteration 2510, loss = 3.96795
I0811 17:26:34.965754 26953 solver.cpp:244]     Train net output #0: loss = 3.96795 (* 1 = 3.96795 loss)
I0811 17:26:36.375983 26953 sgd_solver.cpp:106] Iteration 2510, lr = 0.01
I0811 17:26:54.924347 26953 solver.cpp:228] Iteration 2520, loss = 4.04046
I0811 17:26:54.924597 26953 solver.cpp:244]     Train net output #0: loss = 4.04046 (* 1 = 4.04046 loss)
I0811 17:26:56.342687 26953 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0811 17:27:14.879407 26953 solver.cpp:228] Iteration 2530, loss = 4.04797
I0811 17:27:14.879485 26953 solver.cpp:244]     Train net output #0: loss = 4.04797 (* 1 = 4.04797 loss)
I0811 17:27:16.311281 26953 sgd_solver.cpp:106] Iteration 2530, lr = 0.01
I0811 17:27:34.864588 26953 solver.cpp:228] Iteration 2540, loss = 4.10062
I0811 17:27:34.864753 26953 solver.cpp:244]     Train net output #0: loss = 4.10062 (* 1 = 4.10062 loss)
I0811 17:27:36.277070 26953 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0811 17:27:54.827545 26953 solver.cpp:228] Iteration 2550, loss = 3.99842
I0811 17:27:54.827611 26953 solver.cpp:244]     Train net output #0: loss = 3.99842 (* 1 = 3.99842 loss)
I0811 17:27:56.241341 26953 sgd_solver.cpp:106] Iteration 2550, lr = 0.01
I0811 17:28:14.781668 26953 solver.cpp:228] Iteration 2560, loss = 3.92992
I0811 17:28:14.781898 26953 solver.cpp:244]     Train net output #0: loss = 3.92992 (* 1 = 3.92992 loss)
I0811 17:28:16.182935 26953 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0811 17:28:34.750738 26953 solver.cpp:228] Iteration 2570, loss = 3.94052
I0811 17:28:34.750807 26953 solver.cpp:244]     Train net output #0: loss = 3.94052 (* 1 = 3.94052 loss)
I0811 17:28:36.172165 26953 sgd_solver.cpp:106] Iteration 2570, lr = 0.01
I0811 17:28:54.677944 26953 solver.cpp:228] Iteration 2580, loss = 3.92632
I0811 17:28:54.678120 26953 solver.cpp:244]     Train net output #0: loss = 3.92632 (* 1 = 3.92632 loss)
I0811 17:28:56.109753 26953 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0811 17:29:14.684407 26953 solver.cpp:228] Iteration 2590, loss = 4.00907
I0811 17:29:14.684469 26953 solver.cpp:244]     Train net output #0: loss = 4.00907 (* 1 = 4.00907 loss)
I0811 17:29:16.113504 26953 sgd_solver.cpp:106] Iteration 2590, lr = 0.01
I0811 17:29:34.047283 26953 solver.cpp:337] Iteration 2600, Testing net (#0)
I0811 17:29:34.647133 26953 solver.cpp:404]     Test net output #0: accuracy = 0.218
I0811 17:29:34.647205 26953 solver.cpp:404]     Test net output #1: loss = 3.81361 (* 1 = 3.81361 loss)
I0811 17:29:35.210667 26953 solver.cpp:228] Iteration 2600, loss = 3.96019
I0811 17:29:35.210748 26953 solver.cpp:244]     Train net output #0: loss = 3.96019 (* 1 = 3.96019 loss)
I0811 17:29:36.609200 26953 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0811 17:29:55.101269 26953 solver.cpp:228] Iteration 2610, loss = 3.91329
I0811 17:29:55.101336 26953 solver.cpp:244]     Train net output #0: loss = 3.91329 (* 1 = 3.91329 loss)
I0811 17:29:56.511869 26953 sgd_solver.cpp:106] Iteration 2610, lr = 0.01
I0811 17:30:15.050029 26953 solver.cpp:228] Iteration 2620, loss = 3.95587
I0811 17:30:15.050207 26953 solver.cpp:244]     Train net output #0: loss = 3.95587 (* 1 = 3.95587 loss)
I0811 17:30:16.467896 26953 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0811 17:30:34.978319 26953 solver.cpp:228] Iteration 2630, loss = 3.93333
I0811 17:30:34.978379 26953 solver.cpp:244]     Train net output #0: loss = 3.93333 (* 1 = 3.93333 loss)
I0811 17:30:36.403861 26953 sgd_solver.cpp:106] Iteration 2630, lr = 0.01
I0811 17:30:54.978076 26953 solver.cpp:228] Iteration 2640, loss = 3.95193
I0811 17:30:54.978349 26953 solver.cpp:244]     Train net output #0: loss = 3.95193 (* 1 = 3.95193 loss)
I0811 17:30:56.414400 26953 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0811 17:31:14.923940 26953 solver.cpp:228] Iteration 2650, loss = 3.96467
I0811 17:31:14.924007 26953 solver.cpp:244]     Train net output #0: loss = 3.96467 (* 1 = 3.96467 loss)
I0811 17:31:16.345842 26953 sgd_solver.cpp:106] Iteration 2650, lr = 0.01
I0811 17:31:34.886915 26953 solver.cpp:228] Iteration 2660, loss = 3.82653
I0811 17:31:34.887177 26953 solver.cpp:244]     Train net output #0: loss = 3.82653 (* 1 = 3.82653 loss)
I0811 17:31:36.299221 26953 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0811 17:31:54.834033 26953 solver.cpp:228] Iteration 2670, loss = 3.96014
I0811 17:31:54.834105 26953 solver.cpp:244]     Train net output #0: loss = 3.96014 (* 1 = 3.96014 loss)
I0811 17:31:56.259881 26953 sgd_solver.cpp:106] Iteration 2670, lr = 0.01
I0811 17:32:14.774235 26953 solver.cpp:228] Iteration 2680, loss = 3.85177
I0811 17:32:14.774504 26953 solver.cpp:244]     Train net output #0: loss = 3.85177 (* 1 = 3.85177 loss)
I0811 17:32:16.186332 26953 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0811 17:32:34.754125 26953 solver.cpp:228] Iteration 2690, loss = 3.95673
I0811 17:32:34.754185 26953 solver.cpp:244]     Train net output #0: loss = 3.95673 (* 1 = 3.95673 loss)
I0811 17:32:36.167927 26953 sgd_solver.cpp:106] Iteration 2690, lr = 0.01
I0811 17:32:54.107503 26953 solver.cpp:337] Iteration 2700, Testing net (#0)
I0811 17:32:54.707324 26953 solver.cpp:404]     Test net output #0: accuracy = 0.276
I0811 17:32:54.707392 26953 solver.cpp:404]     Test net output #1: loss = 3.64405 (* 1 = 3.64405 loss)
I0811 17:32:55.277709 26953 solver.cpp:228] Iteration 2700, loss = 3.76577
I0811 17:32:55.277787 26953 solver.cpp:244]     Train net output #0: loss = 3.76577 (* 1 = 3.76577 loss)
I0811 17:32:56.679268 26953 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0811 17:33:15.193226 26953 solver.cpp:228] Iteration 2710, loss = 4.01942
I0811 17:33:15.193306 26953 solver.cpp:244]     Train net output #0: loss = 4.01942 (* 1 = 4.01942 loss)
I0811 17:33:16.600766 26953 sgd_solver.cpp:106] Iteration 2710, lr = 0.01
I0811 17:33:35.152470 26953 solver.cpp:228] Iteration 2720, loss = 3.85242
I0811 17:33:35.152698 26953 solver.cpp:244]     Train net output #0: loss = 3.85242 (* 1 = 3.85242 loss)
I0811 17:33:36.558048 26953 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0811 17:33:55.099124 26953 solver.cpp:228] Iteration 2730, loss = 4.12141
I0811 17:33:55.099207 26953 solver.cpp:244]     Train net output #0: loss = 4.12141 (* 1 = 4.12141 loss)
I0811 17:33:56.506430 26953 sgd_solver.cpp:106] Iteration 2730, lr = 0.01
I0811 17:34:15.053881 26953 solver.cpp:228] Iteration 2740, loss = 4.05862
I0811 17:34:15.054110 26953 solver.cpp:244]     Train net output #0: loss = 4.05862 (* 1 = 4.05862 loss)
I0811 17:34:16.474452 26953 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0811 17:34:34.996909 26953 solver.cpp:228] Iteration 2750, loss = 3.77775
I0811 17:34:34.996979 26953 solver.cpp:244]     Train net output #0: loss = 3.77775 (* 1 = 3.77775 loss)
I0811 17:34:36.418473 26953 sgd_solver.cpp:106] Iteration 2750, lr = 0.01
I0811 17:34:54.984527 26953 solver.cpp:228] Iteration 2760, loss = 3.92447
I0811 17:34:54.984777 26953 solver.cpp:244]     Train net output #0: loss = 3.92447 (* 1 = 3.92447 loss)
I0811 17:34:56.411193 26953 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0811 17:35:14.951198 26953 solver.cpp:228] Iteration 2770, loss = 3.87332
I0811 17:35:14.951264 26953 solver.cpp:244]     Train net output #0: loss = 3.87332 (* 1 = 3.87332 loss)
I0811 17:35:16.354113 26953 sgd_solver.cpp:106] Iteration 2770, lr = 0.01
I0811 17:35:34.909328 26953 solver.cpp:228] Iteration 2780, loss = 3.8023
I0811 17:35:34.909660 26953 solver.cpp:244]     Train net output #0: loss = 3.8023 (* 1 = 3.8023 loss)
I0811 17:35:36.316439 26953 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0811 17:35:54.849839 26953 solver.cpp:228] Iteration 2790, loss = 3.87109
I0811 17:35:54.849903 26953 solver.cpp:244]     Train net output #0: loss = 3.87109 (* 1 = 3.87109 loss)
I0811 17:35:56.274866 26953 sgd_solver.cpp:106] Iteration 2790, lr = 0.01
I0811 17:36:14.232617 26953 solver.cpp:337] Iteration 2800, Testing net (#0)
I0811 17:36:14.833770 26953 solver.cpp:404]     Test net output #0: accuracy = 0.238
I0811 17:36:14.833832 26953 solver.cpp:404]     Test net output #1: loss = 3.78991 (* 1 = 3.78991 loss)
I0811 17:36:15.395107 26953 solver.cpp:228] Iteration 2800, loss = 3.73273
I0811 17:36:15.395184 26953 solver.cpp:244]     Train net output #0: loss = 3.73273 (* 1 = 3.73273 loss)
I0811 17:36:16.783066 26953 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0811 17:36:35.290328 26953 solver.cpp:228] Iteration 2810, loss = 3.79295
I0811 17:36:35.290395 26953 solver.cpp:244]     Train net output #0: loss = 3.79295 (* 1 = 3.79295 loss)
I0811 17:36:36.727535 26953 sgd_solver.cpp:106] Iteration 2810, lr = 0.01
I0811 17:36:55.250584 26953 solver.cpp:228] Iteration 2820, loss = 3.9087
I0811 17:36:55.250777 26953 solver.cpp:244]     Train net output #0: loss = 3.9087 (* 1 = 3.9087 loss)
I0811 17:36:56.678035 26953 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0811 17:37:15.201506 26953 solver.cpp:228] Iteration 2830, loss = 3.84653
I0811 17:37:15.201575 26953 solver.cpp:244]     Train net output #0: loss = 3.84653 (* 1 = 3.84653 loss)
I0811 17:37:16.603821 26953 sgd_solver.cpp:106] Iteration 2830, lr = 0.01
I0811 17:37:35.159333 26953 solver.cpp:228] Iteration 2840, loss = 3.96981
I0811 17:37:35.159572 26953 solver.cpp:244]     Train net output #0: loss = 3.96981 (* 1 = 3.96981 loss)
I0811 17:37:36.573665 26953 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0811 17:37:55.107250 26953 solver.cpp:228] Iteration 2850, loss = 3.79979
I0811 17:37:55.107316 26953 solver.cpp:244]     Train net output #0: loss = 3.79979 (* 1 = 3.79979 loss)
I0811 17:37:56.528830 26953 sgd_solver.cpp:106] Iteration 2850, lr = 0.01
I0811 17:38:15.088217 26953 solver.cpp:228] Iteration 2860, loss = 3.72916
I0811 17:38:15.088449 26953 solver.cpp:244]     Train net output #0: loss = 3.72916 (* 1 = 3.72916 loss)
I0811 17:38:16.504125 26953 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0811 17:38:35.051686 26953 solver.cpp:228] Iteration 2870, loss = 3.75306
I0811 17:38:35.051766 26953 solver.cpp:244]     Train net output #0: loss = 3.75306 (* 1 = 3.75306 loss)
I0811 17:38:36.476104 26953 sgd_solver.cpp:106] Iteration 2870, lr = 0.01
I0811 17:38:55.015612 26953 solver.cpp:228] Iteration 2880, loss = 3.88854
I0811 17:38:55.015789 26953 solver.cpp:244]     Train net output #0: loss = 3.88854 (* 1 = 3.88854 loss)
I0811 17:38:56.434242 26953 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0811 17:39:14.969786 26953 solver.cpp:228] Iteration 2890, loss = 3.64912
I0811 17:39:14.969866 26953 solver.cpp:244]     Train net output #0: loss = 3.64912 (* 1 = 3.64912 loss)
I0811 17:39:16.379595 26953 sgd_solver.cpp:106] Iteration 2890, lr = 0.01
I0811 17:39:34.322777 26953 solver.cpp:337] Iteration 2900, Testing net (#0)
I0811 17:39:34.922488 26953 solver.cpp:404]     Test net output #0: accuracy = 0.246
I0811 17:39:34.922551 26953 solver.cpp:404]     Test net output #1: loss = 3.73784 (* 1 = 3.73784 loss)
I0811 17:39:35.487996 26953 solver.cpp:228] Iteration 2900, loss = 3.76792
I0811 17:39:35.488080 26953 solver.cpp:244]     Train net output #0: loss = 3.76792 (* 1 = 3.76792 loss)
I0811 17:39:36.878983 26953 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0811 17:39:55.371948 26953 solver.cpp:228] Iteration 2910, loss = 3.72212
I0811 17:39:55.372022 26953 solver.cpp:244]     Train net output #0: loss = 3.72212 (* 1 = 3.72212 loss)
I0811 17:39:56.795107 26953 sgd_solver.cpp:106] Iteration 2910, lr = 0.01
I0811 17:40:15.321897 26953 solver.cpp:228] Iteration 2920, loss = 3.60612
I0811 17:40:15.322126 26953 solver.cpp:244]     Train net output #0: loss = 3.60612 (* 1 = 3.60612 loss)
I0811 17:40:16.757624 26953 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0811 17:40:35.313849 26953 solver.cpp:228] Iteration 2930, loss = 3.55278
I0811 17:40:35.313930 26953 solver.cpp:244]     Train net output #0: loss = 3.55278 (* 1 = 3.55278 loss)
I0811 17:40:36.735303 26953 sgd_solver.cpp:106] Iteration 2930, lr = 0.01
I0811 17:40:55.265074 26953 solver.cpp:228] Iteration 2940, loss = 3.75086
I0811 17:40:55.265322 26953 solver.cpp:244]     Train net output #0: loss = 3.75086 (* 1 = 3.75086 loss)
I0811 17:40:56.678143 26953 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0811 17:41:15.191372 26953 solver.cpp:228] Iteration 2950, loss = 3.84263
I0811 17:41:15.191447 26953 solver.cpp:244]     Train net output #0: loss = 3.84263 (* 1 = 3.84263 loss)
I0811 17:41:16.604172 26953 sgd_solver.cpp:106] Iteration 2950, lr = 0.01
I0811 17:41:35.175233 26953 solver.cpp:228] Iteration 2960, loss = 3.84235
I0811 17:41:35.175395 26953 solver.cpp:244]     Train net output #0: loss = 3.84235 (* 1 = 3.84235 loss)
I0811 17:41:36.585734 26953 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0811 17:41:55.129261 26953 solver.cpp:228] Iteration 2970, loss = 3.87963
I0811 17:41:55.129338 26953 solver.cpp:244]     Train net output #0: loss = 3.87963 (* 1 = 3.87963 loss)
I0811 17:41:56.556958 26953 sgd_solver.cpp:106] Iteration 2970, lr = 0.01
I0811 17:42:15.120388 26953 solver.cpp:228] Iteration 2980, loss = 3.8991
I0811 17:42:15.120626 26953 solver.cpp:244]     Train net output #0: loss = 3.8991 (* 1 = 3.8991 loss)
I0811 17:42:16.544493 26953 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0811 17:42:35.058260 26953 solver.cpp:228] Iteration 2990, loss = 3.78136
I0811 17:42:35.058326 26953 solver.cpp:244]     Train net output #0: loss = 3.78136 (* 1 = 3.78136 loss)
I0811 17:42:36.484081 26953 sgd_solver.cpp:106] Iteration 2990, lr = 0.01
I0811 17:42:54.454797 26953 solver.cpp:337] Iteration 3000, Testing net (#0)
I0811 17:42:55.057921 26953 solver.cpp:404]     Test net output #0: accuracy = 0.276
I0811 17:42:55.058003 26953 solver.cpp:404]     Test net output #1: loss = 3.58755 (* 1 = 3.58755 loss)
I0811 17:42:55.653223 26953 solver.cpp:228] Iteration 3000, loss = 3.81285
I0811 17:42:55.653306 26953 solver.cpp:244]     Train net output #0: loss = 3.81285 (* 1 = 3.81285 loss)
I0811 17:42:57.009135 26953 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0811 17:43:15.499902 26953 solver.cpp:228] Iteration 3010, loss = 3.6289
I0811 17:43:15.499968 26953 solver.cpp:244]     Train net output #0: loss = 3.6289 (* 1 = 3.6289 loss)
I0811 17:43:16.917315 26953 sgd_solver.cpp:106] Iteration 3010, lr = 0.01
I0811 17:43:35.435004 26953 solver.cpp:228] Iteration 3020, loss = 3.73961
I0811 17:43:35.435189 26953 solver.cpp:244]     Train net output #0: loss = 3.73961 (* 1 = 3.73961 loss)
I0811 17:43:36.859814 26953 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0811 17:43:55.398246 26953 solver.cpp:228] Iteration 3030, loss = 3.82354
I0811 17:43:55.398310 26953 solver.cpp:244]     Train net output #0: loss = 3.82354 (* 1 = 3.82354 loss)
I0811 17:43:56.812530 26953 sgd_solver.cpp:106] Iteration 3030, lr = 0.01
I0811 17:44:15.348212 26953 solver.cpp:228] Iteration 3040, loss = 3.72486
I0811 17:44:15.348443 26953 solver.cpp:244]     Train net output #0: loss = 3.72486 (* 1 = 3.72486 loss)
I0811 17:44:16.780233 26953 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0811 17:44:35.359392 26953 solver.cpp:228] Iteration 3050, loss = 3.73866
I0811 17:44:35.359469 26953 solver.cpp:244]     Train net output #0: loss = 3.73866 (* 1 = 3.73866 loss)
I0811 17:44:36.758116 26953 sgd_solver.cpp:106] Iteration 3050, lr = 0.01
I0811 17:44:55.299563 26953 solver.cpp:228] Iteration 3060, loss = 3.89276
I0811 17:44:55.299796 26953 solver.cpp:244]     Train net output #0: loss = 3.89276 (* 1 = 3.89276 loss)
I0811 17:44:56.714165 26953 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0811 17:45:15.241122 26953 solver.cpp:228] Iteration 3070, loss = 3.7228
I0811 17:45:15.241190 26953 solver.cpp:244]     Train net output #0: loss = 3.7228 (* 1 = 3.7228 loss)
I0811 17:45:16.653538 26953 sgd_solver.cpp:106] Iteration 3070, lr = 0.01
I0811 17:45:35.191344 26953 solver.cpp:228] Iteration 3080, loss = 3.65726
I0811 17:45:35.191550 26953 solver.cpp:244]     Train net output #0: loss = 3.65726 (* 1 = 3.65726 loss)
I0811 17:45:36.611645 26953 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0811 17:45:55.160466 26953 solver.cpp:228] Iteration 3090, loss = 3.64987
I0811 17:45:55.160538 26953 solver.cpp:244]     Train net output #0: loss = 3.64987 (* 1 = 3.64987 loss)
I0811 17:45:56.587381 26953 sgd_solver.cpp:106] Iteration 3090, lr = 0.01
I0811 17:46:14.555104 26953 solver.cpp:337] Iteration 3100, Testing net (#0)
I0811 17:46:15.163272 26953 solver.cpp:404]     Test net output #0: accuracy = 0.282
I0811 17:46:15.163399 26953 solver.cpp:404]     Test net output #1: loss = 3.54848 (* 1 = 3.54848 loss)
I0811 17:46:15.747930 26953 solver.cpp:228] Iteration 3100, loss = 3.7108
I0811 17:46:15.748028 26953 solver.cpp:244]     Train net output #0: loss = 3.7108 (* 1 = 3.7108 loss)
I0811 17:46:17.120527 26953 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0811 17:46:35.617262 26953 solver.cpp:228] Iteration 3110, loss = 3.70029
I0811 17:46:35.617331 26953 solver.cpp:244]     Train net output #0: loss = 3.70029 (* 1 = 3.70029 loss)
I0811 17:46:37.020949 26953 sgd_solver.cpp:106] Iteration 3110, lr = 0.01
I0811 17:46:55.555475 26953 solver.cpp:228] Iteration 3120, loss = 3.75168
I0811 17:46:55.555703 26953 solver.cpp:244]     Train net output #0: loss = 3.75168 (* 1 = 3.75168 loss)
I0811 17:46:56.963861 26953 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0811 17:47:15.513263 26953 solver.cpp:228] Iteration 3130, loss = 3.73669
I0811 17:47:15.513326 26953 solver.cpp:244]     Train net output #0: loss = 3.73669 (* 1 = 3.73669 loss)
I0811 17:47:16.933933 26953 sgd_solver.cpp:106] Iteration 3130, lr = 0.01
I0811 17:47:35.462287 26953 solver.cpp:228] Iteration 3140, loss = 3.66935
I0811 17:47:35.462537 26953 solver.cpp:244]     Train net output #0: loss = 3.66935 (* 1 = 3.66935 loss)
I0811 17:47:36.885941 26953 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0811 17:47:55.441357 26953 solver.cpp:228] Iteration 3150, loss = 3.59133
I0811 17:47:55.441439 26953 solver.cpp:244]     Train net output #0: loss = 3.59133 (* 1 = 3.59133 loss)
I0811 17:47:56.866927 26953 sgd_solver.cpp:106] Iteration 3150, lr = 0.01
I0811 17:48:15.397670 26953 solver.cpp:228] Iteration 3160, loss = 3.4272
I0811 17:48:15.397913 26953 solver.cpp:244]     Train net output #0: loss = 3.4272 (* 1 = 3.4272 loss)
I0811 17:48:16.831945 26953 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0811 17:48:35.365368 26953 solver.cpp:228] Iteration 3170, loss = 3.58786
I0811 17:48:35.365442 26953 solver.cpp:244]     Train net output #0: loss = 3.58786 (* 1 = 3.58786 loss)
I0811 17:48:36.766643 26953 sgd_solver.cpp:106] Iteration 3170, lr = 0.01
I0811 17:48:55.326817 26953 solver.cpp:228] Iteration 3180, loss = 3.67678
I0811 17:48:55.327080 26953 solver.cpp:244]     Train net output #0: loss = 3.67678 (* 1 = 3.67678 loss)
I0811 17:48:56.749406 26953 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0811 17:49:15.275085 26953 solver.cpp:228] Iteration 3190, loss = 3.70883
I0811 17:49:15.275156 26953 solver.cpp:244]     Train net output #0: loss = 3.70883 (* 1 = 3.70883 loss)
I0811 17:49:16.685252 26953 sgd_solver.cpp:106] Iteration 3190, lr = 0.01
I0811 17:49:34.671335 26953 solver.cpp:337] Iteration 3200, Testing net (#0)
I0811 17:49:35.266613 26953 solver.cpp:404]     Test net output #0: accuracy = 0.3
I0811 17:49:35.266677 26953 solver.cpp:404]     Test net output #1: loss = 3.38977 (* 1 = 3.38977 loss)
I0811 17:49:35.865802 26953 solver.cpp:228] Iteration 3200, loss = 3.64388
I0811 17:49:35.865870 26953 solver.cpp:244]     Train net output #0: loss = 3.64388 (* 1 = 3.64388 loss)
I0811 17:49:37.219210 26953 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0811 17:49:56.747581 26953 solver.cpp:228] Iteration 3210, loss = 3.69815
I0811 17:49:56.747648 26953 solver.cpp:244]     Train net output #0: loss = 3.69815 (* 1 = 3.69815 loss)
I0811 17:49:58.167824 26953 sgd_solver.cpp:106] Iteration 3210, lr = 0.01
I0811 17:50:16.673703 26953 solver.cpp:228] Iteration 3220, loss = 3.59721
I0811 17:50:16.673924 26953 solver.cpp:244]     Train net output #0: loss = 3.59721 (* 1 = 3.59721 loss)
I0811 17:50:18.072078 26953 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0811 17:50:36.611300 26953 solver.cpp:228] Iteration 3230, loss = 3.66746
I0811 17:50:36.611363 26953 solver.cpp:244]     Train net output #0: loss = 3.66746 (* 1 = 3.66746 loss)
I0811 17:50:38.031252 26953 sgd_solver.cpp:106] Iteration 3230, lr = 0.01
I0811 17:50:56.563918 26953 solver.cpp:228] Iteration 3240, loss = 3.70826
I0811 17:50:56.564152 26953 solver.cpp:244]     Train net output #0: loss = 3.70826 (* 1 = 3.70826 loss)
I0811 17:50:57.982820 26953 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0811 17:51:16.557636 26953 solver.cpp:228] Iteration 3250, loss = 3.67557
I0811 17:51:16.557711 26953 solver.cpp:244]     Train net output #0: loss = 3.67557 (* 1 = 3.67557 loss)
I0811 17:51:17.979900 26953 sgd_solver.cpp:106] Iteration 3250, lr = 0.01
I0811 17:51:36.501730 26953 solver.cpp:228] Iteration 3260, loss = 3.51364
I0811 17:51:36.501931 26953 solver.cpp:244]     Train net output #0: loss = 3.51364 (* 1 = 3.51364 loss)
I0811 17:51:37.915706 26953 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0811 17:51:56.483444 26953 solver.cpp:228] Iteration 3270, loss = 3.60816
I0811 17:51:56.483508 26953 solver.cpp:244]     Train net output #0: loss = 3.60816 (* 1 = 3.60816 loss)
I0811 17:51:57.911100 26953 sgd_solver.cpp:106] Iteration 3270, lr = 0.01
I0811 17:52:16.443491 26953 solver.cpp:228] Iteration 3280, loss = 3.57409
I0811 17:52:16.443742 26953 solver.cpp:244]     Train net output #0: loss = 3.57409 (* 1 = 3.57409 loss)
I0811 17:52:17.852859 26953 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0811 17:52:36.391611 26953 solver.cpp:228] Iteration 3290, loss = 3.61487
I0811 17:52:36.391672 26953 solver.cpp:244]     Train net output #0: loss = 3.61487 (* 1 = 3.61487 loss)
I0811 17:52:37.796787 26953 sgd_solver.cpp:106] Iteration 3290, lr = 0.01
I0811 17:52:55.770395 26953 solver.cpp:337] Iteration 3300, Testing net (#0)
I0811 17:52:56.367591 26953 solver.cpp:404]     Test net output #0: accuracy = 0.29
I0811 17:52:56.367655 26953 solver.cpp:404]     Test net output #1: loss = 3.49821 (* 1 = 3.49821 loss)
I0811 17:52:56.953680 26953 solver.cpp:228] Iteration 3300, loss = 3.58731
I0811 17:52:56.953763 26953 solver.cpp:244]     Train net output #0: loss = 3.58731 (* 1 = 3.58731 loss)
I0811 17:52:58.325544 26953 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0811 17:53:16.813781 26953 solver.cpp:228] Iteration 3310, loss = 3.68152
I0811 17:53:16.813844 26953 solver.cpp:244]     Train net output #0: loss = 3.68152 (* 1 = 3.68152 loss)
I0811 17:53:18.221624 26953 sgd_solver.cpp:106] Iteration 3310, lr = 0.01
I0811 17:53:36.762307 26953 solver.cpp:228] Iteration 3320, loss = 3.7308
I0811 17:53:36.762537 26953 solver.cpp:244]     Train net output #0: loss = 3.7308 (* 1 = 3.7308 loss)
I0811 17:53:38.188593 26953 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0811 17:53:56.735754 26953 solver.cpp:228] Iteration 3330, loss = 3.59396
I0811 17:53:56.735819 26953 solver.cpp:244]     Train net output #0: loss = 3.59396 (* 1 = 3.59396 loss)
I0811 17:53:58.156576 26953 sgd_solver.cpp:106] Iteration 3330, lr = 0.01
I0811 17:54:16.663596 26953 solver.cpp:228] Iteration 3340, loss = 3.77947
I0811 17:54:16.663823 26953 solver.cpp:244]     Train net output #0: loss = 3.77947 (* 1 = 3.77947 loss)
I0811 17:54:18.080251 26953 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0811 17:54:36.657192 26953 solver.cpp:228] Iteration 3350, loss = 3.76999
I0811 17:54:36.657269 26953 solver.cpp:244]     Train net output #0: loss = 3.76999 (* 1 = 3.76999 loss)
I0811 17:54:38.084038 26953 sgd_solver.cpp:106] Iteration 3350, lr = 0.01
I0811 17:54:56.609130 26953 solver.cpp:228] Iteration 3360, loss = 3.59448
I0811 17:54:56.609391 26953 solver.cpp:244]     Train net output #0: loss = 3.59448 (* 1 = 3.59448 loss)
I0811 17:54:58.019274 26953 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0811 17:55:16.578806 26953 solver.cpp:228] Iteration 3370, loss = 3.30254
I0811 17:55:16.578873 26953 solver.cpp:244]     Train net output #0: loss = 3.30254 (* 1 = 3.30254 loss)
I0811 17:55:17.998396 26953 sgd_solver.cpp:106] Iteration 3370, lr = 0.01
I0811 17:55:36.533109 26953 solver.cpp:228] Iteration 3380, loss = 3.56696
I0811 17:55:36.533423 26953 solver.cpp:244]     Train net output #0: loss = 3.56696 (* 1 = 3.56696 loss)
I0811 17:55:37.953647 26953 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0811 17:55:56.512521 26953 solver.cpp:228] Iteration 3390, loss = 3.54153
I0811 17:55:56.512585 26953 solver.cpp:244]     Train net output #0: loss = 3.54153 (* 1 = 3.54153 loss)
I0811 17:55:57.919708 26953 sgd_solver.cpp:106] Iteration 3390, lr = 0.01
I0811 17:56:15.876968 26953 solver.cpp:337] Iteration 3400, Testing net (#0)
I0811 17:56:16.468777 26953 solver.cpp:404]     Test net output #0: accuracy = 0.344
I0811 17:56:16.468838 26953 solver.cpp:404]     Test net output #1: loss = 3.33637 (* 1 = 3.33637 loss)
I0811 17:56:17.032346 26953 solver.cpp:228] Iteration 3400, loss = 3.50843
I0811 17:56:17.032424 26953 solver.cpp:244]     Train net output #0: loss = 3.50843 (* 1 = 3.50843 loss)
I0811 17:56:18.434928 26953 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0811 17:56:36.925513 26953 solver.cpp:228] Iteration 3410, loss = 3.62931
I0811 17:56:36.925585 26953 solver.cpp:244]     Train net output #0: loss = 3.62931 (* 1 = 3.62931 loss)
I0811 17:56:38.323104 26953 sgd_solver.cpp:106] Iteration 3410, lr = 0.01
I0811 17:56:56.865664 26953 solver.cpp:228] Iteration 3420, loss = 3.65379
I0811 17:56:56.865903 26953 solver.cpp:244]     Train net output #0: loss = 3.65379 (* 1 = 3.65379 loss)
I0811 17:56:58.294298 26953 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0811 17:57:16.818223 26953 solver.cpp:228] Iteration 3430, loss = 3.55615
I0811 17:57:16.818308 26953 solver.cpp:244]     Train net output #0: loss = 3.55615 (* 1 = 3.55615 loss)
I0811 17:57:18.243095 26953 sgd_solver.cpp:106] Iteration 3430, lr = 0.01
I0811 17:57:36.777416 26953 solver.cpp:228] Iteration 3440, loss = 3.59074
I0811 17:57:36.777595 26953 solver.cpp:244]     Train net output #0: loss = 3.59074 (* 1 = 3.59074 loss)
I0811 17:57:38.194411 26953 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0811 17:57:56.760469 26953 solver.cpp:228] Iteration 3450, loss = 3.69041
I0811 17:57:56.760532 26953 solver.cpp:244]     Train net output #0: loss = 3.69041 (* 1 = 3.69041 loss)
I0811 17:57:58.176362 26953 sgd_solver.cpp:106] Iteration 3450, lr = 0.01
I0811 17:58:16.704154 26953 solver.cpp:228] Iteration 3460, loss = 3.53598
I0811 17:58:16.704334 26953 solver.cpp:244]     Train net output #0: loss = 3.53598 (* 1 = 3.53598 loss)
I0811 17:58:18.116544 26953 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0811 17:58:36.666365 26953 solver.cpp:228] Iteration 3470, loss = 3.62233
I0811 17:58:36.666435 26953 solver.cpp:244]     Train net output #0: loss = 3.62233 (* 1 = 3.62233 loss)
I0811 17:58:38.095067 26953 sgd_solver.cpp:106] Iteration 3470, lr = 0.01
I0811 17:58:56.603538 26953 solver.cpp:228] Iteration 3480, loss = 3.58788
I0811 17:58:56.603793 26953 solver.cpp:244]     Train net output #0: loss = 3.58788 (* 1 = 3.58788 loss)
I0811 17:58:58.028690 26953 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0811 17:59:16.609689 26953 solver.cpp:228] Iteration 3490, loss = 3.6285
I0811 17:59:16.609760 26953 solver.cpp:244]     Train net output #0: loss = 3.6285 (* 1 = 3.6285 loss)
I0811 17:59:18.031174 26953 sgd_solver.cpp:106] Iteration 3490, lr = 0.01
I0811 17:59:35.975625 26953 solver.cpp:337] Iteration 3500, Testing net (#0)
I0811 17:59:36.572368 26953 solver.cpp:404]     Test net output #0: accuracy = 0.334
I0811 17:59:36.572443 26953 solver.cpp:404]     Test net output #1: loss = 3.28419 (* 1 = 3.28419 loss)
I0811 17:59:37.144680 26953 solver.cpp:228] Iteration 3500, loss = 3.43287
I0811 17:59:37.144753 26953 solver.cpp:244]     Train net output #0: loss = 3.43287 (* 1 = 3.43287 loss)
I0811 17:59:38.543946 26953 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0811 17:59:57.037896 26953 solver.cpp:228] Iteration 3510, loss = 3.49383
I0811 17:59:57.037962 26953 solver.cpp:244]     Train net output #0: loss = 3.49383 (* 1 = 3.49383 loss)
I0811 17:59:58.447321 26953 sgd_solver.cpp:106] Iteration 3510, lr = 0.01
I0811 18:00:16.973896 26953 solver.cpp:228] Iteration 3520, loss = 3.63078
I0811 18:00:16.974179 26953 solver.cpp:244]     Train net output #0: loss = 3.63078 (* 1 = 3.63078 loss)
I0811 18:00:18.383967 26953 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0811 18:00:36.906141 26953 solver.cpp:228] Iteration 3530, loss = 3.49016
I0811 18:00:36.906203 26953 solver.cpp:244]     Train net output #0: loss = 3.49016 (* 1 = 3.49016 loss)
I0811 18:00:38.327616 26953 sgd_solver.cpp:106] Iteration 3530, lr = 0.01
I0811 18:00:56.912356 26953 solver.cpp:228] Iteration 3540, loss = 3.58211
I0811 18:00:56.912590 26953 solver.cpp:244]     Train net output #0: loss = 3.58211 (* 1 = 3.58211 loss)
I0811 18:00:58.335919 26953 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0811 18:01:16.868393 26953 solver.cpp:228] Iteration 3550, loss = 3.48612
I0811 18:01:16.868463 26953 solver.cpp:244]     Train net output #0: loss = 3.48612 (* 1 = 3.48612 loss)
I0811 18:01:18.302325 26953 sgd_solver.cpp:106] Iteration 3550, lr = 0.01
I0811 18:01:36.845301 26953 solver.cpp:228] Iteration 3560, loss = 3.47339
I0811 18:01:36.845502 26953 solver.cpp:244]     Train net output #0: loss = 3.47339 (* 1 = 3.47339 loss)
I0811 18:01:38.253351 26953 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0811 18:01:56.797086 26953 solver.cpp:228] Iteration 3570, loss = 3.59932
I0811 18:01:56.797155 26953 solver.cpp:244]     Train net output #0: loss = 3.59932 (* 1 = 3.59932 loss)
I0811 18:01:58.217519 26953 sgd_solver.cpp:106] Iteration 3570, lr = 0.01
I0811 18:02:16.725613 26953 solver.cpp:228] Iteration 3580, loss = 3.70922
I0811 18:02:16.725852 26953 solver.cpp:244]     Train net output #0: loss = 3.70922 (* 1 = 3.70922 loss)
I0811 18:02:18.139159 26953 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0811 18:02:36.708019 26953 solver.cpp:228] Iteration 3590, loss = 3.45607
I0811 18:02:36.708333 26953 solver.cpp:244]     Train net output #0: loss = 3.45607 (* 1 = 3.45607 loss)
I0811 18:02:38.127959 26953 sgd_solver.cpp:106] Iteration 3590, lr = 0.01
I0811 18:02:56.072518 26953 solver.cpp:337] Iteration 3600, Testing net (#0)
I0811 18:02:56.665864 26953 solver.cpp:404]     Test net output #0: accuracy = 0.292
I0811 18:02:56.665938 26953 solver.cpp:404]     Test net output #1: loss = 3.42498 (* 1 = 3.42498 loss)
I0811 18:02:57.226420 26953 solver.cpp:228] Iteration 3600, loss = 3.34494
I0811 18:02:57.226487 26953 solver.cpp:244]     Train net output #0: loss = 3.34494 (* 1 = 3.34494 loss)
I0811 18:02:58.633800 26953 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0811 18:03:17.128602 26953 solver.cpp:228] Iteration 3610, loss = 3.24477
I0811 18:03:17.128667 26953 solver.cpp:244]     Train net output #0: loss = 3.24477 (* 1 = 3.24477 loss)
I0811 18:03:18.550768 26953 sgd_solver.cpp:106] Iteration 3610, lr = 0.01
I0811 18:03:37.101903 26953 solver.cpp:228] Iteration 3620, loss = 3.48435
I0811 18:03:37.102161 26953 solver.cpp:244]     Train net output #0: loss = 3.48435 (* 1 = 3.48435 loss)
I0811 18:03:38.513062 26953 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0811 18:03:57.038831 26953 solver.cpp:228] Iteration 3630, loss = 3.63868
I0811 18:03:57.038913 26953 solver.cpp:244]     Train net output #0: loss = 3.63868 (* 1 = 3.63868 loss)
I0811 18:03:58.449553 26953 sgd_solver.cpp:106] Iteration 3630, lr = 0.01
I0811 18:04:17.013269 26953 solver.cpp:228] Iteration 3640, loss = 3.51739
I0811 18:04:17.013422 26953 solver.cpp:244]     Train net output #0: loss = 3.51739 (* 1 = 3.51739 loss)
I0811 18:04:18.429822 26953 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0811 18:04:36.948462 26953 solver.cpp:228] Iteration 3650, loss = 3.37655
I0811 18:04:36.948525 26953 solver.cpp:244]     Train net output #0: loss = 3.37655 (* 1 = 3.37655 loss)
I0811 18:04:38.375399 26953 sgd_solver.cpp:106] Iteration 3650, lr = 0.01
I0811 18:04:56.921933 26953 solver.cpp:228] Iteration 3660, loss = 3.59824
I0811 18:04:56.922144 26953 solver.cpp:244]     Train net output #0: loss = 3.59824 (* 1 = 3.59824 loss)
I0811 18:04:58.343552 26953 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0811 18:05:16.886879 26953 solver.cpp:228] Iteration 3670, loss = 3.75456
I0811 18:05:16.886950 26953 solver.cpp:244]     Train net output #0: loss = 3.75456 (* 1 = 3.75456 loss)
I0811 18:05:18.320549 26953 sgd_solver.cpp:106] Iteration 3670, lr = 0.01
I0811 18:05:36.849464 26953 solver.cpp:228] Iteration 3680, loss = 3.43818
I0811 18:05:36.849686 26953 solver.cpp:244]     Train net output #0: loss = 3.43818 (* 1 = 3.43818 loss)
I0811 18:05:38.256963 26953 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0811 18:05:56.806851 26953 solver.cpp:228] Iteration 3690, loss = 3.66242
I0811 18:05:56.806920 26953 solver.cpp:244]     Train net output #0: loss = 3.66242 (* 1 = 3.66242 loss)
I0811 18:05:58.226317 26953 sgd_solver.cpp:106] Iteration 3690, lr = 0.01
I0811 18:06:16.169775 26953 solver.cpp:337] Iteration 3700, Testing net (#0)
I0811 18:06:16.768085 26953 solver.cpp:404]     Test net output #0: accuracy = 0.312
I0811 18:06:16.768193 26953 solver.cpp:404]     Test net output #1: loss = 3.32897 (* 1 = 3.32897 loss)
I0811 18:06:17.336748 26953 solver.cpp:228] Iteration 3700, loss = 3.52218
I0811 18:06:17.336824 26953 solver.cpp:244]     Train net output #0: loss = 3.52218 (* 1 = 3.52218 loss)
I0811 18:06:18.721258 26953 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0811 18:06:37.208816 26953 solver.cpp:228] Iteration 3710, loss = 3.54719
I0811 18:06:37.208879 26953 solver.cpp:244]     Train net output #0: loss = 3.54719 (* 1 = 3.54719 loss)
I0811 18:06:38.615288 26953 sgd_solver.cpp:106] Iteration 3710, lr = 0.01
I0811 18:06:57.176990 26953 solver.cpp:228] Iteration 3720, loss = 3.34483
I0811 18:06:57.177135 26953 solver.cpp:244]     Train net output #0: loss = 3.34483 (* 1 = 3.34483 loss)
I0811 18:06:58.607861 26953 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0811 18:07:17.149969 26953 solver.cpp:228] Iteration 3730, loss = 3.69412
I0811 18:07:17.150037 26953 solver.cpp:244]     Train net output #0: loss = 3.69412 (* 1 = 3.69412 loss)
I0811 18:07:18.564002 26953 sgd_solver.cpp:106] Iteration 3730, lr = 0.01
I0811 18:07:37.099170 26953 solver.cpp:228] Iteration 3740, loss = 3.57281
I0811 18:07:37.099380 26953 solver.cpp:244]     Train net output #0: loss = 3.57281 (* 1 = 3.57281 loss)
I0811 18:07:38.528698 26953 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0811 18:07:57.052942 26953 solver.cpp:228] Iteration 3750, loss = 3.59093
I0811 18:07:57.053009 26953 solver.cpp:244]     Train net output #0: loss = 3.59093 (* 1 = 3.59093 loss)
I0811 18:07:58.467061 26953 sgd_solver.cpp:106] Iteration 3750, lr = 0.01
I0811 18:08:17.005560 26953 solver.cpp:228] Iteration 3760, loss = 3.57127
I0811 18:08:17.005785 26953 solver.cpp:244]     Train net output #0: loss = 3.57127 (* 1 = 3.57127 loss)
I0811 18:08:18.423918 26953 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0811 18:08:36.965819 26953 solver.cpp:228] Iteration 3770, loss = 3.47962
I0811 18:08:36.965885 26953 solver.cpp:244]     Train net output #0: loss = 3.47962 (* 1 = 3.47962 loss)
I0811 18:08:38.391019 26953 sgd_solver.cpp:106] Iteration 3770, lr = 0.01
I0811 18:08:56.952853 26953 solver.cpp:228] Iteration 3780, loss = 3.46378
I0811 18:08:56.953074 26953 solver.cpp:244]     Train net output #0: loss = 3.46378 (* 1 = 3.46378 loss)
I0811 18:08:58.393014 26953 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0811 18:09:16.918519 26953 solver.cpp:228] Iteration 3790, loss = 3.41159
I0811 18:09:16.918587 26953 solver.cpp:244]     Train net output #0: loss = 3.41159 (* 1 = 3.41159 loss)
I0811 18:09:18.323256 26953 sgd_solver.cpp:106] Iteration 3790, lr = 0.01
I0811 18:09:36.273448 26953 solver.cpp:337] Iteration 3800, Testing net (#0)
I0811 18:09:36.873075 26953 solver.cpp:404]     Test net output #0: accuracy = 0.378
I0811 18:09:36.873162 26953 solver.cpp:404]     Test net output #1: loss = 3.15504 (* 1 = 3.15504 loss)
I0811 18:09:37.434079 26953 solver.cpp:228] Iteration 3800, loss = 3.44128
I0811 18:09:37.434150 26953 solver.cpp:244]     Train net output #0: loss = 3.44128 (* 1 = 3.44128 loss)
I0811 18:09:38.813419 26953 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0811 18:09:57.308723 26953 solver.cpp:228] Iteration 3810, loss = 3.44736
I0811 18:09:57.308796 26953 solver.cpp:244]     Train net output #0: loss = 3.44736 (* 1 = 3.44736 loss)
I0811 18:09:58.732012 26953 sgd_solver.cpp:106] Iteration 3810, lr = 0.01
I0811 18:10:17.269918 26953 solver.cpp:228] Iteration 3820, loss = 3.753
I0811 18:10:17.270189 26953 solver.cpp:244]     Train net output #0: loss = 3.753 (* 1 = 3.753 loss)
I0811 18:10:18.689347 26953 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0811 18:10:37.233415 26953 solver.cpp:228] Iteration 3830, loss = 3.57168
I0811 18:10:37.233477 26953 solver.cpp:244]     Train net output #0: loss = 3.57168 (* 1 = 3.57168 loss)
I0811 18:10:38.664285 26953 sgd_solver.cpp:106] Iteration 3830, lr = 0.01
I0811 18:10:57.209166 26953 solver.cpp:228] Iteration 3840, loss = 3.60322
I0811 18:10:57.209419 26953 solver.cpp:244]     Train net output #0: loss = 3.60322 (* 1 = 3.60322 loss)
I0811 18:10:58.628355 26953 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0811 18:11:17.195416 26953 solver.cpp:228] Iteration 3850, loss = 3.41203
I0811 18:11:17.195492 26953 solver.cpp:244]     Train net output #0: loss = 3.41203 (* 1 = 3.41203 loss)
I0811 18:11:18.596560 26953 sgd_solver.cpp:106] Iteration 3850, lr = 0.01
I0811 18:11:37.126931 26953 solver.cpp:228] Iteration 3860, loss = 3.1755
I0811 18:11:37.127117 26953 solver.cpp:244]     Train net output #0: loss = 3.1755 (* 1 = 3.1755 loss)
I0811 18:11:38.543216 26953 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0811 18:11:57.061247 26953 solver.cpp:228] Iteration 3870, loss = 3.64815
I0811 18:11:57.061314 26953 solver.cpp:244]     Train net output #0: loss = 3.64815 (* 1 = 3.64815 loss)
I0811 18:11:58.487067 26953 sgd_solver.cpp:106] Iteration 3870, lr = 0.01
I0811 18:12:17.015158 26953 solver.cpp:228] Iteration 3880, loss = 3.4702
I0811 18:12:17.015374 26953 solver.cpp:244]     Train net output #0: loss = 3.4702 (* 1 = 3.4702 loss)
I0811 18:12:18.430403 26953 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0811 18:12:36.976477 26953 solver.cpp:228] Iteration 3890, loss = 3.56658
I0811 18:12:36.976552 26953 solver.cpp:244]     Train net output #0: loss = 3.56658 (* 1 = 3.56658 loss)
I0811 18:12:38.411433 26953 sgd_solver.cpp:106] Iteration 3890, lr = 0.01
I0811 18:12:56.399762 26953 solver.cpp:337] Iteration 3900, Testing net (#0)
I0811 18:12:57.001356 26953 solver.cpp:404]     Test net output #0: accuracy = 0.334
I0811 18:12:57.001456 26953 solver.cpp:404]     Test net output #1: loss = 3.1033 (* 1 = 3.1033 loss)
I0811 18:12:57.598006 26953 solver.cpp:228] Iteration 3900, loss = 3.51235
I0811 18:12:57.598094 26953 solver.cpp:244]     Train net output #0: loss = 3.51235 (* 1 = 3.51235 loss)
I0811 18:12:58.952303 26953 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0811 18:13:17.427479 26953 solver.cpp:228] Iteration 3910, loss = 3.56447
I0811 18:13:17.427546 26953 solver.cpp:244]     Train net output #0: loss = 3.56447 (* 1 = 3.56447 loss)
I0811 18:13:18.844419 26953 sgd_solver.cpp:106] Iteration 3910, lr = 0.01
I0811 18:13:37.350385 26953 solver.cpp:228] Iteration 3920, loss = 3.51559
I0811 18:13:37.351003 26953 solver.cpp:244]     Train net output #0: loss = 3.51559 (* 1 = 3.51559 loss)
I0811 18:13:38.779006 26953 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0811 18:13:57.346807 26953 solver.cpp:228] Iteration 3930, loss = 3.38582
I0811 18:13:57.346873 26953 solver.cpp:244]     Train net output #0: loss = 3.38582 (* 1 = 3.38582 loss)
I0811 18:13:58.763876 26953 sgd_solver.cpp:106] Iteration 3930, lr = 0.01
I0811 18:14:17.258934 26953 solver.cpp:228] Iteration 3940, loss = 3.33418
I0811 18:14:17.259173 26953 solver.cpp:244]     Train net output #0: loss = 3.33418 (* 1 = 3.33418 loss)
I0811 18:14:18.694046 26953 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0811 18:14:37.246175 26953 solver.cpp:228] Iteration 3950, loss = 3.45145
I0811 18:14:37.246242 26953 solver.cpp:244]     Train net output #0: loss = 3.45145 (* 1 = 3.45145 loss)
I0811 18:14:38.664127 26953 sgd_solver.cpp:106] Iteration 3950, lr = 0.01
I0811 18:14:57.225440 26953 solver.cpp:228] Iteration 3960, loss = 3.48956
I0811 18:14:57.225718 26953 solver.cpp:244]     Train net output #0: loss = 3.48956 (* 1 = 3.48956 loss)
I0811 18:14:58.643415 26953 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0811 18:15:17.174849 26953 solver.cpp:228] Iteration 3970, loss = 3.44696
I0811 18:15:17.174913 26953 solver.cpp:244]     Train net output #0: loss = 3.44696 (* 1 = 3.44696 loss)
I0811 18:15:18.564154 26953 sgd_solver.cpp:106] Iteration 3970, lr = 0.01
I0811 18:15:37.145390 26953 solver.cpp:228] Iteration 3980, loss = 3.44419
I0811 18:15:37.145624 26953 solver.cpp:244]     Train net output #0: loss = 3.44419 (* 1 = 3.44419 loss)
I0811 18:15:38.558852 26953 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0811 18:15:57.060968 26953 solver.cpp:228] Iteration 3990, loss = 3.36376
I0811 18:15:57.061036 26953 solver.cpp:244]     Train net output #0: loss = 3.36376 (* 1 = 3.36376 loss)
I0811 18:15:58.478560 26953 sgd_solver.cpp:106] Iteration 3990, lr = 0.01
I0811 18:16:16.341361 26953 solver.cpp:337] Iteration 4000, Testing net (#0)
I0811 18:16:16.936170 26953 solver.cpp:404]     Test net output #0: accuracy = 0.302
I0811 18:16:16.936233 26953 solver.cpp:404]     Test net output #1: loss = 3.35205 (* 1 = 3.35205 loss)
I0811 18:16:17.520553 26953 solver.cpp:228] Iteration 4000, loss = 3.33744
I0811 18:16:17.520627 26953 solver.cpp:244]     Train net output #0: loss = 3.33744 (* 1 = 3.33744 loss)
I0811 18:16:18.912677 26953 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0811 18:16:37.358078 26953 solver.cpp:228] Iteration 4010, loss = 3.44673
I0811 18:16:37.358140 26953 solver.cpp:244]     Train net output #0: loss = 3.44673 (* 1 = 3.44673 loss)
I0811 18:16:38.752971 26953 sgd_solver.cpp:106] Iteration 4010, lr = 0.01
I0811 18:16:57.230757 26953 solver.cpp:228] Iteration 4020, loss = 3.34875
I0811 18:16:57.231000 26953 solver.cpp:244]     Train net output #0: loss = 3.34875 (* 1 = 3.34875 loss)
I0811 18:16:58.642822 26953 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0811 18:17:17.136991 26953 solver.cpp:228] Iteration 4030, loss = 3.43844
I0811 18:17:17.137092 26953 solver.cpp:244]     Train net output #0: loss = 3.43844 (* 1 = 3.43844 loss)
I0811 18:17:18.566776 26953 sgd_solver.cpp:106] Iteration 4030, lr = 0.01
I0811 18:17:37.035410 26953 solver.cpp:228] Iteration 4040, loss = 3.35904
I0811 18:17:37.035648 26953 solver.cpp:244]     Train net output #0: loss = 3.35904 (* 1 = 3.35904 loss)
I0811 18:17:38.448878 26953 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0811 18:17:56.886369 26953 solver.cpp:228] Iteration 4050, loss = 3.48865
I0811 18:17:56.886435 26953 solver.cpp:244]     Train net output #0: loss = 3.48865 (* 1 = 3.48865 loss)
I0811 18:17:58.294751 26953 sgd_solver.cpp:106] Iteration 4050, lr = 0.01
I0811 18:18:16.816572 26953 solver.cpp:228] Iteration 4060, loss = 3.38696
I0811 18:18:16.816840 26953 solver.cpp:244]     Train net output #0: loss = 3.38696 (* 1 = 3.38696 loss)
I0811 18:18:18.251432 26953 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0811 18:18:36.788471 26953 solver.cpp:228] Iteration 4070, loss = 3.41707
I0811 18:18:36.788537 26953 solver.cpp:244]     Train net output #0: loss = 3.41707 (* 1 = 3.41707 loss)
I0811 18:18:38.178797 26953 sgd_solver.cpp:106] Iteration 4070, lr = 0.01
I0811 18:18:56.748291 26953 solver.cpp:228] Iteration 4080, loss = 3.37914
I0811 18:18:56.748538 26953 solver.cpp:244]     Train net output #0: loss = 3.37914 (* 1 = 3.37914 loss)
I0811 18:18:58.157081 26953 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0811 18:19:16.678216 26953 solver.cpp:228] Iteration 4090, loss = 3.25687
I0811 18:19:16.678277 26953 solver.cpp:244]     Train net output #0: loss = 3.25687 (* 1 = 3.25687 loss)
I0811 18:19:18.076563 26953 sgd_solver.cpp:106] Iteration 4090, lr = 0.01
I0811 18:19:36.067662 26953 solver.cpp:337] Iteration 4100, Testing net (#0)
I0811 18:19:36.673589 26953 solver.cpp:404]     Test net output #0: accuracy = 0.33
I0811 18:19:36.673712 26953 solver.cpp:404]     Test net output #1: loss = 3.18504 (* 1 = 3.18504 loss)
I0811 18:19:37.249253 26953 solver.cpp:228] Iteration 4100, loss = 3.40667
I0811 18:19:37.249321 26953 solver.cpp:244]     Train net output #0: loss = 3.40667 (* 1 = 3.40667 loss)
I0811 18:19:38.627946 26953 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0811 18:19:57.118885 26953 solver.cpp:228] Iteration 4110, loss = 3.45394
I0811 18:19:57.118948 26953 solver.cpp:244]     Train net output #0: loss = 3.45394 (* 1 = 3.45394 loss)
I0811 18:19:58.542249 26953 sgd_solver.cpp:106] Iteration 4110, lr = 0.01
I0811 18:20:17.081660 26953 solver.cpp:228] Iteration 4120, loss = 3.36917
I0811 18:20:17.081897 26953 solver.cpp:244]     Train net output #0: loss = 3.36917 (* 1 = 3.36917 loss)
I0811 18:20:18.492539 26953 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0811 18:20:37.043937 26953 solver.cpp:228] Iteration 4130, loss = 3.4478
I0811 18:20:37.044013 26953 solver.cpp:244]     Train net output #0: loss = 3.4478 (* 1 = 3.4478 loss)
I0811 18:20:38.451815 26953 sgd_solver.cpp:106] Iteration 4130, lr = 0.01
I0811 18:20:56.951390 26953 solver.cpp:228] Iteration 4140, loss = 3.36117
I0811 18:20:56.951639 26953 solver.cpp:244]     Train net output #0: loss = 3.36117 (* 1 = 3.36117 loss)
I0811 18:20:58.378870 26953 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0811 18:21:16.981134 26953 solver.cpp:228] Iteration 4150, loss = 3.30301
I0811 18:21:16.981205 26953 solver.cpp:244]     Train net output #0: loss = 3.30301 (* 1 = 3.30301 loss)
I0811 18:21:18.404299 26953 sgd_solver.cpp:106] Iteration 4150, lr = 0.01
I0811 18:21:36.911990 26953 solver.cpp:228] Iteration 4160, loss = 3.28961
I0811 18:21:36.912267 26953 solver.cpp:244]     Train net output #0: loss = 3.28961 (* 1 = 3.28961 loss)
I0811 18:21:38.334017 26953 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0811 18:21:56.870259 26953 solver.cpp:228] Iteration 4170, loss = 3.33889
I0811 18:21:56.870323 26953 solver.cpp:244]     Train net output #0: loss = 3.33889 (* 1 = 3.33889 loss)
I0811 18:21:58.261726 26953 sgd_solver.cpp:106] Iteration 4170, lr = 0.01
I0811 18:22:16.758097 26953 solver.cpp:228] Iteration 4180, loss = 3.29087
I0811 18:22:16.758355 26953 solver.cpp:244]     Train net output #0: loss = 3.29087 (* 1 = 3.29087 loss)
I0811 18:22:18.156899 26953 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0811 18:22:36.577620 26953 solver.cpp:228] Iteration 4190, loss = 3.43212
I0811 18:22:36.577687 26953 solver.cpp:244]     Train net output #0: loss = 3.43212 (* 1 = 3.43212 loss)
I0811 18:22:37.986052 26953 sgd_solver.cpp:106] Iteration 4190, lr = 0.01
I0811 18:22:55.916069 26953 solver.cpp:337] Iteration 4200, Testing net (#0)
I0811 18:22:56.521304 26953 solver.cpp:404]     Test net output #0: accuracy = 0.318
I0811 18:22:56.521503 26953 solver.cpp:404]     Test net output #1: loss = 3.18182 (* 1 = 3.18182 loss)
I0811 18:22:57.089902 26953 solver.cpp:228] Iteration 4200, loss = 3.41602
I0811 18:22:57.089980 26953 solver.cpp:244]     Train net output #0: loss = 3.41602 (* 1 = 3.41602 loss)
I0811 18:22:58.479552 26953 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0811 18:23:16.983120 26953 solver.cpp:228] Iteration 4210, loss = 3.51527
I0811 18:23:16.983186 26953 solver.cpp:244]     Train net output #0: loss = 3.51527 (* 1 = 3.51527 loss)
I0811 18:23:18.400374 26953 sgd_solver.cpp:106] Iteration 4210, lr = 0.01
I0811 18:23:36.925393 26953 solver.cpp:228] Iteration 4220, loss = 3.12706
I0811 18:23:36.925626 26953 solver.cpp:244]     Train net output #0: loss = 3.12706 (* 1 = 3.12706 loss)
I0811 18:23:38.342286 26953 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0811 18:23:56.885939 26953 solver.cpp:228] Iteration 4230, loss = 3.3343
I0811 18:23:56.886005 26953 solver.cpp:244]     Train net output #0: loss = 3.3343 (* 1 = 3.3343 loss)
I0811 18:23:58.302989 26953 sgd_solver.cpp:106] Iteration 4230, lr = 0.01
I0811 18:24:16.850102 26953 solver.cpp:228] Iteration 4240, loss = 3.45369
I0811 18:24:16.850350 26953 solver.cpp:244]     Train net output #0: loss = 3.45369 (* 1 = 3.45369 loss)
I0811 18:24:18.272370 26953 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0811 18:24:36.774710 26953 solver.cpp:228] Iteration 4250, loss = 3.40008
I0811 18:24:36.774772 26953 solver.cpp:244]     Train net output #0: loss = 3.40008 (* 1 = 3.40008 loss)
I0811 18:24:38.185495 26953 sgd_solver.cpp:106] Iteration 4250, lr = 0.01
I0811 18:24:56.652855 26953 solver.cpp:228] Iteration 4260, loss = 3.47519
I0811 18:24:56.653026 26953 solver.cpp:244]     Train net output #0: loss = 3.47519 (* 1 = 3.47519 loss)
I0811 18:24:58.050431 26953 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0811 18:25:16.493091 26953 solver.cpp:228] Iteration 4270, loss = 3.39109
I0811 18:25:16.493193 26953 solver.cpp:244]     Train net output #0: loss = 3.39109 (* 1 = 3.39109 loss)
I0811 18:25:17.914876 26953 sgd_solver.cpp:106] Iteration 4270, lr = 0.01
I0811 18:25:36.340592 26953 solver.cpp:228] Iteration 4280, loss = 3.44779
I0811 18:25:36.340842 26953 solver.cpp:244]     Train net output #0: loss = 3.44779 (* 1 = 3.44779 loss)
I0811 18:25:37.738992 26953 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0811 18:25:56.152086 26953 solver.cpp:228] Iteration 4290, loss = 3.21888
I0811 18:25:56.152174 26953 solver.cpp:244]     Train net output #0: loss = 3.21888 (* 1 = 3.21888 loss)
I0811 18:25:57.597417 26953 sgd_solver.cpp:106] Iteration 4290, lr = 0.01
I0811 18:26:15.576127 26953 solver.cpp:337] Iteration 4300, Testing net (#0)
I0811 18:26:16.173152 26953 solver.cpp:404]     Test net output #0: accuracy = 0.324
I0811 18:26:16.178798 26953 solver.cpp:404]     Test net output #1: loss = 3.21099 (* 1 = 3.21099 loss)
I0811 18:26:16.744897 26953 solver.cpp:228] Iteration 4300, loss = 3.26965
I0811 18:26:16.744971 26953 solver.cpp:244]     Train net output #0: loss = 3.26965 (* 1 = 3.26965 loss)
I0811 18:26:18.117872 26953 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0811 18:26:36.573097 26953 solver.cpp:228] Iteration 4310, loss = 3.37468
I0811 18:26:36.573163 26953 solver.cpp:244]     Train net output #0: loss = 3.37468 (* 1 = 3.37468 loss)
I0811 18:26:37.993666 26953 sgd_solver.cpp:106] Iteration 4310, lr = 0.01
I0811 18:26:56.508251 26953 solver.cpp:228] Iteration 4320, loss = 3.29475
I0811 18:26:56.508507 26953 solver.cpp:244]     Train net output #0: loss = 3.29475 (* 1 = 3.29475 loss)
I0811 18:26:57.939507 26953 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0811 18:27:16.522198 26953 solver.cpp:228] Iteration 4330, loss = 3.2357
I0811 18:27:16.522269 26953 solver.cpp:244]     Train net output #0: loss = 3.2357 (* 1 = 3.2357 loss)
I0811 18:27:17.935695 26953 sgd_solver.cpp:106] Iteration 4330, lr = 0.01
I0811 18:27:36.443888 26953 solver.cpp:228] Iteration 4340, loss = 3.36801
I0811 18:27:36.444133 26953 solver.cpp:244]     Train net output #0: loss = 3.36801 (* 1 = 3.36801 loss)
I0811 18:27:37.875901 26953 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0811 18:27:56.371351 26953 solver.cpp:228] Iteration 4350, loss = 3.33471
I0811 18:27:56.371410 26953 solver.cpp:244]     Train net output #0: loss = 3.33471 (* 1 = 3.33471 loss)
I0811 18:27:57.789151 26953 sgd_solver.cpp:106] Iteration 4350, lr = 0.01
I0811 18:28:16.327564 26953 solver.cpp:228] Iteration 4360, loss = 3.31815
I0811 18:28:16.327812 26953 solver.cpp:244]     Train net output #0: loss = 3.31815 (* 1 = 3.31815 loss)
I0811 18:28:17.729136 26953 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0811 18:28:36.134521 26953 solver.cpp:228] Iteration 4370, loss = 3.17812
I0811 18:28:36.134600 26953 solver.cpp:244]     Train net output #0: loss = 3.17812 (* 1 = 3.17812 loss)
I0811 18:28:37.533273 26953 sgd_solver.cpp:106] Iteration 4370, lr = 0.01
I0811 18:28:56.012912 26953 solver.cpp:228] Iteration 4380, loss = 3.26929
I0811 18:28:56.013203 26953 solver.cpp:244]     Train net output #0: loss = 3.26929 (* 1 = 3.26929 loss)
I0811 18:28:57.446893 26953 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0811 18:29:15.995276 26953 solver.cpp:228] Iteration 4390, loss = 3.224
I0811 18:29:15.995353 26953 solver.cpp:244]     Train net output #0: loss = 3.224 (* 1 = 3.224 loss)
I0811 18:29:17.407290 26953 sgd_solver.cpp:106] Iteration 4390, lr = 0.01
I0811 18:29:35.362246 26953 solver.cpp:337] Iteration 4400, Testing net (#0)
I0811 18:29:35.963737 26953 solver.cpp:404]     Test net output #0: accuracy = 0.226
I0811 18:29:35.963840 26953 solver.cpp:404]     Test net output #1: loss = 4.1187 (* 1 = 4.1187 loss)
I0811 18:29:36.531741 26953 solver.cpp:228] Iteration 4400, loss = 4.42603
I0811 18:29:36.531844 26953 solver.cpp:244]     Train net output #0: loss = 4.42603 (* 1 = 4.42603 loss)
I0811 18:29:37.934957 26953 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0811 18:29:56.384037 26953 solver.cpp:228] Iteration 4410, loss = 3.57563
I0811 18:29:56.384093 26953 solver.cpp:244]     Train net output #0: loss = 3.57563 (* 1 = 3.57563 loss)
I0811 18:29:57.798171 26953 sgd_solver.cpp:106] Iteration 4410, lr = 0.01
I0811 18:30:16.261291 26953 solver.cpp:228] Iteration 4420, loss = 3.53381
I0811 18:30:16.261445 26953 solver.cpp:244]     Train net output #0: loss = 3.53381 (* 1 = 3.53381 loss)
I0811 18:30:17.671825 26953 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0811 18:30:36.104333 26953 solver.cpp:228] Iteration 4430, loss = 3.35651
I0811 18:30:36.104400 26953 solver.cpp:244]     Train net output #0: loss = 3.35651 (* 1 = 3.35651 loss)
I0811 18:30:37.520891 26953 sgd_solver.cpp:106] Iteration 4430, lr = 0.01
I0811 18:30:56.044837 26953 solver.cpp:228] Iteration 4440, loss = 3.37658
I0811 18:30:56.045135 26953 solver.cpp:244]     Train net output #0: loss = 3.37658 (* 1 = 3.37658 loss)
I0811 18:30:57.470662 26953 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0811 18:31:15.993211 26953 solver.cpp:228] Iteration 4450, loss = 3.36772
I0811 18:31:15.993278 26953 solver.cpp:244]     Train net output #0: loss = 3.36772 (* 1 = 3.36772 loss)
I0811 18:31:17.394996 26953 sgd_solver.cpp:106] Iteration 4450, lr = 0.01
I0811 18:31:35.830199 26953 solver.cpp:228] Iteration 4460, loss = 3.30071
I0811 18:31:35.830395 26953 solver.cpp:244]     Train net output #0: loss = 3.30071 (* 1 = 3.30071 loss)
I0811 18:31:37.236759 26953 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0811 18:31:55.702692 26953 solver.cpp:228] Iteration 4470, loss = 3.30962
I0811 18:31:55.702759 26953 solver.cpp:244]     Train net output #0: loss = 3.30962 (* 1 = 3.30962 loss)
I0811 18:31:57.131355 26953 sgd_solver.cpp:106] Iteration 4470, lr = 0.01
I0811 18:32:15.623416 26953 solver.cpp:228] Iteration 4480, loss = 3.27888
I0811 18:32:15.623672 26953 solver.cpp:244]     Train net output #0: loss = 3.27888 (* 1 = 3.27888 loss)
I0811 18:32:17.039842 26953 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0811 18:32:35.623499 26953 solver.cpp:228] Iteration 4490, loss = 3.24746
I0811 18:32:35.623576 26953 solver.cpp:244]     Train net output #0: loss = 3.24746 (* 1 = 3.24746 loss)
I0811 18:32:37.029402 26953 sgd_solver.cpp:106] Iteration 4490, lr = 0.01
I0811 18:32:54.950213 26953 solver.cpp:337] Iteration 4500, Testing net (#0)
I0811 18:32:55.545766 26953 solver.cpp:404]     Test net output #0: accuracy = 0.326
I0811 18:32:55.545863 26953 solver.cpp:404]     Test net output #1: loss = 3.04419 (* 1 = 3.04419 loss)
I0811 18:32:56.131415 26953 solver.cpp:228] Iteration 4500, loss = 3.23909
I0811 18:32:56.131492 26953 solver.cpp:244]     Train net output #0: loss = 3.23909 (* 1 = 3.23909 loss)
I0811 18:32:57.497864 26953 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0811 18:33:15.973459 26953 solver.cpp:228] Iteration 4510, loss = 3.18992
I0811 18:33:15.973520 26953 solver.cpp:244]     Train net output #0: loss = 3.18992 (* 1 = 3.18992 loss)
I0811 18:33:17.385618 26953 sgd_solver.cpp:106] Iteration 4510, lr = 0.01
I0811 18:33:35.826624 26953 solver.cpp:228] Iteration 4520, loss = 3.14365
I0811 18:33:35.826874 26953 solver.cpp:244]     Train net output #0: loss = 3.14365 (* 1 = 3.14365 loss)
I0811 18:33:37.221887 26953 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0811 18:33:55.716256 26953 solver.cpp:228] Iteration 4530, loss = 3.27788
I0811 18:33:55.716328 26953 solver.cpp:244]     Train net output #0: loss = 3.27788 (* 1 = 3.27788 loss)
I0811 18:33:57.131901 26953 sgd_solver.cpp:106] Iteration 4530, lr = 0.01
I0811 18:34:15.634585 26953 solver.cpp:228] Iteration 4540, loss = 3.14398
I0811 18:34:15.634886 26953 solver.cpp:244]     Train net output #0: loss = 3.14398 (* 1 = 3.14398 loss)
I0811 18:34:17.058974 26953 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0811 18:34:35.538166 26953 solver.cpp:228] Iteration 4550, loss = 3.32429
I0811 18:34:35.538245 26953 solver.cpp:244]     Train net output #0: loss = 3.32429 (* 1 = 3.32429 loss)
I0811 18:34:36.950831 26953 sgd_solver.cpp:106] Iteration 4550, lr = 0.01
I0811 18:34:55.371407 26953 solver.cpp:228] Iteration 4560, loss = 3.22345
I0811 18:34:55.371632 26953 solver.cpp:244]     Train net output #0: loss = 3.22345 (* 1 = 3.22345 loss)
I0811 18:34:56.790699 26953 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0811 18:35:15.286754 26953 solver.cpp:228] Iteration 4570, loss = 3.33927
I0811 18:35:15.286818 26953 solver.cpp:244]     Train net output #0: loss = 3.33927 (* 1 = 3.33927 loss)
I0811 18:35:16.706044 26953 sgd_solver.cpp:106] Iteration 4570, lr = 0.01
I0811 18:35:35.192945 26953 solver.cpp:228] Iteration 4580, loss = 3.20842
I0811 18:35:35.193228 26953 solver.cpp:244]     Train net output #0: loss = 3.20842 (* 1 = 3.20842 loss)
I0811 18:35:36.605764 26953 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0811 18:35:55.025713 26953 solver.cpp:228] Iteration 4590, loss = 3.1525
I0811 18:35:55.025780 26953 solver.cpp:244]     Train net output #0: loss = 3.1525 (* 1 = 3.1525 loss)
I0811 18:35:56.427601 26953 sgd_solver.cpp:106] Iteration 4590, lr = 0.01
I0811 18:36:14.334664 26953 solver.cpp:337] Iteration 4600, Testing net (#0)
I0811 18:36:14.927899 26953 solver.cpp:404]     Test net output #0: accuracy = 0.342
I0811 18:36:14.927963 26953 solver.cpp:404]     Test net output #1: loss = 3.02891 (* 1 = 3.02891 loss)
I0811 18:36:15.502977 26953 solver.cpp:228] Iteration 4600, loss = 3.01917
I0811 18:36:15.503054 26953 solver.cpp:244]     Train net output #0: loss = 3.01917 (* 1 = 3.01917 loss)
I0811 18:36:16.874873 26953 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0811 18:36:35.370669 26953 solver.cpp:228] Iteration 4610, loss = 3.15991
I0811 18:36:35.370735 26953 solver.cpp:244]     Train net output #0: loss = 3.15991 (* 1 = 3.15991 loss)
I0811 18:36:36.791100 26953 sgd_solver.cpp:106] Iteration 4610, lr = 0.01
I0811 18:36:55.326506 26953 solver.cpp:228] Iteration 4620, loss = 3.19099
I0811 18:36:55.326680 26953 solver.cpp:244]     Train net output #0: loss = 3.19099 (* 1 = 3.19099 loss)
I0811 18:36:56.731026 26953 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0811 18:37:15.237005 26953 solver.cpp:228] Iteration 4630, loss = 3.29509
I0811 18:37:15.237077 26953 solver.cpp:244]     Train net output #0: loss = 3.29509 (* 1 = 3.29509 loss)
I0811 18:37:16.639292 26953 sgd_solver.cpp:106] Iteration 4630, lr = 0.01
I0811 18:37:35.055716 26953 solver.cpp:228] Iteration 4640, loss = 3.25067
I0811 18:37:35.055953 26953 solver.cpp:244]     Train net output #0: loss = 3.25067 (* 1 = 3.25067 loss)
I0811 18:37:36.465237 26953 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0811 18:37:54.941072 26953 solver.cpp:228] Iteration 4650, loss = 3.20538
I0811 18:37:54.941136 26953 solver.cpp:244]     Train net output #0: loss = 3.20538 (* 1 = 3.20538 loss)
I0811 18:37:56.366154 26953 sgd_solver.cpp:106] Iteration 4650, lr = 0.01
I0811 18:38:14.927793 26953 solver.cpp:228] Iteration 4660, loss = 3.27564
I0811 18:38:14.928037 26953 solver.cpp:244]     Train net output #0: loss = 3.27564 (* 1 = 3.27564 loss)
I0811 18:38:16.355010 26953 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0811 18:38:34.869297 26953 solver.cpp:228] Iteration 4670, loss = 3.17467
I0811 18:38:34.869359 26953 solver.cpp:244]     Train net output #0: loss = 3.17467 (* 1 = 3.17467 loss)
I0811 18:38:36.291280 26953 sgd_solver.cpp:106] Iteration 4670, lr = 0.01
I0811 18:38:54.676317 26953 solver.cpp:228] Iteration 4680, loss = 3.15169
I0811 18:38:54.676504 26953 solver.cpp:244]     Train net output #0: loss = 3.15169 (* 1 = 3.15169 loss)
I0811 18:38:56.086493 26953 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0811 18:39:14.581712 26953 solver.cpp:228] Iteration 4690, loss = 3.28419
I0811 18:39:14.581779 26953 solver.cpp:244]     Train net output #0: loss = 3.28419 (* 1 = 3.28419 loss)
I0811 18:39:16.003093 26953 sgd_solver.cpp:106] Iteration 4690, lr = 0.01
I0811 18:39:33.967306 26953 solver.cpp:337] Iteration 4700, Testing net (#0)
I0811 18:39:34.558533 26953 solver.cpp:404]     Test net output #0: accuracy = 0.334
I0811 18:39:34.558596 26953 solver.cpp:404]     Test net output #1: loss = 3.14561 (* 1 = 3.14561 loss)
I0811 18:39:35.132112 26953 solver.cpp:228] Iteration 4700, loss = 3.4201
I0811 18:39:35.132206 26953 solver.cpp:244]     Train net output #0: loss = 3.4201 (* 1 = 3.4201 loss)
I0811 18:39:36.510604 26953 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0811 18:39:55.008000 26953 solver.cpp:228] Iteration 4710, loss = 3.1888
I0811 18:39:55.008069 26953 solver.cpp:244]     Train net output #0: loss = 3.1888 (* 1 = 3.1888 loss)
I0811 18:39:56.410125 26953 sgd_solver.cpp:106] Iteration 4710, lr = 0.01
I0811 18:40:14.941557 26953 solver.cpp:228] Iteration 4720, loss = 3.33249
I0811 18:40:14.941751 26953 solver.cpp:244]     Train net output #0: loss = 3.33249 (* 1 = 3.33249 loss)
I0811 18:40:16.358436 26953 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0811 18:40:34.865968 26953 solver.cpp:228] Iteration 4730, loss = 3.24283
I0811 18:40:34.866030 26953 solver.cpp:244]     Train net output #0: loss = 3.24283 (* 1 = 3.24283 loss)
I0811 18:40:36.286726 26953 sgd_solver.cpp:106] Iteration 4730, lr = 0.01
I0811 18:40:54.695412 26953 solver.cpp:228] Iteration 4740, loss = 3.34904
I0811 18:40:54.695660 26953 solver.cpp:244]     Train net output #0: loss = 3.34904 (* 1 = 3.34904 loss)
I0811 18:40:56.108893 26953 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0811 18:41:14.599958 26953 solver.cpp:228] Iteration 4750, loss = 3.19931
I0811 18:41:14.600029 26953 solver.cpp:244]     Train net output #0: loss = 3.19931 (* 1 = 3.19931 loss)
I0811 18:41:16.026839 26953 sgd_solver.cpp:106] Iteration 4750, lr = 0.01
I0811 18:41:34.556170 26953 solver.cpp:228] Iteration 4760, loss = 3.2564
I0811 18:41:34.556378 26953 solver.cpp:244]     Train net output #0: loss = 3.2564 (* 1 = 3.2564 loss)
I0811 18:41:35.970474 26953 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0811 18:41:54.474577 26953 solver.cpp:228] Iteration 4770, loss = 3.1505
I0811 18:41:54.474642 26953 solver.cpp:244]     Train net output #0: loss = 3.1505 (* 1 = 3.1505 loss)
I0811 18:41:55.887377 26953 sgd_solver.cpp:106] Iteration 4770, lr = 0.01
I0811 18:42:14.454169 26953 solver.cpp:228] Iteration 4780, loss = 3.09812
I0811 18:42:14.454419 26953 solver.cpp:244]     Train net output #0: loss = 3.09812 (* 1 = 3.09812 loss)
I0811 18:42:15.882171 26953 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0811 18:42:34.375360 26953 solver.cpp:228] Iteration 4790, loss = 3.01982
I0811 18:42:34.375433 26953 solver.cpp:244]     Train net output #0: loss = 3.01982 (* 1 = 3.01982 loss)
I0811 18:42:35.805620 26953 sgd_solver.cpp:106] Iteration 4790, lr = 0.01
I0811 18:42:53.642627 26953 solver.cpp:337] Iteration 4800, Testing net (#0)
I0811 18:42:54.237598 26953 solver.cpp:404]     Test net output #0: accuracy = 0.326
I0811 18:42:54.237669 26953 solver.cpp:404]     Test net output #1: loss = 3.06223 (* 1 = 3.06223 loss)
I0811 18:42:54.816905 26953 solver.cpp:228] Iteration 4800, loss = 3.29111
I0811 18:42:54.816987 26953 solver.cpp:244]     Train net output #0: loss = 3.29111 (* 1 = 3.29111 loss)
I0811 18:42:56.198369 26953 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0811 18:43:14.643743 26953 solver.cpp:228] Iteration 4810, loss = 3.31911
I0811 18:43:14.643808 26953 solver.cpp:244]     Train net output #0: loss = 3.31911 (* 1 = 3.31911 loss)
I0811 18:43:16.061514 26953 sgd_solver.cpp:106] Iteration 4810, lr = 0.01
I0811 18:43:34.570072 26953 solver.cpp:228] Iteration 4820, loss = 3.23363
I0811 18:43:34.570363 26953 solver.cpp:244]     Train net output #0: loss = 3.23363 (* 1 = 3.23363 loss)
I0811 18:43:35.985802 26953 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0811 18:43:54.484982 26953 solver.cpp:228] Iteration 4830, loss = 3.07388
I0811 18:43:54.485045 26953 solver.cpp:244]     Train net output #0: loss = 3.07388 (* 1 = 3.07388 loss)
I0811 18:43:55.895360 26953 sgd_solver.cpp:106] Iteration 4830, lr = 0.01
I0811 18:44:14.358660 26953 solver.cpp:228] Iteration 4840, loss = 3.15661
I0811 18:44:14.358934 26953 solver.cpp:244]     Train net output #0: loss = 3.15661 (* 1 = 3.15661 loss)
I0811 18:44:15.766528 26953 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0811 18:44:34.207918 26953 solver.cpp:228] Iteration 4850, loss = 3.12507
I0811 18:44:34.207983 26953 solver.cpp:244]     Train net output #0: loss = 3.12507 (* 1 = 3.12507 loss)
I0811 18:44:35.622841 26953 sgd_solver.cpp:106] Iteration 4850, lr = 0.01
I0811 18:44:54.149345 26953 solver.cpp:228] Iteration 4860, loss = 3.32388
I0811 18:44:54.149634 26953 solver.cpp:244]     Train net output #0: loss = 3.32388 (* 1 = 3.32388 loss)
I0811 18:44:55.568711 26953 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0811 18:45:14.069231 26953 solver.cpp:228] Iteration 4870, loss = 3.21042
I0811 18:45:14.069298 26953 solver.cpp:244]     Train net output #0: loss = 3.21042 (* 1 = 3.21042 loss)
I0811 18:45:15.488464 26953 sgd_solver.cpp:106] Iteration 4870, lr = 0.01
I0811 18:45:34.060987 26953 solver.cpp:228] Iteration 4880, loss = 2.97308
I0811 18:45:34.061247 26953 solver.cpp:244]     Train net output #0: loss = 2.97308 (* 1 = 2.97308 loss)
I0811 18:45:35.475172 26953 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0811 18:45:53.926409 26953 solver.cpp:228] Iteration 4890, loss = 3.15374
I0811 18:45:53.926481 26953 solver.cpp:244]     Train net output #0: loss = 3.15374 (* 1 = 3.15374 loss)
I0811 18:45:55.329433 26953 sgd_solver.cpp:106] Iteration 4890, lr = 0.01
I0811 18:46:13.190896 26953 solver.cpp:337] Iteration 4900, Testing net (#0)
I0811 18:46:13.795300 26953 solver.cpp:404]     Test net output #0: accuracy = 0.352
I0811 18:46:13.795377 26953 solver.cpp:404]     Test net output #1: loss = 3.36233 (* 1 = 3.36233 loss)
I0811 18:46:14.368232 26953 solver.cpp:228] Iteration 4900, loss = 3.47732
I0811 18:46:14.368307 26953 solver.cpp:244]     Train net output #0: loss = 3.47732 (* 1 = 3.47732 loss)
I0811 18:46:15.746888 26953 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0811 18:46:34.202134 26953 solver.cpp:228] Iteration 4910, loss = 3.18616
I0811 18:46:34.202193 26953 solver.cpp:244]     Train net output #0: loss = 3.18616 (* 1 = 3.18616 loss)
I0811 18:46:35.616495 26953 sgd_solver.cpp:106] Iteration 4910, lr = 0.01
I0811 18:46:54.158079 26953 solver.cpp:228] Iteration 4920, loss = 3.35011
I0811 18:46:54.158344 26953 solver.cpp:244]     Train net output #0: loss = 3.35011 (* 1 = 3.35011 loss)
I0811 18:46:55.585469 26953 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0811 18:47:14.094235 26953 solver.cpp:228] Iteration 4930, loss = 3.14798
I0811 18:47:14.094301 26953 solver.cpp:244]     Train net output #0: loss = 3.14798 (* 1 = 3.14798 loss)
I0811 18:47:15.504710 26953 sgd_solver.cpp:106] Iteration 4930, lr = 0.01
I0811 18:47:33.979198 26953 solver.cpp:228] Iteration 4940, loss = 2.94612
I0811 18:47:33.979459 26953 solver.cpp:244]     Train net output #0: loss = 2.94612 (* 1 = 2.94612 loss)
I0811 18:47:35.389358 26953 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0811 18:47:53.811575 26953 solver.cpp:228] Iteration 4950, loss = 3.09121
I0811 18:47:53.811652 26953 solver.cpp:244]     Train net output #0: loss = 3.09121 (* 1 = 3.09121 loss)
I0811 18:47:55.235481 26953 sgd_solver.cpp:106] Iteration 4950, lr = 0.01
I0811 18:48:13.753667 26953 solver.cpp:228] Iteration 4960, loss = 3.14782
I0811 18:48:13.753891 26953 solver.cpp:244]     Train net output #0: loss = 3.14782 (* 1 = 3.14782 loss)
I0811 18:48:15.159306 26953 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0811 18:48:33.704555 26953 solver.cpp:228] Iteration 4970, loss = 3.20474
I0811 18:48:33.704624 26953 solver.cpp:244]     Train net output #0: loss = 3.20474 (* 1 = 3.20474 loss)
I0811 18:48:35.101483 26953 sgd_solver.cpp:106] Iteration 4970, lr = 0.01
I0811 18:48:53.658059 26953 solver.cpp:228] Iteration 4980, loss = 3.271
I0811 18:48:53.658290 26953 solver.cpp:244]     Train net output #0: loss = 3.271 (* 1 = 3.271 loss)
I0811 18:48:55.085130 26953 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0811 18:49:13.599655 26953 solver.cpp:228] Iteration 4990, loss = 3.43105
I0811 18:49:13.599716 26953 solver.cpp:244]     Train net output #0: loss = 3.43105 (* 1 = 3.43105 loss)
I0811 18:49:15.013514 26953 sgd_solver.cpp:106] Iteration 4990, lr = 0.01
I0811 18:49:33.028412 26953 solver.cpp:337] Iteration 5000, Testing net (#0)
I0811 18:49:33.627636 26953 solver.cpp:404]     Test net output #0: accuracy = 0.356
I0811 18:49:33.627712 26953 solver.cpp:404]     Test net output #1: loss = 2.91984 (* 1 = 2.91984 loss)
I0811 18:49:34.193454 26953 solver.cpp:228] Iteration 5000, loss = 3.17784
I0811 18:49:34.193555 26953 solver.cpp:244]     Train net output #0: loss = 3.17784 (* 1 = 3.17784 loss)
I0811 18:49:35.589321 26953 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0811 18:49:54.049494 26953 solver.cpp:228] Iteration 5010, loss = 3.16231
I0811 18:49:54.049556 26953 solver.cpp:244]     Train net output #0: loss = 3.16231 (* 1 = 3.16231 loss)
I0811 18:49:55.464591 26953 sgd_solver.cpp:106] Iteration 5010, lr = 0.01
I0811 18:50:13.982082 26953 solver.cpp:228] Iteration 5020, loss = 3.22645
I0811 18:50:13.982326 26953 solver.cpp:244]     Train net output #0: loss = 3.22645 (* 1 = 3.22645 loss)
I0811 18:50:15.376310 26953 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0811 18:50:33.830298 26953 solver.cpp:228] Iteration 5030, loss = 3.11066
I0811 18:50:33.830365 26953 solver.cpp:244]     Train net output #0: loss = 3.11066 (* 1 = 3.11066 loss)
I0811 18:50:35.241868 26953 sgd_solver.cpp:106] Iteration 5030, lr = 0.01
I0811 18:50:53.699898 26953 solver.cpp:228] Iteration 5040, loss = 3.18387
I0811 18:50:53.700139 26953 solver.cpp:244]     Train net output #0: loss = 3.18387 (* 1 = 3.18387 loss)
I0811 18:50:55.118386 26953 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0811 18:51:13.596552 26953 solver.cpp:228] Iteration 5050, loss = 3.37264
I0811 18:51:13.596614 26953 solver.cpp:244]     Train net output #0: loss = 3.37264 (* 1 = 3.37264 loss)
I0811 18:51:15.008347 26953 sgd_solver.cpp:106] Iteration 5050, lr = 0.01
I0811 18:51:33.498641 26953 solver.cpp:228] Iteration 5060, loss = 3.3021
I0811 18:51:33.498884 26953 solver.cpp:244]     Train net output #0: loss = 3.3021 (* 1 = 3.3021 loss)
I0811 18:51:34.909363 26953 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0811 18:51:53.324826 26953 solver.cpp:228] Iteration 5070, loss = 3.16435
I0811 18:51:53.324890 26953 solver.cpp:244]     Train net output #0: loss = 3.16435 (* 1 = 3.16435 loss)
I0811 18:51:54.741123 26953 sgd_solver.cpp:106] Iteration 5070, lr = 0.01
I0811 18:52:13.262095 26953 solver.cpp:228] Iteration 5080, loss = 3.22097
I0811 18:52:13.262365 26953 solver.cpp:244]     Train net output #0: loss = 3.22097 (* 1 = 3.22097 loss)
I0811 18:52:14.685799 26953 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0811 18:52:33.192246 26953 solver.cpp:228] Iteration 5090, loss = 3.31705
I0811 18:52:33.192308 26953 solver.cpp:244]     Train net output #0: loss = 3.31705 (* 1 = 3.31705 loss)
I0811 18:52:34.597609 26953 sgd_solver.cpp:106] Iteration 5090, lr = 0.01
I0811 18:52:52.494902 26953 solver.cpp:337] Iteration 5100, Testing net (#0)
I0811 18:52:53.089094 26953 solver.cpp:404]     Test net output #0: accuracy = 0.358
I0811 18:52:53.089174 26953 solver.cpp:404]     Test net output #1: loss = 3.08076 (* 1 = 3.08076 loss)
I0811 18:52:53.653455 26953 solver.cpp:228] Iteration 5100, loss = 3.00966
I0811 18:52:53.653527 26953 solver.cpp:244]     Train net output #0: loss = 3.00966 (* 1 = 3.00966 loss)
I0811 18:52:55.048004 26953 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0811 18:53:13.469039 26953 solver.cpp:228] Iteration 5110, loss = 3.06907
I0811 18:53:13.469116 26953 solver.cpp:244]     Train net output #0: loss = 3.06907 (* 1 = 3.06907 loss)
I0811 18:53:14.882148 26953 sgd_solver.cpp:106] Iteration 5110, lr = 0.01
I0811 18:53:33.357950 26953 solver.cpp:228] Iteration 5120, loss = 3.1444
I0811 18:53:33.358234 26953 solver.cpp:244]     Train net output #0: loss = 3.1444 (* 1 = 3.1444 loss)
I0811 18:53:34.768409 26953 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0811 18:53:53.292630 26953 solver.cpp:228] Iteration 5130, loss = 3.05296
I0811 18:53:53.292692 26953 solver.cpp:244]     Train net output #0: loss = 3.05296 (* 1 = 3.05296 loss)
I0811 18:53:54.702177 26953 sgd_solver.cpp:106] Iteration 5130, lr = 0.01
I0811 18:54:13.171164 26953 solver.cpp:228] Iteration 5140, loss = 3.29551
I0811 18:54:13.171428 26953 solver.cpp:244]     Train net output #0: loss = 3.29551 (* 1 = 3.29551 loss)
I0811 18:54:14.567977 26953 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0811 18:54:33.007277 26953 solver.cpp:228] Iteration 5150, loss = 3.19394
I0811 18:54:33.007339 26953 solver.cpp:244]     Train net output #0: loss = 3.19394 (* 1 = 3.19394 loss)
I0811 18:54:34.420413 26953 sgd_solver.cpp:106] Iteration 5150, lr = 0.01
I0811 18:54:52.910496 26953 solver.cpp:228] Iteration 5160, loss = 3.09477
I0811 18:54:52.910694 26953 solver.cpp:244]     Train net output #0: loss = 3.09477 (* 1 = 3.09477 loss)
I0811 18:54:54.327852 26953 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0811 18:55:12.786886 26953 solver.cpp:228] Iteration 5170, loss = 3.02796
I0811 18:55:12.786949 26953 solver.cpp:244]     Train net output #0: loss = 3.02796 (* 1 = 3.02796 loss)
I0811 18:55:14.201732 26953 sgd_solver.cpp:106] Iteration 5170, lr = 0.01
I0811 18:55:32.650743 26953 solver.cpp:228] Iteration 5180, loss = 3.26284
I0811 18:55:32.650960 26953 solver.cpp:244]     Train net output #0: loss = 3.26284 (* 1 = 3.26284 loss)
I0811 18:55:34.067247 26953 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0811 18:55:52.579083 26953 solver.cpp:228] Iteration 5190, loss = 3.15279
I0811 18:55:52.579149 26953 solver.cpp:244]     Train net output #0: loss = 3.15279 (* 1 = 3.15279 loss)
I0811 18:55:53.989183 26953 sgd_solver.cpp:106] Iteration 5190, lr = 0.01
I0811 18:56:11.983163 26953 solver.cpp:337] Iteration 5200, Testing net (#0)
I0811 18:56:12.586601 26953 solver.cpp:404]     Test net output #0: accuracy = 0.346
I0811 18:56:12.586699 26953 solver.cpp:404]     Test net output #1: loss = 3.0894 (* 1 = 3.0894 loss)
I0811 18:56:13.169031 26953 solver.cpp:228] Iteration 5200, loss = 3.04358
I0811 18:56:13.169098 26953 solver.cpp:244]     Train net output #0: loss = 3.04358 (* 1 = 3.04358 loss)
I0811 18:56:14.525390 26953 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0811 18:56:33.009369 26953 solver.cpp:228] Iteration 5210, loss = 3.22396
I0811 18:56:33.009434 26953 solver.cpp:244]     Train net output #0: loss = 3.22396 (* 1 = 3.22396 loss)
I0811 18:56:34.429941 26953 sgd_solver.cpp:106] Iteration 5210, lr = 0.01
I0811 18:56:52.920747 26953 solver.cpp:228] Iteration 5220, loss = 2.98008
I0811 18:56:52.920969 26953 solver.cpp:244]     Train net output #0: loss = 2.98008 (* 1 = 2.98008 loss)
I0811 18:56:54.330114 26953 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0811 18:57:12.728370 26953 solver.cpp:228] Iteration 5230, loss = 3.09178
I0811 18:57:12.728435 26953 solver.cpp:244]     Train net output #0: loss = 3.09178 (* 1 = 3.09178 loss)
I0811 18:57:14.132714 26953 sgd_solver.cpp:106] Iteration 5230, lr = 0.01
I0811 18:57:32.617343 26953 solver.cpp:228] Iteration 5240, loss = 3.13283
I0811 18:57:32.617493 26953 solver.cpp:244]     Train net output #0: loss = 3.13283 (* 1 = 3.13283 loss)
I0811 18:57:34.036224 26953 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0811 18:57:52.577594 26953 solver.cpp:228] Iteration 5250, loss = 3.14584
I0811 18:57:52.577657 26953 solver.cpp:244]     Train net output #0: loss = 3.14584 (* 1 = 3.14584 loss)
I0811 18:57:53.994016 26953 sgd_solver.cpp:106] Iteration 5250, lr = 0.01
I0811 18:58:12.569913 26953 solver.cpp:228] Iteration 5260, loss = 3.15772
I0811 18:58:12.570188 26953 solver.cpp:244]     Train net output #0: loss = 3.15772 (* 1 = 3.15772 loss)
I0811 18:58:13.968174 26953 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0811 18:58:32.522393 26953 solver.cpp:228] Iteration 5270, loss = 2.93514
I0811 18:58:32.522455 26953 solver.cpp:244]     Train net output #0: loss = 2.93514 (* 1 = 2.93514 loss)
I0811 18:58:33.950011 26953 sgd_solver.cpp:106] Iteration 5270, lr = 0.01
I0811 18:58:52.415264 26953 solver.cpp:228] Iteration 5280, loss = 3.12455
I0811 18:58:52.415540 26953 solver.cpp:244]     Train net output #0: loss = 3.12455 (* 1 = 3.12455 loss)
I0811 18:58:53.822989 26953 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0811 18:59:12.215196 26953 solver.cpp:228] Iteration 5290, loss = 3.11946
I0811 18:59:12.215262 26953 solver.cpp:244]     Train net output #0: loss = 3.11946 (* 1 = 3.11946 loss)
I0811 18:59:13.606320 26953 sgd_solver.cpp:106] Iteration 5290, lr = 0.01
I0811 18:59:31.552841 26953 solver.cpp:337] Iteration 5300, Testing net (#0)
I0811 18:59:32.153154 26953 solver.cpp:404]     Test net output #0: accuracy = 0.37
I0811 18:59:32.153236 26953 solver.cpp:404]     Test net output #1: loss = 2.94906 (* 1 = 2.94906 loss)
I0811 18:59:32.730746 26953 solver.cpp:228] Iteration 5300, loss = 3.28446
I0811 18:59:32.730825 26953 solver.cpp:244]     Train net output #0: loss = 3.28446 (* 1 = 3.28446 loss)
I0811 18:59:34.103449 26953 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0811 18:59:52.591742 26953 solver.cpp:228] Iteration 5310, loss = 3.16596
I0811 18:59:52.591807 26953 solver.cpp:244]     Train net output #0: loss = 3.16596 (* 1 = 3.16596 loss)
I0811 18:59:54.009338 26953 sgd_solver.cpp:106] Iteration 5310, lr = 0.01
I0811 19:00:12.515030 26953 solver.cpp:228] Iteration 5320, loss = 3.22501
I0811 19:00:12.515296 26953 solver.cpp:244]     Train net output #0: loss = 3.22501 (* 1 = 3.22501 loss)
I0811 19:00:13.942199 26953 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0811 19:00:32.372581 26953 solver.cpp:228] Iteration 5330, loss = 3.10022
I0811 19:00:32.372647 26953 solver.cpp:244]     Train net output #0: loss = 3.10022 (* 1 = 3.10022 loss)
I0811 19:00:33.759801 26953 sgd_solver.cpp:106] Iteration 5330, lr = 0.01
I0811 19:00:52.245134 26953 solver.cpp:228] Iteration 5340, loss = 3.2405
I0811 19:00:52.245395 26953 solver.cpp:244]     Train net output #0: loss = 3.2405 (* 1 = 3.2405 loss)
I0811 19:00:53.660699 26953 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0811 19:01:12.068629 26953 solver.cpp:228] Iteration 5350, loss = 3.17904
I0811 19:01:12.068707 26953 solver.cpp:244]     Train net output #0: loss = 3.17904 (* 1 = 3.17904 loss)
I0811 19:01:13.476959 26953 sgd_solver.cpp:106] Iteration 5350, lr = 0.01
I0811 19:01:31.905431 26953 solver.cpp:228] Iteration 5360, loss = 2.91896
I0811 19:01:31.905890 26953 solver.cpp:244]     Train net output #0: loss = 2.91896 (* 1 = 2.91896 loss)
I0811 19:01:33.322731 26953 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0811 19:01:51.847450 26953 solver.cpp:228] Iteration 5370, loss = 3.11749
I0811 19:01:51.847512 26953 solver.cpp:244]     Train net output #0: loss = 3.11749 (* 1 = 3.11749 loss)
I0811 19:01:53.255926 26953 sgd_solver.cpp:106] Iteration 5370, lr = 0.01
I0811 19:02:11.711792 26953 solver.cpp:228] Iteration 5380, loss = 3.01697
I0811 19:02:11.712033 26953 solver.cpp:244]     Train net output #0: loss = 3.01697 (* 1 = 3.01697 loss)
I0811 19:02:13.115340 26953 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0811 19:02:31.544811 26953 solver.cpp:228] Iteration 5390, loss = 2.99839
I0811 19:02:31.544874 26953 solver.cpp:244]     Train net output #0: loss = 2.99839 (* 1 = 2.99839 loss)
I0811 19:02:32.984639 26953 sgd_solver.cpp:106] Iteration 5390, lr = 0.01
I0811 19:02:50.886791 26953 solver.cpp:337] Iteration 5400, Testing net (#0)
I0811 19:02:51.489284 26953 solver.cpp:404]     Test net output #0: accuracy = 0.342
I0811 19:02:51.489363 26953 solver.cpp:404]     Test net output #1: loss = 3.18335 (* 1 = 3.18335 loss)
I0811 19:02:52.053242 26953 solver.cpp:228] Iteration 5400, loss = 3.06148
I0811 19:02:52.053323 26953 solver.cpp:244]     Train net output #0: loss = 3.06148 (* 1 = 3.06148 loss)
I0811 19:02:53.444744 26953 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0811 19:03:11.927333 26953 solver.cpp:228] Iteration 5410, loss = 3.10278
I0811 19:03:11.927397 26953 solver.cpp:244]     Train net output #0: loss = 3.10278 (* 1 = 3.10278 loss)
I0811 19:03:13.325356 26953 sgd_solver.cpp:106] Iteration 5410, lr = 0.01
I0811 19:03:31.728000 26953 solver.cpp:228] Iteration 5420, loss = 3.02645
I0811 19:03:31.728253 26953 solver.cpp:244]     Train net output #0: loss = 3.02645 (* 1 = 3.02645 loss)
I0811 19:03:33.136234 26953 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0811 19:03:51.631737 26953 solver.cpp:228] Iteration 5430, loss = 2.99138
I0811 19:03:51.631804 26953 solver.cpp:244]     Train net output #0: loss = 2.99138 (* 1 = 2.99138 loss)
I0811 19:03:53.046721 26953 sgd_solver.cpp:106] Iteration 5430, lr = 0.01
I0811 19:04:11.529357 26953 solver.cpp:228] Iteration 5440, loss = 3.12877
I0811 19:04:11.529624 26953 solver.cpp:244]     Train net output #0: loss = 3.12877 (* 1 = 3.12877 loss)
I0811 19:04:12.959859 26953 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0811 19:04:31.381685 26953 solver.cpp:228] Iteration 5450, loss = 3.01778
I0811 19:04:31.381762 26953 solver.cpp:244]     Train net output #0: loss = 3.01778 (* 1 = 3.01778 loss)
I0811 19:04:32.777207 26953 sgd_solver.cpp:106] Iteration 5450, lr = 0.01
I0811 19:04:51.268705 26953 solver.cpp:228] Iteration 5460, loss = 3.1231
I0811 19:04:51.268893 26953 solver.cpp:244]     Train net output #0: loss = 3.1231 (* 1 = 3.1231 loss)
I0811 19:04:52.681746 26953 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0811 19:05:11.174938 26953 solver.cpp:228] Iteration 5470, loss = 3.04638
I0811 19:05:11.174999 26953 solver.cpp:244]     Train net output #0: loss = 3.04638 (* 1 = 3.04638 loss)
I0811 19:05:12.600437 26953 sgd_solver.cpp:106] Iteration 5470, lr = 0.01
I0811 19:05:31.099668 26953 solver.cpp:228] Iteration 5480, loss = 3.07102
I0811 19:05:31.099907 26953 solver.cpp:244]     Train net output #0: loss = 3.07102 (* 1 = 3.07102 loss)
I0811 19:05:32.504261 26953 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0811 19:05:50.922195 26953 solver.cpp:228] Iteration 5490, loss = 3.05179
I0811 19:05:50.922257 26953 solver.cpp:244]     Train net output #0: loss = 3.05179 (* 1 = 3.05179 loss)
I0811 19:05:52.349905 26953 sgd_solver.cpp:106] Iteration 5490, lr = 0.01
I0811 19:06:10.262375 26953 solver.cpp:337] Iteration 5500, Testing net (#0)
I0811 19:06:10.858984 26953 solver.cpp:404]     Test net output #0: accuracy = 0.356
I0811 19:06:10.859046 26953 solver.cpp:404]     Test net output #1: loss = 2.8946 (* 1 = 2.8946 loss)
I0811 19:06:11.424226 26953 solver.cpp:228] Iteration 5500, loss = 3.14368
I0811 19:06:11.424298 26953 solver.cpp:244]     Train net output #0: loss = 3.14368 (* 1 = 3.14368 loss)
I0811 19:06:12.809278 26953 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0811 19:06:31.281698 26953 solver.cpp:228] Iteration 5510, loss = 3.02389
I0811 19:06:31.281765 26953 solver.cpp:244]     Train net output #0: loss = 3.02389 (* 1 = 3.02389 loss)
I0811 19:06:32.686000 26953 sgd_solver.cpp:106] Iteration 5510, lr = 0.01
I0811 19:06:51.088232 26953 solver.cpp:228] Iteration 5520, loss = 2.85744
I0811 19:06:51.088486 26953 solver.cpp:244]     Train net output #0: loss = 2.85744 (* 1 = 2.85744 loss)
I0811 19:06:52.484474 26953 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0811 19:07:10.968163 26953 solver.cpp:228] Iteration 5530, loss = 3.01775
I0811 19:07:10.968228 26953 solver.cpp:244]     Train net output #0: loss = 3.01775 (* 1 = 3.01775 loss)
I0811 19:07:12.383699 26953 sgd_solver.cpp:106] Iteration 5530, lr = 0.01
I0811 19:07:30.834890 26953 solver.cpp:228] Iteration 5540, loss = 3.17719
I0811 19:07:30.835145 26953 solver.cpp:244]     Train net output #0: loss = 3.17719 (* 1 = 3.17719 loss)
I0811 19:07:32.229750 26953 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0811 19:07:50.639727 26953 solver.cpp:228] Iteration 5550, loss = 3.19672
I0811 19:07:50.639791 26953 solver.cpp:244]     Train net output #0: loss = 3.19672 (* 1 = 3.19672 loss)
I0811 19:07:52.060236 26953 sgd_solver.cpp:106] Iteration 5550, lr = 0.01
I0811 19:08:10.543222 26953 solver.cpp:228] Iteration 5560, loss = 3.0487
I0811 19:08:10.543452 26953 solver.cpp:244]     Train net output #0: loss = 3.0487 (* 1 = 3.0487 loss)
I0811 19:08:11.957664 26953 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0811 19:08:30.364343 26953 solver.cpp:228] Iteration 5570, loss = 3.19698
I0811 19:08:30.364408 26953 solver.cpp:244]     Train net output #0: loss = 3.19698 (* 1 = 3.19698 loss)
I0811 19:08:31.759493 26953 sgd_solver.cpp:106] Iteration 5570, lr = 0.01
I0811 19:08:50.221532 26953 solver.cpp:228] Iteration 5580, loss = 3.11572
I0811 19:08:50.221809 26953 solver.cpp:244]     Train net output #0: loss = 3.11572 (* 1 = 3.11572 loss)
I0811 19:08:51.634310 26953 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0811 19:09:10.049062 26953 solver.cpp:228] Iteration 5590, loss = 3.03751
I0811 19:09:10.049121 26953 solver.cpp:244]     Train net output #0: loss = 3.03751 (* 1 = 3.03751 loss)
I0811 19:09:11.462116 26953 sgd_solver.cpp:106] Iteration 5590, lr = 0.01
I0811 19:09:29.363840 26953 solver.cpp:337] Iteration 5600, Testing net (#0)
I0811 19:09:29.965749 26953 solver.cpp:404]     Test net output #0: accuracy = 0.348
I0811 19:09:29.965842 26953 solver.cpp:404]     Test net output #1: loss = 2.99541 (* 1 = 2.99541 loss)
I0811 19:09:30.528159 26953 solver.cpp:228] Iteration 5600, loss = 2.96673
I0811 19:09:30.528235 26953 solver.cpp:244]     Train net output #0: loss = 2.96673 (* 1 = 2.96673 loss)
I0811 19:09:31.920086 26953 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0811 19:09:50.384856 26953 solver.cpp:228] Iteration 5610, loss = 2.96672
I0811 19:09:50.384932 26953 solver.cpp:244]     Train net output #0: loss = 2.96672 (* 1 = 2.96672 loss)
I0811 19:09:51.799242 26953 sgd_solver.cpp:106] Iteration 5610, lr = 0.01
I0811 19:10:10.294935 26953 solver.cpp:228] Iteration 5620, loss = 3.01642
I0811 19:10:10.295192 26953 solver.cpp:244]     Train net output #0: loss = 3.01642 (* 1 = 3.01642 loss)
I0811 19:10:11.696658 26953 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0811 19:10:30.109133 26953 solver.cpp:228] Iteration 5630, loss = 3.22152
I0811 19:10:30.109210 26953 solver.cpp:244]     Train net output #0: loss = 3.22152 (* 1 = 3.22152 loss)
I0811 19:10:31.523777 26953 sgd_solver.cpp:106] Iteration 5630, lr = 0.01
I0811 19:10:50.015915 26953 solver.cpp:228] Iteration 5640, loss = 2.98147
I0811 19:10:50.016130 26953 solver.cpp:244]     Train net output #0: loss = 2.98147 (* 1 = 2.98147 loss)
I0811 19:10:51.438657 26953 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0811 19:11:09.894357 26953 solver.cpp:228] Iteration 5650, loss = 3.17046
I0811 19:11:09.894430 26953 solver.cpp:244]     Train net output #0: loss = 3.17046 (* 1 = 3.17046 loss)
I0811 19:11:11.298616 26953 sgd_solver.cpp:106] Iteration 5650, lr = 0.01
I0811 19:11:29.734629 26953 solver.cpp:228] Iteration 5660, loss = 2.95534
I0811 19:11:29.734832 26953 solver.cpp:244]     Train net output #0: loss = 2.95534 (* 1 = 2.95534 loss)
I0811 19:11:31.148483 26953 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0811 19:11:49.660115 26953 solver.cpp:228] Iteration 5670, loss = 3.11588
I0811 19:11:49.660194 26953 solver.cpp:244]     Train net output #0: loss = 3.11588 (* 1 = 3.11588 loss)
I0811 19:11:51.089624 26953 sgd_solver.cpp:106] Iteration 5670, lr = 0.01
I0811 19:12:09.535651 26953 solver.cpp:228] Iteration 5680, loss = 3.31076
I0811 19:12:09.535867 26953 solver.cpp:244]     Train net output #0: loss = 3.31076 (* 1 = 3.31076 loss)
I0811 19:12:10.934833 26953 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0811 19:12:29.362725 26953 solver.cpp:228] Iteration 5690, loss = 3.0287
I0811 19:12:29.362787 26953 solver.cpp:244]     Train net output #0: loss = 3.0287 (* 1 = 3.0287 loss)
I0811 19:12:30.760705 26953 sgd_solver.cpp:106] Iteration 5690, lr = 0.01
I0811 19:12:48.722719 26953 solver.cpp:337] Iteration 5700, Testing net (#0)
I0811 19:12:49.325495 26953 solver.cpp:404]     Test net output #0: accuracy = 0.382
I0811 19:12:49.325561 26953 solver.cpp:404]     Test net output #1: loss = 2.91816 (* 1 = 2.91816 loss)
I0811 19:12:49.914685 26953 solver.cpp:228] Iteration 5700, loss = 3.12511
I0811 19:12:49.914749 26953 solver.cpp:244]     Train net output #0: loss = 3.12511 (* 1 = 3.12511 loss)
I0811 19:12:51.273916 26953 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0811 19:13:09.749788 26953 solver.cpp:228] Iteration 5710, loss = 3.12808
I0811 19:13:09.749848 26953 solver.cpp:244]     Train net output #0: loss = 3.12808 (* 1 = 3.12808 loss)
I0811 19:13:11.169874 26953 sgd_solver.cpp:106] Iteration 5710, lr = 0.01
I0811 19:13:29.646278 26953 solver.cpp:228] Iteration 5720, loss = 3.04634
I0811 19:13:29.646569 26953 solver.cpp:244]     Train net output #0: loss = 3.04634 (* 1 = 3.04634 loss)
I0811 19:13:31.061206 26953 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0811 19:13:49.470706 26953 solver.cpp:228] Iteration 5730, loss = 3.14414
I0811 19:13:49.470773 26953 solver.cpp:244]     Train net output #0: loss = 3.14414 (* 1 = 3.14414 loss)
I0811 19:13:50.894415 26953 sgd_solver.cpp:106] Iteration 5730, lr = 0.01
I0811 19:14:09.405552 26953 solver.cpp:228] Iteration 5740, loss = 2.95441
I0811 19:14:09.405832 26953 solver.cpp:244]     Train net output #0: loss = 2.95441 (* 1 = 2.95441 loss)
I0811 19:14:10.826498 26953 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0811 19:14:29.310947 26953 solver.cpp:228] Iteration 5750, loss = 3.07436
I0811 19:14:29.311025 26953 solver.cpp:244]     Train net output #0: loss = 3.07436 (* 1 = 3.07436 loss)
I0811 19:14:30.727113 26953 sgd_solver.cpp:106] Iteration 5750, lr = 0.01
I0811 19:14:49.138684 26953 solver.cpp:228] Iteration 5760, loss = 3.02601
I0811 19:14:49.138928 26953 solver.cpp:244]     Train net output #0: loss = 3.02601 (* 1 = 3.02601 loss)
I0811 19:14:50.535696 26953 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0811 19:15:09.019701 26953 solver.cpp:228] Iteration 5770, loss = 2.98362
I0811 19:15:09.019767 26953 solver.cpp:244]     Train net output #0: loss = 2.98362 (* 1 = 2.98362 loss)
I0811 19:15:10.421552 26953 sgd_solver.cpp:106] Iteration 5770, lr = 0.01
I0811 19:15:28.883229 26953 solver.cpp:228] Iteration 5780, loss = 2.99815
I0811 19:15:28.883481 26953 solver.cpp:244]     Train net output #0: loss = 2.99815 (* 1 = 2.99815 loss)
I0811 19:15:30.288867 26953 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0811 19:15:48.707659 26953 solver.cpp:228] Iteration 5790, loss = 2.97862
I0811 19:15:48.707756 26953 solver.cpp:244]     Train net output #0: loss = 2.97862 (* 1 = 2.97862 loss)
I0811 19:15:50.143797 26953 sgd_solver.cpp:106] Iteration 5790, lr = 0.01
I0811 19:16:08.059340 26953 solver.cpp:337] Iteration 5800, Testing net (#0)
I0811 19:16:08.652523 26953 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0811 19:16:08.652600 26953 solver.cpp:404]     Test net output #1: loss = 2.93642 (* 1 = 2.93642 loss)
I0811 19:16:09.235944 26953 solver.cpp:228] Iteration 5800, loss = 2.83112
I0811 19:16:09.236047 26953 solver.cpp:244]     Train net output #0: loss = 2.83112 (* 1 = 2.83112 loss)
I0811 19:16:10.606897 26953 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0811 19:16:29.125310 26953 solver.cpp:228] Iteration 5810, loss = 3.01352
I0811 19:16:29.125375 26953 solver.cpp:244]     Train net output #0: loss = 3.01352 (* 1 = 3.01352 loss)
I0811 19:16:30.533583 26953 sgd_solver.cpp:106] Iteration 5810, lr = 0.01
I0811 19:16:48.923949 26953 solver.cpp:228] Iteration 5820, loss = 3.20162
I0811 19:16:48.924190 26953 solver.cpp:244]     Train net output #0: loss = 3.20162 (* 1 = 3.20162 loss)
I0811 19:16:50.337702 26953 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0811 19:17:08.781719 26953 solver.cpp:228] Iteration 5830, loss = 3.02044
I0811 19:17:08.781782 26953 solver.cpp:244]     Train net output #0: loss = 3.02044 (* 1 = 3.02044 loss)
I0811 19:17:10.207898 26953 sgd_solver.cpp:106] Iteration 5830, lr = 0.01
I0811 19:17:28.716720 26953 solver.cpp:228] Iteration 5840, loss = 3.14316
I0811 19:17:28.717001 26953 solver.cpp:244]     Train net output #0: loss = 3.14316 (* 1 = 3.14316 loss)
I0811 19:17:30.125720 26953 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0811 19:17:48.595309 26953 solver.cpp:228] Iteration 5850, loss = 3.06073
I0811 19:17:48.595376 26953 solver.cpp:244]     Train net output #0: loss = 3.06073 (* 1 = 3.06073 loss)
I0811 19:17:50.004498 26953 sgd_solver.cpp:106] Iteration 5850, lr = 0.01
I0811 19:18:08.453495 26953 solver.cpp:228] Iteration 5860, loss = 3.02704
I0811 19:18:08.453775 26953 solver.cpp:244]     Train net output #0: loss = 3.02704 (* 1 = 3.02704 loss)
I0811 19:18:09.853073 26953 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0811 19:18:28.273514 26953 solver.cpp:228] Iteration 5870, loss = 3.04266
I0811 19:18:28.273578 26953 solver.cpp:244]     Train net output #0: loss = 3.04266 (* 1 = 3.04266 loss)
I0811 19:18:29.675225 26953 sgd_solver.cpp:106] Iteration 5870, lr = 0.01
I0811 19:18:48.106467 26953 solver.cpp:228] Iteration 5880, loss = 2.87752
I0811 19:18:48.106729 26953 solver.cpp:244]     Train net output #0: loss = 2.87752 (* 1 = 2.87752 loss)
I0811 19:18:49.511904 26953 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0811 19:19:08.016162 26953 solver.cpp:228] Iteration 5890, loss = 2.93402
I0811 19:19:08.016230 26953 solver.cpp:244]     Train net output #0: loss = 2.93402 (* 1 = 2.93402 loss)
I0811 19:19:09.422215 26953 sgd_solver.cpp:106] Iteration 5890, lr = 0.01
I0811 19:19:27.266906 26953 solver.cpp:337] Iteration 5900, Testing net (#0)
I0811 19:19:27.876770 26953 solver.cpp:404]     Test net output #0: accuracy = 0.39
I0811 19:19:27.876864 26953 solver.cpp:404]     Test net output #1: loss = 2.92923 (* 1 = 2.92923 loss)
I0811 19:19:28.442847 26953 solver.cpp:228] Iteration 5900, loss = 3.24896
I0811 19:19:28.442947 26953 solver.cpp:244]     Train net output #0: loss = 3.24896 (* 1 = 3.24896 loss)
I0811 19:19:29.825871 26953 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0811 19:19:48.223476 26953 solver.cpp:228] Iteration 5910, loss = 2.98392
I0811 19:19:48.223542 26953 solver.cpp:244]     Train net output #0: loss = 2.98392 (* 1 = 2.98392 loss)
I0811 19:19:49.648780 26953 sgd_solver.cpp:106] Iteration 5910, lr = 0.01
I0811 19:20:08.125759 26953 solver.cpp:228] Iteration 5920, loss = 3.10896
I0811 19:20:08.125984 26953 solver.cpp:244]     Train net output #0: loss = 3.10896 (* 1 = 3.10896 loss)
I0811 19:20:09.531774 26953 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0811 19:20:27.914557 26953 solver.cpp:228] Iteration 5930, loss = 2.93863
I0811 19:20:27.914624 26953 solver.cpp:244]     Train net output #0: loss = 2.93863 (* 1 = 2.93863 loss)
I0811 19:20:29.322707 26953 sgd_solver.cpp:106] Iteration 5930, lr = 0.01
I0811 19:20:47.845260 26953 solver.cpp:228] Iteration 5940, loss = 2.93047
I0811 19:20:47.845507 26953 solver.cpp:244]     Train net output #0: loss = 2.93047 (* 1 = 2.93047 loss)
I0811 19:20:49.254163 26953 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0811 19:21:07.654999 26953 solver.cpp:228] Iteration 5950, loss = 2.86145
I0811 19:21:07.655077 26953 solver.cpp:244]     Train net output #0: loss = 2.86145 (* 1 = 2.86145 loss)
I0811 19:21:09.053647 26953 sgd_solver.cpp:106] Iteration 5950, lr = 0.01
I0811 19:21:27.513267 26953 solver.cpp:228] Iteration 5960, loss = 3.12108
I0811 19:21:27.513456 26953 solver.cpp:244]     Train net output #0: loss = 3.12108 (* 1 = 3.12108 loss)
I0811 19:21:28.939343 26953 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0811 19:21:47.390478 26953 solver.cpp:228] Iteration 5970, loss = 2.92267
I0811 19:21:47.390540 26953 solver.cpp:244]     Train net output #0: loss = 2.92267 (* 1 = 2.92267 loss)
I0811 19:21:48.797873 26953 sgd_solver.cpp:106] Iteration 5970, lr = 0.01
I0811 19:22:07.221575 26953 solver.cpp:228] Iteration 5980, loss = 2.91453
I0811 19:22:07.221809 26953 solver.cpp:244]     Train net output #0: loss = 2.91453 (* 1 = 2.91453 loss)
I0811 19:22:08.615056 26953 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0811 19:22:27.164438 26953 solver.cpp:228] Iteration 5990, loss = 3.00533
I0811 19:22:27.164515 26953 solver.cpp:244]     Train net output #0: loss = 3.00533 (* 1 = 3.00533 loss)
I0811 19:22:28.569258 26953 sgd_solver.cpp:106] Iteration 5990, lr = 0.01
I0811 19:22:46.412739 26953 solver.cpp:337] Iteration 6000, Testing net (#0)
I0811 19:22:47.008473 26953 solver.cpp:404]     Test net output #0: accuracy = 0.34
I0811 19:22:47.008544 26953 solver.cpp:404]     Test net output #1: loss = 2.99287 (* 1 = 2.99287 loss)
I0811 19:22:47.573027 26953 solver.cpp:228] Iteration 6000, loss = 3.09164
I0811 19:22:47.573107 26953 solver.cpp:244]     Train net output #0: loss = 3.09164 (* 1 = 3.09164 loss)
I0811 19:22:48.959986 26953 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0811 19:23:07.344008 26953 solver.cpp:228] Iteration 6010, loss = 2.93016
I0811 19:23:07.344074 26953 solver.cpp:244]     Train net output #0: loss = 2.93016 (* 1 = 2.93016 loss)
I0811 19:23:08.759428 26953 sgd_solver.cpp:106] Iteration 6010, lr = 0.01
I0811 19:23:27.221012 26953 solver.cpp:228] Iteration 6020, loss = 2.95455
I0811 19:23:27.221261 26953 solver.cpp:244]     Train net output #0: loss = 2.95455 (* 1 = 2.95455 loss)
I0811 19:23:28.631474 26953 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0811 19:23:47.044391 26953 solver.cpp:228] Iteration 6030, loss = 2.96091
I0811 19:23:47.044451 26953 solver.cpp:244]     Train net output #0: loss = 2.96091 (* 1 = 2.96091 loss)
I0811 19:23:48.448596 26953 sgd_solver.cpp:106] Iteration 6030, lr = 0.01
I0811 19:24:06.942793 26953 solver.cpp:228] Iteration 6040, loss = 2.9275
I0811 19:24:06.943045 26953 solver.cpp:244]     Train net output #0: loss = 2.9275 (* 1 = 2.9275 loss)
I0811 19:24:08.354859 26953 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0811 19:24:26.748845 26953 solver.cpp:228] Iteration 6050, loss = 3.06936
I0811 19:24:26.748911 26953 solver.cpp:244]     Train net output #0: loss = 3.06936 (* 1 = 3.06936 loss)
I0811 19:24:28.147430 26953 sgd_solver.cpp:106] Iteration 6050, lr = 0.01
I0811 19:24:46.637110 26953 solver.cpp:228] Iteration 6060, loss = 3.01994
I0811 19:24:46.637400 26953 solver.cpp:244]     Train net output #0: loss = 3.01994 (* 1 = 3.01994 loss)
I0811 19:24:48.044927 26953 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0811 19:25:06.594316 26953 solver.cpp:228] Iteration 6070, loss = 2.9853
I0811 19:25:06.594379 26953 solver.cpp:244]     Train net output #0: loss = 2.9853 (* 1 = 2.9853 loss)
I0811 19:25:08.002971 26953 sgd_solver.cpp:106] Iteration 6070, lr = 0.01
I0811 19:25:26.523587 26953 solver.cpp:228] Iteration 6080, loss = 2.94269
I0811 19:25:26.523838 26953 solver.cpp:244]     Train net output #0: loss = 2.94269 (* 1 = 2.94269 loss)
I0811 19:25:27.949616 26953 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0811 19:25:46.395913 26953 solver.cpp:228] Iteration 6090, loss = 2.9071
I0811 19:25:46.395987 26953 solver.cpp:244]     Train net output #0: loss = 2.9071 (* 1 = 2.9071 loss)
I0811 19:25:47.800132 26953 sgd_solver.cpp:106] Iteration 6090, lr = 0.01
I0811 19:26:05.658401 26953 solver.cpp:337] Iteration 6100, Testing net (#0)
I0811 19:26:06.249853 26953 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0811 19:26:06.249918 26953 solver.cpp:404]     Test net output #1: loss = 2.82817 (* 1 = 2.82817 loss)
I0811 19:26:06.832018 26953 solver.cpp:228] Iteration 6100, loss = 2.91801
I0811 19:26:06.832103 26953 solver.cpp:244]     Train net output #0: loss = 2.91801 (* 1 = 2.91801 loss)
I0811 19:26:08.187783 26953 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0811 19:26:26.683845 26953 solver.cpp:228] Iteration 6110, loss = 2.85716
I0811 19:26:26.683908 26953 solver.cpp:244]     Train net output #0: loss = 2.85716 (* 1 = 2.85716 loss)
I0811 19:26:28.097257 26953 sgd_solver.cpp:106] Iteration 6110, lr = 0.01
I0811 19:26:46.584514 26953 solver.cpp:228] Iteration 6120, loss = 2.98161
I0811 19:26:46.584766 26953 solver.cpp:244]     Train net output #0: loss = 2.98161 (* 1 = 2.98161 loss)
I0811 19:26:47.989215 26953 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0811 19:27:06.375823 26953 solver.cpp:228] Iteration 6130, loss = 3.06837
I0811 19:27:06.375888 26953 solver.cpp:244]     Train net output #0: loss = 3.06837 (* 1 = 3.06837 loss)
I0811 19:27:07.799450 26953 sgd_solver.cpp:106] Iteration 6130, lr = 0.01
I0811 19:27:26.248731 26953 solver.cpp:228] Iteration 6140, loss = 2.95275
I0811 19:27:26.249050 26953 solver.cpp:244]     Train net output #0: loss = 2.95275 (* 1 = 2.95275 loss)
I0811 19:27:27.653302 26953 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0811 19:27:46.083956 26953 solver.cpp:228] Iteration 6150, loss = 2.93838
I0811 19:27:46.084024 26953 solver.cpp:244]     Train net output #0: loss = 2.93838 (* 1 = 2.93838 loss)
I0811 19:27:47.478571 26953 sgd_solver.cpp:106] Iteration 6150, lr = 0.01
I0811 19:28:06.000664 26953 solver.cpp:228] Iteration 6160, loss = 2.94448
I0811 19:28:06.000891 26953 solver.cpp:244]     Train net output #0: loss = 2.94448 (* 1 = 2.94448 loss)
I0811 19:28:07.400344 26953 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0811 19:28:25.796562 26953 solver.cpp:228] Iteration 6170, loss = 2.81162
I0811 19:28:25.796627 26953 solver.cpp:244]     Train net output #0: loss = 2.81162 (* 1 = 2.81162 loss)
I0811 19:28:27.197661 26953 sgd_solver.cpp:106] Iteration 6170, lr = 0.01
I0811 19:28:45.642191 26953 solver.cpp:228] Iteration 6180, loss = 2.96309
I0811 19:28:45.642446 26953 solver.cpp:244]     Train net output #0: loss = 2.96309 (* 1 = 2.96309 loss)
I0811 19:28:47.065693 26953 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0811 19:29:05.570195 26953 solver.cpp:228] Iteration 6190, loss = 2.79698
I0811 19:29:05.570261 26953 solver.cpp:244]     Train net output #0: loss = 2.79698 (* 1 = 2.79698 loss)
I0811 19:29:06.985667 26953 sgd_solver.cpp:106] Iteration 6190, lr = 0.01
I0811 19:29:24.815027 26953 solver.cpp:337] Iteration 6200, Testing net (#0)
I0811 19:29:25.409149 26953 solver.cpp:404]     Test net output #0: accuracy = 0.396
I0811 19:29:25.409216 26953 solver.cpp:404]     Test net output #1: loss = 2.77274 (* 1 = 2.77274 loss)
I0811 19:29:25.978224 26953 solver.cpp:228] Iteration 6200, loss = 3.04392
I0811 19:29:25.978296 26953 solver.cpp:244]     Train net output #0: loss = 3.04392 (* 1 = 3.04392 loss)
I0811 19:29:27.354082 26953 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0811 19:29:45.798470 26953 solver.cpp:228] Iteration 6210, loss = 3.00684
I0811 19:29:45.798533 26953 solver.cpp:244]     Train net output #0: loss = 3.00684 (* 1 = 3.00684 loss)
I0811 19:29:47.201527 26953 sgd_solver.cpp:106] Iteration 6210, lr = 0.01
I0811 19:30:05.648149 26953 solver.cpp:228] Iteration 6220, loss = 2.94835
I0811 19:30:05.648313 26953 solver.cpp:244]     Train net output #0: loss = 2.94835 (* 1 = 2.94835 loss)
I0811 19:30:07.041136 26953 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0811 19:30:25.471954 26953 solver.cpp:228] Iteration 6230, loss = 2.81738
I0811 19:30:25.472023 26953 solver.cpp:244]     Train net output #0: loss = 2.81738 (* 1 = 2.81738 loss)
I0811 19:30:26.892076 26953 sgd_solver.cpp:106] Iteration 6230, lr = 0.01
I0811 19:30:45.400156 26953 solver.cpp:228] Iteration 6240, loss = 2.98879
I0811 19:30:45.400400 26953 solver.cpp:244]     Train net output #0: loss = 2.98879 (* 1 = 2.98879 loss)
I0811 19:30:46.818148 26953 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0811 19:31:05.225970 26953 solver.cpp:228] Iteration 6250, loss = 2.92273
I0811 19:31:05.226044 26953 solver.cpp:244]     Train net output #0: loss = 2.92273 (* 1 = 2.92273 loss)
I0811 19:31:06.631192 26953 sgd_solver.cpp:106] Iteration 6250, lr = 0.01
I0811 19:31:25.099007 26953 solver.cpp:228] Iteration 6260, loss = 2.81711
I0811 19:31:25.099256 26953 solver.cpp:244]     Train net output #0: loss = 2.81711 (* 1 = 2.81711 loss)
I0811 19:31:26.525053 26953 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0811 19:31:45.019117 26953 solver.cpp:228] Iteration 6270, loss = 3.02593
I0811 19:31:45.019194 26953 solver.cpp:244]     Train net output #0: loss = 3.02593 (* 1 = 3.02593 loss)
I0811 19:31:46.440366 26953 sgd_solver.cpp:106] Iteration 6270, lr = 0.01
I0811 19:32:04.837720 26953 solver.cpp:228] Iteration 6280, loss = 3.1361
I0811 19:32:04.837959 26953 solver.cpp:244]     Train net output #0: loss = 3.1361 (* 1 = 3.1361 loss)
I0811 19:32:06.231695 26953 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0811 19:32:24.712896 26953 solver.cpp:228] Iteration 6290, loss = 2.92303
I0811 19:32:24.712966 26953 solver.cpp:244]     Train net output #0: loss = 2.92303 (* 1 = 2.92303 loss)
I0811 19:32:26.117023 26953 sgd_solver.cpp:106] Iteration 6290, lr = 0.01
I0811 19:32:43.949103 26953 solver.cpp:337] Iteration 6300, Testing net (#0)
I0811 19:32:44.536317 26953 solver.cpp:404]     Test net output #0: accuracy = 0.396
I0811 19:32:44.536396 26953 solver.cpp:404]     Test net output #1: loss = 2.80694 (* 1 = 2.80694 loss)
I0811 19:32:45.126740 26953 solver.cpp:228] Iteration 6300, loss = 2.85641
I0811 19:32:45.126801 26953 solver.cpp:244]     Train net output #0: loss = 2.85641 (* 1 = 2.85641 loss)
I0811 19:32:46.492578 26953 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0811 19:33:04.901464 26953 solver.cpp:228] Iteration 6310, loss = 3.17268
I0811 19:33:04.901533 26953 solver.cpp:244]     Train net output #0: loss = 3.17268 (* 1 = 3.17268 loss)
I0811 19:33:06.327026 26953 sgd_solver.cpp:106] Iteration 6310, lr = 0.01
I0811 19:33:24.788987 26953 solver.cpp:228] Iteration 6320, loss = 3.261
I0811 19:33:24.789278 26953 solver.cpp:244]     Train net output #0: loss = 3.261 (* 1 = 3.261 loss)
I0811 19:33:26.200080 26953 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0811 19:33:44.600683 26953 solver.cpp:228] Iteration 6330, loss = 2.77758
I0811 19:33:44.600742 26953 solver.cpp:244]     Train net output #0: loss = 2.77758 (* 1 = 2.77758 loss)
I0811 19:33:45.995189 26953 sgd_solver.cpp:106] Iteration 6330, lr = 0.01
I0811 19:34:04.523895 26953 solver.cpp:228] Iteration 6340, loss = 2.6368
I0811 19:34:04.524142 26953 solver.cpp:244]     Train net output #0: loss = 2.6368 (* 1 = 2.6368 loss)
I0811 19:34:05.927953 26953 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0811 19:34:24.314934 26953 solver.cpp:228] Iteration 6350, loss = 2.86799
I0811 19:34:24.314995 26953 solver.cpp:244]     Train net output #0: loss = 2.86799 (* 1 = 2.86799 loss)
I0811 19:34:25.712396 26953 sgd_solver.cpp:106] Iteration 6350, lr = 0.01
I0811 19:34:44.189479 26953 solver.cpp:228] Iteration 6360, loss = 3.00031
I0811 19:34:44.189661 26953 solver.cpp:244]     Train net output #0: loss = 3.00031 (* 1 = 3.00031 loss)
I0811 19:34:45.619163 26953 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0811 19:35:04.081212 26953 solver.cpp:228] Iteration 6370, loss = 2.983
I0811 19:35:04.081279 26953 solver.cpp:244]     Train net output #0: loss = 2.983 (* 1 = 2.983 loss)
I0811 19:35:05.486213 26953 sgd_solver.cpp:106] Iteration 6370, lr = 0.01
I0811 19:35:23.896456 26953 solver.cpp:228] Iteration 6380, loss = 2.87074
I0811 19:35:23.896703 26953 solver.cpp:244]     Train net output #0: loss = 2.87074 (* 1 = 2.87074 loss)
I0811 19:35:25.318218 26953 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0811 19:35:43.773870 26953 solver.cpp:228] Iteration 6390, loss = 2.75547
I0811 19:35:43.773933 26953 solver.cpp:244]     Train net output #0: loss = 2.75547 (* 1 = 2.75547 loss)
I0811 19:35:45.175827 26953 sgd_solver.cpp:106] Iteration 6390, lr = 0.01
I0811 19:36:03.010368 26953 solver.cpp:337] Iteration 6400, Testing net (#0)
I0811 19:36:03.603685 26953 solver.cpp:404]     Test net output #0: accuracy = 0.448
I0811 19:36:03.603756 26953 solver.cpp:404]     Test net output #1: loss = 2.62917 (* 1 = 2.62917 loss)
I0811 19:36:04.177954 26953 solver.cpp:228] Iteration 6400, loss = 2.863
I0811 19:36:04.178032 26953 solver.cpp:244]     Train net output #0: loss = 2.863 (* 1 = 2.863 loss)
I0811 19:36:05.566972 26953 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0811 19:36:23.988237 26953 solver.cpp:228] Iteration 6410, loss = 2.93932
I0811 19:36:23.988327 26953 solver.cpp:244]     Train net output #0: loss = 2.93932 (* 1 = 2.93932 loss)
I0811 19:36:25.398962 26953 sgd_solver.cpp:106] Iteration 6410, lr = 0.01
I0811 19:36:43.838059 26953 solver.cpp:228] Iteration 6420, loss = 2.94985
I0811 19:36:43.838297 26953 solver.cpp:244]     Train net output #0: loss = 2.94985 (* 1 = 2.94985 loss)
I0811 19:36:45.237275 26953 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0811 19:37:03.686477 26953 solver.cpp:228] Iteration 6430, loss = 2.70502
I0811 19:37:03.686537 26953 solver.cpp:244]     Train net output #0: loss = 2.70502 (* 1 = 2.70502 loss)
I0811 19:37:05.103780 26953 sgd_solver.cpp:106] Iteration 6430, lr = 0.01
I0811 19:37:23.627184 26953 solver.cpp:228] Iteration 6440, loss = 2.93825
I0811 19:37:23.627488 26953 solver.cpp:244]     Train net output #0: loss = 2.93825 (* 1 = 2.93825 loss)
I0811 19:37:25.046188 26953 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0811 19:37:43.452162 26953 solver.cpp:228] Iteration 6450, loss = 2.98799
I0811 19:37:43.452235 26953 solver.cpp:244]     Train net output #0: loss = 2.98799 (* 1 = 2.98799 loss)
I0811 19:37:44.860981 26953 sgd_solver.cpp:106] Iteration 6450, lr = 0.01
I0811 19:38:03.307113 26953 solver.cpp:228] Iteration 6460, loss = 2.88347
I0811 19:38:03.307379 26953 solver.cpp:244]     Train net output #0: loss = 2.88347 (* 1 = 2.88347 loss)
I0811 19:38:04.712082 26953 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0811 19:38:23.218206 26953 solver.cpp:228] Iteration 6470, loss = 2.95677
I0811 19:38:23.218271 26953 solver.cpp:244]     Train net output #0: loss = 2.95677 (* 1 = 2.95677 loss)
I0811 19:38:24.626880 26953 sgd_solver.cpp:106] Iteration 6470, lr = 0.01
I0811 19:38:43.029358 26953 solver.cpp:228] Iteration 6480, loss = 2.91138
I0811 19:38:43.029542 26953 solver.cpp:244]     Train net output #0: loss = 2.91138 (* 1 = 2.91138 loss)
I0811 19:38:44.450067 26953 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0811 19:39:02.925413 26953 solver.cpp:228] Iteration 6490, loss = 2.91925
I0811 19:39:02.925478 26953 solver.cpp:244]     Train net output #0: loss = 2.91925 (* 1 = 2.91925 loss)
I0811 19:39:04.352347 26953 sgd_solver.cpp:106] Iteration 6490, lr = 0.01
I0811 19:39:22.216622 26953 solver.cpp:337] Iteration 6500, Testing net (#0)
I0811 19:39:22.809980 26953 solver.cpp:404]     Test net output #0: accuracy = 0.38
I0811 19:39:22.810042 26953 solver.cpp:404]     Test net output #1: loss = 2.73855 (* 1 = 2.73855 loss)
I0811 19:39:23.368319 26953 solver.cpp:228] Iteration 6500, loss = 2.86486
I0811 19:39:23.368394 26953 solver.cpp:244]     Train net output #0: loss = 2.86486 (* 1 = 2.86486 loss)
I0811 19:39:24.775060 26953 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0811 19:39:43.188730 26953 solver.cpp:228] Iteration 6510, loss = 2.8858
I0811 19:39:43.188822 26953 solver.cpp:244]     Train net output #0: loss = 2.8858 (* 1 = 2.8858 loss)
I0811 19:39:44.596209 26953 sgd_solver.cpp:106] Iteration 6510, lr = 0.01
I0811 19:40:03.081162 26953 solver.cpp:228] Iteration 6520, loss = 2.91781
I0811 19:40:03.081416 26953 solver.cpp:244]     Train net output #0: loss = 2.91781 (* 1 = 2.91781 loss)
I0811 19:40:04.496244 26953 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0811 19:40:22.912479 26953 solver.cpp:228] Iteration 6530, loss = 2.89389
I0811 19:40:22.912542 26953 solver.cpp:244]     Train net output #0: loss = 2.89389 (* 1 = 2.89389 loss)
I0811 19:40:24.324005 26953 sgd_solver.cpp:106] Iteration 6530, lr = 0.01
I0811 19:40:42.751971 26953 solver.cpp:228] Iteration 6540, loss = 2.89658
I0811 19:40:42.752208 26953 solver.cpp:244]     Train net output #0: loss = 2.89658 (* 1 = 2.89658 loss)
I0811 19:40:44.164232 26953 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0811 19:41:02.639608 26953 solver.cpp:228] Iteration 6550, loss = 2.98387
I0811 19:41:02.639670 26953 solver.cpp:244]     Train net output #0: loss = 2.98387 (* 1 = 2.98387 loss)
I0811 19:41:04.064043 26953 sgd_solver.cpp:106] Iteration 6550, lr = 0.01
I0811 19:41:22.484160 26953 solver.cpp:228] Iteration 6560, loss = 2.94706
I0811 19:41:22.484376 26953 solver.cpp:244]     Train net output #0: loss = 2.94706 (* 1 = 2.94706 loss)
I0811 19:41:23.877321 26953 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0811 19:41:42.320930 26953 solver.cpp:228] Iteration 6570, loss = 2.90285
I0811 19:41:42.320997 26953 solver.cpp:244]     Train net output #0: loss = 2.90285 (* 1 = 2.90285 loss)
I0811 19:41:43.718116 26953 sgd_solver.cpp:106] Iteration 6570, lr = 0.01
I0811 19:42:02.122738 26953 solver.cpp:228] Iteration 6580, loss = 2.95314
I0811 19:42:02.123020 26953 solver.cpp:244]     Train net output #0: loss = 2.95314 (* 1 = 2.95314 loss)
I0811 19:42:03.531782 26953 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0811 19:42:22.019294 26953 solver.cpp:228] Iteration 6590, loss = 2.65964
I0811 19:42:22.019353 26953 solver.cpp:244]     Train net output #0: loss = 2.65964 (* 1 = 2.65964 loss)
I0811 19:42:23.436894 26953 sgd_solver.cpp:106] Iteration 6590, lr = 0.01
I0811 19:42:41.325866 26953 solver.cpp:337] Iteration 6600, Testing net (#0)
I0811 19:42:41.916213 26953 solver.cpp:404]     Test net output #0: accuracy = 0.468
I0811 19:42:41.916275 26953 solver.cpp:404]     Test net output #1: loss = 2.54908 (* 1 = 2.54908 loss)
I0811 19:42:42.482056 26953 solver.cpp:228] Iteration 6600, loss = 3.03697
I0811 19:42:42.482125 26953 solver.cpp:244]     Train net output #0: loss = 3.03697 (* 1 = 3.03697 loss)
I0811 19:42:43.876363 26953 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0811 19:43:02.290786 26953 solver.cpp:228] Iteration 6610, loss = 2.97111
I0811 19:43:02.290851 26953 solver.cpp:244]     Train net output #0: loss = 2.97111 (* 1 = 2.97111 loss)
I0811 19:43:03.693783 26953 sgd_solver.cpp:106] Iteration 6610, lr = 0.01
I0811 19:43:22.183208 26953 solver.cpp:228] Iteration 6620, loss = 2.77409
I0811 19:43:22.183491 26953 solver.cpp:244]     Train net output #0: loss = 2.77409 (* 1 = 2.77409 loss)
I0811 19:43:23.583199 26953 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0811 19:43:42.003702 26953 solver.cpp:228] Iteration 6630, loss = 2.70703
I0811 19:43:42.003796 26953 solver.cpp:244]     Train net output #0: loss = 2.70703 (* 1 = 2.70703 loss)
I0811 19:43:43.406172 26953 sgd_solver.cpp:106] Iteration 6630, lr = 0.01
I0811 19:44:01.858345 26953 solver.cpp:228] Iteration 6640, loss = 2.95321
I0811 19:44:01.858580 26953 solver.cpp:244]     Train net output #0: loss = 2.95321 (* 1 = 2.95321 loss)
I0811 19:44:03.264801 26953 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0811 19:44:21.764807 26953 solver.cpp:228] Iteration 6650, loss = 2.9284
I0811 19:44:21.764873 26953 solver.cpp:244]     Train net output #0: loss = 2.9284 (* 1 = 2.9284 loss)
I0811 19:44:23.169523 26953 sgd_solver.cpp:106] Iteration 6650, lr = 0.01
I0811 19:44:41.570225 26953 solver.cpp:228] Iteration 6660, loss = 2.89168
I0811 19:44:41.570456 26953 solver.cpp:244]     Train net output #0: loss = 2.89168 (* 1 = 2.89168 loss)
I0811 19:44:42.976430 26953 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0811 19:45:01.470827 26953 solver.cpp:228] Iteration 6670, loss = 2.91752
I0811 19:45:01.470906 26953 solver.cpp:244]     Train net output #0: loss = 2.91752 (* 1 = 2.91752 loss)
I0811 19:45:02.898793 26953 sgd_solver.cpp:106] Iteration 6670, lr = 0.01
I0811 19:45:21.381006 26953 solver.cpp:228] Iteration 6680, loss = 2.72575
I0811 19:45:21.381232 26953 solver.cpp:244]     Train net output #0: loss = 2.72575 (* 1 = 2.72575 loss)
I0811 19:45:22.799335 26953 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0811 19:45:41.189708 26953 solver.cpp:228] Iteration 6690, loss = 2.92059
I0811 19:45:41.189774 26953 solver.cpp:244]     Train net output #0: loss = 2.92059 (* 1 = 2.92059 loss)
I0811 19:45:42.586756 26953 sgd_solver.cpp:106] Iteration 6690, lr = 0.01
I0811 19:46:00.522068 26953 solver.cpp:337] Iteration 6700, Testing net (#0)
I0811 19:46:01.112666 26953 solver.cpp:404]     Test net output #0: accuracy = 0.44
I0811 19:46:01.112740 26953 solver.cpp:404]     Test net output #1: loss = 2.64913 (* 1 = 2.64913 loss)
I0811 19:46:01.701462 26953 solver.cpp:228] Iteration 6700, loss = 2.98247
I0811 19:46:01.701539 26953 solver.cpp:244]     Train net output #0: loss = 2.98247 (* 1 = 2.98247 loss)
I0811 19:46:03.075943 26953 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0811 19:46:21.549880 26953 solver.cpp:228] Iteration 6710, loss = 2.78782
I0811 19:46:21.549945 26953 solver.cpp:244]     Train net output #0: loss = 2.78782 (* 1 = 2.78782 loss)
I0811 19:46:22.958859 26953 sgd_solver.cpp:106] Iteration 6710, lr = 0.01
I0811 19:46:41.352581 26953 solver.cpp:228] Iteration 6720, loss = 2.94798
I0811 19:46:41.352872 26953 solver.cpp:244]     Train net output #0: loss = 2.94798 (* 1 = 2.94798 loss)
I0811 19:46:42.759260 26953 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0811 19:47:01.203090 26953 solver.cpp:228] Iteration 6730, loss = 2.91487
I0811 19:47:01.203155 26953 solver.cpp:244]     Train net output #0: loss = 2.91487 (* 1 = 2.91487 loss)
I0811 19:47:02.622458 26953 sgd_solver.cpp:106] Iteration 6730, lr = 0.01
I0811 19:47:21.059388 26953 solver.cpp:228] Iteration 6740, loss = 2.83515
I0811 19:47:21.059634 26953 solver.cpp:244]     Train net output #0: loss = 2.83515 (* 1 = 2.83515 loss)
I0811 19:47:22.457587 26953 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0811 19:47:40.928405 26953 solver.cpp:228] Iteration 6750, loss = 2.77741
I0811 19:47:40.928468 26953 solver.cpp:244]     Train net output #0: loss = 2.77741 (* 1 = 2.77741 loss)
I0811 19:47:42.336398 26953 sgd_solver.cpp:106] Iteration 6750, lr = 0.01
I0811 19:48:00.723295 26953 solver.cpp:228] Iteration 6760, loss = 2.67149
I0811 19:48:00.723537 26953 solver.cpp:244]     Train net output #0: loss = 2.67149 (* 1 = 2.67149 loss)
I0811 19:48:02.129354 26953 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0811 19:48:20.558766 26953 solver.cpp:228] Iteration 6770, loss = 2.78606
I0811 19:48:20.558835 26953 solver.cpp:244]     Train net output #0: loss = 2.78606 (* 1 = 2.78606 loss)
I0811 19:48:21.962400 26953 sgd_solver.cpp:106] Iteration 6770, lr = 0.01
I0811 19:48:40.332617 26953 solver.cpp:228] Iteration 6780, loss = 2.90618
I0811 19:48:40.332773 26953 solver.cpp:244]     Train net output #0: loss = 2.90618 (* 1 = 2.90618 loss)
I0811 19:48:41.742133 26953 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0811 19:49:00.222797 26953 solver.cpp:228] Iteration 6790, loss = 2.93527
I0811 19:49:00.222859 26953 solver.cpp:244]     Train net output #0: loss = 2.93527 (* 1 = 2.93527 loss)
I0811 19:49:01.645550 26953 sgd_solver.cpp:106] Iteration 6790, lr = 0.01
I0811 19:49:19.486371 26953 solver.cpp:337] Iteration 6800, Testing net (#0)
I0811 19:49:20.088296 26953 solver.cpp:404]     Test net output #0: accuracy = 0.434
I0811 19:49:20.088374 26953 solver.cpp:404]     Test net output #1: loss = 2.60842 (* 1 = 2.60842 loss)
I0811 19:49:20.646461 26953 solver.cpp:228] Iteration 6800, loss = 3.00139
I0811 19:49:20.646536 26953 solver.cpp:244]     Train net output #0: loss = 3.00139 (* 1 = 3.00139 loss)
I0811 19:49:22.045290 26953 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0811 19:49:40.464947 26953 solver.cpp:228] Iteration 6810, loss = 2.83336
I0811 19:49:40.465010 26953 solver.cpp:244]     Train net output #0: loss = 2.83336 (* 1 = 2.83336 loss)
I0811 19:49:41.868643 26953 sgd_solver.cpp:106] Iteration 6810, lr = 0.01
I0811 19:50:00.321532 26953 solver.cpp:228] Iteration 6820, loss = 2.94094
I0811 19:50:00.321811 26953 solver.cpp:244]     Train net output #0: loss = 2.94094 (* 1 = 2.94094 loss)
I0811 19:50:01.712260 26953 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0811 19:50:20.107065 26953 solver.cpp:228] Iteration 6830, loss = 2.90903
I0811 19:50:20.107115 26953 solver.cpp:244]     Train net output #0: loss = 2.90903 (* 1 = 2.90903 loss)
I0811 19:50:21.519064 26953 sgd_solver.cpp:106] Iteration 6830, lr = 0.01
I0811 19:50:39.994633 26953 solver.cpp:228] Iteration 6840, loss = 3.02418
I0811 19:50:39.994848 26953 solver.cpp:244]     Train net output #0: loss = 3.02418 (* 1 = 3.02418 loss)
I0811 19:50:41.407382 26953 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0811 19:50:59.822074 26953 solver.cpp:228] Iteration 6850, loss = 3.02078
I0811 19:50:59.822139 26953 solver.cpp:244]     Train net output #0: loss = 3.02078 (* 1 = 3.02078 loss)
I0811 19:51:01.237519 26953 sgd_solver.cpp:106] Iteration 6850, lr = 0.01
I0811 19:51:19.736682 26953 solver.cpp:228] Iteration 6860, loss = 2.99044
I0811 19:51:19.736917 26953 solver.cpp:244]     Train net output #0: loss = 2.99044 (* 1 = 2.99044 loss)
I0811 19:51:21.143054 26953 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0811 19:51:39.544091 26953 solver.cpp:228] Iteration 6870, loss = 2.67217
I0811 19:51:39.544157 26953 solver.cpp:244]     Train net output #0: loss = 2.67217 (* 1 = 2.67217 loss)
I0811 19:51:40.933745 26953 sgd_solver.cpp:106] Iteration 6870, lr = 0.01
I0811 19:51:59.394670 26953 solver.cpp:228] Iteration 6880, loss = 2.98885
I0811 19:51:59.394974 26953 solver.cpp:244]     Train net output #0: loss = 2.98885 (* 1 = 2.98885 loss)
I0811 19:52:00.811682 26953 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0811 19:52:19.321835 26953 solver.cpp:228] Iteration 6890, loss = 2.95107
I0811 19:52:19.321902 26953 solver.cpp:244]     Train net output #0: loss = 2.95107 (* 1 = 2.95107 loss)
I0811 19:52:20.725927 26953 sgd_solver.cpp:106] Iteration 6890, lr = 0.01
I0811 19:52:38.588959 26953 solver.cpp:337] Iteration 6900, Testing net (#0)
I0811 19:52:39.177449 26953 solver.cpp:404]     Test net output #0: accuracy = 0.37
I0811 19:52:39.177516 26953 solver.cpp:404]     Test net output #1: loss = 2.81993 (* 1 = 2.81993 loss)
I0811 19:52:39.757266 26953 solver.cpp:228] Iteration 6900, loss = 2.94425
I0811 19:52:39.757342 26953 solver.cpp:244]     Train net output #0: loss = 2.94425 (* 1 = 2.94425 loss)
I0811 19:52:41.130681 26953 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0811 19:52:59.538305 26953 solver.cpp:228] Iteration 6910, loss = 3.03493
I0811 19:52:59.538381 26953 solver.cpp:244]     Train net output #0: loss = 3.03493 (* 1 = 3.03493 loss)
I0811 19:53:00.963294 26953 sgd_solver.cpp:106] Iteration 6910, lr = 0.01
I0811 19:53:19.432201 26953 solver.cpp:228] Iteration 6920, loss = 2.8002
I0811 19:53:19.432420 26953 solver.cpp:244]     Train net output #0: loss = 2.8002 (* 1 = 2.8002 loss)
I0811 19:53:20.836994 26953 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0811 19:53:39.216190 26953 solver.cpp:228] Iteration 6930, loss = 2.76861
I0811 19:53:39.216253 26953 solver.cpp:244]     Train net output #0: loss = 2.76861 (* 1 = 2.76861 loss)
I0811 19:53:40.621318 26953 sgd_solver.cpp:106] Iteration 6930, lr = 0.01
I0811 19:53:59.024639 26953 solver.cpp:228] Iteration 6940, loss = 2.87639
I0811 19:53:59.024860 26953 solver.cpp:244]     Train net output #0: loss = 2.87639 (* 1 = 2.87639 loss)
I0811 19:54:00.421566 26953 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0811 19:54:18.885237 26953 solver.cpp:228] Iteration 6950, loss = 2.86761
I0811 19:54:18.885303 26953 solver.cpp:244]     Train net output #0: loss = 2.86761 (* 1 = 2.86761 loss)
I0811 19:54:20.290580 26953 sgd_solver.cpp:106] Iteration 6950, lr = 0.01
I0811 19:54:38.772527 26953 solver.cpp:228] Iteration 6960, loss = 2.89531
I0811 19:54:38.772716 26953 solver.cpp:244]     Train net output #0: loss = 2.89531 (* 1 = 2.89531 loss)
I0811 19:54:40.172545 26953 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0811 19:54:58.570405 26953 solver.cpp:228] Iteration 6970, loss = 2.77656
I0811 19:54:58.570472 26953 solver.cpp:244]     Train net output #0: loss = 2.77656 (* 1 = 2.77656 loss)
I0811 19:54:59.979405 26953 sgd_solver.cpp:106] Iteration 6970, lr = 0.01
I0811 19:55:18.443361 26953 solver.cpp:228] Iteration 6980, loss = 3.04274
I0811 19:55:18.443613 26953 solver.cpp:244]     Train net output #0: loss = 3.04274 (* 1 = 3.04274 loss)
I0811 19:55:19.848852 26953 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0811 19:55:38.233821 26953 solver.cpp:228] Iteration 6990, loss = 2.98755
I0811 19:55:38.233922 26953 solver.cpp:244]     Train net output #0: loss = 2.98755 (* 1 = 2.98755 loss)
I0811 19:55:39.640702 26953 sgd_solver.cpp:106] Iteration 6990, lr = 0.01
I0811 19:55:57.578104 26953 solver.cpp:337] Iteration 7000, Testing net (#0)
I0811 19:55:58.173087 26953 solver.cpp:404]     Test net output #0: accuracy = 0.4
I0811 19:55:58.173164 26953 solver.cpp:404]     Test net output #1: loss = 2.86069 (* 1 = 2.86069 loss)
I0811 19:55:58.757946 26953 solver.cpp:228] Iteration 7000, loss = 2.90681
I0811 19:55:58.758038 26953 solver.cpp:244]     Train net output #0: loss = 2.90681 (* 1 = 2.90681 loss)
I0811 19:56:00.128906 26953 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0811 19:56:18.569552 26953 solver.cpp:228] Iteration 7010, loss = 2.95137
I0811 19:56:18.569615 26953 solver.cpp:244]     Train net output #0: loss = 2.95137 (* 1 = 2.95137 loss)
I0811 19:56:19.966476 26953 sgd_solver.cpp:106] Iteration 7010, lr = 0.01
I0811 19:56:38.350723 26953 solver.cpp:228] Iteration 7020, loss = 2.98759
I0811 19:56:38.350934 26953 solver.cpp:244]     Train net output #0: loss = 2.98759 (* 1 = 2.98759 loss)
I0811 19:56:39.795087 26953 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0811 19:56:58.286952 26953 solver.cpp:228] Iteration 7030, loss = 2.83771
I0811 19:56:58.287017 26953 solver.cpp:244]     Train net output #0: loss = 2.83771 (* 1 = 2.83771 loss)
I0811 19:56:59.694667 26953 sgd_solver.cpp:106] Iteration 7030, lr = 0.01
I0811 19:57:18.125843 26953 solver.cpp:228] Iteration 7040, loss = 2.86146
I0811 19:57:18.126077 26953 solver.cpp:244]     Train net output #0: loss = 2.86146 (* 1 = 2.86146 loss)
I0811 19:57:19.515275 26953 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0811 19:57:37.974611 26953 solver.cpp:228] Iteration 7050, loss = 2.99849
I0811 19:57:37.974673 26953 solver.cpp:244]     Train net output #0: loss = 2.99849 (* 1 = 2.99849 loss)
I0811 19:57:39.372071 26953 sgd_solver.cpp:106] Iteration 7050, lr = 0.01
I0811 19:57:57.759848 26953 solver.cpp:228] Iteration 7060, loss = 2.94071
I0811 19:57:57.760097 26953 solver.cpp:244]     Train net output #0: loss = 2.94071 (* 1 = 2.94071 loss)
I0811 19:57:59.156514 26953 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0811 19:58:17.646878 26953 solver.cpp:228] Iteration 7070, loss = 2.81755
I0811 19:58:17.646941 26953 solver.cpp:244]     Train net output #0: loss = 2.81755 (* 1 = 2.81755 loss)
I0811 19:58:19.073953 26953 sgd_solver.cpp:106] Iteration 7070, lr = 0.01
I0811 19:58:37.505990 26953 solver.cpp:228] Iteration 7080, loss = 2.85696
I0811 19:58:37.506242 26953 solver.cpp:244]     Train net output #0: loss = 2.85696 (* 1 = 2.85696 loss)
I0811 19:58:38.914093 26953 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0811 19:58:57.388227 26953 solver.cpp:228] Iteration 7090, loss = 2.86049
I0811 19:58:57.388295 26953 solver.cpp:244]     Train net output #0: loss = 2.86049 (* 1 = 2.86049 loss)
I0811 19:58:58.785552 26953 sgd_solver.cpp:106] Iteration 7090, lr = 0.01
I0811 19:59:16.710280 26953 solver.cpp:337] Iteration 7100, Testing net (#0)
I0811 19:59:17.312491 26953 solver.cpp:404]     Test net output #0: accuracy = 0.424
I0811 19:59:17.312575 26953 solver.cpp:404]     Test net output #1: loss = 2.6573 (* 1 = 2.6573 loss)
I0811 19:59:17.888262 26953 solver.cpp:228] Iteration 7100, loss = 2.85071
I0811 19:59:17.888361 26953 solver.cpp:244]     Train net output #0: loss = 2.85071 (* 1 = 2.85071 loss)
I0811 19:59:19.270462 26953 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0811 19:59:37.724525 26953 solver.cpp:228] Iteration 7110, loss = 2.80603
I0811 19:59:37.724588 26953 solver.cpp:244]     Train net output #0: loss = 2.80603 (* 1 = 2.80603 loss)
I0811 19:59:39.137539 26953 sgd_solver.cpp:106] Iteration 7110, lr = 0.01
I0811 19:59:57.665922 26953 solver.cpp:228] Iteration 7120, loss = 2.84821
I0811 19:59:57.666159 26953 solver.cpp:244]     Train net output #0: loss = 2.84821 (* 1 = 2.84821 loss)
I0811 19:59:59.068553 26953 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0811 20:00:17.466537 26953 solver.cpp:228] Iteration 7130, loss = 2.90299
I0811 20:00:17.466615 26953 solver.cpp:244]     Train net output #0: loss = 2.90299 (* 1 = 2.90299 loss)
I0811 20:00:18.876629 26953 sgd_solver.cpp:106] Iteration 7130, lr = 0.01
I0811 20:00:37.382478 26953 solver.cpp:228] Iteration 7140, loss = 2.96817
I0811 20:00:37.382709 26953 solver.cpp:244]     Train net output #0: loss = 2.96817 (* 1 = 2.96817 loss)
I0811 20:00:38.814810 26953 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0811 20:00:57.223543 26953 solver.cpp:228] Iteration 7150, loss = 2.76745
I0811 20:00:57.223606 26953 solver.cpp:244]     Train net output #0: loss = 2.76745 (* 1 = 2.76745 loss)
I0811 20:00:58.627040 26953 sgd_solver.cpp:106] Iteration 7150, lr = 0.01
I0811 20:01:17.040933 26953 solver.cpp:228] Iteration 7160, loss = 2.80291
I0811 20:01:17.041240 26953 solver.cpp:244]     Train net output #0: loss = 2.80291 (* 1 = 2.80291 loss)
I0811 20:01:18.467979 26953 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0811 20:01:36.943565 26953 solver.cpp:228] Iteration 7170, loss = 2.89168
I0811 20:01:36.943629 26953 solver.cpp:244]     Train net output #0: loss = 2.89168 (* 1 = 2.89168 loss)
I0811 20:01:38.352809 26953 sgd_solver.cpp:106] Iteration 7170, lr = 0.01
I0811 20:01:56.770705 26953 solver.cpp:228] Iteration 7180, loss = 2.78298
I0811 20:01:56.770942 26953 solver.cpp:244]     Train net output #0: loss = 2.78298 (* 1 = 2.78298 loss)
I0811 20:01:58.184753 26953 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0811 20:02:16.671171 26953 solver.cpp:228] Iteration 7190, loss = 2.89636
I0811 20:02:16.671236 26953 solver.cpp:244]     Train net output #0: loss = 2.89636 (* 1 = 2.89636 loss)
I0811 20:02:18.090785 26953 sgd_solver.cpp:106] Iteration 7190, lr = 0.01
I0811 20:02:35.950839 26953 solver.cpp:337] Iteration 7200, Testing net (#0)
I0811 20:02:36.542850 26953 solver.cpp:404]     Test net output #0: accuracy = 0.402
I0811 20:02:36.542912 26953 solver.cpp:404]     Test net output #1: loss = 2.70565 (* 1 = 2.70565 loss)
I0811 20:02:37.128705 26953 solver.cpp:228] Iteration 7200, loss = 2.78062
I0811 20:02:37.128780 26953 solver.cpp:244]     Train net output #0: loss = 2.78062 (* 1 = 2.78062 loss)
I0811 20:02:38.508723 26953 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0811 20:02:56.971232 26953 solver.cpp:228] Iteration 7210, loss = 2.86444
I0811 20:02:56.971298 26953 solver.cpp:244]     Train net output #0: loss = 2.86444 (* 1 = 2.86444 loss)
I0811 20:02:58.365435 26953 sgd_solver.cpp:106] Iteration 7210, lr = 0.01
I0811 20:03:16.807986 26953 solver.cpp:228] Iteration 7220, loss = 2.75252
I0811 20:03:16.808187 26953 solver.cpp:244]     Train net output #0: loss = 2.75252 (* 1 = 2.75252 loss)
I0811 20:03:18.215945 26953 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0811 20:03:36.641564 26953 solver.cpp:228] Iteration 7230, loss = 2.8895
I0811 20:03:36.641628 26953 solver.cpp:244]     Train net output #0: loss = 2.8895 (* 1 = 2.8895 loss)
I0811 20:03:38.041365 26953 sgd_solver.cpp:106] Iteration 7230, lr = 0.01
I0811 20:03:56.463865 26953 solver.cpp:228] Iteration 7240, loss = 2.82593
I0811 20:03:56.464108 26953 solver.cpp:244]     Train net output #0: loss = 2.82593 (* 1 = 2.82593 loss)
I0811 20:03:57.875890 26953 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0811 20:04:16.292495 26953 solver.cpp:228] Iteration 7250, loss = 2.78328
I0811 20:04:16.292562 26953 solver.cpp:244]     Train net output #0: loss = 2.78328 (* 1 = 2.78328 loss)
I0811 20:04:17.695677 26953 sgd_solver.cpp:106] Iteration 7250, lr = 0.01
I0811 20:04:36.097599 26953 solver.cpp:228] Iteration 7260, loss = 2.86001
I0811 20:04:36.097848 26953 solver.cpp:244]     Train net output #0: loss = 2.86001 (* 1 = 2.86001 loss)
I0811 20:04:37.526610 26953 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0811 20:04:55.957659 26953 solver.cpp:228] Iteration 7270, loss = 2.77009
I0811 20:04:55.957733 26953 solver.cpp:244]     Train net output #0: loss = 2.77009 (* 1 = 2.77009 loss)
I0811 20:04:57.351167 26953 sgd_solver.cpp:106] Iteration 7270, lr = 0.01
I0811 20:05:15.818353 26953 solver.cpp:228] Iteration 7280, loss = 2.96985
I0811 20:05:15.818588 26953 solver.cpp:244]     Train net output #0: loss = 2.96985 (* 1 = 2.96985 loss)
I0811 20:05:17.222753 26953 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0811 20:05:35.646867 26953 solver.cpp:228] Iteration 7290, loss = 2.93668
I0811 20:05:35.646944 26953 solver.cpp:244]     Train net output #0: loss = 2.93668 (* 1 = 2.93668 loss)
I0811 20:05:37.061568 26953 sgd_solver.cpp:106] Iteration 7290, lr = 0.01
I0811 20:05:54.883929 26953 solver.cpp:337] Iteration 7300, Testing net (#0)
I0811 20:05:55.477303 26953 solver.cpp:404]     Test net output #0: accuracy = 0.396
I0811 20:05:55.477377 26953 solver.cpp:404]     Test net output #1: loss = 2.77777 (* 1 = 2.77777 loss)
I0811 20:05:56.044219 26953 solver.cpp:228] Iteration 7300, loss = 2.72356
I0811 20:05:56.044293 26953 solver.cpp:244]     Train net output #0: loss = 2.72356 (* 1 = 2.72356 loss)
I0811 20:05:57.427000 26953 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0811 20:06:15.906903 26953 solver.cpp:228] Iteration 7310, loss = 2.70695
I0811 20:06:15.906966 26953 solver.cpp:244]     Train net output #0: loss = 2.70695 (* 1 = 2.70695 loss)
I0811 20:06:17.331337 26953 sgd_solver.cpp:106] Iteration 7310, lr = 0.01
I0811 20:06:35.767073 26953 solver.cpp:228] Iteration 7320, loss = 2.6462
I0811 20:06:35.767272 26953 solver.cpp:244]     Train net output #0: loss = 2.6462 (* 1 = 2.6462 loss)
I0811 20:06:37.166604 26953 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0811 20:06:55.608593 26953 solver.cpp:228] Iteration 7330, loss = 2.76627
I0811 20:06:55.608672 26953 solver.cpp:244]     Train net output #0: loss = 2.76627 (* 1 = 2.76627 loss)
I0811 20:06:57.016564 26953 sgd_solver.cpp:106] Iteration 7330, lr = 0.01
I0811 20:07:15.399341 26953 solver.cpp:228] Iteration 7340, loss = 2.78436
I0811 20:07:15.399576 26953 solver.cpp:244]     Train net output #0: loss = 2.78436 (* 1 = 2.78436 loss)
I0811 20:07:16.799088 26953 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0811 20:07:35.277137 26953 solver.cpp:228] Iteration 7350, loss = 2.87374
I0811 20:07:35.277214 26953 solver.cpp:244]     Train net output #0: loss = 2.87374 (* 1 = 2.87374 loss)
I0811 20:07:36.688218 26953 sgd_solver.cpp:106] Iteration 7350, lr = 0.01
I0811 20:07:55.097055 26953 solver.cpp:228] Iteration 7360, loss = 2.70469
I0811 20:07:55.097347 26953 solver.cpp:244]     Train net output #0: loss = 2.70469 (* 1 = 2.70469 loss)
I0811 20:07:56.504904 26953 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0811 20:08:14.973223 26953 solver.cpp:228] Iteration 7370, loss = 2.87855
I0811 20:08:14.973328 26953 solver.cpp:244]     Train net output #0: loss = 2.87855 (* 1 = 2.87855 loss)
I0811 20:08:16.383901 26953 sgd_solver.cpp:106] Iteration 7370, lr = 0.01
I0811 20:08:34.842450 26953 solver.cpp:228] Iteration 7380, loss = 2.91787
I0811 20:08:34.842686 26953 solver.cpp:244]     Train net output #0: loss = 2.91787 (* 1 = 2.91787 loss)
I0811 20:08:36.257918 26953 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0811 20:08:54.661458 26953 solver.cpp:228] Iteration 7390, loss = 2.82288
I0811 20:08:54.661521 26953 solver.cpp:244]     Train net output #0: loss = 2.82288 (* 1 = 2.82288 loss)
I0811 20:08:56.078058 26953 sgd_solver.cpp:106] Iteration 7390, lr = 0.01
I0811 20:09:13.895331 26953 solver.cpp:337] Iteration 7400, Testing net (#0)
I0811 20:09:14.498208 26953 solver.cpp:404]     Test net output #0: accuracy = 0.436
I0811 20:09:14.498281 26953 solver.cpp:404]     Test net output #1: loss = 2.6116 (* 1 = 2.6116 loss)
I0811 20:09:15.075495 26953 solver.cpp:228] Iteration 7400, loss = 2.91237
I0811 20:09:15.075587 26953 solver.cpp:244]     Train net output #0: loss = 2.91237 (* 1 = 2.91237 loss)
I0811 20:09:16.459323 26953 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0811 20:09:34.860185 26953 solver.cpp:228] Iteration 7410, loss = 2.79825
I0811 20:09:34.860249 26953 solver.cpp:244]     Train net output #0: loss = 2.79825 (* 1 = 2.79825 loss)
I0811 20:09:36.259326 26953 sgd_solver.cpp:106] Iteration 7410, lr = 0.01
I0811 20:09:54.734877 26953 solver.cpp:228] Iteration 7420, loss = 2.64845
I0811 20:09:54.735134 26953 solver.cpp:244]     Train net output #0: loss = 2.64845 (* 1 = 2.64845 loss)
I0811 20:09:56.135741 26953 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0811 20:10:14.565898 26953 solver.cpp:228] Iteration 7430, loss = 2.88326
I0811 20:10:14.565969 26953 solver.cpp:244]     Train net output #0: loss = 2.88326 (* 1 = 2.88326 loss)
I0811 20:10:15.974902 26953 sgd_solver.cpp:106] Iteration 7430, lr = 0.01
I0811 20:10:34.418215 26953 solver.cpp:228] Iteration 7440, loss = 2.78965
I0811 20:10:34.418463 26953 solver.cpp:244]     Train net output #0: loss = 2.78965 (* 1 = 2.78965 loss)
I0811 20:10:35.837638 26953 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0811 20:10:54.220366 26953 solver.cpp:228] Iteration 7450, loss = 2.73866
I0811 20:10:54.220428 26953 solver.cpp:244]     Train net output #0: loss = 2.73866 (* 1 = 2.73866 loss)
I0811 20:10:55.623985 26953 sgd_solver.cpp:106] Iteration 7450, lr = 0.01
I0811 20:11:14.081264 26953 solver.cpp:228] Iteration 7460, loss = 2.76167
I0811 20:11:14.081531 26953 solver.cpp:244]     Train net output #0: loss = 2.76167 (* 1 = 2.76167 loss)
I0811 20:11:15.501082 26953 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0811 20:11:34.029142 26953 solver.cpp:228] Iteration 7470, loss = 2.77674
I0811 20:11:34.029217 26953 solver.cpp:244]     Train net output #0: loss = 2.77674 (* 1 = 2.77674 loss)
I0811 20:11:35.438241 26953 sgd_solver.cpp:106] Iteration 7470, lr = 0.01
I0811 20:11:53.831655 26953 solver.cpp:228] Iteration 7480, loss = 2.7965
I0811 20:11:53.831946 26953 solver.cpp:244]     Train net output #0: loss = 2.7965 (* 1 = 2.7965 loss)
I0811 20:11:55.243515 26953 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0811 20:12:13.715607 26953 solver.cpp:228] Iteration 7490, loss = 2.68908
I0811 20:12:13.715670 26953 solver.cpp:244]     Train net output #0: loss = 2.68908 (* 1 = 2.68908 loss)
I0811 20:12:15.127182 26953 sgd_solver.cpp:106] Iteration 7490, lr = 0.01
I0811 20:12:32.944316 26953 solver.cpp:337] Iteration 7500, Testing net (#0)
I0811 20:12:33.545982 26953 solver.cpp:404]     Test net output #0: accuracy = 0.424
I0811 20:12:33.546082 26953 solver.cpp:404]     Test net output #1: loss = 2.69676 (* 1 = 2.69676 loss)
I0811 20:12:34.118511 26953 solver.cpp:228] Iteration 7500, loss = 2.81831
I0811 20:12:34.118587 26953 solver.cpp:244]     Train net output #0: loss = 2.81831 (* 1 = 2.81831 loss)
I0811 20:12:35.496845 26953 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0811 20:12:53.919894 26953 solver.cpp:228] Iteration 7510, loss = 2.76233
I0811 20:12:53.919958 26953 solver.cpp:244]     Train net output #0: loss = 2.76233 (* 1 = 2.76233 loss)
I0811 20:12:55.320781 26953 sgd_solver.cpp:106] Iteration 7510, lr = 0.01
I0811 20:13:13.780093 26953 solver.cpp:228] Iteration 7520, loss = 2.69347
I0811 20:13:13.780287 26953 solver.cpp:244]     Train net output #0: loss = 2.69347 (* 1 = 2.69347 loss)
I0811 20:13:15.183838 26953 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0811 20:13:33.580719 26953 solver.cpp:228] Iteration 7530, loss = 2.81247
I0811 20:13:33.580783 26953 solver.cpp:244]     Train net output #0: loss = 2.81247 (* 1 = 2.81247 loss)
I0811 20:13:34.985411 26953 sgd_solver.cpp:106] Iteration 7530, lr = 0.01
I0811 20:13:53.427804 26953 solver.cpp:228] Iteration 7540, loss = 2.8438
I0811 20:13:53.428058 26953 solver.cpp:244]     Train net output #0: loss = 2.8438 (* 1 = 2.8438 loss)
I0811 20:13:54.839570 26953 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0811 20:14:13.256800 26953 solver.cpp:228] Iteration 7550, loss = 2.95797
I0811 20:14:13.256862 26953 solver.cpp:244]     Train net output #0: loss = 2.95797 (* 1 = 2.95797 loss)
I0811 20:14:14.674526 26953 sgd_solver.cpp:106] Iteration 7550, lr = 0.01
I0811 20:14:33.090276 26953 solver.cpp:228] Iteration 7560, loss = 2.59809
I0811 20:14:33.090500 26953 solver.cpp:244]     Train net output #0: loss = 2.59809 (* 1 = 2.59809 loss)
I0811 20:14:34.485965 26953 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0811 20:14:52.940861 26953 solver.cpp:228] Iteration 7570, loss = 2.7495
I0811 20:14:52.940929 26953 solver.cpp:244]     Train net output #0: loss = 2.7495 (* 1 = 2.7495 loss)
I0811 20:14:54.343261 26953 sgd_solver.cpp:106] Iteration 7570, lr = 0.01
I0811 20:15:12.793612 26953 solver.cpp:228] Iteration 7580, loss = 2.66072
I0811 20:15:12.793844 26953 solver.cpp:244]     Train net output #0: loss = 2.66072 (* 1 = 2.66072 loss)
I0811 20:15:14.198390 26953 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0811 20:15:32.607169 26953 solver.cpp:228] Iteration 7590, loss = 2.93098
I0811 20:15:32.607237 26953 solver.cpp:244]     Train net output #0: loss = 2.93098 (* 1 = 2.93098 loss)
I0811 20:15:34.015491 26953 sgd_solver.cpp:106] Iteration 7590, lr = 0.01
I0811 20:15:51.906860 26953 solver.cpp:337] Iteration 7600, Testing net (#0)
I0811 20:15:52.501297 26953 solver.cpp:404]     Test net output #0: accuracy = 0.422
I0811 20:15:52.501394 26953 solver.cpp:404]     Test net output #1: loss = 2.63764 (* 1 = 2.63764 loss)
I0811 20:15:53.094786 26953 solver.cpp:228] Iteration 7600, loss = 2.74147
I0811 20:15:53.094878 26953 solver.cpp:244]     Train net output #0: loss = 2.74147 (* 1 = 2.74147 loss)
I0811 20:15:54.469400 26953 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0811 20:16:12.918015 26953 solver.cpp:228] Iteration 7610, loss = 2.80162
I0811 20:16:12.918084 26953 solver.cpp:244]     Train net output #0: loss = 2.80162 (* 1 = 2.80162 loss)
I0811 20:16:14.319612 26953 sgd_solver.cpp:106] Iteration 7610, lr = 0.01
I0811 20:16:32.741734 26953 solver.cpp:228] Iteration 7620, loss = 2.71116
I0811 20:16:32.742337 26953 solver.cpp:244]     Train net output #0: loss = 2.71116 (* 1 = 2.71116 loss)
I0811 20:16:34.134654 26953 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0811 20:16:52.594446 26953 solver.cpp:228] Iteration 7630, loss = 2.62492
I0811 20:16:52.594508 26953 solver.cpp:244]     Train net output #0: loss = 2.62492 (* 1 = 2.62492 loss)
I0811 20:16:54.000130 26953 sgd_solver.cpp:106] Iteration 7630, lr = 0.01
I0811 20:17:12.398807 26953 solver.cpp:228] Iteration 7640, loss = 2.66235
I0811 20:17:12.399056 26953 solver.cpp:244]     Train net output #0: loss = 2.66235 (* 1 = 2.66235 loss)
I0811 20:17:13.805881 26953 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0811 20:17:32.213903 26953 solver.cpp:228] Iteration 7650, loss = 2.80158
I0811 20:17:32.213966 26953 solver.cpp:244]     Train net output #0: loss = 2.80158 (* 1 = 2.80158 loss)
I0811 20:17:33.617914 26953 sgd_solver.cpp:106] Iteration 7650, lr = 0.01
I0811 20:17:52.051172 26953 solver.cpp:228] Iteration 7660, loss = 2.74399
I0811 20:17:52.051436 26953 solver.cpp:244]     Train net output #0: loss = 2.74399 (* 1 = 2.74399 loss)
I0811 20:17:53.476979 26953 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0811 20:18:11.912878 26953 solver.cpp:228] Iteration 7670, loss = 2.61495
I0811 20:18:11.912941 26953 solver.cpp:244]     Train net output #0: loss = 2.61495 (* 1 = 2.61495 loss)
I0811 20:18:13.304504 26953 sgd_solver.cpp:106] Iteration 7670, lr = 0.01
I0811 20:18:31.725416 26953 solver.cpp:228] Iteration 7680, loss = 2.68176
I0811 20:18:31.725639 26953 solver.cpp:244]     Train net output #0: loss = 2.68176 (* 1 = 2.68176 loss)
I0811 20:18:33.132937 26953 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0811 20:18:51.594338 26953 solver.cpp:228] Iteration 7690, loss = 2.76599
I0811 20:18:51.594411 26953 solver.cpp:244]     Train net output #0: loss = 2.76599 (* 1 = 2.76599 loss)
I0811 20:18:52.995116 26953 sgd_solver.cpp:106] Iteration 7690, lr = 0.01
I0811 20:19:10.825305 26953 solver.cpp:337] Iteration 7700, Testing net (#0)
I0811 20:19:11.412312 26953 solver.cpp:404]     Test net output #0: accuracy = 0.42
I0811 20:19:11.412377 26953 solver.cpp:404]     Test net output #1: loss = 2.71888 (* 1 = 2.71888 loss)
I0811 20:19:11.990255 26953 solver.cpp:228] Iteration 7700, loss = 2.70424
I0811 20:19:11.990341 26953 solver.cpp:244]     Train net output #0: loss = 2.70424 (* 1 = 2.70424 loss)
I0811 20:19:13.361871 26953 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0811 20:19:31.854467 26953 solver.cpp:228] Iteration 7710, loss = 2.75216
I0811 20:19:31.854537 26953 solver.cpp:244]     Train net output #0: loss = 2.75216 (* 1 = 2.75216 loss)
I0811 20:19:33.275017 26953 sgd_solver.cpp:106] Iteration 7710, lr = 0.01
I0811 20:19:51.698104 26953 solver.cpp:228] Iteration 7720, loss = 2.69591
I0811 20:19:51.698349 26953 solver.cpp:244]     Train net output #0: loss = 2.69591 (* 1 = 2.69591 loss)
I0811 20:19:53.097657 26953 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0811 20:20:11.519840 26953 solver.cpp:228] Iteration 7730, loss = 2.84535
I0811 20:20:11.519903 26953 solver.cpp:244]     Train net output #0: loss = 2.84535 (* 1 = 2.84535 loss)
I0811 20:20:12.928771 26953 sgd_solver.cpp:106] Iteration 7730, lr = 0.01
I0811 20:20:31.438361 26953 solver.cpp:228] Iteration 7740, loss = 2.72903
I0811 20:20:31.438591 26953 solver.cpp:244]     Train net output #0: loss = 2.72903 (* 1 = 2.72903 loss)
I0811 20:20:32.837754 26953 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0811 20:20:51.251269 26953 solver.cpp:228] Iteration 7750, loss = 2.68932
I0811 20:20:51.251339 26953 solver.cpp:244]     Train net output #0: loss = 2.68932 (* 1 = 2.68932 loss)
I0811 20:20:52.643194 26953 sgd_solver.cpp:106] Iteration 7750, lr = 0.01
I0811 20:21:11.109232 26953 solver.cpp:228] Iteration 7760, loss = 2.72866
I0811 20:21:11.109428 26953 solver.cpp:244]     Train net output #0: loss = 2.72866 (* 1 = 2.72866 loss)
I0811 20:21:12.508878 26953 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0811 20:21:30.882375 26953 solver.cpp:228] Iteration 7770, loss = 2.56666
I0811 20:21:30.882432 26953 solver.cpp:244]     Train net output #0: loss = 2.56666 (* 1 = 2.56666 loss)
I0811 20:21:32.304082 26953 sgd_solver.cpp:106] Iteration 7770, lr = 0.01
I0811 20:21:50.759305 26953 solver.cpp:228] Iteration 7780, loss = 2.69163
I0811 20:21:50.759497 26953 solver.cpp:244]     Train net output #0: loss = 2.69163 (* 1 = 2.69163 loss)
I0811 20:21:52.166203 26953 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0811 20:22:10.593683 26953 solver.cpp:228] Iteration 7790, loss = 2.88974
I0811 20:22:10.593755 26953 solver.cpp:244]     Train net output #0: loss = 2.88974 (* 1 = 2.88974 loss)
I0811 20:22:12.005367 26953 sgd_solver.cpp:106] Iteration 7790, lr = 0.01
I0811 20:22:29.847623 26953 solver.cpp:337] Iteration 7800, Testing net (#0)
I0811 20:22:30.443979 26953 solver.cpp:404]     Test net output #0: accuracy = 0.42
I0811 20:22:30.444056 26953 solver.cpp:404]     Test net output #1: loss = 2.73225 (* 1 = 2.73225 loss)
I0811 20:22:31.018123 26953 solver.cpp:228] Iteration 7800, loss = 2.608
I0811 20:22:31.018220 26953 solver.cpp:244]     Train net output #0: loss = 2.608 (* 1 = 2.608 loss)
I0811 20:22:32.413951 26953 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0811 20:22:50.799816 26953 solver.cpp:228] Iteration 7810, loss = 2.75202
I0811 20:22:50.799887 26953 solver.cpp:244]     Train net output #0: loss = 2.75202 (* 1 = 2.75202 loss)
I0811 20:22:52.198307 26953 sgd_solver.cpp:106] Iteration 7810, lr = 0.01
I0811 20:23:10.670346 26953 solver.cpp:228] Iteration 7820, loss = 2.64953
I0811 20:23:10.670588 26953 solver.cpp:244]     Train net output #0: loss = 2.64953 (* 1 = 2.64953 loss)
I0811 20:23:12.082882 26953 sgd_solver.cpp:106] Iteration 7820, lr = 0.01
I0811 20:23:30.645280 26953 solver.cpp:228] Iteration 7830, loss = 2.85488
I0811 20:23:30.645344 26953 solver.cpp:244]     Train net output #0: loss = 2.85488 (* 1 = 2.85488 loss)
I0811 20:23:32.055826 26953 sgd_solver.cpp:106] Iteration 7830, lr = 0.01
I0811 20:23:50.570250 26953 solver.cpp:228] Iteration 7840, loss = 2.73681
I0811 20:23:50.570500 26953 solver.cpp:244]     Train net output #0: loss = 2.73681 (* 1 = 2.73681 loss)
I0811 20:23:51.982772 26953 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I0811 20:24:10.345868 26953 solver.cpp:228] Iteration 7850, loss = 2.85778
I0811 20:24:10.345957 26953 solver.cpp:244]     Train net output #0: loss = 2.85778 (* 1 = 2.85778 loss)
I0811 20:24:11.750661 26953 sgd_solver.cpp:106] Iteration 7850, lr = 0.01
I0811 20:24:30.114027 26953 solver.cpp:228] Iteration 7860, loss = 2.62947
I0811 20:24:30.114249 26953 solver.cpp:244]     Train net output #0: loss = 2.62947 (* 1 = 2.62947 loss)
I0811 20:24:31.510798 26953 sgd_solver.cpp:106] Iteration 7860, lr = 0.01
I0811 20:24:49.961933 26953 solver.cpp:228] Iteration 7870, loss = 2.56183
I0811 20:24:49.961997 26953 solver.cpp:244]     Train net output #0: loss = 2.56183 (* 1 = 2.56183 loss)
I0811 20:24:51.367533 26953 sgd_solver.cpp:106] Iteration 7870, lr = 0.01
I0811 20:25:09.745731 26953 solver.cpp:228] Iteration 7880, loss = 2.82274
I0811 20:25:09.746001 26953 solver.cpp:244]     Train net output #0: loss = 2.82274 (* 1 = 2.82274 loss)
I0811 20:25:11.142397 26953 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I0811 20:25:29.589653 26953 solver.cpp:228] Iteration 7890, loss = 2.69605
I0811 20:25:29.589716 26953 solver.cpp:244]     Train net output #0: loss = 2.69605 (* 1 = 2.69605 loss)
I0811 20:25:30.993543 26953 sgd_solver.cpp:106] Iteration 7890, lr = 0.01
I0811 20:25:48.809768 26953 solver.cpp:337] Iteration 7900, Testing net (#0)
I0811 20:25:49.410110 26953 solver.cpp:404]     Test net output #0: accuracy = 0.432
I0811 20:25:49.410212 26953 solver.cpp:404]     Test net output #1: loss = 2.61159 (* 1 = 2.61159 loss)
I0811 20:25:49.993222 26953 solver.cpp:228] Iteration 7900, loss = 2.71218
I0811 20:25:49.993299 26953 solver.cpp:244]     Train net output #0: loss = 2.71218 (* 1 = 2.71218 loss)
I0811 20:25:51.364984 26953 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0811 20:26:09.842028 26953 solver.cpp:228] Iteration 7910, loss = 2.81563
I0811 20:26:09.842103 26953 solver.cpp:244]     Train net output #0: loss = 2.81563 (* 1 = 2.81563 loss)
I0811 20:26:11.246994 26953 sgd_solver.cpp:106] Iteration 7910, lr = 0.01
I0811 20:26:29.618072 26953 solver.cpp:228] Iteration 7920, loss = 3.05193
I0811 20:26:29.618381 26953 solver.cpp:244]     Train net output #0: loss = 3.05193 (* 1 = 3.05193 loss)
I0811 20:26:31.018944 26953 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I0811 20:26:49.484062 26953 solver.cpp:228] Iteration 7930, loss = 2.8752
I0811 20:26:49.484140 26953 solver.cpp:244]     Train net output #0: loss = 2.8752 (* 1 = 2.8752 loss)
I0811 20:26:50.888428 26953 sgd_solver.cpp:106] Iteration 7930, lr = 0.01
I0811 20:27:09.293164 26953 solver.cpp:228] Iteration 7940, loss = 2.61599
I0811 20:27:09.293413 26953 solver.cpp:244]     Train net output #0: loss = 2.61599 (* 1 = 2.61599 loss)
I0811 20:27:10.696516 26953 sgd_solver.cpp:106] Iteration 7940, lr = 0.01
I0811 20:27:29.124441 26953 solver.cpp:228] Iteration 7950, loss = 2.7049
I0811 20:27:29.124506 26953 solver.cpp:244]     Train net output #0: loss = 2.7049 (* 1 = 2.7049 loss)
I0811 20:27:30.534687 26953 sgd_solver.cpp:106] Iteration 7950, lr = 0.01
I0811 20:27:48.931953 26953 solver.cpp:228] Iteration 7960, loss = 2.84464
I0811 20:27:48.932201 26953 solver.cpp:244]     Train net output #0: loss = 2.84464 (* 1 = 2.84464 loss)
I0811 20:27:50.347843 26953 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I0811 20:28:08.832717 26953 solver.cpp:228] Iteration 7970, loss = 2.64813
I0811 20:28:08.832788 26953 solver.cpp:244]     Train net output #0: loss = 2.64813 (* 1 = 2.64813 loss)
I0811 20:28:10.238241 26953 sgd_solver.cpp:106] Iteration 7970, lr = 0.01
I0811 20:28:28.603318 26953 solver.cpp:228] Iteration 7980, loss = 2.85144
I0811 20:28:28.603541 26953 solver.cpp:244]     Train net output #0: loss = 2.85144 (* 1 = 2.85144 loss)
I0811 20:28:30.013679 26953 sgd_solver.cpp:106] Iteration 7980, lr = 0.01
I0811 20:28:48.386595 26953 solver.cpp:228] Iteration 7990, loss = 2.55219
I0811 20:28:48.386667 26953 solver.cpp:244]     Train net output #0: loss = 2.55219 (* 1 = 2.55219 loss)
I0811 20:28:49.788002 26953 sgd_solver.cpp:106] Iteration 7990, lr = 0.01
I0811 20:29:07.631389 26953 solver.cpp:337] Iteration 8000, Testing net (#0)
I0811 20:29:08.221251 26953 solver.cpp:404]     Test net output #0: accuracy = 0.392
I0811 20:29:08.221305 26953 solver.cpp:404]     Test net output #1: loss = 2.87103 (* 1 = 2.87103 loss)
I0811 20:29:08.782361 26953 solver.cpp:228] Iteration 8000, loss = 2.72622
I0811 20:29:08.782438 26953 solver.cpp:244]     Train net output #0: loss = 2.72622 (* 1 = 2.72622 loss)
I0811 20:29:10.173708 26953 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0811 20:29:28.619745 26953 solver.cpp:228] Iteration 8010, loss = 2.7879
I0811 20:29:28.619815 26953 solver.cpp:244]     Train net output #0: loss = 2.7879 (* 1 = 2.7879 loss)
I0811 20:29:30.030081 26953 sgd_solver.cpp:106] Iteration 8010, lr = 0.01
I0811 20:29:48.394043 26953 solver.cpp:228] Iteration 8020, loss = 2.8039
I0811 20:29:48.394314 26953 solver.cpp:244]     Train net output #0: loss = 2.8039 (* 1 = 2.8039 loss)
I0811 20:29:49.795907 26953 sgd_solver.cpp:106] Iteration 8020, lr = 0.01
I0811 20:30:08.236976 26953 solver.cpp:228] Iteration 8030, loss = 2.95941
I0811 20:30:08.237054 26953 solver.cpp:244]     Train net output #0: loss = 2.95941 (* 1 = 2.95941 loss)
I0811 20:30:09.640455 26953 sgd_solver.cpp:106] Iteration 8030, lr = 0.01
I0811 20:30:28.061498 26953 solver.cpp:228] Iteration 8040, loss = 2.7651
I0811 20:30:28.061765 26953 solver.cpp:244]     Train net output #0: loss = 2.7651 (* 1 = 2.7651 loss)
I0811 20:30:29.478857 26953 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I0811 20:30:47.836504 26953 solver.cpp:228] Iteration 8050, loss = 2.91718
I0811 20:30:47.836580 26953 solver.cpp:244]     Train net output #0: loss = 2.91718 (* 1 = 2.91718 loss)
I0811 20:30:49.239722 26953 sgd_solver.cpp:106] Iteration 8050, lr = 0.01
I0811 20:31:07.700383 26953 solver.cpp:228] Iteration 8060, loss = 2.74679
I0811 20:31:07.700569 26953 solver.cpp:244]     Train net output #0: loss = 2.74679 (* 1 = 2.74679 loss)
I0811 20:31:09.113987 26953 sgd_solver.cpp:106] Iteration 8060, lr = 0.01
I0811 20:31:27.476387 26953 solver.cpp:228] Iteration 8070, loss = 2.78385
I0811 20:31:27.476461 26953 solver.cpp:244]     Train net output #0: loss = 2.78385 (* 1 = 2.78385 loss)
I0811 20:31:28.883782 26953 sgd_solver.cpp:106] Iteration 8070, lr = 0.01
I0811 20:31:47.327548 26953 solver.cpp:228] Iteration 8080, loss = 2.72722
I0811 20:31:47.327713 26953 solver.cpp:244]     Train net output #0: loss = 2.72722 (* 1 = 2.72722 loss)
I0811 20:31:48.732444 26953 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I0811 20:32:07.137361 26953 solver.cpp:228] Iteration 8090, loss = 2.7728
I0811 20:32:07.137436 26953 solver.cpp:244]     Train net output #0: loss = 2.7728 (* 1 = 2.7728 loss)
I0811 20:32:08.543994 26953 sgd_solver.cpp:106] Iteration 8090, lr = 0.01
I0811 20:32:26.366595 26953 solver.cpp:337] Iteration 8100, Testing net (#0)
I0811 20:32:26.955910 26953 solver.cpp:404]     Test net output #0: accuracy = 0.434
I0811 20:32:26.955986 26953 solver.cpp:404]     Test net output #1: loss = 2.62293 (* 1 = 2.62293 loss)
I0811 20:32:27.538199 26953 solver.cpp:228] Iteration 8100, loss = 2.65728
I0811 20:32:27.538275 26953 solver.cpp:244]     Train net output #0: loss = 2.65728 (* 1 = 2.65728 loss)
I0811 20:32:28.915189 26953 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0811 20:32:47.301331 26953 solver.cpp:228] Iteration 8110, loss = 2.66337
I0811 20:32:47.301411 26953 solver.cpp:244]     Train net output #0: loss = 2.66337 (* 1 = 2.66337 loss)
I0811 20:32:48.705603 26953 sgd_solver.cpp:106] Iteration 8110, lr = 0.01
I0811 20:33:07.063776 26953 solver.cpp:228] Iteration 8120, loss = 2.87114
I0811 20:33:07.064018 26953 solver.cpp:244]     Train net output #0: loss = 2.87114 (* 1 = 2.87114 loss)
I0811 20:33:08.468942 26953 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I0811 20:33:26.940898 26953 solver.cpp:228] Iteration 8130, loss = 2.77967
I0811 20:33:26.940979 26953 solver.cpp:244]     Train net output #0: loss = 2.77967 (* 1 = 2.77967 loss)
I0811 20:33:28.348107 26953 sgd_solver.cpp:106] Iteration 8130, lr = 0.01
I0811 20:33:46.734654 26953 solver.cpp:228] Iteration 8140, loss = 2.9271
I0811 20:33:46.734906 26953 solver.cpp:244]     Train net output #0: loss = 2.9271 (* 1 = 2.9271 loss)
I0811 20:33:48.144994 26953 sgd_solver.cpp:106] Iteration 8140, lr = 0.01
I0811 20:34:06.538635 26953 solver.cpp:228] Iteration 8150, loss = 2.71421
I0811 20:34:06.538712 26953 solver.cpp:244]     Train net output #0: loss = 2.71421 (* 1 = 2.71421 loss)
I0811 20:34:07.938232 26953 sgd_solver.cpp:106] Iteration 8150, lr = 0.01
I0811 20:34:26.325412 26953 solver.cpp:228] Iteration 8160, loss = 2.73127
I0811 20:34:26.325634 26953 solver.cpp:244]     Train net output #0: loss = 2.73127 (* 1 = 2.73127 loss)
I0811 20:34:27.753432 26953 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I0811 20:34:46.139662 26953 solver.cpp:228] Iteration 8170, loss = 2.73466
I0811 20:34:46.139741 26953 solver.cpp:244]     Train net output #0: loss = 2.73466 (* 1 = 2.73466 loss)
I0811 20:34:47.533632 26953 sgd_solver.cpp:106] Iteration 8170, lr = 0.01
I0811 20:35:05.932627 26953 solver.cpp:228] Iteration 8180, loss = 2.87998
I0811 20:35:05.932884 26953 solver.cpp:244]     Train net output #0: loss = 2.87998 (* 1 = 2.87998 loss)
I0811 20:35:07.341761 26953 sgd_solver.cpp:106] Iteration 8180, lr = 0.01
I0811 20:35:25.692932 26953 solver.cpp:228] Iteration 8190, loss = 2.64594
I0811 20:35:25.693008 26953 solver.cpp:244]     Train net output #0: loss = 2.64594 (* 1 = 2.64594 loss)
I0811 20:35:27.101259 26953 sgd_solver.cpp:106] Iteration 8190, lr = 0.01
I0811 20:35:44.932273 26953 solver.cpp:337] Iteration 8200, Testing net (#0)
I0811 20:35:45.523704 26953 solver.cpp:404]     Test net output #0: accuracy = 0.418
I0811 20:35:45.523777 26953 solver.cpp:404]     Test net output #1: loss = 2.74476 (* 1 = 2.74476 loss)
I0811 20:35:46.085690 26953 solver.cpp:228] Iteration 8200, loss = 2.78812
I0811 20:35:46.085767 26953 solver.cpp:244]     Train net output #0: loss = 2.78812 (* 1 = 2.78812 loss)
I0811 20:35:47.486346 26953 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0811 20:36:05.891196 26953 solver.cpp:228] Iteration 8210, loss = 2.83143
I0811 20:36:05.891278 26953 solver.cpp:244]     Train net output #0: loss = 2.83143 (* 1 = 2.83143 loss)
I0811 20:36:07.301301 26953 sgd_solver.cpp:106] Iteration 8210, lr = 0.01
I0811 20:36:25.700469 26953 solver.cpp:228] Iteration 8220, loss = 2.75099
I0811 20:36:25.700691 26953 solver.cpp:244]     Train net output #0: loss = 2.75099 (* 1 = 2.75099 loss)
I0811 20:36:27.110991 26953 sgd_solver.cpp:106] Iteration 8220, lr = 0.01
I0811 20:36:45.538609 26953 solver.cpp:228] Iteration 8230, loss = 2.83076
I0811 20:36:45.538683 26953 solver.cpp:244]     Train net output #0: loss = 2.83076 (* 1 = 2.83076 loss)
I0811 20:36:46.962324 26953 sgd_solver.cpp:106] Iteration 8230, lr = 0.01
I0811 20:37:05.465342 26953 solver.cpp:228] Iteration 8240, loss = 2.89865
I0811 20:37:05.465569 26953 solver.cpp:244]     Train net output #0: loss = 2.89865 (* 1 = 2.89865 loss)
I0811 20:37:06.863973 26953 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I0811 20:37:25.260120 26953 solver.cpp:228] Iteration 8250, loss = 2.64708
I0811 20:37:25.260193 26953 solver.cpp:244]     Train net output #0: loss = 2.64708 (* 1 = 2.64708 loss)
I0811 20:37:26.674933 26953 sgd_solver.cpp:106] Iteration 8250, lr = 0.01
I0811 20:37:45.135812 26953 solver.cpp:228] Iteration 8260, loss = 2.89036
I0811 20:37:45.136024 26953 solver.cpp:244]     Train net output #0: loss = 2.89036 (* 1 = 2.89036 loss)
I0811 20:37:46.538935 26953 sgd_solver.cpp:106] Iteration 8260, lr = 0.01
I0811 20:38:04.912618 26953 solver.cpp:228] Iteration 8270, loss = 2.74934
I0811 20:38:04.912690 26953 solver.cpp:244]     Train net output #0: loss = 2.74934 (* 1 = 2.74934 loss)
I0811 20:38:06.315845 26953 sgd_solver.cpp:106] Iteration 8270, lr = 0.01
I0811 20:38:24.719698 26953 solver.cpp:228] Iteration 8280, loss = 2.67151
I0811 20:38:24.719837 26953 solver.cpp:244]     Train net output #0: loss = 2.67151 (* 1 = 2.67151 loss)
I0811 20:38:26.132167 26953 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I0811 20:38:44.566146 26953 solver.cpp:228] Iteration 8290, loss = 2.52198
I0811 20:38:44.566226 26953 solver.cpp:244]     Train net output #0: loss = 2.52198 (* 1 = 2.52198 loss)
I0811 20:38:45.969434 26953 sgd_solver.cpp:106] Iteration 8290, lr = 0.01
I0811 20:39:03.833726 26953 solver.cpp:337] Iteration 8300, Testing net (#0)
I0811 20:39:04.421845 26953 solver.cpp:404]     Test net output #0: accuracy = 0.424
I0811 20:39:04.421910 26953 solver.cpp:404]     Test net output #1: loss = 2.65262 (* 1 = 2.65262 loss)
I0811 20:39:05.000002 26953 solver.cpp:228] Iteration 8300, loss = 2.52076
I0811 20:39:05.000077 26953 solver.cpp:244]     Train net output #0: loss = 2.52076 (* 1 = 2.52076 loss)
I0811 20:39:06.371076 26953 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0811 20:39:24.772366 26953 solver.cpp:228] Iteration 8310, loss = 2.72402
I0811 20:39:24.772433 26953 solver.cpp:244]     Train net output #0: loss = 2.72402 (* 1 = 2.72402 loss)
I0811 20:39:26.180848 26953 sgd_solver.cpp:106] Iteration 8310, lr = 0.01
I0811 20:39:44.645845 26953 solver.cpp:228] Iteration 8320, loss = 2.76798
I0811 20:39:44.646095 26953 solver.cpp:244]     Train net output #0: loss = 2.76798 (* 1 = 2.76798 loss)
I0811 20:39:46.049686 26953 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I0811 20:40:04.424010 26953 solver.cpp:228] Iteration 8330, loss = 2.54077
I0811 20:40:04.424082 26953 solver.cpp:244]     Train net output #0: loss = 2.54077 (* 1 = 2.54077 loss)
I0811 20:40:05.825914 26953 sgd_solver.cpp:106] Iteration 8330, lr = 0.01
I0811 20:40:24.197047 26953 solver.cpp:228] Iteration 8340, loss = 2.84789
I0811 20:40:24.197273 26953 solver.cpp:244]     Train net output #0: loss = 2.84789 (* 1 = 2.84789 loss)
I0811 20:40:25.595156 26953 sgd_solver.cpp:106] Iteration 8340, lr = 0.01
I0811 20:40:44.049157 26953 solver.cpp:228] Iteration 8350, loss = 2.7479
I0811 20:40:44.049235 26953 solver.cpp:244]     Train net output #0: loss = 2.7479 (* 1 = 2.7479 loss)
I0811 20:40:45.453433 26953 sgd_solver.cpp:106] Iteration 8350, lr = 0.01
I0811 20:41:03.809363 26953 solver.cpp:228] Iteration 8360, loss = 2.62153
I0811 20:41:03.809628 26953 solver.cpp:244]     Train net output #0: loss = 2.62153 (* 1 = 2.62153 loss)
I0811 20:41:05.225098 26953 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I0811 20:41:23.670537 26953 solver.cpp:228] Iteration 8370, loss = 2.94054
I0811 20:41:23.670605 26953 solver.cpp:244]     Train net output #0: loss = 2.94054 (* 1 = 2.94054 loss)
I0811 20:41:25.070000 26953 sgd_solver.cpp:106] Iteration 8370, lr = 0.01
I0811 20:41:43.457803 26953 solver.cpp:228] Iteration 8380, loss = 2.6492
I0811 20:41:43.457999 26953 solver.cpp:244]     Train net output #0: loss = 2.6492 (* 1 = 2.6492 loss)
I0811 20:41:44.862746 26953 sgd_solver.cpp:106] Iteration 8380, lr = 0.01
I0811 20:42:03.275159 26953 solver.cpp:228] Iteration 8390, loss = 2.66943
I0811 20:42:03.275228 26953 solver.cpp:244]     Train net output #0: loss = 2.66943 (* 1 = 2.66943 loss)
I0811 20:42:04.662397 26953 sgd_solver.cpp:106] Iteration 8390, lr = 0.01
I0811 20:42:22.515307 26953 solver.cpp:337] Iteration 8400, Testing net (#0)
I0811 20:42:23.109927 26953 solver.cpp:404]     Test net output #0: accuracy = 0.444
I0811 20:42:23.110005 26953 solver.cpp:404]     Test net output #1: loss = 2.55655 (* 1 = 2.55655 loss)
I0811 20:42:23.699983 26953 solver.cpp:228] Iteration 8400, loss = 2.93836
I0811 20:42:23.700072 26953 solver.cpp:244]     Train net output #0: loss = 2.93836 (* 1 = 2.93836 loss)
I0811 20:42:25.070662 26953 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0811 20:42:43.429291 26953 solver.cpp:228] Iteration 8410, loss = 2.74182
I0811 20:42:43.429388 26953 solver.cpp:244]     Train net output #0: loss = 2.74182 (* 1 = 2.74182 loss)
I0811 20:42:44.825768 26953 sgd_solver.cpp:106] Iteration 8410, lr = 0.01
I0811 20:43:03.302678 26953 solver.cpp:228] Iteration 8420, loss = 2.61515
I0811 20:43:03.302891 26953 solver.cpp:244]     Train net output #0: loss = 2.61515 (* 1 = 2.61515 loss)
I0811 20:43:04.718513 26953 sgd_solver.cpp:106] Iteration 8420, lr = 0.01
I0811 20:43:23.071527 26953 solver.cpp:228] Iteration 8430, loss = 2.81205
I0811 20:43:23.071593 26953 solver.cpp:244]     Train net output #0: loss = 2.81205 (* 1 = 2.81205 loss)
I0811 20:43:24.481822 26953 sgd_solver.cpp:106] Iteration 8430, lr = 0.01
I0811 20:43:42.865353 26953 solver.cpp:228] Iteration 8440, loss = 2.69021
I0811 20:43:42.865602 26953 solver.cpp:244]     Train net output #0: loss = 2.69021 (* 1 = 2.69021 loss)
I0811 20:43:44.266763 26953 sgd_solver.cpp:106] Iteration 8440, lr = 0.01
I0811 20:44:02.682353 26953 solver.cpp:228] Iteration 8450, loss = 2.61746
I0811 20:44:02.682420 26953 solver.cpp:244]     Train net output #0: loss = 2.61746 (* 1 = 2.61746 loss)
I0811 20:44:04.085271 26953 sgd_solver.cpp:106] Iteration 8450, lr = 0.01
I0811 20:44:22.439007 26953 solver.cpp:228] Iteration 8460, loss = 2.75149
I0811 20:44:22.439249 26953 solver.cpp:244]     Train net output #0: loss = 2.75149 (* 1 = 2.75149 loss)
I0811 20:44:23.845038 26953 sgd_solver.cpp:106] Iteration 8460, lr = 0.01
I0811 20:44:42.287034 26953 solver.cpp:228] Iteration 8470, loss = 2.79095
I0811 20:44:42.287109 26953 solver.cpp:244]     Train net output #0: loss = 2.79095 (* 1 = 2.79095 loss)
I0811 20:44:43.691294 26953 sgd_solver.cpp:106] Iteration 8470, lr = 0.01
I0811 20:45:02.070706 26953 solver.cpp:228] Iteration 8480, loss = 2.73635
I0811 20:45:02.070938 26953 solver.cpp:244]     Train net output #0: loss = 2.73635 (* 1 = 2.73635 loss)
I0811 20:45:03.471963 26953 sgd_solver.cpp:106] Iteration 8480, lr = 0.01
I0811 20:45:21.844322 26953 solver.cpp:228] Iteration 8490, loss = 2.70952
I0811 20:45:21.844393 26953 solver.cpp:244]     Train net output #0: loss = 2.70952 (* 1 = 2.70952 loss)
I0811 20:45:23.266865 26953 sgd_solver.cpp:106] Iteration 8490, lr = 0.01
I0811 20:45:41.120740 26953 solver.cpp:337] Iteration 8500, Testing net (#0)
I0811 20:45:41.714385 26953 solver.cpp:404]     Test net output #0: accuracy = 0.424
I0811 20:45:41.714476 26953 solver.cpp:404]     Test net output #1: loss = 2.57132 (* 1 = 2.57132 loss)
I0811 20:45:42.284669 26953 solver.cpp:228] Iteration 8500, loss = 2.64566
I0811 20:45:42.284739 26953 solver.cpp:244]     Train net output #0: loss = 2.64566 (* 1 = 2.64566 loss)
I0811 20:45:43.675185 26953 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0811 20:46:02.090302 26953 solver.cpp:228] Iteration 8510, loss = 2.81287
I0811 20:46:02.090373 26953 solver.cpp:244]     Train net output #0: loss = 2.81287 (* 1 = 2.81287 loss)
I0811 20:46:03.480679 26953 sgd_solver.cpp:106] Iteration 8510, lr = 0.01
I0811 20:46:21.898154 26953 solver.cpp:228] Iteration 8520, loss = 2.92792
I0811 20:46:21.898396 26953 solver.cpp:244]     Train net output #0: loss = 2.92792 (* 1 = 2.92792 loss)
I0811 20:46:23.306315 26953 sgd_solver.cpp:106] Iteration 8520, lr = 0.01
I0811 20:46:41.685420 26953 solver.cpp:228] Iteration 8530, loss = 2.63071
I0811 20:46:41.685489 26953 solver.cpp:244]     Train net output #0: loss = 2.63071 (* 1 = 2.63071 loss)
I0811 20:46:43.085321 26953 sgd_solver.cpp:106] Iteration 8530, lr = 0.01
I0811 20:47:01.524114 26953 solver.cpp:228] Iteration 8540, loss = 2.66859
I0811 20:47:01.524283 26953 solver.cpp:244]     Train net output #0: loss = 2.66859 (* 1 = 2.66859 loss)
I0811 20:47:02.928347 26953 sgd_solver.cpp:106] Iteration 8540, lr = 0.01
I0811 20:47:21.331979 26953 solver.cpp:228] Iteration 8550, loss = 2.65399
I0811 20:47:21.332052 26953 solver.cpp:244]     Train net output #0: loss = 2.65399 (* 1 = 2.65399 loss)
I0811 20:47:22.750025 26953 sgd_solver.cpp:106] Iteration 8550, lr = 0.01
I0811 20:47:41.132619 26953 solver.cpp:228] Iteration 8560, loss = 2.63575
I0811 20:47:41.132781 26953 solver.cpp:244]     Train net output #0: loss = 2.63575 (* 1 = 2.63575 loss)
I0811 20:47:42.523293 26953 sgd_solver.cpp:106] Iteration 8560, lr = 0.01
I0811 20:48:00.977628 26953 solver.cpp:228] Iteration 8570, loss = 2.63699
I0811 20:48:00.977699 26953 solver.cpp:244]     Train net output #0: loss = 2.63699 (* 1 = 2.63699 loss)
I0811 20:48:02.382639 26953 sgd_solver.cpp:106] Iteration 8570, lr = 0.01
I0811 20:48:20.784889 26953 solver.cpp:228] Iteration 8580, loss = 2.6547
I0811 20:48:20.785074 26953 solver.cpp:244]     Train net output #0: loss = 2.6547 (* 1 = 2.6547 loss)
I0811 20:48:22.187525 26953 sgd_solver.cpp:106] Iteration 8580, lr = 0.01
I0811 20:48:40.597805 26953 solver.cpp:228] Iteration 8590, loss = 2.66505
I0811 20:48:40.597882 26953 solver.cpp:244]     Train net output #0: loss = 2.66505 (* 1 = 2.66505 loss)
I0811 20:48:41.996702 26953 sgd_solver.cpp:106] Iteration 8590, lr = 0.01
I0811 20:48:59.762905 26953 solver.cpp:337] Iteration 8600, Testing net (#0)
I0811 20:49:00.358184 26953 solver.cpp:404]     Test net output #0: accuracy = 0.41
I0811 20:49:00.358266 26953 solver.cpp:404]     Test net output #1: loss = 2.72354 (* 1 = 2.72354 loss)
I0811 20:49:00.918059 26953 solver.cpp:228] Iteration 8600, loss = 2.66965
I0811 20:49:00.918136 26953 solver.cpp:244]     Train net output #0: loss = 2.66965 (* 1 = 2.66965 loss)
I0811 20:49:02.305058 26953 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I0811 20:49:20.750926 26953 solver.cpp:228] Iteration 8610, loss = 3.00112
I0811 20:49:20.751001 26953 solver.cpp:244]     Train net output #0: loss = 3.00112 (* 1 = 3.00112 loss)
I0811 20:49:22.163537 26953 sgd_solver.cpp:106] Iteration 8610, lr = 0.01
I0811 20:49:40.565874 26953 solver.cpp:228] Iteration 8620, loss = 2.56273
I0811 20:49:40.566164 26953 solver.cpp:244]     Train net output #0: loss = 2.56273 (* 1 = 2.56273 loss)
I0811 20:49:41.970073 26953 sgd_solver.cpp:106] Iteration 8620, lr = 0.01
I0811 20:50:00.404965 26953 solver.cpp:228] Iteration 8630, loss = 2.77554
I0811 20:50:00.405030 26953 solver.cpp:244]     Train net output #0: loss = 2.77554 (* 1 = 2.77554 loss)
I0811 20:50:01.808487 26953 sgd_solver.cpp:106] Iteration 8630, lr = 0.01
I0811 20:50:20.186295 26953 solver.cpp:228] Iteration 8640, loss = 2.78156
I0811 20:50:20.186436 26953 solver.cpp:244]     Train net output #0: loss = 2.78156 (* 1 = 2.78156 loss)
I0811 20:50:21.586861 26953 sgd_solver.cpp:106] Iteration 8640, lr = 0.01
I0811 20:50:39.985764 26953 solver.cpp:228] Iteration 8650, loss = 2.589
I0811 20:50:39.985836 26953 solver.cpp:244]     Train net output #0: loss = 2.589 (* 1 = 2.589 loss)
I0811 20:50:41.383443 26953 sgd_solver.cpp:106] Iteration 8650, lr = 0.01
I0811 20:50:59.848091 26953 solver.cpp:228] Iteration 8660, loss = 2.81944
I0811 20:50:59.848258 26953 solver.cpp:244]     Train net output #0: loss = 2.81944 (* 1 = 2.81944 loss)
I0811 20:51:01.264210 26953 sgd_solver.cpp:106] Iteration 8660, lr = 0.01
I0811 20:51:19.659260 26953 solver.cpp:228] Iteration 8670, loss = 2.59626
I0811 20:51:19.659332 26953 solver.cpp:244]     Train net output #0: loss = 2.59626 (* 1 = 2.59626 loss)
I0811 20:51:21.072621 26953 sgd_solver.cpp:106] Iteration 8670, lr = 0.01
I0811 20:51:39.502111 26953 solver.cpp:228] Iteration 8680, loss = 2.53376
I0811 20:51:39.502252 26953 solver.cpp:244]     Train net output #0: loss = 2.53376 (* 1 = 2.53376 loss)
I0811 20:51:40.909000 26953 sgd_solver.cpp:106] Iteration 8680, lr = 0.01
I0811 20:51:59.289398 26953 solver.cpp:228] Iteration 8690, loss = 2.65556
I0811 20:51:59.289469 26953 solver.cpp:244]     Train net output #0: loss = 2.65556 (* 1 = 2.65556 loss)
I0811 20:52:00.693224 26953 sgd_solver.cpp:106] Iteration 8690, lr = 0.01
I0811 20:52:18.614123 26953 solver.cpp:337] Iteration 8700, Testing net (#0)
I0811 20:52:19.208459 26953 solver.cpp:404]     Test net output #0: accuracy = 0.424
I0811 20:52:19.208525 26953 solver.cpp:404]     Test net output #1: loss = 2.73752 (* 1 = 2.73752 loss)
I0811 20:52:19.773020 26953 solver.cpp:228] Iteration 8700, loss = 2.74967
I0811 20:52:19.773079 26953 solver.cpp:244]     Train net output #0: loss = 2.74967 (* 1 = 2.74967 loss)
I0811 20:52:21.152763 26953 sgd_solver.cpp:106] Iteration 8700, lr = 0.01
I0811 20:52:39.521455 26953 solver.cpp:228] Iteration 8710, loss = 2.59655
I0811 20:52:39.521525 26953 solver.cpp:244]     Train net output #0: loss = 2.59655 (* 1 = 2.59655 loss)
I0811 20:52:40.909147 26953 sgd_solver.cpp:106] Iteration 8710, lr = 0.01
I0811 20:52:59.341471 26953 solver.cpp:228] Iteration 8720, loss = 2.80463
I0811 20:52:59.341773 26953 solver.cpp:244]     Train net output #0: loss = 2.80463 (* 1 = 2.80463 loss)
I0811 20:53:00.748950 26953 sgd_solver.cpp:106] Iteration 8720, lr = 0.01
I0811 20:53:19.104647 26953 solver.cpp:228] Iteration 8730, loss = 2.66981
I0811 20:53:19.104707 26953 solver.cpp:244]     Train net output #0: loss = 2.66981 (* 1 = 2.66981 loss)
I0811 20:53:20.520416 26953 sgd_solver.cpp:106] Iteration 8730, lr = 0.01
I0811 20:53:38.887104 26953 solver.cpp:228] Iteration 8740, loss = 2.70506
I0811 20:53:38.887284 26953 solver.cpp:244]     Train net output #0: loss = 2.70506 (* 1 = 2.70506 loss)
I0811 20:53:40.290164 26953 sgd_solver.cpp:106] Iteration 8740, lr = 0.01
I0811 20:53:58.703663 26953 solver.cpp:228] Iteration 8750, loss = 2.79973
I0811 20:53:58.703742 26953 solver.cpp:244]     Train net output #0: loss = 2.79973 (* 1 = 2.79973 loss)
I0811 20:54:00.101418 26953 sgd_solver.cpp:106] Iteration 8750, lr = 0.01
I0811 20:54:18.465175 26953 solver.cpp:228] Iteration 8760, loss = 2.75352
I0811 20:54:18.465328 26953 solver.cpp:244]     Train net output #0: loss = 2.75352 (* 1 = 2.75352 loss)
I0811 20:54:19.886791 26953 sgd_solver.cpp:106] Iteration 8760, lr = 0.01
I0811 20:54:38.302958 26953 solver.cpp:228] Iteration 8770, loss = 2.8292
I0811 20:54:38.303038 26953 solver.cpp:244]     Train net output #0: loss = 2.8292 (* 1 = 2.8292 loss)
I0811 20:54:39.693955 26953 sgd_solver.cpp:106] Iteration 8770, lr = 0.01
I0811 20:54:58.107543 26953 solver.cpp:228] Iteration 8780, loss = 2.82921
I0811 20:54:58.107781 26953 solver.cpp:244]     Train net output #0: loss = 2.82921 (* 1 = 2.82921 loss)
I0811 20:54:59.508092 26953 sgd_solver.cpp:106] Iteration 8780, lr = 0.01
I0811 20:55:17.875479 26953 solver.cpp:228] Iteration 8790, loss = 2.59898
I0811 20:55:17.875561 26953 solver.cpp:244]     Train net output #0: loss = 2.59898 (* 1 = 2.59898 loss)
I0811 20:55:19.298357 26953 sgd_solver.cpp:106] Iteration 8790, lr = 0.01
I0811 20:55:37.238330 26953 solver.cpp:337] Iteration 8800, Testing net (#0)
I0811 20:55:37.823978 26953 solver.cpp:404]     Test net output #0: accuracy = 0.47
I0811 20:55:37.824036 26953 solver.cpp:404]     Test net output #1: loss = 2.55659 (* 1 = 2.55659 loss)
I0811 20:55:38.409413 26953 solver.cpp:228] Iteration 8800, loss = 2.65751
I0811 20:55:38.409487 26953 solver.cpp:244]     Train net output #0: loss = 2.65751 (* 1 = 2.65751 loss)
I0811 20:55:39.768710 26953 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I0811 20:55:58.221333 26953 solver.cpp:228] Iteration 8810, loss = 2.80982
I0811 20:55:58.221411 26953 solver.cpp:244]     Train net output #0: loss = 2.80982 (* 1 = 2.80982 loss)
I0811 20:55:59.608758 26953 sgd_solver.cpp:106] Iteration 8810, lr = 0.01
I0811 20:56:17.989540 26953 solver.cpp:228] Iteration 8820, loss = 2.73735
I0811 20:56:17.989787 26953 solver.cpp:244]     Train net output #0: loss = 2.73735 (* 1 = 2.73735 loss)
I0811 20:56:19.404142 26953 sgd_solver.cpp:106] Iteration 8820, lr = 0.01
I0811 20:56:37.756992 26953 solver.cpp:228] Iteration 8830, loss = 2.7396
I0811 20:56:37.757086 26953 solver.cpp:244]     Train net output #0: loss = 2.7396 (* 1 = 2.7396 loss)
I0811 20:56:39.155555 26953 sgd_solver.cpp:106] Iteration 8830, lr = 0.01
I0811 20:56:57.580330 26953 solver.cpp:228] Iteration 8840, loss = 2.73888
I0811 20:56:57.580569 26953 solver.cpp:244]     Train net output #0: loss = 2.73888 (* 1 = 2.73888 loss)
I0811 20:56:58.974493 26953 sgd_solver.cpp:106] Iteration 8840, lr = 0.01
I0811 20:57:17.372570 26953 solver.cpp:228] Iteration 8850, loss = 2.54885
I0811 20:57:17.372649 26953 solver.cpp:244]     Train net output #0: loss = 2.54885 (* 1 = 2.54885 loss)
I0811 20:57:18.781703 26953 sgd_solver.cpp:106] Iteration 8850, lr = 0.01
I0811 20:57:37.201323 26953 solver.cpp:228] Iteration 8860, loss = 2.45257
I0811 20:57:37.201555 26953 solver.cpp:244]     Train net output #0: loss = 2.45257 (* 1 = 2.45257 loss)
I0811 20:57:38.591730 26953 sgd_solver.cpp:106] Iteration 8860, lr = 0.01
I0811 20:57:57.001780 26953 solver.cpp:228] Iteration 8870, loss = 2.81692
I0811 20:57:57.001858 26953 solver.cpp:244]     Train net output #0: loss = 2.81692 (* 1 = 2.81692 loss)
I0811 20:57:58.402411 26953 sgd_solver.cpp:106] Iteration 8870, lr = 0.01
I0811 20:58:16.779580 26953 solver.cpp:228] Iteration 8880, loss = 2.60816
I0811 20:58:16.779772 26953 solver.cpp:244]     Train net output #0: loss = 2.60816 (* 1 = 2.60816 loss)
I0811 20:58:18.192745 26953 sgd_solver.cpp:106] Iteration 8880, lr = 0.01
I0811 20:58:36.625969 26953 solver.cpp:228] Iteration 8890, loss = 2.62373
I0811 20:58:36.626046 26953 solver.cpp:244]     Train net output #0: loss = 2.62373 (* 1 = 2.62373 loss)
I0811 20:58:38.012455 26953 sgd_solver.cpp:106] Iteration 8890, lr = 0.01
I0811 20:58:55.836671 26953 solver.cpp:337] Iteration 8900, Testing net (#0)
I0811 20:58:56.427467 26953 solver.cpp:404]     Test net output #0: accuracy = 0.45
I0811 20:58:56.427532 26953 solver.cpp:404]     Test net output #1: loss = 2.46763 (* 1 = 2.46763 loss)
I0811 20:58:56.990413 26953 solver.cpp:228] Iteration 8900, loss = 2.69739
I0811 20:58:56.990490 26953 solver.cpp:244]     Train net output #0: loss = 2.69739 (* 1 = 2.69739 loss)
I0811 20:58:58.377007 26953 sgd_solver.cpp:106] Iteration 8900, lr = 0.01
I0811 20:59:16.795392 26953 solver.cpp:228] Iteration 8910, loss = 2.55339
I0811 20:59:16.795474 26953 solver.cpp:244]     Train net output #0: loss = 2.55339 (* 1 = 2.55339 loss)
I0811 20:59:18.199178 26953 sgd_solver.cpp:106] Iteration 8910, lr = 0.01
I0811 20:59:36.616511 26953 solver.cpp:228] Iteration 8920, loss = 2.4999
I0811 20:59:36.616781 26953 solver.cpp:244]     Train net output #0: loss = 2.4999 (* 1 = 2.4999 loss)
I0811 20:59:38.010790 26953 sgd_solver.cpp:106] Iteration 8920, lr = 0.01
I0811 20:59:56.518787 26953 solver.cpp:228] Iteration 8930, loss = 2.57992
I0811 20:59:56.518863 26953 solver.cpp:244]     Train net output #0: loss = 2.57992 (* 1 = 2.57992 loss)
I0811 20:59:57.906888 26953 sgd_solver.cpp:106] Iteration 8930, lr = 0.01
I0811 21:00:16.284808 26953 solver.cpp:228] Iteration 8940, loss = 2.55308
I0811 21:00:16.285049 26953 solver.cpp:244]     Train net output #0: loss = 2.55308 (* 1 = 2.55308 loss)
I0811 21:00:17.691962 26953 sgd_solver.cpp:106] Iteration 8940, lr = 0.01
I0811 21:00:36.096593 26953 solver.cpp:228] Iteration 8950, loss = 2.62212
I0811 21:00:36.096675 26953 solver.cpp:244]     Train net output #0: loss = 2.62212 (* 1 = 2.62212 loss)
I0811 21:00:37.493084 26953 sgd_solver.cpp:106] Iteration 8950, lr = 0.01
I0811 21:00:55.918900 26953 solver.cpp:228] Iteration 8960, loss = 2.51025
I0811 21:00:55.919119 26953 solver.cpp:244]     Train net output #0: loss = 2.51025 (* 1 = 2.51025 loss)
I0811 21:00:57.330072 26953 sgd_solver.cpp:106] Iteration 8960, lr = 0.01
I0811 21:01:15.678836 26953 solver.cpp:228] Iteration 8970, loss = 2.63155
I0811 21:01:15.678920 26953 solver.cpp:244]     Train net output #0: loss = 2.63155 (* 1 = 2.63155 loss)
I0811 21:01:17.102664 26953 sgd_solver.cpp:106] Iteration 8970, lr = 0.01
I0811 21:01:35.461375 26953 solver.cpp:228] Iteration 8980, loss = 2.68493
I0811 21:01:35.461571 26953 solver.cpp:244]     Train net output #0: loss = 2.68493 (* 1 = 2.68493 loss)
I0811 21:01:36.862798 26953 sgd_solver.cpp:106] Iteration 8980, lr = 0.01
I0811 21:01:55.285300 26953 solver.cpp:228] Iteration 8990, loss = 2.68613
I0811 21:01:55.285375 26953 solver.cpp:244]     Train net output #0: loss = 2.68613 (* 1 = 2.68613 loss)
I0811 21:01:56.701246 26953 sgd_solver.cpp:106] Iteration 8990, lr = 0.01
I0811 21:02:14.479106 26953 solver.cpp:337] Iteration 9000, Testing net (#0)
I0811 21:02:15.075067 26953 solver.cpp:404]     Test net output #0: accuracy = 0.454
I0811 21:02:15.075134 26953 solver.cpp:404]     Test net output #1: loss = 2.55326 (* 1 = 2.55326 loss)
I0811 21:02:15.651294 26953 solver.cpp:228] Iteration 9000, loss = 2.49788
I0811 21:02:15.651373 26953 solver.cpp:244]     Train net output #0: loss = 2.49788 (* 1 = 2.49788 loss)
I0811 21:02:17.022521 26953 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0811 21:02:35.473121 26953 solver.cpp:228] Iteration 9010, loss = 2.56697
I0811 21:02:35.473201 26953 solver.cpp:244]     Train net output #0: loss = 2.56697 (* 1 = 2.56697 loss)
I0811 21:02:36.865031 26953 sgd_solver.cpp:106] Iteration 9010, lr = 0.01
I0811 21:02:55.269570 26953 solver.cpp:228] Iteration 9020, loss = 2.60465
I0811 21:02:55.269767 26953 solver.cpp:244]     Train net output #0: loss = 2.60465 (* 1 = 2.60465 loss)
I0811 21:02:56.672209 26953 sgd_solver.cpp:106] Iteration 9020, lr = 0.01
I0811 21:03:15.125936 26953 solver.cpp:228] Iteration 9030, loss = 2.51596
I0811 21:03:15.126019 26953 solver.cpp:244]     Train net output #0: loss = 2.51596 (* 1 = 2.51596 loss)
I0811 21:03:16.529805 26953 sgd_solver.cpp:106] Iteration 9030, lr = 0.01
I0811 21:03:34.913355 26953 solver.cpp:228] Iteration 9040, loss = 2.72988
I0811 21:03:34.913487 26953 solver.cpp:244]     Train net output #0: loss = 2.72988 (* 1 = 2.72988 loss)
I0811 21:03:36.311918 26953 sgd_solver.cpp:106] Iteration 9040, lr = 0.01
I0811 21:03:54.746696 26953 solver.cpp:228] Iteration 9050, loss = 2.49601
I0811 21:03:54.746768 26953 solver.cpp:244]     Train net output #0: loss = 2.49601 (* 1 = 2.49601 loss)
I0811 21:03:56.130544 26953 sgd_solver.cpp:106] Iteration 9050, lr = 0.01
I0811 21:04:14.546389 26953 solver.cpp:228] Iteration 9060, loss = 2.62849
I0811 21:04:14.546651 26953 solver.cpp:244]     Train net output #0: loss = 2.62849 (* 1 = 2.62849 loss)
I0811 21:04:15.946290 26953 sgd_solver.cpp:106] Iteration 9060, lr = 0.01
I0811 21:04:34.344415 26953 solver.cpp:228] Iteration 9070, loss = 2.6424
I0811 21:04:34.344494 26953 solver.cpp:244]     Train net output #0: loss = 2.6424 (* 1 = 2.6424 loss)
I0811 21:04:35.744146 26953 sgd_solver.cpp:106] Iteration 9070, lr = 0.01
I0811 21:04:54.165477 26953 solver.cpp:228] Iteration 9080, loss = 2.73584
I0811 21:04:54.165729 26953 solver.cpp:244]     Train net output #0: loss = 2.73584 (* 1 = 2.73584 loss)
I0811 21:04:55.555970 26953 sgd_solver.cpp:106] Iteration 9080, lr = 0.01
I0811 21:05:13.951475 26953 solver.cpp:228] Iteration 9090, loss = 2.54825
I0811 21:05:13.951551 26953 solver.cpp:244]     Train net output #0: loss = 2.54825 (* 1 = 2.54825 loss)
I0811 21:05:15.366050 26953 sgd_solver.cpp:106] Iteration 9090, lr = 0.01
I0811 21:05:33.188356 26953 solver.cpp:337] Iteration 9100, Testing net (#0)
I0811 21:05:33.787199 26953 solver.cpp:404]     Test net output #0: accuracy = 0.444
I0811 21:05:33.787293 26953 solver.cpp:404]     Test net output #1: loss = 2.51886 (* 1 = 2.51886 loss)
I0811 21:05:34.352761 26953 solver.cpp:228] Iteration 9100, loss = 2.62477
I0811 21:05:34.352833 26953 solver.cpp:244]     Train net output #0: loss = 2.62477 (* 1 = 2.62477 loss)
I0811 21:05:35.742740 26953 sgd_solver.cpp:106] Iteration 9100, lr = 0.01
I0811 21:05:54.105765 26953 solver.cpp:228] Iteration 9110, loss = 2.57437
I0811 21:05:54.105839 26953 solver.cpp:244]     Train net output #0: loss = 2.57437 (* 1 = 2.57437 loss)
I0811 21:05:55.510285 26953 sgd_solver.cpp:106] Iteration 9110, lr = 0.01
I0811 21:06:13.850289 26953 solver.cpp:228] Iteration 9120, loss = 2.53474
I0811 21:06:13.850509 26953 solver.cpp:244]     Train net output #0: loss = 2.53474 (* 1 = 2.53474 loss)
I0811 21:06:15.262054 26953 sgd_solver.cpp:106] Iteration 9120, lr = 0.01
I0811 21:06:33.724375 26953 solver.cpp:228] Iteration 9130, loss = 2.50734
I0811 21:06:33.724439 26953 solver.cpp:244]     Train net output #0: loss = 2.50734 (* 1 = 2.50734 loss)
I0811 21:06:35.132014 26953 sgd_solver.cpp:106] Iteration 9130, lr = 0.01
I0811 21:06:53.469408 26953 solver.cpp:228] Iteration 9140, loss = 2.79254
I0811 21:06:53.469643 26953 solver.cpp:244]     Train net output #0: loss = 2.79254 (* 1 = 2.79254 loss)
I0811 21:06:54.885830 26953 sgd_solver.cpp:106] Iteration 9140, lr = 0.01
I0811 21:07:13.287489 26953 solver.cpp:228] Iteration 9150, loss = 2.85878
I0811 21:07:13.287547 26953 solver.cpp:244]     Train net output #0: loss = 2.85878 (* 1 = 2.85878 loss)
I0811 21:07:14.687770 26953 sgd_solver.cpp:106] Iteration 9150, lr = 0.01
I0811 21:07:33.087008 26953 solver.cpp:228] Iteration 9160, loss = 2.71789
I0811 21:07:33.087239 26953 solver.cpp:244]     Train net output #0: loss = 2.71789 (* 1 = 2.71789 loss)
I0811 21:07:34.484530 26953 sgd_solver.cpp:106] Iteration 9160, lr = 0.01
I0811 21:07:52.842875 26953 solver.cpp:228] Iteration 9170, loss = 2.69374
I0811 21:07:52.842950 26953 solver.cpp:244]     Train net output #0: loss = 2.69374 (* 1 = 2.69374 loss)
I0811 21:07:54.255640 26953 sgd_solver.cpp:106] Iteration 9170, lr = 0.01
I0811 21:08:12.624855 26953 solver.cpp:228] Iteration 9180, loss = 2.55098
I0811 21:08:12.625036 26953 solver.cpp:244]     Train net output #0: loss = 2.55098 (* 1 = 2.55098 loss)
I0811 21:08:14.019204 26953 sgd_solver.cpp:106] Iteration 9180, lr = 0.01
I0811 21:08:32.479689 26953 solver.cpp:228] Iteration 9190, loss = 2.67676
I0811 21:08:32.479756 26953 solver.cpp:244]     Train net output #0: loss = 2.67676 (* 1 = 2.67676 loss)
I0811 21:08:33.883466 26953 sgd_solver.cpp:106] Iteration 9190, lr = 0.01
I0811 21:08:51.676525 26953 solver.cpp:337] Iteration 9200, Testing net (#0)
I0811 21:08:52.270615 26953 solver.cpp:404]     Test net output #0: accuracy = 0.428
I0811 21:08:52.270684 26953 solver.cpp:404]     Test net output #1: loss = 2.54794 (* 1 = 2.54794 loss)
I0811 21:08:52.843320 26953 solver.cpp:228] Iteration 9200, loss = 2.60932
I0811 21:08:52.843397 26953 solver.cpp:244]     Train net output #0: loss = 2.60932 (* 1 = 2.60932 loss)
I0811 21:08:54.219136 26953 sgd_solver.cpp:106] Iteration 9200, lr = 0.01
I0811 21:09:12.677660 26953 solver.cpp:228] Iteration 9210, loss = 2.67502
I0811 21:09:12.677719 26953 solver.cpp:244]     Train net output #0: loss = 2.67502 (* 1 = 2.67502 loss)
I0811 21:09:14.093094 26953 sgd_solver.cpp:106] Iteration 9210, lr = 0.01
I0811 21:09:32.483098 26953 solver.cpp:228] Iteration 9220, loss = 2.60405
I0811 21:09:32.483392 26953 solver.cpp:244]     Train net output #0: loss = 2.60405 (* 1 = 2.60405 loss)
I0811 21:09:33.874850 26953 sgd_solver.cpp:106] Iteration 9220, lr = 0.01
I0811 21:09:52.263561 26953 solver.cpp:228] Iteration 9230, loss = 2.80491
I0811 21:09:52.263636 26953 solver.cpp:244]     Train net output #0: loss = 2.80491 (* 1 = 2.80491 loss)
I0811 21:09:53.663602 26953 sgd_solver.cpp:106] Iteration 9230, lr = 0.01
I0811 21:10:12.047962 26953 solver.cpp:228] Iteration 9240, loss = 2.71283
I0811 21:10:12.048235 26953 solver.cpp:244]     Train net output #0: loss = 2.71283 (* 1 = 2.71283 loss)
I0811 21:10:13.473855 26953 sgd_solver.cpp:106] Iteration 9240, lr = 0.01
I0811 21:10:31.816567 26953 solver.cpp:228] Iteration 9250, loss = 2.79229
I0811 21:10:31.816637 26953 solver.cpp:244]     Train net output #0: loss = 2.79229 (* 1 = 2.79229 loss)
I0811 21:10:33.220125 26953 sgd_solver.cpp:106] Iteration 9250, lr = 0.01
I0811 21:10:51.591353 26953 solver.cpp:228] Iteration 9260, loss = 2.68001
I0811 21:10:51.591619 26953 solver.cpp:244]     Train net output #0: loss = 2.68001 (* 1 = 2.68001 loss)
I0811 21:10:53.000970 26953 sgd_solver.cpp:106] Iteration 9260, lr = 0.01
I0811 21:11:11.403237 26953 solver.cpp:228] Iteration 9270, loss = 2.7679
I0811 21:11:11.403318 26953 solver.cpp:244]     Train net output #0: loss = 2.7679 (* 1 = 2.7679 loss)
I0811 21:11:12.816974 26953 sgd_solver.cpp:106] Iteration 9270, lr = 0.01
I0811 21:11:31.187882 26953 solver.cpp:228] Iteration 9280, loss = 2.77797
I0811 21:11:31.188029 26953 solver.cpp:244]     Train net output #0: loss = 2.77797 (* 1 = 2.77797 loss)
I0811 21:11:32.591969 26953 sgd_solver.cpp:106] Iteration 9280, lr = 0.01
I0811 21:11:51.006961 26953 solver.cpp:228] Iteration 9290, loss = 2.52878
I0811 21:11:51.007033 26953 solver.cpp:244]     Train net output #0: loss = 2.52878 (* 1 = 2.52878 loss)
I0811 21:11:52.414351 26953 sgd_solver.cpp:106] Iteration 9290, lr = 0.01
I0811 21:12:10.220491 26953 solver.cpp:337] Iteration 9300, Testing net (#0)
I0811 21:12:10.802353 26953 solver.cpp:404]     Test net output #0: accuracy = 0.448
I0811 21:12:10.802420 26953 solver.cpp:404]     Test net output #1: loss = 2.56274 (* 1 = 2.56274 loss)
I0811 21:12:11.394490 26953 solver.cpp:228] Iteration 9300, loss = 2.60756
I0811 21:12:11.394564 26953 solver.cpp:244]     Train net output #0: loss = 2.60756 (* 1 = 2.60756 loss)
I0811 21:12:12.765223 26953 sgd_solver.cpp:106] Iteration 9300, lr = 0.01
I0811 21:12:31.129477 26953 solver.cpp:228] Iteration 9310, loss = 2.6598
I0811 21:12:31.129556 26953 solver.cpp:244]     Train net output #0: loss = 2.6598 (* 1 = 2.6598 loss)
I0811 21:12:32.537358 26953 sgd_solver.cpp:106] Iteration 9310, lr = 0.01
I0811 21:12:51.000857 26953 solver.cpp:228] Iteration 9320, loss = 2.70402
I0811 21:12:51.001072 26953 solver.cpp:244]     Train net output #0: loss = 2.70402 (* 1 = 2.70402 loss)
I0811 21:12:52.418165 26953 sgd_solver.cpp:106] Iteration 9320, lr = 0.01
I0811 21:13:10.773038 26953 solver.cpp:228] Iteration 9330, loss = 2.67457
I0811 21:13:10.773110 26953 solver.cpp:244]     Train net output #0: loss = 2.67457 (* 1 = 2.67457 loss)
I0811 21:13:12.183468 26953 sgd_solver.cpp:106] Iteration 9330, lr = 0.01
I0811 21:13:30.551079 26953 solver.cpp:228] Iteration 9340, loss = 2.64942
I0811 21:13:30.551308 26953 solver.cpp:244]     Train net output #0: loss = 2.64942 (* 1 = 2.64942 loss)
I0811 21:13:31.945778 26953 sgd_solver.cpp:106] Iteration 9340, lr = 0.01
I0811 21:13:50.364992 26953 solver.cpp:228] Iteration 9350, loss = 2.64791
I0811 21:13:50.365073 26953 solver.cpp:244]     Train net output #0: loss = 2.64791 (* 1 = 2.64791 loss)
I0811 21:13:51.785845 26953 sgd_solver.cpp:106] Iteration 9350, lr = 0.01
I0811 21:14:10.147922 26953 solver.cpp:228] Iteration 9360, loss = 2.81558
I0811 21:14:10.148186 26953 solver.cpp:244]     Train net output #0: loss = 2.81558 (* 1 = 2.81558 loss)
I0811 21:14:11.553455 26953 sgd_solver.cpp:106] Iteration 9360, lr = 0.01
I0811 21:14:29.968631 26953 solver.cpp:228] Iteration 9370, loss = 2.54949
I0811 21:14:29.968710 26953 solver.cpp:244]     Train net output #0: loss = 2.54949 (* 1 = 2.54949 loss)
I0811 21:14:31.359320 26953 sgd_solver.cpp:106] Iteration 9370, lr = 0.01
I0811 21:14:49.706117 26953 solver.cpp:228] Iteration 9380, loss = 2.52006
I0811 21:14:49.706360 26953 solver.cpp:244]     Train net output #0: loss = 2.52006 (* 1 = 2.52006 loss)
I0811 21:14:51.116545 26953 sgd_solver.cpp:106] Iteration 9380, lr = 0.01
I0811 21:15:09.510591 26953 solver.cpp:228] Iteration 9390, loss = 2.5177
I0811 21:15:09.510663 26953 solver.cpp:244]     Train net output #0: loss = 2.5177 (* 1 = 2.5177 loss)
I0811 21:15:10.923583 26953 sgd_solver.cpp:106] Iteration 9390, lr = 0.01
I0811 21:15:28.746450 26953 solver.cpp:337] Iteration 9400, Testing net (#0)
I0811 21:15:29.332482 26953 solver.cpp:404]     Test net output #0: accuracy = 0.442
I0811 21:15:29.332576 26953 solver.cpp:404]     Test net output #1: loss = 2.5395 (* 1 = 2.5395 loss)
I0811 21:15:29.900763 26953 solver.cpp:228] Iteration 9400, loss = 2.46483
I0811 21:15:29.900841 26953 solver.cpp:244]     Train net output #0: loss = 2.46483 (* 1 = 2.46483 loss)
I0811 21:15:31.268949 26953 sgd_solver.cpp:106] Iteration 9400, lr = 0.01
I0811 21:15:49.661224 26953 solver.cpp:228] Iteration 9410, loss = 2.71573
I0811 21:15:49.661299 26953 solver.cpp:244]     Train net output #0: loss = 2.71573 (* 1 = 2.71573 loss)
I0811 21:15:51.068681 26953 sgd_solver.cpp:106] Iteration 9410, lr = 0.01
I0811 21:16:09.405129 26953 solver.cpp:228] Iteration 9420, loss = 2.6366
I0811 21:16:09.405393 26953 solver.cpp:244]     Train net output #0: loss = 2.6366 (* 1 = 2.6366 loss)
I0811 21:16:10.830138 26953 sgd_solver.cpp:106] Iteration 9420, lr = 0.01
I0811 21:16:29.217978 26953 solver.cpp:228] Iteration 9430, loss = 2.66327
I0811 21:16:29.218058 26953 solver.cpp:244]     Train net output #0: loss = 2.66327 (* 1 = 2.66327 loss)
I0811 21:16:30.615847 26953 sgd_solver.cpp:106] Iteration 9430, lr = 0.01
I0811 21:16:48.999770 26953 solver.cpp:228] Iteration 9440, loss = 2.82487
I0811 21:16:48.999975 26953 solver.cpp:244]     Train net output #0: loss = 2.82487 (* 1 = 2.82487 loss)
I0811 21:16:50.407732 26953 sgd_solver.cpp:106] Iteration 9440, lr = 0.01
I0811 21:17:08.764849 26953 solver.cpp:228] Iteration 9450, loss = 2.51587
I0811 21:17:08.764920 26953 solver.cpp:244]     Train net output #0: loss = 2.51587 (* 1 = 2.51587 loss)
I0811 21:17:10.183908 26953 sgd_solver.cpp:106] Iteration 9450, lr = 0.01
I0811 21:17:28.559828 26953 solver.cpp:228] Iteration 9460, loss = 2.53696
I0811 21:17:28.560062 26953 solver.cpp:244]     Train net output #0: loss = 2.53696 (* 1 = 2.53696 loss)
I0811 21:17:29.965039 26953 sgd_solver.cpp:106] Iteration 9460, lr = 0.01
I0811 21:17:48.405035 26953 solver.cpp:228] Iteration 9470, loss = 2.87972
I0811 21:17:48.405117 26953 solver.cpp:244]     Train net output #0: loss = 2.87972 (* 1 = 2.87972 loss)
I0811 21:17:49.816891 26953 sgd_solver.cpp:106] Iteration 9470, lr = 0.01
I0811 21:18:08.211015 26953 solver.cpp:228] Iteration 9480, loss = 2.64199
I0811 21:18:08.211256 26953 solver.cpp:244]     Train net output #0: loss = 2.64199 (* 1 = 2.64199 loss)
I0811 21:18:09.604049 26953 sgd_solver.cpp:106] Iteration 9480, lr = 0.01
I0811 21:18:27.996693 26953 solver.cpp:228] Iteration 9490, loss = 2.73442
I0811 21:18:27.996776 26953 solver.cpp:244]     Train net output #0: loss = 2.73442 (* 1 = 2.73442 loss)
I0811 21:18:29.392427 26953 sgd_solver.cpp:106] Iteration 9490, lr = 0.01
I0811 21:18:47.188680 26953 solver.cpp:337] Iteration 9500, Testing net (#0)
I0811 21:18:47.774112 26953 solver.cpp:404]     Test net output #0: accuracy = 0.436
I0811 21:18:47.774168 26953 solver.cpp:404]     Test net output #1: loss = 2.53277 (* 1 = 2.53277 loss)
I0811 21:18:48.333549 26953 solver.cpp:228] Iteration 9500, loss = 2.64412
I0811 21:18:48.333622 26953 solver.cpp:244]     Train net output #0: loss = 2.64412 (* 1 = 2.64412 loss)
I0811 21:18:49.725951 26953 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0811 21:19:08.144481 26953 solver.cpp:228] Iteration 9510, loss = 2.58116
I0811 21:19:08.144554 26953 solver.cpp:244]     Train net output #0: loss = 2.58116 (* 1 = 2.58116 loss)
I0811 21:19:09.534973 26953 sgd_solver.cpp:106] Iteration 9510, lr = 0.01
I0811 21:19:27.966892 26953 solver.cpp:228] Iteration 9520, loss = 2.44337
I0811 21:19:27.967128 26953 solver.cpp:244]     Train net output #0: loss = 2.44337 (* 1 = 2.44337 loss)
I0811 21:19:29.376251 26953 sgd_solver.cpp:106] Iteration 9520, lr = 0.01
I0811 21:19:47.715634 26953 solver.cpp:228] Iteration 9530, loss = 2.49171
I0811 21:19:47.715708 26953 solver.cpp:244]     Train net output #0: loss = 2.49171 (* 1 = 2.49171 loss)
I0811 21:19:49.120160 26953 sgd_solver.cpp:106] Iteration 9530, lr = 0.01
I0811 21:20:07.512357 26953 solver.cpp:228] Iteration 9540, loss = 2.64163
I0811 21:20:07.512619 26953 solver.cpp:244]     Train net output #0: loss = 2.64163 (* 1 = 2.64163 loss)
I0811 21:20:08.915611 26953 sgd_solver.cpp:106] Iteration 9540, lr = 0.01
I0811 21:20:27.341641 26953 solver.cpp:228] Iteration 9550, loss = 2.72423
I0811 21:20:27.341717 26953 solver.cpp:244]     Train net output #0: loss = 2.72423 (* 1 = 2.72423 loss)
I0811 21:20:28.752578 26953 sgd_solver.cpp:106] Iteration 9550, lr = 0.01
I0811 21:20:47.109115 26953 solver.cpp:228] Iteration 9560, loss = 2.55868
I0811 21:20:47.109354 26953 solver.cpp:244]     Train net output #0: loss = 2.55868 (* 1 = 2.55868 loss)
I0811 21:20:48.511468 26953 sgd_solver.cpp:106] Iteration 9560, lr = 0.01
I0811 21:21:06.910353 26953 solver.cpp:228] Iteration 9570, loss = 2.59639
I0811 21:21:06.910436 26953 solver.cpp:244]     Train net output #0: loss = 2.59639 (* 1 = 2.59639 loss)
I0811 21:21:08.310113 26953 sgd_solver.cpp:106] Iteration 9570, lr = 0.01
I0811 21:21:26.701403 26953 solver.cpp:228] Iteration 9580, loss = 2.5403
I0811 21:21:26.701629 26953 solver.cpp:244]     Train net output #0: loss = 2.5403 (* 1 = 2.5403 loss)
I0811 21:21:28.115267 26953 sgd_solver.cpp:106] Iteration 9580, lr = 0.01
I0811 21:21:46.478883 26953 solver.cpp:228] Iteration 9590, loss = 2.67615
I0811 21:21:46.478965 26953 solver.cpp:244]     Train net output #0: loss = 2.67615 (* 1 = 2.67615 loss)
I0811 21:21:47.873589 26953 sgd_solver.cpp:106] Iteration 9590, lr = 0.01
I0811 21:22:05.687609 26953 solver.cpp:337] Iteration 9600, Testing net (#0)
I0811 21:22:06.282948 26953 solver.cpp:404]     Test net output #0: accuracy = 0.444
I0811 21:22:06.283041 26953 solver.cpp:404]     Test net output #1: loss = 2.62377 (* 1 = 2.62377 loss)
I0811 21:22:06.853201 26953 solver.cpp:228] Iteration 9600, loss = 2.5638
I0811 21:22:06.853284 26953 solver.cpp:244]     Train net output #0: loss = 2.5638 (* 1 = 2.5638 loss)
I0811 21:22:08.242589 26953 sgd_solver.cpp:106] Iteration 9600, lr = 0.01
I0811 21:22:26.619648 26953 solver.cpp:228] Iteration 9610, loss = 2.63345
I0811 21:22:26.619730 26953 solver.cpp:244]     Train net output #0: loss = 2.63345 (* 1 = 2.63345 loss)
I0811 21:22:28.024862 26953 sgd_solver.cpp:106] Iteration 9610, lr = 0.01
I0811 21:22:46.457447 26953 solver.cpp:228] Iteration 9620, loss = 2.55061
I0811 21:22:46.457662 26953 solver.cpp:244]     Train net output #0: loss = 2.55061 (* 1 = 2.55061 loss)
I0811 21:22:47.865936 26953 sgd_solver.cpp:106] Iteration 9620, lr = 0.01
I0811 21:23:06.266376 26953 solver.cpp:228] Iteration 9630, loss = 2.63273
I0811 21:23:06.266456 26953 solver.cpp:244]     Train net output #0: loss = 2.63273 (* 1 = 2.63273 loss)
I0811 21:23:07.690137 26953 sgd_solver.cpp:106] Iteration 9630, lr = 0.01
I0811 21:23:26.059818 26953 solver.cpp:228] Iteration 9640, loss = 2.42389
I0811 21:23:26.059963 26953 solver.cpp:244]     Train net output #0: loss = 2.42389 (* 1 = 2.42389 loss)
I0811 21:23:27.443048 26953 sgd_solver.cpp:106] Iteration 9640, lr = 0.01
I0811 21:23:45.835369 26953 solver.cpp:228] Iteration 9650, loss = 2.60278
I0811 21:23:45.835465 26953 solver.cpp:244]     Train net output #0: loss = 2.60278 (* 1 = 2.60278 loss)
I0811 21:23:47.229444 26953 sgd_solver.cpp:106] Iteration 9650, lr = 0.01
I0811 21:24:05.631145 26953 solver.cpp:228] Iteration 9660, loss = 2.5939
I0811 21:24:05.631305 26953 solver.cpp:244]     Train net output #0: loss = 2.5939 (* 1 = 2.5939 loss)
I0811 21:24:07.055187 26953 sgd_solver.cpp:106] Iteration 9660, lr = 0.01
I0811 21:24:25.403555 26953 solver.cpp:228] Iteration 9670, loss = 2.63315
I0811 21:24:25.403633 26953 solver.cpp:244]     Train net output #0: loss = 2.63315 (* 1 = 2.63315 loss)
I0811 21:24:26.803984 26953 sgd_solver.cpp:106] Iteration 9670, lr = 0.01
I0811 21:24:45.227605 26953 solver.cpp:228] Iteration 9680, loss = 2.70372
I0811 21:24:45.227867 26953 solver.cpp:244]     Train net output #0: loss = 2.70372 (* 1 = 2.70372 loss)
I0811 21:24:46.616570 26953 sgd_solver.cpp:106] Iteration 9680, lr = 0.01
I0811 21:25:05.015306 26953 solver.cpp:228] Iteration 9690, loss = 2.6219
I0811 21:25:05.015385 26953 solver.cpp:244]     Train net output #0: loss = 2.6219 (* 1 = 2.6219 loss)
I0811 21:25:06.428172 26953 sgd_solver.cpp:106] Iteration 9690, lr = 0.01
I0811 21:25:24.225291 26953 solver.cpp:337] Iteration 9700, Testing net (#0)
I0811 21:25:24.815645 26953 solver.cpp:404]     Test net output #0: accuracy = 0.414
I0811 21:25:24.815713 26953 solver.cpp:404]     Test net output #1: loss = 2.61131 (* 1 = 2.61131 loss)
I0811 21:25:25.396628 26953 solver.cpp:228] Iteration 9700, loss = 2.65943
I0811 21:25:25.396716 26953 solver.cpp:244]     Train net output #0: loss = 2.65943 (* 1 = 2.65943 loss)
I0811 21:25:26.753551 26953 sgd_solver.cpp:106] Iteration 9700, lr = 0.01
I0811 21:25:45.192441 26953 solver.cpp:228] Iteration 9710, loss = 2.74457
I0811 21:25:45.192530 26953 solver.cpp:244]     Train net output #0: loss = 2.74457 (* 1 = 2.74457 loss)
I0811 21:25:46.587795 26953 sgd_solver.cpp:106] Iteration 9710, lr = 0.01
I0811 21:26:04.960537 26953 solver.cpp:228] Iteration 9720, loss = 2.51212
I0811 21:26:04.960770 26953 solver.cpp:244]     Train net output #0: loss = 2.51212 (* 1 = 2.51212 loss)
I0811 21:26:06.379528 26953 sgd_solver.cpp:106] Iteration 9720, lr = 0.01
I0811 21:26:24.744460 26953 solver.cpp:228] Iteration 9730, loss = 2.70946
I0811 21:26:24.744529 26953 solver.cpp:244]     Train net output #0: loss = 2.70946 (* 1 = 2.70946 loss)
I0811 21:26:26.152215 26953 sgd_solver.cpp:106] Iteration 9730, lr = 0.01
I0811 21:26:44.552665 26953 solver.cpp:228] Iteration 9740, loss = 2.51737
I0811 21:26:44.552901 26953 solver.cpp:244]     Train net output #0: loss = 2.51737 (* 1 = 2.51737 loss)
I0811 21:26:45.953641 26953 sgd_solver.cpp:106] Iteration 9740, lr = 0.01
I0811 21:27:04.330570 26953 solver.cpp:228] Iteration 9750, loss = 2.65102
I0811 21:27:04.330636 26953 solver.cpp:244]     Train net output #0: loss = 2.65102 (* 1 = 2.65102 loss)
I0811 21:27:05.754175 26953 sgd_solver.cpp:106] Iteration 9750, lr = 0.01
I0811 21:27:24.131009 26953 solver.cpp:228] Iteration 9760, loss = 2.55658
I0811 21:27:24.131137 26953 solver.cpp:244]     Train net output #0: loss = 2.55658 (* 1 = 2.55658 loss)
I0811 21:27:25.536738 26953 sgd_solver.cpp:106] Iteration 9760, lr = 0.01
I0811 21:27:43.933159 26953 solver.cpp:228] Iteration 9770, loss = 2.49479
I0811 21:27:43.933238 26953 solver.cpp:244]     Train net output #0: loss = 2.49479 (* 1 = 2.49479 loss)
I0811 21:27:45.332973 26953 sgd_solver.cpp:106] Iteration 9770, lr = 0.01
I0811 21:28:03.687469 26953 solver.cpp:228] Iteration 9780, loss = 2.61605
I0811 21:28:03.687680 26953 solver.cpp:244]     Train net output #0: loss = 2.61605 (* 1 = 2.61605 loss)
I0811 21:28:05.088680 26953 sgd_solver.cpp:106] Iteration 9780, lr = 0.01
I0811 21:28:23.525962 26953 solver.cpp:228] Iteration 9790, loss = 2.56002
I0811 21:28:23.526043 26953 solver.cpp:244]     Train net output #0: loss = 2.56002 (* 1 = 2.56002 loss)
I0811 21:28:24.919579 26953 sgd_solver.cpp:106] Iteration 9790, lr = 0.01
I0811 21:28:42.745277 26953 solver.cpp:337] Iteration 9800, Testing net (#0)
I0811 21:28:43.335337 26953 solver.cpp:404]     Test net output #0: accuracy = 0.492
I0811 21:28:43.335407 26953 solver.cpp:404]     Test net output #1: loss = 2.29243 (* 1 = 2.29243 loss)
I0811 21:28:43.896445 26953 solver.cpp:228] Iteration 9800, loss = 2.65522
I0811 21:28:43.896522 26953 solver.cpp:244]     Train net output #0: loss = 2.65522 (* 1 = 2.65522 loss)
I0811 21:28:45.310324 26953 sgd_solver.cpp:106] Iteration 9800, lr = 0.01
I0811 21:29:03.692502 26953 solver.cpp:228] Iteration 9810, loss = 2.49932
I0811 21:29:03.692564 26953 solver.cpp:244]     Train net output #0: loss = 2.49932 (* 1 = 2.49932 loss)
I0811 21:29:05.090621 26953 sgd_solver.cpp:106] Iteration 9810, lr = 0.01
I0811 21:29:23.545027 26953 solver.cpp:228] Iteration 9820, loss = 2.53544
I0811 21:29:23.545240 26953 solver.cpp:244]     Train net output #0: loss = 2.53544 (* 1 = 2.53544 loss)
I0811 21:29:24.943939 26953 sgd_solver.cpp:106] Iteration 9820, lr = 0.01
I0811 21:29:43.314453 26953 solver.cpp:228] Iteration 9830, loss = 2.49272
I0811 21:29:43.314515 26953 solver.cpp:244]     Train net output #0: loss = 2.49272 (* 1 = 2.49272 loss)
I0811 21:29:44.711484 26953 sgd_solver.cpp:106] Iteration 9830, lr = 0.01
I0811 21:30:03.139405 26953 solver.cpp:228] Iteration 9840, loss = 2.63063
I0811 21:30:03.139605 26953 solver.cpp:244]     Train net output #0: loss = 2.63063 (* 1 = 2.63063 loss)
I0811 21:30:04.528322 26953 sgd_solver.cpp:106] Iteration 9840, lr = 0.01
I0811 21:30:22.894963 26953 solver.cpp:228] Iteration 9850, loss = 2.49943
I0811 21:30:22.895030 26953 solver.cpp:244]     Train net output #0: loss = 2.49943 (* 1 = 2.49943 loss)
I0811 21:30:24.305604 26953 sgd_solver.cpp:106] Iteration 9850, lr = 0.01
I0811 21:30:42.663153 26953 solver.cpp:228] Iteration 9860, loss = 2.70545
I0811 21:30:42.663311 26953 solver.cpp:244]     Train net output #0: loss = 2.70545 (* 1 = 2.70545 loss)
I0811 21:30:44.077236 26953 sgd_solver.cpp:106] Iteration 9860, lr = 0.01
I0811 21:31:02.505420 26953 solver.cpp:228] Iteration 9870, loss = 2.43416
I0811 21:31:02.505486 26953 solver.cpp:244]     Train net output #0: loss = 2.43416 (* 1 = 2.43416 loss)
I0811 21:31:03.910475 26953 sgd_solver.cpp:106] Iteration 9870, lr = 0.01
I0811 21:31:22.272774 26953 solver.cpp:228] Iteration 9880, loss = 2.53857
I0811 21:31:22.273005 26953 solver.cpp:244]     Train net output #0: loss = 2.53857 (* 1 = 2.53857 loss)
I0811 21:31:23.682916 26953 sgd_solver.cpp:106] Iteration 9880, lr = 0.01
I0811 21:31:42.130709 26953 solver.cpp:228] Iteration 9890, loss = 2.78812
I0811 21:31:42.130766 26953 solver.cpp:244]     Train net output #0: loss = 2.78812 (* 1 = 2.78812 loss)
I0811 21:31:43.523783 26953 sgd_solver.cpp:106] Iteration 9890, lr = 0.01
I0811 21:32:01.326843 26953 solver.cpp:337] Iteration 9900, Testing net (#0)
I0811 21:32:01.917615 26953 solver.cpp:404]     Test net output #0: accuracy = 0.436
I0811 21:32:01.917685 26953 solver.cpp:404]     Test net output #1: loss = 2.52793 (* 1 = 2.52793 loss)
I0811 21:32:02.483877 26953 solver.cpp:228] Iteration 9900, loss = 2.67889
I0811 21:32:02.483976 26953 solver.cpp:244]     Train net output #0: loss = 2.67889 (* 1 = 2.67889 loss)
I0811 21:32:03.890254 26953 sgd_solver.cpp:106] Iteration 9900, lr = 0.01
I0811 21:32:22.239133 26953 solver.cpp:228] Iteration 9910, loss = 2.59416
I0811 21:32:22.239209 26953 solver.cpp:244]     Train net output #0: loss = 2.59416 (* 1 = 2.59416 loss)
I0811 21:32:23.643425 26953 sgd_solver.cpp:106] Iteration 9910, lr = 0.01
I0811 21:32:42.026564 26953 solver.cpp:228] Iteration 9920, loss = 2.5206
I0811 21:32:42.026813 26953 solver.cpp:244]     Train net output #0: loss = 2.5206 (* 1 = 2.5206 loss)
I0811 21:32:43.426278 26953 sgd_solver.cpp:106] Iteration 9920, lr = 0.01
I0811 21:33:01.830641 26953 solver.cpp:228] Iteration 9930, loss = 2.4532
I0811 21:33:01.830699 26953 solver.cpp:244]     Train net output #0: loss = 2.4532 (* 1 = 2.4532 loss)
I0811 21:33:03.253037 26953 sgd_solver.cpp:106] Iteration 9930, lr = 0.01
I0811 21:33:21.602915 26953 solver.cpp:228] Iteration 9940, loss = 2.5361
I0811 21:33:21.603190 26953 solver.cpp:244]     Train net output #0: loss = 2.5361 (* 1 = 2.5361 loss)
I0811 21:33:23.011441 26953 sgd_solver.cpp:106] Iteration 9940, lr = 0.01
I0811 21:33:41.423055 26953 solver.cpp:228] Iteration 9950, loss = 2.59968
I0811 21:33:41.423127 26953 solver.cpp:244]     Train net output #0: loss = 2.59968 (* 1 = 2.59968 loss)
I0811 21:33:42.813146 26953 sgd_solver.cpp:106] Iteration 9950, lr = 0.01
I0811 21:34:01.212350 26953 solver.cpp:228] Iteration 9960, loss = 2.56851
I0811 21:34:01.212584 26953 solver.cpp:244]     Train net output #0: loss = 2.56851 (* 1 = 2.56851 loss)
I0811 21:34:02.633031 26953 sgd_solver.cpp:106] Iteration 9960, lr = 0.01
I0811 21:34:20.969760 26953 solver.cpp:228] Iteration 9970, loss = 2.5123
I0811 21:34:20.969825 26953 solver.cpp:244]     Train net output #0: loss = 2.5123 (* 1 = 2.5123 loss)
I0811 21:34:22.376770 26953 sgd_solver.cpp:106] Iteration 9970, lr = 0.01
I0811 21:34:40.819629 26953 solver.cpp:228] Iteration 9980, loss = 2.73052
I0811 21:34:40.819761 26953 solver.cpp:244]     Train net output #0: loss = 2.73052 (* 1 = 2.73052 loss)
I0811 21:34:42.232074 26953 sgd_solver.cpp:106] Iteration 9980, lr = 0.01
I0811 21:35:00.631137 26953 solver.cpp:228] Iteration 9990, loss = 2.41629
I0811 21:35:00.631197 26953 solver.cpp:244]     Train net output #0: loss = 2.41629 (* 1 = 2.41629 loss)
I0811 21:35:02.030113 26953 sgd_solver.cpp:106] Iteration 9990, lr = 0.01
I0811 21:35:19.899251 26953 solver.cpp:454] Snapshotting to binary proto file caffe_alexnet_train_iter_10000.caffemodel
I0811 21:36:15.433606 26953 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe_alexnet_train_iter_10000.solverstate
I0811 21:36:16.400691 26953 solver.cpp:337] Iteration 10000, Testing net (#0)
I0811 21:36:17.076217 26953 solver.cpp:404]     Test net output #0: accuracy = 0.43
I0811 21:36:17.076280 26953 solver.cpp:404]     Test net output #1: loss = 2.52932 (* 1 = 2.52932 loss)
I0811 21:36:17.671499 26953 solver.cpp:228] Iteration 10000, loss = 2.71358
I0811 21:36:17.671577 26953 solver.cpp:244]     Train net output #0: loss = 2.71358 (* 1 = 2.71358 loss)
I0811 21:36:19.058871 26953 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0811 21:36:37.332693 26953 solver.cpp:228] Iteration 10010, loss = 2.65282
I0811 21:36:37.332787 26953 solver.cpp:244]     Train net output #0: loss = 2.65282 (* 1 = 2.65282 loss)
I0811 21:36:38.742166 26953 sgd_solver.cpp:106] Iteration 10010, lr = 0.01
I0811 21:36:57.082798 26953 solver.cpp:228] Iteration 10020, loss = 2.69264
I0811 21:36:57.082960 26953 solver.cpp:244]     Train net output #0: loss = 2.69264 (* 1 = 2.69264 loss)
I0811 21:36:58.494382 26953 sgd_solver.cpp:106] Iteration 10020, lr = 0.01
I0811 21:37:16.875501 26953 solver.cpp:228] Iteration 10030, loss = 2.5342
I0811 21:37:16.875576 26953 solver.cpp:244]     Train net output #0: loss = 2.5342 (* 1 = 2.5342 loss)
I0811 21:37:18.268811 26953 sgd_solver.cpp:106] Iteration 10030, lr = 0.01
I0811 21:37:36.677395 26953 solver.cpp:228] Iteration 10040, loss = 2.60646
I0811 21:37:36.677712 26953 solver.cpp:244]     Train net output #0: loss = 2.60646 (* 1 = 2.60646 loss)
I0811 21:37:38.074872 26953 sgd_solver.cpp:106] Iteration 10040, lr = 0.01
I0811 21:37:56.469699 26953 solver.cpp:228] Iteration 10050, loss = 2.49322
I0811 21:37:56.469772 26953 solver.cpp:244]     Train net output #0: loss = 2.49322 (* 1 = 2.49322 loss)
I0811 21:37:57.876215 26953 sgd_solver.cpp:106] Iteration 10050, lr = 0.01
I0811 21:38:16.237503 26953 solver.cpp:228] Iteration 10060, loss = 2.58001
I0811 21:38:16.237749 26953 solver.cpp:244]     Train net output #0: loss = 2.58001 (* 1 = 2.58001 loss)
I0811 21:38:17.658978 26953 sgd_solver.cpp:106] Iteration 10060, lr = 0.01
I0811 21:38:36.117220 26953 solver.cpp:228] Iteration 10070, loss = 2.65887
I0811 21:38:36.117292 26953 solver.cpp:244]     Train net output #0: loss = 2.65887 (* 1 = 2.65887 loss)
I0811 21:38:37.521127 26953 sgd_solver.cpp:106] Iteration 10070, lr = 0.01
I0811 21:38:55.899060 26953 solver.cpp:228] Iteration 10080, loss = 2.58549
I0811 21:38:55.899240 26953 solver.cpp:244]     Train net output #0: loss = 2.58549 (* 1 = 2.58549 loss)
I0811 21:38:57.311530 26953 sgd_solver.cpp:106] Iteration 10080, lr = 0.01
I0811 21:39:15.744576 26953 solver.cpp:228] Iteration 10090, loss = 2.53333
I0811 21:39:15.744650 26953 solver.cpp:244]     Train net output #0: loss = 2.53333 (* 1 = 2.53333 loss)
I0811 21:39:17.145090 26953 sgd_solver.cpp:106] Iteration 10090, lr = 0.01
I0811 21:39:34.969287 26953 solver.cpp:337] Iteration 10100, Testing net (#0)
I0811 21:39:35.565748 26953 solver.cpp:404]     Test net output #0: accuracy = 0.448
I0811 21:39:35.565832 26953 solver.cpp:404]     Test net output #1: loss = 2.49662 (* 1 = 2.49662 loss)
I0811 21:39:36.154119 26953 solver.cpp:228] Iteration 10100, loss = 2.4209
I0811 21:39:36.154184 26953 solver.cpp:244]     Train net output #0: loss = 2.4209 (* 1 = 2.4209 loss)
I0811 21:39:37.509284 26953 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0811 21:39:55.930819 26953 solver.cpp:228] Iteration 10110, loss = 2.58989
I0811 21:39:55.930876 26953 solver.cpp:244]     Train net output #0: loss = 2.58989 (* 1 = 2.58989 loss)
I0811 21:39:57.329869 26953 sgd_solver.cpp:106] Iteration 10110, lr = 0.01
I0811 21:40:15.699337 26953 solver.cpp:228] Iteration 10120, loss = 2.69046
I0811 21:40:15.699609 26953 solver.cpp:244]     Train net output #0: loss = 2.69046 (* 1 = 2.69046 loss)
I0811 21:40:17.108191 26953 sgd_solver.cpp:106] Iteration 10120, lr = 0.01
I0811 21:40:35.498184 26953 solver.cpp:228] Iteration 10130, loss = 2.58451
I0811 21:40:35.498258 26953 solver.cpp:244]     Train net output #0: loss = 2.58451 (* 1 = 2.58451 loss)
I0811 21:40:36.914978 26953 sgd_solver.cpp:106] Iteration 10130, lr = 0.01
I0811 21:40:55.348510 26953 solver.cpp:228] Iteration 10140, loss = 2.65384
I0811 21:40:55.348659 26953 solver.cpp:244]     Train net output #0: loss = 2.65384 (* 1 = 2.65384 loss)
I0811 21:40:56.755771 26953 sgd_solver.cpp:106] Iteration 10140, lr = 0.01
I0811 21:41:15.135440 26953 solver.cpp:228] Iteration 10150, loss = 2.57766
I0811 21:41:15.135512 26953 solver.cpp:244]     Train net output #0: loss = 2.57766 (* 1 = 2.57766 loss)
I0811 21:41:16.552932 26953 sgd_solver.cpp:106] Iteration 10150, lr = 0.01
I0811 21:41:34.939240 26953 solver.cpp:228] Iteration 10160, loss = 2.62581
I0811 21:41:34.939386 26953 solver.cpp:244]     Train net output #0: loss = 2.62581 (* 1 = 2.62581 loss)
I0811 21:41:36.343396 26953 sgd_solver.cpp:106] Iteration 10160, lr = 0.01
I0811 21:41:54.760155 26953 solver.cpp:228] Iteration 10170, loss = 2.55634
I0811 21:41:54.760224 26953 solver.cpp:244]     Train net output #0: loss = 2.55634 (* 1 = 2.55634 loss)
I0811 21:41:56.180568 26953 sgd_solver.cpp:106] Iteration 10170, lr = 0.01
I0811 21:42:14.542330 26953 solver.cpp:228] Iteration 10180, loss = 2.52837
I0811 21:42:14.542472 26953 solver.cpp:244]     Train net output #0: loss = 2.52837 (* 1 = 2.52837 loss)
I0811 21:42:15.942329 26953 sgd_solver.cpp:106] Iteration 10180, lr = 0.01
I0811 21:42:34.382947 26953 solver.cpp:228] Iteration 10190, loss = 2.42042
I0811 21:42:34.383016 26953 solver.cpp:244]     Train net output #0: loss = 2.42042 (* 1 = 2.42042 loss)
I0811 21:42:35.790061 26953 sgd_solver.cpp:106] Iteration 10190, lr = 0.01
I0811 21:42:53.606977 26953 solver.cpp:337] Iteration 10200, Testing net (#0)
I0811 21:42:54.195040 26953 solver.cpp:404]     Test net output #0: accuracy = 0.438
I0811 21:42:54.195124 26953 solver.cpp:404]     Test net output #1: loss = 2.61868 (* 1 = 2.61868 loss)
I0811 21:42:54.777876 26953 solver.cpp:228] Iteration 10200, loss = 2.65216
I0811 21:42:54.777946 26953 solver.cpp:244]     Train net output #0: loss = 2.65216 (* 1 = 2.65216 loss)
I0811 21:42:56.155093 26953 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0811 21:43:14.623803 26953 solver.cpp:228] Iteration 10210, loss = 2.66113
I0811 21:43:14.623877 26953 solver.cpp:244]     Train net output #0: loss = 2.66113 (* 1 = 2.66113 loss)
I0811 21:43:16.024430 26953 sgd_solver.cpp:106] Iteration 10210, lr = 0.01
I0811 21:43:34.404881 26953 solver.cpp:228] Iteration 10220, loss = 2.67919
I0811 21:43:34.405082 26953 solver.cpp:244]     Train net output #0: loss = 2.67919 (* 1 = 2.67919 loss)
I0811 21:43:35.801942 26953 sgd_solver.cpp:106] Iteration 10220, lr = 0.01
I0811 21:43:54.162793 26953 solver.cpp:228] Iteration 10230, loss = 2.44518
I0811 21:43:54.162873 26953 solver.cpp:244]     Train net output #0: loss = 2.44518 (* 1 = 2.44518 loss)
I0811 21:43:55.564687 26953 sgd_solver.cpp:106] Iteration 10230, lr = 0.01
I0811 21:44:13.975112 26953 solver.cpp:228] Iteration 10240, loss = 2.65341
I0811 21:44:13.975272 26953 solver.cpp:244]     Train net output #0: loss = 2.65341 (* 1 = 2.65341 loss)
I0811 21:44:15.378286 26953 sgd_solver.cpp:106] Iteration 10240, lr = 0.01
I0811 21:44:33.728355 26953 solver.cpp:228] Iteration 10250, loss = 2.55163
I0811 21:44:33.728435 26953 solver.cpp:244]     Train net output #0: loss = 2.55163 (* 1 = 2.55163 loss)
I0811 21:44:35.139643 26953 sgd_solver.cpp:106] Iteration 10250, lr = 0.01
I0811 21:44:53.496157 26953 solver.cpp:228] Iteration 10260, loss = 2.54636
I0811 21:44:53.497259 26953 solver.cpp:244]     Train net output #0: loss = 2.54636 (* 1 = 2.54636 loss)
I0811 21:44:54.905326 26953 sgd_solver.cpp:106] Iteration 10260, lr = 0.01
I0811 21:45:13.296878 26953 solver.cpp:228] Iteration 10270, loss = 2.48064
I0811 21:45:13.296938 26953 solver.cpp:244]     Train net output #0: loss = 2.48064 (* 1 = 2.48064 loss)
I0811 21:45:14.687609 26953 sgd_solver.cpp:106] Iteration 10270, lr = 0.01
I0811 21:45:33.070873 26953 solver.cpp:228] Iteration 10280, loss = 2.45422
I0811 21:45:33.071092 26953 solver.cpp:244]     Train net output #0: loss = 2.45422 (* 1 = 2.45422 loss)
I0811 21:45:34.486065 26953 sgd_solver.cpp:106] Iteration 10280, lr = 0.01
I0811 21:45:52.845283 26953 solver.cpp:228] Iteration 10290, loss = 2.4036
I0811 21:45:52.845343 26953 solver.cpp:244]     Train net output #0: loss = 2.4036 (* 1 = 2.4036 loss)
I0811 21:45:54.246803 26953 sgd_solver.cpp:106] Iteration 10290, lr = 0.01
I0811 21:46:12.106274 26953 solver.cpp:337] Iteration 10300, Testing net (#0)
I0811 21:46:12.696997 26953 solver.cpp:404]     Test net output #0: accuracy = 0.442
I0811 21:46:12.697062 26953 solver.cpp:404]     Test net output #1: loss = 2.61521 (* 1 = 2.61521 loss)
I0811 21:46:13.268980 26953 solver.cpp:228] Iteration 10300, loss = 2.57682
I0811 21:46:13.269073 26953 solver.cpp:244]     Train net output #0: loss = 2.57682 (* 1 = 2.57682 loss)
I0811 21:46:14.643905 26953 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0811 21:46:32.995296 26953 solver.cpp:228] Iteration 10310, loss = 2.57166
I0811 21:46:32.995355 26953 solver.cpp:244]     Train net output #0: loss = 2.57166 (* 1 = 2.57166 loss)
I0811 21:46:34.406225 26953 sgd_solver.cpp:106] Iteration 10310, lr = 0.01
I0811 21:46:52.802837 26953 solver.cpp:228] Iteration 10320, loss = 2.4355
I0811 21:46:52.803053 26953 solver.cpp:244]     Train net output #0: loss = 2.4355 (* 1 = 2.4355 loss)
I0811 21:46:54.198642 26953 sgd_solver.cpp:106] Iteration 10320, lr = 0.01
I0811 21:47:12.615420 26953 solver.cpp:228] Iteration 10330, loss = 2.60617
I0811 21:47:12.615478 26953 solver.cpp:244]     Train net output #0: loss = 2.60617 (* 1 = 2.60617 loss)
I0811 21:47:14.017436 26953 sgd_solver.cpp:106] Iteration 10330, lr = 0.01
I0811 21:47:32.369299 26953 solver.cpp:228] Iteration 10340, loss = 2.55641
I0811 21:47:32.369509 26953 solver.cpp:244]     Train net output #0: loss = 2.55641 (* 1 = 2.55641 loss)
I0811 21:47:33.770123 26953 sgd_solver.cpp:106] Iteration 10340, lr = 0.01
I0811 21:47:52.134034 26953 solver.cpp:228] Iteration 10350, loss = 2.43341
I0811 21:47:52.134097 26953 solver.cpp:244]     Train net output #0: loss = 2.43341 (* 1 = 2.43341 loss)
I0811 21:47:53.532806 26953 sgd_solver.cpp:106] Iteration 10350, lr = 0.01
I0811 21:48:11.977130 26953 solver.cpp:228] Iteration 10360, loss = 2.54814
I0811 21:48:11.977375 26953 solver.cpp:244]     Train net output #0: loss = 2.54814 (* 1 = 2.54814 loss)
I0811 21:48:13.372865 26953 sgd_solver.cpp:106] Iteration 10360, lr = 0.01
I0811 21:48:31.703220 26953 solver.cpp:228] Iteration 10370, loss = 2.77239
I0811 21:48:31.703290 26953 solver.cpp:244]     Train net output #0: loss = 2.77239 (* 1 = 2.77239 loss)
I0811 21:48:33.119946 26953 sgd_solver.cpp:106] Iteration 10370, lr = 0.01
I0811 21:48:51.469815 26953 solver.cpp:228] Iteration 10380, loss = 2.70435
I0811 21:48:51.470082 26953 solver.cpp:244]     Train net output #0: loss = 2.70435 (* 1 = 2.70435 loss)
I0811 21:48:52.887926 26953 sgd_solver.cpp:106] Iteration 10380, lr = 0.01
I0811 21:49:11.260072 26953 solver.cpp:228] Iteration 10390, loss = 2.68629
I0811 21:49:11.260144 26953 solver.cpp:244]     Train net output #0: loss = 2.68629 (* 1 = 2.68629 loss)
I0811 21:49:12.663497 26953 sgd_solver.cpp:106] Iteration 10390, lr = 0.01
I0811 21:49:30.479921 26953 solver.cpp:337] Iteration 10400, Testing net (#0)
I0811 21:49:31.071110 26953 solver.cpp:404]     Test net output #0: accuracy = 0.466
I0811 21:49:31.071166 26953 solver.cpp:404]     Test net output #1: loss = 2.39954 (* 1 = 2.39954 loss)
I0811 21:49:31.644839 26953 solver.cpp:228] Iteration 10400, loss = 2.49972
I0811 21:49:31.644942 26953 solver.cpp:244]     Train net output #0: loss = 2.49972 (* 1 = 2.49972 loss)
I0811 21:49:33.016230 26953 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0811 21:49:51.370770 26953 solver.cpp:228] Iteration 10410, loss = 2.39721
I0811 21:49:51.370826 26953 solver.cpp:244]     Train net output #0: loss = 2.39721 (* 1 = 2.39721 loss)
I0811 21:49:52.772053 26953 sgd_solver.cpp:106] Iteration 10410, lr = 0.01
I0811 21:50:11.184196 26953 solver.cpp:228] Iteration 10420, loss = 2.53515
I0811 21:50:11.184340 26953 solver.cpp:244]     Train net output #0: loss = 2.53515 (* 1 = 2.53515 loss)
I0811 21:50:12.578752 26953 sgd_solver.cpp:106] Iteration 10420, lr = 0.01
I0811 21:50:30.981196 26953 solver.cpp:228] Iteration 10430, loss = 2.6062
I0811 21:50:30.981256 26953 solver.cpp:244]     Train net output #0: loss = 2.6062 (* 1 = 2.6062 loss)
I0811 21:50:32.384481 26953 sgd_solver.cpp:106] Iteration 10430, lr = 0.01
I0811 21:50:50.772208 26953 solver.cpp:228] Iteration 10440, loss = 2.4725
I0811 21:50:50.772413 26953 solver.cpp:244]     Train net output #0: loss = 2.4725 (* 1 = 2.4725 loss)
I0811 21:50:52.184651 26953 sgd_solver.cpp:106] Iteration 10440, lr = 0.01
I0811 21:51:10.554718 26953 solver.cpp:228] Iteration 10450, loss = 2.49177
I0811 21:51:10.554790 26953 solver.cpp:244]     Train net output #0: loss = 2.49177 (* 1 = 2.49177 loss)
I0811 21:51:11.954787 26953 sgd_solver.cpp:106] Iteration 10450, lr = 0.01
I0811 21:51:30.336350 26953 solver.cpp:228] Iteration 10460, loss = 2.43566
I0811 21:51:30.336582 26953 solver.cpp:244]     Train net output #0: loss = 2.43566 (* 1 = 2.43566 loss)
I0811 21:51:31.739009 26953 sgd_solver.cpp:106] Iteration 10460, lr = 0.01
I0811 21:51:50.107319 26953 solver.cpp:228] Iteration 10470, loss = 2.60972
I0811 21:51:50.107378 26953 solver.cpp:244]     Train net output #0: loss = 2.60972 (* 1 = 2.60972 loss)
I0811 21:51:51.518621 26953 sgd_solver.cpp:106] Iteration 10470, lr = 0.01
I0811 21:52:09.924933 26953 solver.cpp:228] Iteration 10480, loss = 2.59904
I0811 21:52:09.925153 26953 solver.cpp:244]     Train net output #0: loss = 2.59904 (* 1 = 2.59904 loss)
I0811 21:52:11.317817 26953 sgd_solver.cpp:106] Iteration 10480, lr = 0.01
I0811 21:52:29.748615 26953 solver.cpp:228] Iteration 10490, loss = 2.62344
I0811 21:52:29.748683 26953 solver.cpp:244]     Train net output #0: loss = 2.62344 (* 1 = 2.62344 loss)
I0811 21:52:31.166687 26953 sgd_solver.cpp:106] Iteration 10490, lr = 0.01
I0811 21:52:48.949889 26953 solver.cpp:337] Iteration 10500, Testing net (#0)
I0811 21:52:49.544219 26953 solver.cpp:404]     Test net output #0: accuracy = 0.464
I0811 21:52:49.544303 26953 solver.cpp:404]     Test net output #1: loss = 2.41292 (* 1 = 2.41292 loss)
I0811 21:52:50.148003 26953 solver.cpp:228] Iteration 10500, loss = 2.66613
I0811 21:52:50.148082 26953 solver.cpp:244]     Train net output #0: loss = 2.66613 (* 1 = 2.66613 loss)
I0811 21:52:51.490114 26953 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0811 21:53:09.869773 26953 solver.cpp:228] Iteration 10510, loss = 2.77542
I0811 21:53:09.869859 26953 solver.cpp:244]     Train net output #0: loss = 2.77542 (* 1 = 2.77542 loss)
I0811 21:53:11.294678 26953 sgd_solver.cpp:106] Iteration 10510, lr = 0.01
I0811 21:53:29.689713 26953 solver.cpp:228] Iteration 10520, loss = 2.47132
I0811 21:53:29.689930 26953 solver.cpp:244]     Train net output #0: loss = 2.47132 (* 1 = 2.47132 loss)
I0811 21:53:31.081310 26953 sgd_solver.cpp:106] Iteration 10520, lr = 0.01
I0811 21:53:49.452047 26953 solver.cpp:228] Iteration 10530, loss = 2.52352
I0811 21:53:49.452121 26953 solver.cpp:244]     Train net output #0: loss = 2.52352 (* 1 = 2.52352 loss)
I0811 21:53:50.846604 26953 sgd_solver.cpp:106] Iteration 10530, lr = 0.01
I0811 21:54:09.231065 26953 solver.cpp:228] Iteration 10540, loss = 2.54579
I0811 21:54:09.231240 26953 solver.cpp:244]     Train net output #0: loss = 2.54579 (* 1 = 2.54579 loss)
I0811 21:54:10.636801 26953 sgd_solver.cpp:106] Iteration 10540, lr = 0.01
I0811 21:54:29.023515 26953 solver.cpp:228] Iteration 10550, loss = 2.58457
I0811 21:54:29.023584 26953 solver.cpp:244]     Train net output #0: loss = 2.58457 (* 1 = 2.58457 loss)
I0811 21:54:30.401018 26953 sgd_solver.cpp:106] Iteration 10550, lr = 0.01
I0811 21:54:48.767304 26953 solver.cpp:228] Iteration 10560, loss = 2.5425
I0811 21:54:48.767546 26953 solver.cpp:244]     Train net output #0: loss = 2.5425 (* 1 = 2.5425 loss)
I0811 21:54:50.166975 26953 sgd_solver.cpp:106] Iteration 10560, lr = 0.01
I0811 21:55:08.629943 26953 solver.cpp:228] Iteration 10570, loss = 2.45794
I0811 21:55:08.630022 26953 solver.cpp:244]     Train net output #0: loss = 2.45794 (* 1 = 2.45794 loss)
I0811 21:55:10.015656 26953 sgd_solver.cpp:106] Iteration 10570, lr = 0.01
I0811 21:55:28.392508 26953 solver.cpp:228] Iteration 10580, loss = 2.56503
I0811 21:55:28.392724 26953 solver.cpp:244]     Train net output #0: loss = 2.56503 (* 1 = 2.56503 loss)
I0811 21:55:29.785012 26953 sgd_solver.cpp:106] Iteration 10580, lr = 0.01
I0811 21:55:48.136128 26953 solver.cpp:228] Iteration 10590, loss = 2.73369
I0811 21:55:48.136200 26953 solver.cpp:244]     Train net output #0: loss = 2.73369 (* 1 = 2.73369 loss)
I0811 21:55:49.546788 26953 sgd_solver.cpp:106] Iteration 10590, lr = 0.01
I0811 21:56:07.371374 26953 solver.cpp:337] Iteration 10600, Testing net (#0)
I0811 21:56:07.958246 26953 solver.cpp:404]     Test net output #0: accuracy = 0.482
I0811 21:56:07.958320 26953 solver.cpp:404]     Test net output #1: loss = 2.42747 (* 1 = 2.42747 loss)
I0811 21:56:08.553092 26953 solver.cpp:228] Iteration 10600, loss = 2.35247
I0811 21:56:08.553197 26953 solver.cpp:244]     Train net output #0: loss = 2.35247 (* 1 = 2.35247 loss)
I0811 21:56:09.902663 26953 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0811 21:56:28.242882 26953 solver.cpp:228] Iteration 10610, loss = 2.68638
I0811 21:56:28.242950 26953 solver.cpp:244]     Train net output #0: loss = 2.68638 (* 1 = 2.68638 loss)
I0811 21:56:29.657737 26953 sgd_solver.cpp:106] Iteration 10610, lr = 0.01
I0811 21:56:47.999490 26953 solver.cpp:228] Iteration 10620, loss = 2.48086
I0811 21:56:47.999701 26953 solver.cpp:244]     Train net output #0: loss = 2.48086 (* 1 = 2.48086 loss)
I0811 21:56:49.416013 26953 sgd_solver.cpp:106] Iteration 10620, lr = 0.01
I0811 21:57:07.824615 26953 solver.cpp:228] Iteration 10630, loss = 2.42736
I0811 21:57:07.824679 26953 solver.cpp:244]     Train net output #0: loss = 2.42736 (* 1 = 2.42736 loss)
I0811 21:57:09.217293 26953 sgd_solver.cpp:106] Iteration 10630, lr = 0.01
I0811 21:57:27.637858 26953 solver.cpp:228] Iteration 10640, loss = 2.47523
I0811 21:57:27.638063 26953 solver.cpp:244]     Train net output #0: loss = 2.47523 (* 1 = 2.47523 loss)
I0811 21:57:29.048636 26953 sgd_solver.cpp:106] Iteration 10640, lr = 0.01
I0811 21:57:47.415979 26953 solver.cpp:228] Iteration 10650, loss = 2.47098
I0811 21:57:47.416049 26953 solver.cpp:244]     Train net output #0: loss = 2.47098 (* 1 = 2.47098 loss)
I0811 21:57:48.805404 26953 sgd_solver.cpp:106] Iteration 10650, lr = 0.01
I0811 21:58:07.243787 26953 solver.cpp:228] Iteration 10660, loss = 2.609
I0811 21:58:07.243973 26953 solver.cpp:244]     Train net output #0: loss = 2.609 (* 1 = 2.609 loss)
I0811 21:58:08.655339 26953 sgd_solver.cpp:106] Iteration 10660, lr = 0.01
I0811 21:58:27.030928 26953 solver.cpp:228] Iteration 10670, loss = 2.57669
I0811 21:58:27.030999 26953 solver.cpp:244]     Train net output #0: loss = 2.57669 (* 1 = 2.57669 loss)
I0811 21:58:28.418228 26953 sgd_solver.cpp:106] Iteration 10670, lr = 0.01
I0811 21:58:46.796937 26953 solver.cpp:228] Iteration 10680, loss = 2.5092
I0811 21:58:46.797088 26953 solver.cpp:244]     Train net output #0: loss = 2.5092 (* 1 = 2.5092 loss)
I0811 21:58:48.221411 26953 sgd_solver.cpp:106] Iteration 10680, lr = 0.01
I0811 21:59:06.703083 26953 solver.cpp:228] Iteration 10690, loss = 2.39061
I0811 21:59:06.703152 26953 solver.cpp:244]     Train net output #0: loss = 2.39061 (* 1 = 2.39061 loss)
I0811 21:59:08.118494 26953 sgd_solver.cpp:106] Iteration 10690, lr = 0.01
I0811 21:59:25.912793 26953 solver.cpp:337] Iteration 10700, Testing net (#0)
I0811 21:59:26.505323 26953 solver.cpp:404]     Test net output #0: accuracy = 0.444
I0811 21:59:26.505388 26953 solver.cpp:404]     Test net output #1: loss = 2.39546 (* 1 = 2.39546 loss)
I0811 21:59:27.085652 26953 solver.cpp:228] Iteration 10700, loss = 2.49166
I0811 21:59:27.085737 26953 solver.cpp:244]     Train net output #0: loss = 2.49166 (* 1 = 2.49166 loss)
I0811 21:59:28.451318 26953 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0811 21:59:46.854480 26953 solver.cpp:228] Iteration 10710, loss = 2.54645
I0811 21:59:46.854547 26953 solver.cpp:244]     Train net output #0: loss = 2.54645 (* 1 = 2.54645 loss)
I0811 21:59:48.264524 26953 sgd_solver.cpp:106] Iteration 10710, lr = 0.01
I0811 22:00:06.638176 26953 solver.cpp:228] Iteration 10720, loss = 2.62561
I0811 22:00:06.638423 26953 solver.cpp:244]     Train net output #0: loss = 2.62561 (* 1 = 2.62561 loss)
I0811 22:00:08.034956 26953 sgd_solver.cpp:106] Iteration 10720, lr = 0.01
I0811 22:00:26.461988 26953 solver.cpp:228] Iteration 10730, loss = 2.43134
I0811 22:00:26.462051 26953 solver.cpp:244]     Train net output #0: loss = 2.43134 (* 1 = 2.43134 loss)
I0811 22:00:27.879030 26953 sgd_solver.cpp:106] Iteration 10730, lr = 0.01
I0811 22:00:46.268080 26953 solver.cpp:228] Iteration 10740, loss = 2.49636
I0811 22:00:46.268299 26953 solver.cpp:244]     Train net output #0: loss = 2.49636 (* 1 = 2.49636 loss)
I0811 22:00:47.673732 26953 sgd_solver.cpp:106] Iteration 10740, lr = 0.01
I0811 22:01:06.127881 26953 solver.cpp:228] Iteration 10750, loss = 2.49215
I0811 22:01:06.127954 26953 solver.cpp:244]     Train net output #0: loss = 2.49215 (* 1 = 2.49215 loss)
I0811 22:01:07.519119 26953 sgd_solver.cpp:106] Iteration 10750, lr = 0.01
I0811 22:01:25.911639 26953 solver.cpp:228] Iteration 10760, loss = 2.38637
I0811 22:01:25.911785 26953 solver.cpp:244]     Train net output #0: loss = 2.38637 (* 1 = 2.38637 loss)
I0811 22:01:27.319056 26953 sgd_solver.cpp:106] Iteration 10760, lr = 0.01
I0811 22:01:45.671954 26953 solver.cpp:228] Iteration 10770, loss = 2.5453
I0811 22:01:45.672015 26953 solver.cpp:244]     Train net output #0: loss = 2.5453 (* 1 = 2.5453 loss)
I0811 22:01:47.084120 26953 sgd_solver.cpp:106] Iteration 10770, lr = 0.01
I0811 22:02:05.524097 26953 solver.cpp:228] Iteration 10780, loss = 2.64915
I0811 22:02:05.524277 26953 solver.cpp:244]     Train net output #0: loss = 2.64915 (* 1 = 2.64915 loss)
I0811 22:02:06.914813 26953 sgd_solver.cpp:106] Iteration 10780, lr = 0.01
I0811 22:02:25.282729 26953 solver.cpp:228] Iteration 10790, loss = 2.48359
I0811 22:02:25.282799 26953 solver.cpp:244]     Train net output #0: loss = 2.48359 (* 1 = 2.48359 loss)
I0811 22:02:26.700209 26953 sgd_solver.cpp:106] Iteration 10790, lr = 0.01
I0811 22:02:44.468786 26953 solver.cpp:337] Iteration 10800, Testing net (#0)
I0811 22:02:45.054011 26953 solver.cpp:404]     Test net output #0: accuracy = 0.442
I0811 22:02:45.054088 26953 solver.cpp:404]     Test net output #1: loss = 2.53718 (* 1 = 2.53718 loss)
I0811 22:02:45.636629 26953 solver.cpp:228] Iteration 10800, loss = 2.60618
I0811 22:02:45.636728 26953 solver.cpp:244]     Train net output #0: loss = 2.60618 (* 1 = 2.60618 loss)
I0811 22:02:47.011466 26953 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0811 22:03:05.433652 26953 solver.cpp:228] Iteration 10810, loss = 2.65695
I0811 22:03:05.433728 26953 solver.cpp:244]     Train net output #0: loss = 2.65695 (* 1 = 2.65695 loss)
I0811 22:03:06.839458 26953 sgd_solver.cpp:106] Iteration 10810, lr = 0.01
I0811 22:03:25.209695 26953 solver.cpp:228] Iteration 10820, loss = 2.65367
I0811 22:03:25.209913 26953 solver.cpp:244]     Train net output #0: loss = 2.65367 (* 1 = 2.65367 loss)
I0811 22:03:26.610199 26953 sgd_solver.cpp:106] Iteration 10820, lr = 0.01
I0811 22:03:44.968312 26953 solver.cpp:228] Iteration 10830, loss = 2.46079
I0811 22:03:44.968379 26953 solver.cpp:244]     Train net output #0: loss = 2.46079 (* 1 = 2.46079 loss)
I0811 22:03:46.372252 26953 sgd_solver.cpp:106] Iteration 10830, lr = 0.01
I0811 22:04:04.795692 26953 solver.cpp:228] Iteration 10840, loss = 2.45202
I0811 22:04:04.795938 26953 solver.cpp:244]     Train net output #0: loss = 2.45202 (* 1 = 2.45202 loss)
I0811 22:04:06.199051 26953 sgd_solver.cpp:106] Iteration 10840, lr = 0.01
I0811 22:04:24.583437 26953 solver.cpp:228] Iteration 10850, loss = 2.44025
I0811 22:04:24.583508 26953 solver.cpp:244]     Train net output #0: loss = 2.44025 (* 1 = 2.44025 loss)
I0811 22:04:25.995214 26953 sgd_solver.cpp:106] Iteration 10850, lr = 0.01
I0811 22:04:44.460547 26953 solver.cpp:228] Iteration 10860, loss = 2.42195
I0811 22:04:44.460769 26953 solver.cpp:244]     Train net output #0: loss = 2.42195 (* 1 = 2.42195 loss)
I0811 22:04:45.863811 26953 sgd_solver.cpp:106] Iteration 10860, lr = 0.01
I0811 22:05:04.255898 26953 solver.cpp:228] Iteration 10870, loss = 2.34539
I0811 22:05:04.255969 26953 solver.cpp:244]     Train net output #0: loss = 2.34539 (* 1 = 2.34539 loss)
I0811 22:05:05.658053 26953 sgd_solver.cpp:106] Iteration 10870, lr = 0.01
I0811 22:05:24.027212 26953 solver.cpp:228] Iteration 10880, loss = 2.38767
I0811 22:05:24.027467 26953 solver.cpp:244]     Train net output #0: loss = 2.38767 (* 1 = 2.38767 loss)
I0811 22:05:25.422492 26953 sgd_solver.cpp:106] Iteration 10880, lr = 0.01
I0811 22:05:43.862166 26953 solver.cpp:228] Iteration 10890, loss = 2.43548
I0811 22:05:43.862227 26953 solver.cpp:244]     Train net output #0: loss = 2.43548 (* 1 = 2.43548 loss)
I0811 22:05:45.272267 26953 sgd_solver.cpp:106] Iteration 10890, lr = 0.01
I0811 22:06:03.035282 26953 solver.cpp:337] Iteration 10900, Testing net (#0)
I0811 22:06:03.634662 26953 solver.cpp:404]     Test net output #0: accuracy = 0.498
I0811 22:06:03.634721 26953 solver.cpp:404]     Test net output #1: loss = 2.30538 (* 1 = 2.30538 loss)
I0811 22:06:04.198418 26953 solver.cpp:228] Iteration 10900, loss = 2.52264
I0811 22:06:04.198493 26953 solver.cpp:244]     Train net output #0: loss = 2.52264 (* 1 = 2.52264 loss)
I0811 22:06:05.578362 26953 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0811 22:06:23.986887 26953 solver.cpp:228] Iteration 10910, loss = 2.7708
I0811 22:06:23.986958 26953 solver.cpp:244]     Train net output #0: loss = 2.7708 (* 1 = 2.7708 loss)
I0811 22:06:25.371665 26953 sgd_solver.cpp:106] Iteration 10910, lr = 0.01
I0811 22:06:43.810418 26953 solver.cpp:228] Iteration 10920, loss = 2.28769
I0811 22:06:43.810637 26953 solver.cpp:244]     Train net output #0: loss = 2.28769 (* 1 = 2.28769 loss)
I0811 22:06:45.223820 26953 sgd_solver.cpp:106] Iteration 10920, lr = 0.01
I0811 22:07:03.613092 26953 solver.cpp:228] Iteration 10930, loss = 2.53628
I0811 22:07:03.613162 26953 solver.cpp:244]     Train net output #0: loss = 2.53628 (* 1 = 2.53628 loss)
I0811 22:07:05.009907 26953 sgd_solver.cpp:106] Iteration 10930, lr = 0.01
I0811 22:07:23.451180 26953 solver.cpp:228] Iteration 10940, loss = 2.6036
I0811 22:07:23.451407 26953 solver.cpp:244]     Train net output #0: loss = 2.6036 (* 1 = 2.6036 loss)
I0811 22:07:24.858170 26953 sgd_solver.cpp:106] Iteration 10940, lr = 0.01
I0811 22:07:43.200861 26953 solver.cpp:228] Iteration 10950, loss = 2.35132
I0811 22:07:43.200934 26953 solver.cpp:244]     Train net output #0: loss = 2.35132 (* 1 = 2.35132 loss)
I0811 22:07:44.600277 26953 sgd_solver.cpp:106] Iteration 10950, lr = 0.01
I0811 22:08:02.958907 26953 solver.cpp:228] Iteration 10960, loss = 2.42619
I0811 22:08:02.959193 26953 solver.cpp:244]     Train net output #0: loss = 2.42619 (* 1 = 2.42619 loss)
I0811 22:08:04.361747 26953 sgd_solver.cpp:106] Iteration 10960, lr = 0.01
I0811 22:08:22.820142 26953 solver.cpp:228] Iteration 10970, loss = 2.55958
I0811 22:08:22.820233 26953 solver.cpp:244]     Train net output #0: loss = 2.55958 (* 1 = 2.55958 loss)
I0811 22:08:24.240159 26953 sgd_solver.cpp:106] Iteration 10970, lr = 0.01
I0811 22:08:42.623975 26953 solver.cpp:228] Iteration 10980, loss = 2.52355
I0811 22:08:42.624119 26953 solver.cpp:244]     Train net output #0: loss = 2.52355 (* 1 = 2.52355 loss)
I0811 22:08:44.037474 26953 sgd_solver.cpp:106] Iteration 10980, lr = 0.01
I0811 22:09:02.457228 26953 solver.cpp:228] Iteration 10990, loss = 2.43619
I0811 22:09:02.457293 26953 solver.cpp:244]     Train net output #0: loss = 2.43619 (* 1 = 2.43619 loss)
I0811 22:09:03.869148 26953 sgd_solver.cpp:106] Iteration 10990, lr = 0.01
I0811 22:09:21.678361 26953 solver.cpp:337] Iteration 11000, Testing net (#0)
I0811 22:09:22.268368 26953 solver.cpp:404]     Test net output #0: accuracy = 0.456
I0811 22:09:22.268436 26953 solver.cpp:404]     Test net output #1: loss = 2.51243 (* 1 = 2.51243 loss)
I0811 22:09:22.845536 26953 solver.cpp:228] Iteration 11000, loss = 2.38634
I0811 22:09:22.845599 26953 solver.cpp:244]     Train net output #0: loss = 2.38634 (* 1 = 2.38634 loss)
I0811 22:09:24.209556 26953 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0811 22:09:42.643705 26953 solver.cpp:228] Iteration 11010, loss = 2.4246
I0811 22:09:42.643769 26953 solver.cpp:244]     Train net output #0: loss = 2.4246 (* 1 = 2.4246 loss)
I0811 22:09:44.041462 26953 sgd_solver.cpp:106] Iteration 11010, lr = 0.01
I0811 22:10:02.388876 26953 solver.cpp:228] Iteration 11020, loss = 2.42274
I0811 22:10:02.389047 26953 solver.cpp:244]     Train net output #0: loss = 2.42274 (* 1 = 2.42274 loss)
I0811 22:10:03.793892 26953 sgd_solver.cpp:106] Iteration 11020, lr = 0.01
I0811 22:10:22.188906 26953 solver.cpp:228] Iteration 11030, loss = 2.48687
I0811 22:10:22.188964 26953 solver.cpp:244]     Train net output #0: loss = 2.48687 (* 1 = 2.48687 loss)
I0811 22:10:23.584424 26953 sgd_solver.cpp:106] Iteration 11030, lr = 0.01
I0811 22:10:42.008905 26953 solver.cpp:228] Iteration 11040, loss = 2.38982
I0811 22:10:42.009042 26953 solver.cpp:244]     Train net output #0: loss = 2.38982 (* 1 = 2.38982 loss)
I0811 22:10:43.407198 26953 sgd_solver.cpp:106] Iteration 11040, lr = 0.01
I0811 22:11:01.790134 26953 solver.cpp:228] Iteration 11050, loss = 2.47632
I0811 22:11:01.790196 26953 solver.cpp:244]     Train net output #0: loss = 2.47632 (* 1 = 2.47632 loss)
I0811 22:11:03.186604 26953 sgd_solver.cpp:106] Iteration 11050, lr = 0.01
I0811 22:11:21.559074 26953 solver.cpp:228] Iteration 11060, loss = 2.37738
I0811 22:11:21.559208 26953 solver.cpp:244]     Train net output #0: loss = 2.37738 (* 1 = 2.37738 loss)
I0811 22:11:22.950973 26953 sgd_solver.cpp:106] Iteration 11060, lr = 0.01
I0811 22:11:41.366865 26953 solver.cpp:228] Iteration 11070, loss = 2.33131
I0811 22:11:41.366928 26953 solver.cpp:244]     Train net output #0: loss = 2.33131 (* 1 = 2.33131 loss)
I0811 22:11:42.755791 26953 sgd_solver.cpp:106] Iteration 11070, lr = 0.01
I0811 22:12:01.148349 26953 solver.cpp:228] Iteration 11080, loss = 2.4317
I0811 22:12:01.148535 26953 solver.cpp:244]     Train net output #0: loss = 2.4317 (* 1 = 2.4317 loss)
I0811 22:12:02.558840 26953 sgd_solver.cpp:106] Iteration 11080, lr = 0.01
I0811 22:12:20.981305 26953 solver.cpp:228] Iteration 11090, loss = 2.49789
I0811 22:12:20.981377 26953 solver.cpp:244]     Train net output #0: loss = 2.49789 (* 1 = 2.49789 loss)
I0811 22:12:22.376971 26953 sgd_solver.cpp:106] Iteration 11090, lr = 0.01
I0811 22:12:40.206348 26953 solver.cpp:337] Iteration 11100, Testing net (#0)
I0811 22:12:40.792933 26953 solver.cpp:404]     Test net output #0: accuracy = 0.452
I0811 22:12:40.793000 26953 solver.cpp:404]     Test net output #1: loss = 2.39289 (* 1 = 2.39289 loss)
I0811 22:12:41.361830 26953 solver.cpp:228] Iteration 11100, loss = 2.54719
I0811 22:12:41.361904 26953 solver.cpp:244]     Train net output #0: loss = 2.54719 (* 1 = 2.54719 loss)
I0811 22:12:42.757760 26953 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0811 22:13:01.167999 26953 solver.cpp:228] Iteration 11110, loss = 2.5248
I0811 22:13:01.168061 26953 solver.cpp:244]     Train net output #0: loss = 2.5248 (* 1 = 2.5248 loss)
I0811 22:13:02.584712 26953 sgd_solver.cpp:106] Iteration 11110, lr = 0.01
I0811 22:13:20.955039 26953 solver.cpp:228] Iteration 11120, loss = 2.56636
I0811 22:13:20.955211 26953 solver.cpp:244]     Train net output #0: loss = 2.56636 (* 1 = 2.56636 loss)
I0811 22:13:22.386471 26953 sgd_solver.cpp:106] Iteration 11120, lr = 0.01
I0811 22:13:40.756484 26953 solver.cpp:228] Iteration 11130, loss = 2.36771
I0811 22:13:40.756566 26953 solver.cpp:244]     Train net output #0: loss = 2.36771 (* 1 = 2.36771 loss)
I0811 22:13:42.169734 26953 sgd_solver.cpp:106] Iteration 11130, lr = 0.01
I0811 22:14:00.602159 26953 solver.cpp:228] Iteration 11140, loss = 2.37749
I0811 22:14:00.602383 26953 solver.cpp:244]     Train net output #0: loss = 2.37749 (* 1 = 2.37749 loss)
I0811 22:14:01.989305 26953 sgd_solver.cpp:106] Iteration 11140, lr = 0.01
I0811 22:14:20.347903 26953 solver.cpp:228] Iteration 11150, loss = 2.45337
I0811 22:14:20.347965 26953 solver.cpp:244]     Train net output #0: loss = 2.45337 (* 1 = 2.45337 loss)
I0811 22:14:21.770489 26953 sgd_solver.cpp:106] Iteration 11150, lr = 0.01
I0811 22:14:40.244117 26953 solver.cpp:228] Iteration 11160, loss = 2.38656
I0811 22:14:40.244335 26953 solver.cpp:244]     Train net output #0: loss = 2.38656 (* 1 = 2.38656 loss)
I0811 22:14:41.639045 26953 sgd_solver.cpp:106] Iteration 11160, lr = 0.01
I0811 22:14:59.996116 26953 solver.cpp:228] Iteration 11170, loss = 2.39193
I0811 22:14:59.996188 26953 solver.cpp:244]     Train net output #0: loss = 2.39193 (* 1 = 2.39193 loss)
I0811 22:15:01.404986 26953 sgd_solver.cpp:106] Iteration 11170, lr = 0.01
I0811 22:15:19.764154 26953 solver.cpp:228] Iteration 11180, loss = 2.45957
I0811 22:15:19.764349 26953 solver.cpp:244]     Train net output #0: loss = 2.45957 (* 1 = 2.45957 loss)
I0811 22:15:21.159791 26953 sgd_solver.cpp:106] Iteration 11180, lr = 0.01
I0811 22:15:39.531522 26953 solver.cpp:228] Iteration 11190, loss = 2.54905
I0811 22:15:39.531586 26953 solver.cpp:244]     Train net output #0: loss = 2.54905 (* 1 = 2.54905 loss)
I0811 22:15:40.935539 26953 sgd_solver.cpp:106] Iteration 11190, lr = 0.01
I0811 22:15:58.806011 26953 solver.cpp:337] Iteration 11200, Testing net (#0)
I0811 22:15:59.397227 26953 solver.cpp:404]     Test net output #0: accuracy = 0.446
I0811 22:15:59.397279 26953 solver.cpp:404]     Test net output #1: loss = 2.40092 (* 1 = 2.40092 loss)
I0811 22:15:59.981812 26953 solver.cpp:228] Iteration 11200, loss = 2.46595
I0811 22:15:59.981886 26953 solver.cpp:244]     Train net output #0: loss = 2.46595 (* 1 = 2.46595 loss)
I0811 22:16:01.353935 26953 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0811 22:16:19.776129 26953 solver.cpp:228] Iteration 11210, loss = 2.46323
I0811 22:16:19.776201 26953 solver.cpp:244]     Train net output #0: loss = 2.46323 (* 1 = 2.46323 loss)
I0811 22:16:21.174451 26953 sgd_solver.cpp:106] Iteration 11210, lr = 0.01
I0811 22:16:39.576185 26953 solver.cpp:228] Iteration 11220, loss = 2.25971
I0811 22:16:39.576431 26953 solver.cpp:244]     Train net output #0: loss = 2.25971 (* 1 = 2.25971 loss)
I0811 22:16:40.999627 26953 sgd_solver.cpp:106] Iteration 11220, lr = 0.01
I0811 22:16:59.358577 26953 solver.cpp:228] Iteration 11230, loss = 2.47136
I0811 22:16:59.358657 26953 solver.cpp:244]     Train net output #0: loss = 2.47136 (* 1 = 2.47136 loss)
I0811 22:17:00.768915 26953 sgd_solver.cpp:106] Iteration 11230, lr = 0.01
I0811 22:17:19.213611 26953 solver.cpp:228] Iteration 11240, loss = 2.61083
I0811 22:17:19.213825 26953 solver.cpp:244]     Train net output #0: loss = 2.61083 (* 1 = 2.61083 loss)
I0811 22:17:20.625066 26953 sgd_solver.cpp:106] Iteration 11240, lr = 0.01
I0811 22:17:38.973822 26953 solver.cpp:228] Iteration 11250, loss = 2.48141
I0811 22:17:38.973892 26953 solver.cpp:244]     Train net output #0: loss = 2.48141 (* 1 = 2.48141 loss)
I0811 22:17:40.379621 26953 sgd_solver.cpp:106] Iteration 11250, lr = 0.01
I0811 22:17:58.753216 26953 solver.cpp:228] Iteration 11260, loss = 2.38739
I0811 22:17:58.753371 26953 solver.cpp:244]     Train net output #0: loss = 2.38739 (* 1 = 2.38739 loss)
I0811 22:18:00.149354 26953 sgd_solver.cpp:106] Iteration 11260, lr = 0.01
I0811 22:18:18.558053 26953 solver.cpp:228] Iteration 11270, loss = 2.45711
I0811 22:18:18.558130 26953 solver.cpp:244]     Train net output #0: loss = 2.45711 (* 1 = 2.45711 loss)
I0811 22:18:19.974766 26953 sgd_solver.cpp:106] Iteration 11270, lr = 0.01
I0811 22:18:38.377822 26953 solver.cpp:228] Iteration 11280, loss = 2.32079
I0811 22:18:38.378072 26953 solver.cpp:244]     Train net output #0: loss = 2.32079 (* 1 = 2.32079 loss)
I0811 22:18:39.787716 26953 sgd_solver.cpp:106] Iteration 11280, lr = 0.01
I0811 22:18:58.175359 26953 solver.cpp:228] Iteration 11290, loss = 2.32457
I0811 22:18:58.175429 26953 solver.cpp:244]     Train net output #0: loss = 2.32457 (* 1 = 2.32457 loss)
I0811 22:18:59.581131 26953 sgd_solver.cpp:106] Iteration 11290, lr = 0.01
I0811 22:19:17.438628 26953 solver.cpp:337] Iteration 11300, Testing net (#0)
I0811 22:19:18.029237 26953 solver.cpp:404]     Test net output #0: accuracy = 0.44
I0811 22:19:18.029294 26953 solver.cpp:404]     Test net output #1: loss = 2.51074 (* 1 = 2.51074 loss)
I0811 22:19:18.605058 26953 solver.cpp:228] Iteration 11300, loss = 2.49849
I0811 22:19:18.605129 26953 solver.cpp:244]     Train net output #0: loss = 2.49849 (* 1 = 2.49849 loss)
I0811 22:19:19.975842 26953 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0811 22:19:38.418732 26953 solver.cpp:228] Iteration 11310, loss = 2.61849
I0811 22:19:38.418812 26953 solver.cpp:244]     Train net output #0: loss = 2.61849 (* 1 = 2.61849 loss)
I0811 22:19:39.824934 26953 sgd_solver.cpp:106] Iteration 11310, lr = 0.01
I0811 22:19:58.193603 26953 solver.cpp:228] Iteration 11320, loss = 2.40599
I0811 22:19:58.193830 26953 solver.cpp:244]     Train net output #0: loss = 2.40599 (* 1 = 2.40599 loss)
I0811 22:19:59.606287 26953 sgd_solver.cpp:106] Iteration 11320, lr = 0.01
I0811 22:20:18.068914 26953 solver.cpp:228] Iteration 11330, loss = 2.43777
I0811 22:20:18.068986 26953 solver.cpp:244]     Train net output #0: loss = 2.43777 (* 1 = 2.43777 loss)
I0811 22:20:19.471694 26953 sgd_solver.cpp:106] Iteration 11330, lr = 0.01
I0811 22:20:37.852409 26953 solver.cpp:228] Iteration 11340, loss = 2.69435
I0811 22:20:37.852560 26953 solver.cpp:244]     Train net output #0: loss = 2.69435 (* 1 = 2.69435 loss)
I0811 22:20:39.273068 26953 sgd_solver.cpp:106] Iteration 11340, lr = 0.01
I0811 22:20:57.701527 26953 solver.cpp:228] Iteration 11350, loss = 2.64763
I0811 22:20:57.701602 26953 solver.cpp:244]     Train net output #0: loss = 2.64763 (* 1 = 2.64763 loss)
I0811 22:20:59.090684 26953 sgd_solver.cpp:106] Iteration 11350, lr = 0.01
I0811 22:21:17.485115 26953 solver.cpp:228] Iteration 11360, loss = 2.43916
I0811 22:21:17.485386 26953 solver.cpp:244]     Train net output #0: loss = 2.43916 (* 1 = 2.43916 loss)
I0811 22:21:18.881994 26953 sgd_solver.cpp:106] Iteration 11360, lr = 0.01
I0811 22:21:37.260948 26953 solver.cpp:228] Iteration 11370, loss = 2.57193
I0811 22:21:37.261029 26953 solver.cpp:244]     Train net output #0: loss = 2.57193 (* 1 = 2.57193 loss)
I0811 22:21:38.679522 26953 sgd_solver.cpp:106] Iteration 11370, lr = 0.01
I0811 22:21:57.075990 26953 solver.cpp:228] Iteration 11380, loss = 2.44849
I0811 22:21:57.076160 26953 solver.cpp:244]     Train net output #0: loss = 2.44849 (* 1 = 2.44849 loss)
I0811 22:21:58.475471 26953 sgd_solver.cpp:106] Iteration 11380, lr = 0.01
I0811 22:22:16.883724 26953 solver.cpp:228] Iteration 11390, loss = 2.51118
I0811 22:22:16.883803 26953 solver.cpp:244]     Train net output #0: loss = 2.51118 (* 1 = 2.51118 loss)
I0811 22:22:18.280818 26953 sgd_solver.cpp:106] Iteration 11390, lr = 0.01
I0811 22:22:36.059085 26953 solver.cpp:337] Iteration 11400, Testing net (#0)
I0811 22:22:36.651000 26953 solver.cpp:404]     Test net output #0: accuracy = 0.456
I0811 22:22:36.651062 26953 solver.cpp:404]     Test net output #1: loss = 2.44825 (* 1 = 2.44825 loss)
I0811 22:22:37.209892 26953 solver.cpp:228] Iteration 11400, loss = 2.37003
I0811 22:22:37.209951 26953 solver.cpp:244]     Train net output #0: loss = 2.37003 (* 1 = 2.37003 loss)
I0811 22:22:38.608997 26953 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0811 22:22:57.026458 26953 solver.cpp:228] Iteration 11410, loss = 2.48073
I0811 22:22:57.026530 26953 solver.cpp:244]     Train net output #0: loss = 2.48073 (* 1 = 2.48073 loss)
I0811 22:22:58.426367 26953 sgd_solver.cpp:106] Iteration 11410, lr = 0.01
I0811 22:23:16.787593 26953 solver.cpp:228] Iteration 11420, loss = 2.4587
I0811 22:23:16.787812 26953 solver.cpp:244]     Train net output #0: loss = 2.4587 (* 1 = 2.4587 loss)
I0811 22:23:18.205977 26953 sgd_solver.cpp:106] Iteration 11420, lr = 0.01
I0811 22:23:36.573340 26953 solver.cpp:228] Iteration 11430, loss = 2.40259
I0811 22:23:36.573424 26953 solver.cpp:244]     Train net output #0: loss = 2.40259 (* 1 = 2.40259 loss)
I0811 22:23:37.971837 26953 sgd_solver.cpp:106] Iteration 11430, lr = 0.01
I0811 22:23:56.400331 26953 solver.cpp:228] Iteration 11440, loss = 2.54092
I0811 22:23:56.400575 26953 solver.cpp:244]     Train net output #0: loss = 2.54092 (* 1 = 2.54092 loss)
I0811 22:23:57.799952 26953 sgd_solver.cpp:106] Iteration 11440, lr = 0.01
I0811 22:24:16.180147 26953 solver.cpp:228] Iteration 11450, loss = 2.46555
I0811 22:24:16.180213 26953 solver.cpp:244]     Train net output #0: loss = 2.46555 (* 1 = 2.46555 loss)
I0811 22:24:17.581547 26953 sgd_solver.cpp:106] Iteration 11450, lr = 0.01
I0811 22:24:35.988023 26953 solver.cpp:228] Iteration 11460, loss = 2.61731
I0811 22:24:35.988273 26953 solver.cpp:244]     Train net output #0: loss = 2.61731 (* 1 = 2.61731 loss)
I0811 22:24:37.395905 26953 sgd_solver.cpp:106] Iteration 11460, lr = 0.01
I0811 22:24:55.854157 26953 solver.cpp:228] Iteration 11470, loss = 2.44963
I0811 22:24:55.854228 26953 solver.cpp:244]     Train net output #0: loss = 2.44963 (* 1 = 2.44963 loss)
I0811 22:24:57.255457 26953 sgd_solver.cpp:106] Iteration 11470, lr = 0.01
I0811 22:25:15.647689 26953 solver.cpp:228] Iteration 11480, loss = 2.61185
I0811 22:25:15.647899 26953 solver.cpp:244]     Train net output #0: loss = 2.61185 (* 1 = 2.61185 loss)
I0811 22:25:17.046818 26953 sgd_solver.cpp:106] Iteration 11480, lr = 0.01
I0811 22:25:35.476042 26953 solver.cpp:228] Iteration 11490, loss = 2.43513
I0811 22:25:35.476104 26953 solver.cpp:244]     Train net output #0: loss = 2.43513 (* 1 = 2.43513 loss)
I0811 22:25:36.901728 26953 sgd_solver.cpp:106] Iteration 11490, lr = 0.01
I0811 22:25:54.654304 26953 solver.cpp:337] Iteration 11500, Testing net (#0)
I0811 22:25:55.248338 26953 solver.cpp:404]     Test net output #0: accuracy = 0.442
I0811 22:25:55.248423 26953 solver.cpp:404]     Test net output #1: loss = 2.50532 (* 1 = 2.50532 loss)
I0811 22:25:55.829475 26953 solver.cpp:228] Iteration 11500, loss = 2.38819
I0811 22:25:55.829552 26953 solver.cpp:244]     Train net output #0: loss = 2.38819 (* 1 = 2.38819 loss)
I0811 22:25:57.190182 26953 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0811 22:26:15.588003 26953 solver.cpp:228] Iteration 11510, loss = 2.3858
I0811 22:26:15.588078 26953 solver.cpp:244]     Train net output #0: loss = 2.3858 (* 1 = 2.3858 loss)
I0811 22:26:16.982702 26953 sgd_solver.cpp:106] Iteration 11510, lr = 0.01
I0811 22:26:35.369771 26953 solver.cpp:228] Iteration 11520, loss = 2.54553
I0811 22:26:35.369966 26953 solver.cpp:244]     Train net output #0: loss = 2.54553 (* 1 = 2.54553 loss)
I0811 22:26:36.788836 26953 sgd_solver.cpp:106] Iteration 11520, lr = 0.01
I0811 22:26:55.146294 26953 solver.cpp:228] Iteration 11530, loss = 2.44392
I0811 22:26:55.146375 26953 solver.cpp:244]     Train net output #0: loss = 2.44392 (* 1 = 2.44392 loss)
I0811 22:26:56.546936 26953 sgd_solver.cpp:106] Iteration 11530, lr = 0.01
I0811 22:27:14.950435 26953 solver.cpp:228] Iteration 11540, loss = 2.58769
I0811 22:27:14.950702 26953 solver.cpp:244]     Train net output #0: loss = 2.58769 (* 1 = 2.58769 loss)
I0811 22:27:16.349048 26953 sgd_solver.cpp:106] Iteration 11540, lr = 0.01
I0811 22:27:34.770433 26953 solver.cpp:228] Iteration 11550, loss = 2.46326
I0811 22:27:34.770488 26953 solver.cpp:244]     Train net output #0: loss = 2.46326 (* 1 = 2.46326 loss)
I0811 22:27:36.177639 26953 sgd_solver.cpp:106] Iteration 11550, lr = 0.01
I0811 22:27:54.590685 26953 solver.cpp:228] Iteration 11560, loss = 2.70154
I0811 22:27:54.590884 26953 solver.cpp:244]     Train net output #0: loss = 2.70154 (* 1 = 2.70154 loss)
I0811 22:27:55.986970 26953 sgd_solver.cpp:106] Iteration 11560, lr = 0.01
I0811 22:28:14.412729 26953 solver.cpp:228] Iteration 11570, loss = 2.39983
I0811 22:28:14.412806 26953 solver.cpp:244]     Train net output #0: loss = 2.39983 (* 1 = 2.39983 loss)
I0811 22:28:15.817937 26953 sgd_solver.cpp:106] Iteration 11570, lr = 0.01
I0811 22:28:34.177356 26953 solver.cpp:228] Iteration 11580, loss = 2.27883
I0811 22:28:34.177577 26953 solver.cpp:244]     Train net output #0: loss = 2.27883 (* 1 = 2.27883 loss)
I0811 22:28:35.592758 26953 sgd_solver.cpp:106] Iteration 11580, lr = 0.01
I0811 22:28:53.944443 26953 solver.cpp:228] Iteration 11590, loss = 2.2722
I0811 22:28:53.944515 26953 solver.cpp:244]     Train net output #0: loss = 2.2722 (* 1 = 2.2722 loss)
I0811 22:28:55.343122 26953 sgd_solver.cpp:106] Iteration 11590, lr = 0.01
I0811 22:29:13.212033 26953 solver.cpp:337] Iteration 11600, Testing net (#0)
I0811 22:29:13.803180 26953 solver.cpp:404]     Test net output #0: accuracy = 0.456
I0811 22:29:13.803241 26953 solver.cpp:404]     Test net output #1: loss = 2.55446 (* 1 = 2.55446 loss)
I0811 22:29:14.368162 26953 solver.cpp:228] Iteration 11600, loss = 2.42722
I0811 22:29:14.368242 26953 solver.cpp:244]     Train net output #0: loss = 2.42722 (* 1 = 2.42722 loss)
I0811 22:29:15.743083 26953 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0811 22:29:34.229243 26953 solver.cpp:228] Iteration 11610, loss = 2.47281
I0811 22:29:34.229324 26953 solver.cpp:244]     Train net output #0: loss = 2.47281 (* 1 = 2.47281 loss)
I0811 22:29:35.627130 26953 sgd_solver.cpp:106] Iteration 11610, lr = 0.01
I0811 22:29:53.995746 26953 solver.cpp:228] Iteration 11620, loss = 2.46711
I0811 22:29:53.995967 26953 solver.cpp:244]     Train net output #0: loss = 2.46711 (* 1 = 2.46711 loss)
I0811 22:29:55.398074 26953 sgd_solver.cpp:106] Iteration 11620, lr = 0.01
I0811 22:30:13.764456 26953 solver.cpp:228] Iteration 11630, loss = 2.33549
I0811 22:30:13.764531 26953 solver.cpp:244]     Train net output #0: loss = 2.33549 (* 1 = 2.33549 loss)
I0811 22:30:15.174298 26953 sgd_solver.cpp:106] Iteration 11630, lr = 0.01
I0811 22:30:33.608840 26953 solver.cpp:228] Iteration 11640, loss = 2.46848
I0811 22:30:33.609074 26953 solver.cpp:244]     Train net output #0: loss = 2.46848 (* 1 = 2.46848 loss)
I0811 22:30:35.008013 26953 sgd_solver.cpp:106] Iteration 11640, lr = 0.01
I0811 22:30:53.398809 26953 solver.cpp:228] Iteration 11650, loss = 2.47781
I0811 22:30:53.398869 26953 solver.cpp:244]     Train net output #0: loss = 2.47781 (* 1 = 2.47781 loss)
I0811 22:30:54.785497 26953 sgd_solver.cpp:106] Iteration 11650, lr = 0.01
I0811 22:31:13.166676 26953 solver.cpp:228] Iteration 11660, loss = 2.5043
I0811 22:31:13.166824 26953 solver.cpp:244]     Train net output #0: loss = 2.5043 (* 1 = 2.5043 loss)
I0811 22:31:14.568478 26953 sgd_solver.cpp:106] Iteration 11660, lr = 0.01
I0811 22:31:33.000120 26953 solver.cpp:228] Iteration 11670, loss = 2.53201
I0811 22:31:33.000188 26953 solver.cpp:244]     Train net output #0: loss = 2.53201 (* 1 = 2.53201 loss)
I0811 22:31:34.398564 26953 sgd_solver.cpp:106] Iteration 11670, lr = 0.01
I0811 22:31:52.767266 26953 solver.cpp:228] Iteration 11680, loss = 2.49395
I0811 22:31:52.767442 26953 solver.cpp:244]     Train net output #0: loss = 2.49395 (* 1 = 2.49395 loss)
I0811 22:31:54.174260 26953 sgd_solver.cpp:106] Iteration 11680, lr = 0.01
I0811 22:32:12.574596 26953 solver.cpp:228] Iteration 11690, loss = 2.34062
I0811 22:32:12.574658 26953 solver.cpp:244]     Train net output #0: loss = 2.34062 (* 1 = 2.34062 loss)
I0811 22:32:13.966058 26953 sgd_solver.cpp:106] Iteration 11690, lr = 0.01
I0811 22:32:31.786412 26953 solver.cpp:337] Iteration 11700, Testing net (#0)
I0811 22:32:32.374413 26953 solver.cpp:404]     Test net output #0: accuracy = 0.438
I0811 22:32:32.374470 26953 solver.cpp:404]     Test net output #1: loss = 2.60083 (* 1 = 2.60083 loss)
I0811 22:32:32.955844 26953 solver.cpp:228] Iteration 11700, loss = 2.49485
I0811 22:32:32.955936 26953 solver.cpp:244]     Train net output #0: loss = 2.49485 (* 1 = 2.49485 loss)
I0811 22:32:34.326272 26953 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0811 22:32:52.714979 26953 solver.cpp:228] Iteration 11710, loss = 2.35742
I0811 22:32:52.715039 26953 solver.cpp:244]     Train net output #0: loss = 2.35742 (* 1 = 2.35742 loss)
I0811 22:32:54.089397 26953 sgd_solver.cpp:106] Iteration 11710, lr = 0.01
I0811 22:33:12.507331 26953 solver.cpp:228] Iteration 11720, loss = 2.63221
I0811 22:33:12.507514 26953 solver.cpp:244]     Train net output #0: loss = 2.63221 (* 1 = 2.63221 loss)
I0811 22:33:13.912078 26953 sgd_solver.cpp:106] Iteration 11720, lr = 0.01
I0811 22:33:32.280516 26953 solver.cpp:228] Iteration 11730, loss = 2.45723
I0811 22:33:32.280586 26953 solver.cpp:244]     Train net output #0: loss = 2.45723 (* 1 = 2.45723 loss)
I0811 22:33:33.679333 26953 sgd_solver.cpp:106] Iteration 11730, lr = 0.01
I0811 22:33:52.049135 26953 solver.cpp:228] Iteration 11740, loss = 2.62328
I0811 22:33:52.049386 26953 solver.cpp:244]     Train net output #0: loss = 2.62328 (* 1 = 2.62328 loss)
I0811 22:33:53.462208 26953 sgd_solver.cpp:106] Iteration 11740, lr = 0.01
I0811 22:34:11.864763 26953 solver.cpp:228] Iteration 11750, loss = 2.50999
I0811 22:34:11.864832 26953 solver.cpp:244]     Train net output #0: loss = 2.50999 (* 1 = 2.50999 loss)
I0811 22:34:13.266976 26953 sgd_solver.cpp:106] Iteration 11750, lr = 0.01
I0811 22:34:31.661623 26953 solver.cpp:228] Iteration 11760, loss = 2.37761
I0811 22:34:31.661849 26953 solver.cpp:244]     Train net output #0: loss = 2.37761 (* 1 = 2.37761 loss)
I0811 22:34:33.061897 26953 sgd_solver.cpp:106] Iteration 11760, lr = 0.01
I0811 22:34:51.437862 26953 solver.cpp:228] Iteration 11770, loss = 2.5625
I0811 22:34:51.437922 26953 solver.cpp:244]     Train net output #0: loss = 2.5625 (* 1 = 2.5625 loss)
I0811 22:34:52.833231 26953 sgd_solver.cpp:106] Iteration 11770, lr = 0.01
I0811 22:35:11.213712 26953 solver.cpp:228] Iteration 11780, loss = 2.25665
I0811 22:35:11.213948 26953 solver.cpp:244]     Train net output #0: loss = 2.25665 (* 1 = 2.25665 loss)
I0811 22:35:12.614116 26953 sgd_solver.cpp:106] Iteration 11780, lr = 0.01
I0811 22:35:31.040246 26953 solver.cpp:228] Iteration 11790, loss = 2.4928
I0811 22:35:31.040308 26953 solver.cpp:244]     Train net output #0: loss = 2.4928 (* 1 = 2.4928 loss)
I0811 22:35:32.451339 26953 sgd_solver.cpp:106] Iteration 11790, lr = 0.01
I0811 22:35:50.219818 26953 solver.cpp:337] Iteration 11800, Testing net (#0)
I0811 22:35:50.820022 26953 solver.cpp:404]     Test net output #0: accuracy = 0.448
I0811 22:35:50.820085 26953 solver.cpp:404]     Test net output #1: loss = 2.47696 (* 1 = 2.47696 loss)
I0811 22:35:51.393642 26953 solver.cpp:228] Iteration 11800, loss = 2.42059
I0811 22:35:51.393739 26953 solver.cpp:244]     Train net output #0: loss = 2.42059 (* 1 = 2.42059 loss)
I0811 22:35:52.760277 26953 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0811 22:36:11.167521 26953 solver.cpp:228] Iteration 11810, loss = 2.43139
I0811 22:36:11.167587 26953 solver.cpp:244]     Train net output #0: loss = 2.43139 (* 1 = 2.43139 loss)
I0811 22:36:12.581267 26953 sgd_solver.cpp:106] Iteration 11810, lr = 0.01
I0811 22:36:30.973441 26953 solver.cpp:228] Iteration 11820, loss = 2.47553
I0811 22:36:30.973621 26953 solver.cpp:244]     Train net output #0: loss = 2.47553 (* 1 = 2.47553 loss)
I0811 22:36:32.374766 26953 sgd_solver.cpp:106] Iteration 11820, lr = 0.01
I0811 22:36:50.802335 26953 solver.cpp:228] Iteration 11830, loss = 2.33841
I0811 22:36:50.802397 26953 solver.cpp:244]     Train net output #0: loss = 2.33841 (* 1 = 2.33841 loss)
I0811 22:36:52.207242 26953 sgd_solver.cpp:106] Iteration 11830, lr = 0.01
I0811 22:37:10.600512 26953 solver.cpp:228] Iteration 11840, loss = 2.36864
I0811 22:37:10.600729 26953 solver.cpp:244]     Train net output #0: loss = 2.36864 (* 1 = 2.36864 loss)
I0811 22:37:11.990829 26953 sgd_solver.cpp:106] Iteration 11840, lr = 0.01
I0811 22:37:30.347945 26953 solver.cpp:228] Iteration 11850, loss = 2.55902
I0811 22:37:30.348017 26953 solver.cpp:244]     Train net output #0: loss = 2.55902 (* 1 = 2.55902 loss)
I0811 22:37:31.751780 26953 sgd_solver.cpp:106] Iteration 11850, lr = 0.01
I0811 22:37:50.112401 26953 solver.cpp:228] Iteration 11860, loss = 2.38393
I0811 22:37:50.112620 26953 solver.cpp:244]     Train net output #0: loss = 2.38393 (* 1 = 2.38393 loss)
I0811 22:37:51.512229 26953 sgd_solver.cpp:106] Iteration 11860, lr = 0.01
I0811 22:38:09.902650 26953 solver.cpp:228] Iteration 11870, loss = 2.34807
I0811 22:38:09.902724 26953 solver.cpp:244]     Train net output #0: loss = 2.34807 (* 1 = 2.34807 loss)
I0811 22:38:11.313546 26953 sgd_solver.cpp:106] Iteration 11870, lr = 0.01
I0811 22:38:29.734704 26953 solver.cpp:228] Iteration 11880, loss = 2.28606
I0811 22:38:29.734948 26953 solver.cpp:244]     Train net output #0: loss = 2.28606 (* 1 = 2.28606 loss)
I0811 22:38:31.145325 26953 sgd_solver.cpp:106] Iteration 11880, lr = 0.01
I0811 22:38:49.532135 26953 solver.cpp:228] Iteration 11890, loss = 2.4709
I0811 22:38:49.532215 26953 solver.cpp:244]     Train net output #0: loss = 2.4709 (* 1 = 2.4709 loss)
I0811 22:38:50.926437 26953 sgd_solver.cpp:106] Iteration 11890, lr = 0.01
I0811 22:39:08.812461 26953 solver.cpp:337] Iteration 11900, Testing net (#0)
I0811 22:39:09.402961 26953 solver.cpp:404]     Test net output #0: accuracy = 0.448
I0811 22:39:09.403030 26953 solver.cpp:404]     Test net output #1: loss = 2.56803 (* 1 = 2.56803 loss)
I0811 22:39:09.989809 26953 solver.cpp:228] Iteration 11900, loss = 2.4413
I0811 22:39:09.989899 26953 solver.cpp:244]     Train net output #0: loss = 2.4413 (* 1 = 2.4413 loss)
I0811 22:39:11.350473 26953 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0811 22:39:29.775944 26953 solver.cpp:228] Iteration 11910, loss = 2.38208
I0811 22:39:29.776036 26953 solver.cpp:244]     Train net output #0: loss = 2.38208 (* 1 = 2.38208 loss)
I0811 22:39:31.181929 26953 sgd_solver.cpp:106] Iteration 11910, lr = 0.01
I0811 22:39:49.554466 26953 solver.cpp:228] Iteration 11920, loss = 2.5319
I0811 22:39:49.554616 26953 solver.cpp:244]     Train net output #0: loss = 2.5319 (* 1 = 2.5319 loss)
I0811 22:39:50.973701 26953 sgd_solver.cpp:106] Iteration 11920, lr = 0.01
I0811 22:40:09.377714 26953 solver.cpp:228] Iteration 11930, loss = 2.4322
I0811 22:40:09.377825 26953 solver.cpp:244]     Train net output #0: loss = 2.4322 (* 1 = 2.4322 loss)
I0811 22:40:10.779287 26953 sgd_solver.cpp:106] Iteration 11930, lr = 0.01
I0811 22:40:29.192695 26953 solver.cpp:228] Iteration 11940, loss = 2.39497
I0811 22:40:29.192905 26953 solver.cpp:244]     Train net output #0: loss = 2.39497 (* 1 = 2.39497 loss)
I0811 22:40:30.589263 26953 sgd_solver.cpp:106] Iteration 11940, lr = 0.01
I0811 22:40:48.957139 26953 solver.cpp:228] Iteration 11950, loss = 2.4932
I0811 22:40:48.957228 26953 solver.cpp:244]     Train net output #0: loss = 2.4932 (* 1 = 2.4932 loss)
I0811 22:40:50.350466 26953 sgd_solver.cpp:106] Iteration 11950, lr = 0.01
I0811 22:41:08.723299 26953 solver.cpp:228] Iteration 11960, loss = 2.48318
I0811 22:41:08.723616 26953 solver.cpp:244]     Train net output #0: loss = 2.48318 (* 1 = 2.48318 loss)
I0811 22:41:10.123069 26953 sgd_solver.cpp:106] Iteration 11960, lr = 0.01
I0811 22:41:28.537881 26953 solver.cpp:228] Iteration 11970, loss = 2.27305
I0811 22:41:28.537962 26953 solver.cpp:244]     Train net output #0: loss = 2.27305 (* 1 = 2.27305 loss)
I0811 22:41:29.943344 26953 sgd_solver.cpp:106] Iteration 11970, lr = 0.01
I0811 22:41:48.308490 26953 solver.cpp:228] Iteration 11980, loss = 2.36132
I0811 22:41:48.308748 26953 solver.cpp:244]     Train net output #0: loss = 2.36132 (* 1 = 2.36132 loss)
I0811 22:41:49.721693 26953 sgd_solver.cpp:106] Iteration 11980, lr = 0.01
I0811 22:42:08.121331 26953 solver.cpp:228] Iteration 11990, loss = 2.4594
I0811 22:42:08.121412 26953 solver.cpp:244]     Train net output #0: loss = 2.4594 (* 1 = 2.4594 loss)
I0811 22:42:09.520560 26953 sgd_solver.cpp:106] Iteration 11990, lr = 0.01
I0811 22:42:27.320519 26953 solver.cpp:337] Iteration 12000, Testing net (#0)
I0811 22:42:27.908826 26953 solver.cpp:404]     Test net output #0: accuracy = 0.46
I0811 22:42:27.908897 26953 solver.cpp:404]     Test net output #1: loss = 2.40086 (* 1 = 2.40086 loss)
I0811 22:42:28.473598 26953 solver.cpp:228] Iteration 12000, loss = 2.34991
I0811 22:42:28.473696 26953 solver.cpp:244]     Train net output #0: loss = 2.34991 (* 1 = 2.34991 loss)
I0811 22:42:29.875102 26953 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0811 22:42:48.279512 26953 solver.cpp:228] Iteration 12010, loss = 2.44411
I0811 22:42:48.279584 26953 solver.cpp:244]     Train net output #0: loss = 2.44411 (* 1 = 2.44411 loss)
I0811 22:42:49.672255 26953 sgd_solver.cpp:106] Iteration 12010, lr = 0.01
I0811 22:43:08.147480 26953 solver.cpp:228] Iteration 12020, loss = 2.27365
I0811 22:43:08.147667 26953 solver.cpp:244]     Train net output #0: loss = 2.27365 (* 1 = 2.27365 loss)
I0811 22:43:09.540601 26953 sgd_solver.cpp:106] Iteration 12020, lr = 0.01
I0811 22:43:27.918054 26953 solver.cpp:228] Iteration 12030, loss = 2.36172
I0811 22:43:27.918121 26953 solver.cpp:244]     Train net output #0: loss = 2.36172 (* 1 = 2.36172 loss)
I0811 22:43:29.328253 26953 sgd_solver.cpp:106] Iteration 12030, lr = 0.01
I0811 22:43:47.811887 26953 solver.cpp:228] Iteration 12040, loss = 2.59974
I0811 22:43:47.812110 26953 solver.cpp:244]     Train net output #0: loss = 2.59974 (* 1 = 2.59974 loss)
I0811 22:43:49.233623 26953 sgd_solver.cpp:106] Iteration 12040, lr = 0.01
I0811 22:44:07.592407 26953 solver.cpp:228] Iteration 12050, loss = 2.48594
I0811 22:44:07.592483 26953 solver.cpp:244]     Train net output #0: loss = 2.48594 (* 1 = 2.48594 loss)
I0811 22:44:08.996891 26953 sgd_solver.cpp:106] Iteration 12050, lr = 0.01
I0811 22:44:27.387394 26953 solver.cpp:228] Iteration 12060, loss = 2.51221
I0811 22:44:27.387579 26953 solver.cpp:244]     Train net output #0: loss = 2.51221 (* 1 = 2.51221 loss)
I0811 22:44:28.782840 26953 sgd_solver.cpp:106] Iteration 12060, lr = 0.01
I0811 22:44:47.177531 26953 solver.cpp:228] Iteration 12070, loss = 2.50154
I0811 22:44:47.177599 26953 solver.cpp:244]     Train net output #0: loss = 2.50154 (* 1 = 2.50154 loss)
I0811 22:44:48.592020 26953 sgd_solver.cpp:106] Iteration 12070, lr = 0.01
I0811 22:45:06.945341 26953 solver.cpp:228] Iteration 12080, loss = 2.34782
I0811 22:45:06.945545 26953 solver.cpp:244]     Train net output #0: loss = 2.34782 (* 1 = 2.34782 loss)
I0811 22:45:08.344252 26953 sgd_solver.cpp:106] Iteration 12080, lr = 0.01
I0811 22:45:26.720791 26953 solver.cpp:228] Iteration 12090, loss = 2.322
I0811 22:45:26.720862 26953 solver.cpp:244]     Train net output #0: loss = 2.322 (* 1 = 2.322 loss)
I0811 22:45:28.128947 26953 sgd_solver.cpp:106] Iteration 12090, lr = 0.01
I0811 22:45:45.980223 26953 solver.cpp:337] Iteration 12100, Testing net (#0)
I0811 22:45:46.576747 26953 solver.cpp:404]     Test net output #0: accuracy = 0.438
I0811 22:45:46.576814 26953 solver.cpp:404]     Test net output #1: loss = 2.48778 (* 1 = 2.48778 loss)
I0811 22:45:47.142570 26953 solver.cpp:228] Iteration 12100, loss = 2.34802
I0811 22:45:47.142642 26953 solver.cpp:244]     Train net output #0: loss = 2.34802 (* 1 = 2.34802 loss)
I0811 22:45:48.528492 26953 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0811 22:46:06.949662 26953 solver.cpp:228] Iteration 12110, loss = 2.32444
I0811 22:46:06.949730 26953 solver.cpp:244]     Train net output #0: loss = 2.32444 (* 1 = 2.32444 loss)
I0811 22:46:08.343027 26953 sgd_solver.cpp:106] Iteration 12110, lr = 0.01
I0811 22:46:26.734736 26953 solver.cpp:228] Iteration 12120, loss = 2.29821
I0811 22:46:26.734961 26953 solver.cpp:244]     Train net output #0: loss = 2.29821 (* 1 = 2.29821 loss)
I0811 22:46:28.130700 26953 sgd_solver.cpp:106] Iteration 12120, lr = 0.01
I0811 22:46:46.516170 26953 solver.cpp:228] Iteration 12130, loss = 2.38678
I0811 22:46:46.516227 26953 solver.cpp:244]     Train net output #0: loss = 2.38678 (* 1 = 2.38678 loss)
I0811 22:46:47.924420 26953 sgd_solver.cpp:106] Iteration 12130, lr = 0.01
I0811 22:47:06.274317 26953 solver.cpp:228] Iteration 12140, loss = 2.43458
I0811 22:47:06.274566 26953 solver.cpp:244]     Train net output #0: loss = 2.43458 (* 1 = 2.43458 loss)
I0811 22:47:07.672832 26953 sgd_solver.cpp:106] Iteration 12140, lr = 0.01
I0811 22:47:26.098023 26953 solver.cpp:228] Iteration 12150, loss = 2.47004
I0811 22:47:26.098089 26953 solver.cpp:244]     Train net output #0: loss = 2.47004 (* 1 = 2.47004 loss)
I0811 22:47:27.500277 26953 sgd_solver.cpp:106] Iteration 12150, lr = 0.01
I0811 22:47:45.857590 26953 solver.cpp:228] Iteration 12160, loss = 2.43884
I0811 22:47:45.857822 26953 solver.cpp:244]     Train net output #0: loss = 2.43884 (* 1 = 2.43884 loss)
I0811 22:47:47.264658 26953 sgd_solver.cpp:106] Iteration 12160, lr = 0.01
I0811 22:48:05.630316 26953 solver.cpp:228] Iteration 12170, loss = 2.31921
I0811 22:48:05.630385 26953 solver.cpp:244]     Train net output #0: loss = 2.31921 (* 1 = 2.31921 loss)
I0811 22:48:07.036178 26953 sgd_solver.cpp:106] Iteration 12170, lr = 0.01
I0811 22:48:25.395014 26953 solver.cpp:228] Iteration 12180, loss = 2.37926
I0811 22:48:25.395238 26953 solver.cpp:244]     Train net output #0: loss = 2.37926 (* 1 = 2.37926 loss)
I0811 22:48:26.792377 26953 sgd_solver.cpp:106] Iteration 12180, lr = 0.01
I0811 22:48:45.216526 26953 solver.cpp:228] Iteration 12190, loss = 2.51511
I0811 22:48:45.216598 26953 solver.cpp:244]     Train net output #0: loss = 2.51511 (* 1 = 2.51511 loss)
I0811 22:48:46.620154 26953 sgd_solver.cpp:106] Iteration 12190, lr = 0.01
I0811 22:49:04.411911 26953 solver.cpp:337] Iteration 12200, Testing net (#0)
I0811 22:49:05.006495 26953 solver.cpp:404]     Test net output #0: accuracy = 0.452
I0811 22:49:05.006564 26953 solver.cpp:404]     Test net output #1: loss = 2.31661 (* 1 = 2.31661 loss)
I0811 22:49:05.574970 26953 solver.cpp:228] Iteration 12200, loss = 2.51905
I0811 22:49:05.575062 26953 solver.cpp:244]     Train net output #0: loss = 2.51905 (* 1 = 2.51905 loss)
I0811 22:49:06.941212 26953 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0811 22:49:25.337015 26953 solver.cpp:228] Iteration 12210, loss = 2.41229
I0811 22:49:25.337087 26953 solver.cpp:244]     Train net output #0: loss = 2.41229 (* 1 = 2.41229 loss)
I0811 22:49:26.744354 26953 sgd_solver.cpp:106] Iteration 12210, lr = 0.01
I0811 22:49:45.130807 26953 solver.cpp:228] Iteration 12220, loss = 2.37629
I0811 22:49:45.131007 26953 solver.cpp:244]     Train net output #0: loss = 2.37629 (* 1 = 2.37629 loss)
I0811 22:49:46.544685 26953 sgd_solver.cpp:106] Iteration 12220, lr = 0.01
I0811 22:50:04.965375 26953 solver.cpp:228] Iteration 12230, loss = 2.38383
I0811 22:50:04.965456 26953 solver.cpp:244]     Train net output #0: loss = 2.38383 (* 1 = 2.38383 loss)
I0811 22:50:06.371661 26953 sgd_solver.cpp:106] Iteration 12230, lr = 0.01
I0811 22:50:24.787967 26953 solver.cpp:228] Iteration 12240, loss = 2.50201
I0811 22:50:24.788202 26953 solver.cpp:244]     Train net output #0: loss = 2.50201 (* 1 = 2.50201 loss)
I0811 22:50:26.196912 26953 sgd_solver.cpp:106] Iteration 12240, lr = 0.01
I0811 22:50:44.565443 26953 solver.cpp:228] Iteration 12250, loss = 2.24059
I0811 22:50:44.565507 26953 solver.cpp:244]     Train net output #0: loss = 2.24059 (* 1 = 2.24059 loss)
I0811 22:50:45.959966 26953 sgd_solver.cpp:106] Iteration 12250, lr = 0.01
I0811 22:51:04.418440 26953 solver.cpp:228] Iteration 12260, loss = 2.35478
I0811 22:51:04.418730 26953 solver.cpp:244]     Train net output #0: loss = 2.35478 (* 1 = 2.35478 loss)
I0811 22:51:05.840430 26953 sgd_solver.cpp:106] Iteration 12260, lr = 0.01
I0811 22:51:24.185348 26953 solver.cpp:228] Iteration 12270, loss = 2.33498
I0811 22:51:24.185426 26953 solver.cpp:244]     Train net output #0: loss = 2.33498 (* 1 = 2.33498 loss)
I0811 22:51:25.589598 26953 sgd_solver.cpp:106] Iteration 12270, lr = 0.01
I0811 22:51:43.985213 26953 solver.cpp:228] Iteration 12280, loss = 2.41916
I0811 22:51:43.985474 26953 solver.cpp:244]     Train net output #0: loss = 2.41916 (* 1 = 2.41916 loss)
I0811 22:51:45.384286 26953 sgd_solver.cpp:106] Iteration 12280, lr = 0.01
I0811 22:52:03.763778 26953 solver.cpp:228] Iteration 12290, loss = 2.3776
I0811 22:52:03.763839 26953 solver.cpp:244]     Train net output #0: loss = 2.3776 (* 1 = 2.3776 loss)
I0811 22:52:05.175211 26953 sgd_solver.cpp:106] Iteration 12290, lr = 0.01
I0811 22:52:22.993146 26953 solver.cpp:337] Iteration 12300, Testing net (#0)
I0811 22:52:23.579888 26953 solver.cpp:404]     Test net output #0: accuracy = 0.442
I0811 22:52:23.579953 26953 solver.cpp:404]     Test net output #1: loss = 2.51893 (* 1 = 2.51893 loss)
I0811 22:52:24.149123 26953 solver.cpp:228] Iteration 12300, loss = 2.36982
I0811 22:52:24.149204 26953 solver.cpp:244]     Train net output #0: loss = 2.36982 (* 1 = 2.36982 loss)
I0811 22:52:25.521010 26953 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0811 22:52:43.935966 26953 solver.cpp:228] Iteration 12310, loss = 2.44667
I0811 22:52:43.936045 26953 solver.cpp:244]     Train net output #0: loss = 2.44667 (* 1 = 2.44667 loss)
I0811 22:52:45.334870 26953 sgd_solver.cpp:106] Iteration 12310, lr = 0.01
I0811 22:53:03.708842 26953 solver.cpp:228] Iteration 12320, loss = 2.34428
I0811 22:53:03.709086 26953 solver.cpp:244]     Train net output #0: loss = 2.34428 (* 1 = 2.34428 loss)
I0811 22:53:05.133419 26953 sgd_solver.cpp:106] Iteration 12320, lr = 0.01
I0811 22:53:23.494664 26953 solver.cpp:228] Iteration 12330, loss = 2.39593
I0811 22:53:23.494735 26953 solver.cpp:244]     Train net output #0: loss = 2.39593 (* 1 = 2.39593 loss)
I0811 22:53:24.901365 26953 sgd_solver.cpp:106] Iteration 12330, lr = 0.01
I0811 22:53:43.360430 26953 solver.cpp:228] Iteration 12340, loss = 2.42893
I0811 22:53:43.360589 26953 solver.cpp:244]     Train net output #0: loss = 2.42893 (* 1 = 2.42893 loss)
I0811 22:53:44.767099 26953 sgd_solver.cpp:106] Iteration 12340, lr = 0.01
I0811 22:54:03.120605 26953 solver.cpp:228] Iteration 12350, loss = 2.41579
I0811 22:54:03.120682 26953 solver.cpp:244]     Train net output #0: loss = 2.41579 (* 1 = 2.41579 loss)
I0811 22:54:04.532698 26953 sgd_solver.cpp:106] Iteration 12350, lr = 0.01
I0811 22:54:22.907027 26953 solver.cpp:228] Iteration 12360, loss = 2.3981
I0811 22:54:22.907250 26953 solver.cpp:244]     Train net output #0: loss = 2.3981 (* 1 = 2.3981 loss)
I0811 22:54:24.315722 26953 sgd_solver.cpp:106] Iteration 12360, lr = 0.01
I0811 22:54:42.727531 26953 solver.cpp:228] Iteration 12370, loss = 2.3081
I0811 22:54:42.727599 26953 solver.cpp:244]     Train net output #0: loss = 2.3081 (* 1 = 2.3081 loss)
I0811 22:54:44.148368 26953 sgd_solver.cpp:106] Iteration 12370, lr = 0.01
I0811 22:55:02.499543 26953 solver.cpp:228] Iteration 12380, loss = 2.50827
I0811 22:55:02.499778 26953 solver.cpp:244]     Train net output #0: loss = 2.50827 (* 1 = 2.50827 loss)
I0811 22:55:03.905596 26953 sgd_solver.cpp:106] Iteration 12380, lr = 0.01
I0811 22:55:22.316334 26953 solver.cpp:228] Iteration 12390, loss = 2.59247
I0811 22:55:22.316401 26953 solver.cpp:244]     Train net output #0: loss = 2.59247 (* 1 = 2.59247 loss)
I0811 22:55:23.712729 26953 sgd_solver.cpp:106] Iteration 12390, lr = 0.01
I0811 22:55:41.516810 26953 solver.cpp:337] Iteration 12400, Testing net (#0)
I0811 22:55:42.109458 26953 solver.cpp:404]     Test net output #0: accuracy = 0.44
I0811 22:55:42.109536 26953 solver.cpp:404]     Test net output #1: loss = 2.39861 (* 1 = 2.39861 loss)
I0811 22:55:42.679169 26953 solver.cpp:228] Iteration 12400, loss = 2.3145
I0811 22:55:42.679273 26953 solver.cpp:244]     Train net output #0: loss = 2.3145 (* 1 = 2.3145 loss)
I0811 22:55:44.062496 26953 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0811 22:56:02.431803 26953 solver.cpp:228] Iteration 12410, loss = 2.44958
I0811 22:56:02.431862 26953 solver.cpp:244]     Train net output #0: loss = 2.44958 (* 1 = 2.44958 loss)
I0811 22:56:03.830549 26953 sgd_solver.cpp:106] Iteration 12410, lr = 0.01
I0811 22:56:22.213366 26953 solver.cpp:228] Iteration 12420, loss = 2.46226
I0811 22:56:22.213527 26953 solver.cpp:244]     Train net output #0: loss = 2.46226 (* 1 = 2.46226 loss)
I0811 22:56:23.623224 26953 sgd_solver.cpp:106] Iteration 12420, lr = 0.01
I0811 22:56:41.985231 26953 solver.cpp:228] Iteration 12430, loss = 2.34821
I0811 22:56:41.985308 26953 solver.cpp:244]     Train net output #0: loss = 2.34821 (* 1 = 2.34821 loss)
I0811 22:56:43.391579 26953 sgd_solver.cpp:106] Iteration 12430, lr = 0.01
I0811 22:57:01.768851 26953 solver.cpp:228] Iteration 12440, loss = 2.27888
I0811 22:57:01.768999 26953 solver.cpp:244]     Train net output #0: loss = 2.27888 (* 1 = 2.27888 loss)
I0811 22:57:03.172580 26953 sgd_solver.cpp:106] Iteration 12440, lr = 0.01
I0811 22:57:21.561128 26953 solver.cpp:228] Iteration 12450, loss = 2.38903
I0811 22:57:21.561206 26953 solver.cpp:244]     Train net output #0: loss = 2.38903 (* 1 = 2.38903 loss)
I0811 22:57:22.966120 26953 sgd_solver.cpp:106] Iteration 12450, lr = 0.01
I0811 22:57:41.392540 26953 solver.cpp:228] Iteration 12460, loss = 2.55497
I0811 22:57:41.392746 26953 solver.cpp:244]     Train net output #0: loss = 2.55497 (* 1 = 2.55497 loss)
I0811 22:57:42.798638 26953 sgd_solver.cpp:106] Iteration 12460, lr = 0.01
I0811 22:58:01.155226 26953 solver.cpp:228] Iteration 12470, loss = 2.3913
I0811 22:58:01.155292 26953 solver.cpp:244]     Train net output #0: loss = 2.3913 (* 1 = 2.3913 loss)
I0811 22:58:02.573854 26953 sgd_solver.cpp:106] Iteration 12470, lr = 0.01
I0811 22:58:20.950376 26953 solver.cpp:228] Iteration 12480, loss = 2.40189
I0811 22:58:20.950593 26953 solver.cpp:244]     Train net output #0: loss = 2.40189 (* 1 = 2.40189 loss)
I0811 22:58:22.345284 26953 sgd_solver.cpp:106] Iteration 12480, lr = 0.01
I0811 22:58:40.743798 26953 solver.cpp:228] Iteration 12490, loss = 2.42017
I0811 22:58:40.743867 26953 solver.cpp:244]     Train net output #0: loss = 2.42017 (* 1 = 2.42017 loss)
I0811 22:58:42.147560 26953 sgd_solver.cpp:106] Iteration 12490, lr = 0.01
I0811 22:58:59.931006 26953 solver.cpp:337] Iteration 12500, Testing net (#0)
I0811 22:59:00.522419 26953 solver.cpp:404]     Test net output #0: accuracy = 0.442
I0811 22:59:00.522493 26953 solver.cpp:404]     Test net output #1: loss = 2.43248 (* 1 = 2.43248 loss)
I0811 22:59:01.092249 26953 solver.cpp:228] Iteration 12500, loss = 2.23717
I0811 22:59:01.092350 26953 solver.cpp:244]     Train net output #0: loss = 2.23717 (* 1 = 2.23717 loss)
I0811 22:59:02.465214 26953 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0811 22:59:20.806396 26953 solver.cpp:228] Iteration 12510, loss = 2.45333
I0811 22:59:20.806457 26953 solver.cpp:244]     Train net output #0: loss = 2.45333 (* 1 = 2.45333 loss)
I0811 22:59:22.203933 26953 sgd_solver.cpp:106] Iteration 12510, lr = 0.01
I0811 22:59:40.621704 26953 solver.cpp:228] Iteration 12520, loss = 2.23844
I0811 22:59:40.621870 26953 solver.cpp:244]     Train net output #0: loss = 2.23844 (* 1 = 2.23844 loss)
I0811 22:59:42.039731 26953 sgd_solver.cpp:106] Iteration 12520, lr = 0.01
I0811 23:00:00.411891 26953 solver.cpp:228] Iteration 12530, loss = 2.44839
I0811 23:00:00.411968 26953 solver.cpp:244]     Train net output #0: loss = 2.44839 (* 1 = 2.44839 loss)
I0811 23:00:01.823644 26953 sgd_solver.cpp:106] Iteration 12530, lr = 0.01
I0811 23:00:20.233700 26953 solver.cpp:228] Iteration 12540, loss = 2.56838
I0811 23:00:20.233957 26953 solver.cpp:244]     Train net output #0: loss = 2.56838 (* 1 = 2.56838 loss)
I0811 23:00:21.631296 26953 sgd_solver.cpp:106] Iteration 12540, lr = 0.01
I0811 23:00:40.069355 26953 solver.cpp:228] Iteration 12550, loss = 2.27539
I0811 23:00:40.069430 26953 solver.cpp:244]     Train net output #0: loss = 2.27539 (* 1 = 2.27539 loss)
I0811 23:00:41.476645 26953 sgd_solver.cpp:106] Iteration 12550, lr = 0.01
I0811 23:00:59.838671 26953 solver.cpp:228] Iteration 12560, loss = 2.54416
I0811 23:00:59.838902 26953 solver.cpp:244]     Train net output #0: loss = 2.54416 (* 1 = 2.54416 loss)
I0811 23:01:01.242177 26953 sgd_solver.cpp:106] Iteration 12560, lr = 0.01
I0811 23:01:19.688947 26953 solver.cpp:228] Iteration 12570, loss = 2.49572
I0811 23:01:19.689018 26953 solver.cpp:244]     Train net output #0: loss = 2.49572 (* 1 = 2.49572 loss)
I0811 23:01:21.082129 26953 sgd_solver.cpp:106] Iteration 12570, lr = 0.01
I0811 23:01:39.434658 26953 solver.cpp:228] Iteration 12580, loss = 2.41081
I0811 23:01:39.434890 26953 solver.cpp:244]     Train net output #0: loss = 2.41081 (* 1 = 2.41081 loss)
I0811 23:01:40.844940 26953 sgd_solver.cpp:106] Iteration 12580, lr = 0.01
I0811 23:01:59.196564 26953 solver.cpp:228] Iteration 12590, loss = 2.44981
I0811 23:01:59.196636 26953 solver.cpp:244]     Train net output #0: loss = 2.44981 (* 1 = 2.44981 loss)
I0811 23:02:00.610590 26953 sgd_solver.cpp:106] Iteration 12590, lr = 0.01
I0811 23:02:18.411885 26953 solver.cpp:337] Iteration 12600, Testing net (#0)
I0811 23:02:19.005317 26953 solver.cpp:404]     Test net output #0: accuracy = 0.454
I0811 23:02:19.005408 26953 solver.cpp:404]     Test net output #1: loss = 2.4395 (* 1 = 2.4395 loss)
I0811 23:02:19.584069 26953 solver.cpp:228] Iteration 12600, loss = 2.41149
I0811 23:02:19.584164 26953 solver.cpp:244]     Train net output #0: loss = 2.41149 (* 1 = 2.41149 loss)
I0811 23:02:20.956400 26953 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0811 23:02:39.331059 26953 solver.cpp:228] Iteration 12610, loss = 2.44263
I0811 23:02:39.331156 26953 solver.cpp:244]     Train net output #0: loss = 2.44263 (* 1 = 2.44263 loss)
I0811 23:02:40.733844 26953 sgd_solver.cpp:106] Iteration 12610, lr = 0.01
I0811 23:02:59.079318 26953 solver.cpp:228] Iteration 12620, loss = 2.37637
I0811 23:02:59.079530 26953 solver.cpp:244]     Train net output #0: loss = 2.37637 (* 1 = 2.37637 loss)
I0811 23:03:00.483666 26953 sgd_solver.cpp:106] Iteration 12620, lr = 0.01
I0811 23:03:18.923871 26953 solver.cpp:228] Iteration 12630, loss = 2.28007
I0811 23:03:18.923936 26953 solver.cpp:244]     Train net output #0: loss = 2.28007 (* 1 = 2.28007 loss)
I0811 23:03:20.325604 26953 sgd_solver.cpp:106] Iteration 12630, lr = 0.01
I0811 23:03:38.696688 26953 solver.cpp:228] Iteration 12640, loss = 2.35662
I0811 23:03:38.696820 26953 solver.cpp:244]     Train net output #0: loss = 2.35662 (* 1 = 2.35662 loss)
I0811 23:03:40.102645 26953 sgd_solver.cpp:106] Iteration 12640, lr = 0.01
I0811 23:03:58.529100 26953 solver.cpp:228] Iteration 12650, loss = 2.40951
I0811 23:03:58.529199 26953 solver.cpp:244]     Train net output #0: loss = 2.40951 (* 1 = 2.40951 loss)
I0811 23:03:59.927309 26953 sgd_solver.cpp:106] Iteration 12650, lr = 0.01
I0811 23:04:18.383055 26953 solver.cpp:228] Iteration 12660, loss = 2.45005
I0811 23:04:18.383268 26953 solver.cpp:244]     Train net output #0: loss = 2.45005 (* 1 = 2.45005 loss)
I0811 23:04:19.781726 26953 sgd_solver.cpp:106] Iteration 12660, lr = 0.01
I0811 23:04:38.157505 26953 solver.cpp:228] Iteration 12670, loss = 2.42011
I0811 23:04:38.157568 26953 solver.cpp:244]     Train net output #0: loss = 2.42011 (* 1 = 2.42011 loss)
I0811 23:04:39.554803 26953 sgd_solver.cpp:106] Iteration 12670, lr = 0.01
I0811 23:04:57.930276 26953 solver.cpp:228] Iteration 12680, loss = 2.32917
I0811 23:04:57.930495 26953 solver.cpp:244]     Train net output #0: loss = 2.32917 (* 1 = 2.32917 loss)
I0811 23:04:59.329965 26953 sgd_solver.cpp:106] Iteration 12680, lr = 0.01
I0811 23:05:17.754976 26953 solver.cpp:228] Iteration 12690, loss = 2.43986
I0811 23:05:17.755046 26953 solver.cpp:244]     Train net output #0: loss = 2.43986 (* 1 = 2.43986 loss)
I0811 23:05:19.165042 26953 sgd_solver.cpp:106] Iteration 12690, lr = 0.01
I0811 23:05:36.946513 26953 solver.cpp:337] Iteration 12700, Testing net (#0)
I0811 23:05:37.538602 26953 solver.cpp:404]     Test net output #0: accuracy = 0.464
I0811 23:05:37.538676 26953 solver.cpp:404]     Test net output #1: loss = 2.48673 (* 1 = 2.48673 loss)
I0811 23:05:38.114408 26953 solver.cpp:228] Iteration 12700, loss = 2.36664
I0811 23:05:38.114501 26953 solver.cpp:244]     Train net output #0: loss = 2.36664 (* 1 = 2.36664 loss)
I0811 23:05:39.479985 26953 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0811 23:05:57.860641 26953 solver.cpp:228] Iteration 12710, loss = 2.51595
I0811 23:05:57.860709 26953 solver.cpp:244]     Train net output #0: loss = 2.51595 (* 1 = 2.51595 loss)
I0811 23:05:59.250953 26953 sgd_solver.cpp:106] Iteration 12710, lr = 0.01
I0811 23:06:17.619266 26953 solver.cpp:228] Iteration 12720, loss = 2.4938
I0811 23:06:17.619499 26953 solver.cpp:244]     Train net output #0: loss = 2.4938 (* 1 = 2.4938 loss)
I0811 23:06:19.035256 26953 sgd_solver.cpp:106] Iteration 12720, lr = 0.01
I0811 23:06:37.492413 26953 solver.cpp:228] Iteration 12730, loss = 2.31015
I0811 23:06:37.492482 26953 solver.cpp:244]     Train net output #0: loss = 2.31015 (* 1 = 2.31015 loss)
I0811 23:06:38.884011 26953 sgd_solver.cpp:106] Iteration 12730, lr = 0.01
I0811 23:06:57.289501 26953 solver.cpp:228] Iteration 12740, loss = 2.38655
I0811 23:06:57.289750 26953 solver.cpp:244]     Train net output #0: loss = 2.38655 (* 1 = 2.38655 loss)
I0811 23:06:58.687727 26953 sgd_solver.cpp:106] Iteration 12740, lr = 0.01
I0811 23:07:17.049667 26953 solver.cpp:228] Iteration 12750, loss = 2.53363
I0811 23:07:17.049739 26953 solver.cpp:244]     Train net output #0: loss = 2.53363 (* 1 = 2.53363 loss)
I0811 23:07:18.453408 26953 sgd_solver.cpp:106] Iteration 12750, lr = 0.01
I0811 23:07:36.881448 26953 solver.cpp:228] Iteration 12760, loss = 2.25449
I0811 23:07:36.881657 26953 solver.cpp:244]     Train net output #0: loss = 2.25449 (* 1 = 2.25449 loss)
I0811 23:07:38.278899 26953 sgd_solver.cpp:106] Iteration 12760, lr = 0.01
I0811 23:07:56.678567 26953 solver.cpp:228] Iteration 12770, loss = 2.51109
I0811 23:07:56.678639 26953 solver.cpp:244]     Train net output #0: loss = 2.51109 (* 1 = 2.51109 loss)
I0811 23:07:58.090270 26953 sgd_solver.cpp:106] Iteration 12770, lr = 0.01
I0811 23:08:16.464243 26953 solver.cpp:228] Iteration 12780, loss = 2.32657
I0811 23:08:16.464440 26953 solver.cpp:244]     Train net output #0: loss = 2.32657 (* 1 = 2.32657 loss)
I0811 23:08:17.866847 26953 sgd_solver.cpp:106] Iteration 12780, lr = 0.01
I0811 23:08:36.262820 26953 solver.cpp:228] Iteration 12790, loss = 2.47076
I0811 23:08:36.262889 26953 solver.cpp:244]     Train net output #0: loss = 2.47076 (* 1 = 2.47076 loss)
I0811 23:08:37.662981 26953 sgd_solver.cpp:106] Iteration 12790, lr = 0.01
I0811 23:08:55.477761 26953 solver.cpp:337] Iteration 12800, Testing net (#0)
I0811 23:08:56.072286 26953 solver.cpp:404]     Test net output #0: accuracy = 0.438
I0811 23:08:56.072360 26953 solver.cpp:404]     Test net output #1: loss = 2.52578 (* 1 = 2.52578 loss)
I0811 23:08:56.635519 26953 solver.cpp:228] Iteration 12800, loss = 2.26546
I0811 23:08:56.635589 26953 solver.cpp:244]     Train net output #0: loss = 2.26546 (* 1 = 2.26546 loss)
I0811 23:08:58.016746 26953 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0811 23:09:16.479802 26953 solver.cpp:228] Iteration 12810, loss = 2.36069
I0811 23:09:16.479872 26953 solver.cpp:244]     Train net output #0: loss = 2.36069 (* 1 = 2.36069 loss)
I0811 23:09:17.898849 26953 sgd_solver.cpp:106] Iteration 12810, lr = 0.01
I0811 23:09:36.264346 26953 solver.cpp:228] Iteration 12820, loss = 2.33316
I0811 23:09:36.264508 26953 solver.cpp:244]     Train net output #0: loss = 2.33316 (* 1 = 2.33316 loss)
I0811 23:09:37.667647 26953 sgd_solver.cpp:106] Iteration 12820, lr = 0.01
I0811 23:09:56.065176 26953 solver.cpp:228] Iteration 12830, loss = 2.29013
I0811 23:09:56.065249 26953 solver.cpp:244]     Train net output #0: loss = 2.29013 (* 1 = 2.29013 loss)
I0811 23:09:57.459004 26953 sgd_solver.cpp:106] Iteration 12830, lr = 0.01
I0811 23:10:15.821432 26953 solver.cpp:228] Iteration 12840, loss = 2.3715
I0811 23:10:15.821671 26953 solver.cpp:244]     Train net output #0: loss = 2.3715 (* 1 = 2.3715 loss)
I0811 23:10:17.232388 26953 sgd_solver.cpp:106] Iteration 12840, lr = 0.01
I0811 23:10:35.632318 26953 solver.cpp:228] Iteration 12850, loss = 2.35188
I0811 23:10:35.632397 26953 solver.cpp:244]     Train net output #0: loss = 2.35188 (* 1 = 2.35188 loss)
I0811 23:10:37.036690 26953 sgd_solver.cpp:106] Iteration 12850, lr = 0.01
I0811 23:10:55.388120 26953 solver.cpp:228] Iteration 12860, loss = 2.14903
I0811 23:10:55.388293 26953 solver.cpp:244]     Train net output #0: loss = 2.14903 (* 1 = 2.14903 loss)
I0811 23:10:56.783638 26953 sgd_solver.cpp:106] Iteration 12860, lr = 0.01
I0811 23:11:15.189048 26953 solver.cpp:228] Iteration 12870, loss = 2.42544
I0811 23:11:15.189127 26953 solver.cpp:244]     Train net output #0: loss = 2.42544 (* 1 = 2.42544 loss)
I0811 23:11:16.596546 26953 sgd_solver.cpp:106] Iteration 12870, lr = 0.01
I0811 23:11:34.993819 26953 solver.cpp:228] Iteration 12880, loss = 2.17704
I0811 23:11:34.994050 26953 solver.cpp:244]     Train net output #0: loss = 2.17704 (* 1 = 2.17704 loss)
I0811 23:11:36.402560 26953 sgd_solver.cpp:106] Iteration 12880, lr = 0.01
I0811 23:11:54.751653 26953 solver.cpp:228] Iteration 12890, loss = 2.47643
I0811 23:11:54.751731 26953 solver.cpp:244]     Train net output #0: loss = 2.47643 (* 1 = 2.47643 loss)
I0811 23:11:56.170743 26953 sgd_solver.cpp:106] Iteration 12890, lr = 0.01
I0811 23:12:14.021319 26953 solver.cpp:337] Iteration 12900, Testing net (#0)
I0811 23:12:14.614728 26953 solver.cpp:404]     Test net output #0: accuracy = 0.438
I0811 23:12:14.614800 26953 solver.cpp:404]     Test net output #1: loss = 2.52351 (* 1 = 2.52351 loss)
I0811 23:12:15.210774 26953 solver.cpp:228] Iteration 12900, loss = 2.4521
I0811 23:12:15.210836 26953 solver.cpp:244]     Train net output #0: loss = 2.4521 (* 1 = 2.4521 loss)
I0811 23:12:16.569725 26953 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0811 23:12:34.940387 26953 solver.cpp:228] Iteration 12910, loss = 2.32149
I0811 23:12:34.940459 26953 solver.cpp:244]     Train net output #0: loss = 2.32149 (* 1 = 2.32149 loss)
I0811 23:12:36.338193 26953 sgd_solver.cpp:106] Iteration 12910, lr = 0.01
I0811 23:12:54.791476 26953 solver.cpp:228] Iteration 12920, loss = 2.3328
I0811 23:12:54.791702 26953 solver.cpp:244]     Train net output #0: loss = 2.3328 (* 1 = 2.3328 loss)
I0811 23:12:56.199887 26953 sgd_solver.cpp:106] Iteration 12920, lr = 0.01
I0811 23:13:14.598584 26953 solver.cpp:228] Iteration 12930, loss = 2.3212
I0811 23:13:14.598651 26953 solver.cpp:244]     Train net output #0: loss = 2.3212 (* 1 = 2.3212 loss)
I0811 23:13:16.004037 26953 sgd_solver.cpp:106] Iteration 12930, lr = 0.01
I0811 23:13:34.389660 26953 solver.cpp:228] Iteration 12940, loss = 2.38242
I0811 23:13:34.389922 26953 solver.cpp:244]     Train net output #0: loss = 2.38242 (* 1 = 2.38242 loss)
I0811 23:13:35.796944 26953 sgd_solver.cpp:106] Iteration 12940, lr = 0.01
I0811 23:13:54.209645 26953 solver.cpp:228] Iteration 12950, loss = 2.35398
I0811 23:13:54.209713 26953 solver.cpp:244]     Train net output #0: loss = 2.35398 (* 1 = 2.35398 loss)
I0811 23:13:55.608445 26953 sgd_solver.cpp:106] Iteration 12950, lr = 0.01
I0811 23:14:13.977298 26953 solver.cpp:228] Iteration 12960, loss = 2.39479
I0811 23:14:13.977566 26953 solver.cpp:244]     Train net output #0: loss = 2.39479 (* 1 = 2.39479 loss)
I0811 23:14:15.383599 26953 sgd_solver.cpp:106] Iteration 12960, lr = 0.01
I0811 23:14:33.750437 26953 solver.cpp:228] Iteration 12970, loss = 2.44071
I0811 23:14:33.750517 26953 solver.cpp:244]     Train net output #0: loss = 2.44071 (* 1 = 2.44071 loss)
I0811 23:14:35.139832 26953 sgd_solver.cpp:106] Iteration 12970, lr = 0.01
I0811 23:14:53.589205 26953 solver.cpp:228] Iteration 12980, loss = 2.45685
I0811 23:14:53.589442 26953 solver.cpp:244]     Train net output #0: loss = 2.45685 (* 1 = 2.45685 loss)
I0811 23:14:54.996244 26953 sgd_solver.cpp:106] Iteration 12980, lr = 0.01
I0811 23:15:13.345291 26953 solver.cpp:228] Iteration 12990, loss = 2.50368
I0811 23:15:13.345352 26953 solver.cpp:244]     Train net output #0: loss = 2.50368 (* 1 = 2.50368 loss)
I0811 23:15:14.757932 26953 sgd_solver.cpp:106] Iteration 12990, lr = 0.01
I0811 23:15:32.599838 26953 solver.cpp:337] Iteration 13000, Testing net (#0)
I0811 23:15:33.188736 26953 solver.cpp:404]     Test net output #0: accuracy = 0.494
I0811 23:15:33.188817 26953 solver.cpp:404]     Test net output #1: loss = 2.29673 (* 1 = 2.29673 loss)
I0811 23:15:33.778108 26953 solver.cpp:228] Iteration 13000, loss = 2.4435
I0811 23:15:33.778200 26953 solver.cpp:244]     Train net output #0: loss = 2.4435 (* 1 = 2.4435 loss)
I0811 23:15:35.147580 26953 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0811 23:15:53.549206 26953 solver.cpp:228] Iteration 13010, loss = 2.2313
I0811 23:15:53.549264 26953 solver.cpp:244]     Train net output #0: loss = 2.2313 (* 1 = 2.2313 loss)
I0811 23:15:54.962558 26953 sgd_solver.cpp:106] Iteration 13010, lr = 0.01
I0811 23:16:13.408145 26953 solver.cpp:228] Iteration 13020, loss = 2.53497
I0811 23:16:13.408399 26953 solver.cpp:244]     Train net output #0: loss = 2.53497 (* 1 = 2.53497 loss)
I0811 23:16:14.805595 26953 sgd_solver.cpp:106] Iteration 13020, lr = 0.01
I0811 23:16:33.171097 26953 solver.cpp:228] Iteration 13030, loss = 2.37941
I0811 23:16:33.171164 26953 solver.cpp:244]     Train net output #0: loss = 2.37941 (* 1 = 2.37941 loss)
I0811 23:16:34.582821 26953 sgd_solver.cpp:106] Iteration 13030, lr = 0.01
I0811 23:16:52.926941 26953 solver.cpp:228] Iteration 13040, loss = 2.45047
I0811 23:16:52.927170 26953 solver.cpp:244]     Train net output #0: loss = 2.45047 (* 1 = 2.45047 loss)
I0811 23:16:54.343773 26953 sgd_solver.cpp:106] Iteration 13040, lr = 0.01
I0811 23:17:12.812717 26953 solver.cpp:228] Iteration 13050, loss = 2.42855
I0811 23:17:12.812779 26953 solver.cpp:244]     Train net output #0: loss = 2.42855 (* 1 = 2.42855 loss)
I0811 23:17:14.203820 26953 sgd_solver.cpp:106] Iteration 13050, lr = 0.01
I0811 23:17:32.550097 26953 solver.cpp:228] Iteration 13060, loss = 2.08282
I0811 23:17:32.550330 26953 solver.cpp:244]     Train net output #0: loss = 2.08282 (* 1 = 2.08282 loss)
I0811 23:17:33.967270 26953 sgd_solver.cpp:106] Iteration 13060, lr = 0.01
I0811 23:17:52.352896 26953 solver.cpp:228] Iteration 13070, loss = 2.27723
I0811 23:17:52.352964 26953 solver.cpp:244]     Train net output #0: loss = 2.27723 (* 1 = 2.27723 loss)
I0811 23:17:53.745255 26953 sgd_solver.cpp:106] Iteration 13070, lr = 0.01
I0811 23:18:12.127777 26953 solver.cpp:228] Iteration 13080, loss = 2.39123
I0811 23:18:12.127913 26953 solver.cpp:244]     Train net output #0: loss = 2.39123 (* 1 = 2.39123 loss)
I0811 23:18:13.517376 26953 sgd_solver.cpp:106] Iteration 13080, lr = 0.01
I0811 23:18:31.918440 26953 solver.cpp:228] Iteration 13090, loss = 2.53455
I0811 23:18:31.918509 26953 solver.cpp:244]     Train net output #0: loss = 2.53455 (* 1 = 2.53455 loss)
I0811 23:18:33.329680 26953 sgd_solver.cpp:106] Iteration 13090, lr = 0.01
I0811 23:18:51.129194 26953 solver.cpp:337] Iteration 13100, Testing net (#0)
I0811 23:18:51.720307 26953 solver.cpp:404]     Test net output #0: accuracy = 0.476
I0811 23:18:51.720381 26953 solver.cpp:404]     Test net output #1: loss = 2.25153 (* 1 = 2.25153 loss)
I0811 23:18:52.291522 26953 solver.cpp:228] Iteration 13100, loss = 2.24535
I0811 23:18:52.291600 26953 solver.cpp:244]     Train net output #0: loss = 2.24535 (* 1 = 2.24535 loss)
I0811 23:18:53.658974 26953 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0811 23:19:12.042798 26953 solver.cpp:228] Iteration 13110, loss = 2.47373
I0811 23:19:12.042866 26953 solver.cpp:244]     Train net output #0: loss = 2.47373 (* 1 = 2.47373 loss)
I0811 23:19:13.443775 26953 sgd_solver.cpp:106] Iteration 13110, lr = 0.01
I0811 23:19:31.817921 26953 solver.cpp:228] Iteration 13120, loss = 2.35859
I0811 23:19:31.818226 26953 solver.cpp:244]     Train net output #0: loss = 2.35859 (* 1 = 2.35859 loss)
I0811 23:19:33.225337 26953 sgd_solver.cpp:106] Iteration 13120, lr = 0.01
I0811 23:19:51.656117 26953 solver.cpp:228] Iteration 13130, loss = 2.33588
I0811 23:19:51.656184 26953 solver.cpp:244]     Train net output #0: loss = 2.33588 (* 1 = 2.33588 loss)
I0811 23:19:53.060230 26953 sgd_solver.cpp:106] Iteration 13130, lr = 0.01
I0811 23:20:11.463361 26953 solver.cpp:228] Iteration 13140, loss = 2.36666
I0811 23:20:11.463515 26953 solver.cpp:244]     Train net output #0: loss = 2.36666 (* 1 = 2.36666 loss)
I0811 23:20:12.867777 26953 sgd_solver.cpp:106] Iteration 13140, lr = 0.01
I0811 23:20:31.237998 26953 solver.cpp:228] Iteration 13150, loss = 2.59157
I0811 23:20:31.238067 26953 solver.cpp:244]     Train net output #0: loss = 2.59157 (* 1 = 2.59157 loss)
I0811 23:20:32.641243 26953 sgd_solver.cpp:106] Iteration 13150, lr = 0.01
I0811 23:20:50.987504 26953 solver.cpp:228] Iteration 13160, loss = 2.35179
I0811 23:20:50.987766 26953 solver.cpp:244]     Train net output #0: loss = 2.35179 (* 1 = 2.35179 loss)
I0811 23:20:52.390739 26953 sgd_solver.cpp:106] Iteration 13160, lr = 0.01
I0811 23:21:10.842088 26953 solver.cpp:228] Iteration 13170, loss = 2.31515
I0811 23:21:10.842154 26953 solver.cpp:244]     Train net output #0: loss = 2.31515 (* 1 = 2.31515 loss)
I0811 23:21:12.270541 26953 sgd_solver.cpp:106] Iteration 13170, lr = 0.01
I0811 23:21:30.622305 26953 solver.cpp:228] Iteration 13180, loss = 2.5379
I0811 23:21:30.622473 26953 solver.cpp:244]     Train net output #0: loss = 2.5379 (* 1 = 2.5379 loss)
I0811 23:21:32.023196 26953 sgd_solver.cpp:106] Iteration 13180, lr = 0.01
I0811 23:21:50.461362 26953 solver.cpp:228] Iteration 13190, loss = 2.43873
I0811 23:21:50.461421 26953 solver.cpp:244]     Train net output #0: loss = 2.43873 (* 1 = 2.43873 loss)
I0811 23:21:51.851766 26953 sgd_solver.cpp:106] Iteration 13190, lr = 0.01
I0811 23:22:09.659571 26953 solver.cpp:337] Iteration 13200, Testing net (#0)
I0811 23:22:10.249979 26953 solver.cpp:404]     Test net output #0: accuracy = 0.476
I0811 23:22:10.250041 26953 solver.cpp:404]     Test net output #1: loss = 2.38696 (* 1 = 2.38696 loss)
I0811 23:22:10.814903 26953 solver.cpp:228] Iteration 13200, loss = 2.31402
I0811 23:22:10.814990 26953 solver.cpp:244]     Train net output #0: loss = 2.31402 (* 1 = 2.31402 loss)
I0811 23:22:12.191274 26953 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0811 23:22:30.613431 26953 solver.cpp:228] Iteration 13210, loss = 2.28014
I0811 23:22:30.613503 26953 solver.cpp:244]     Train net output #0: loss = 2.28014 (* 1 = 2.28014 loss)
I0811 23:22:32.018873 26953 sgd_solver.cpp:106] Iteration 13210, lr = 0.01
I0811 23:22:50.388980 26953 solver.cpp:228] Iteration 13220, loss = 2.27997
I0811 23:22:50.389236 26953 solver.cpp:244]     Train net output #0: loss = 2.27997 (* 1 = 2.27997 loss)
I0811 23:22:51.778036 26953 sgd_solver.cpp:106] Iteration 13220, lr = 0.01
I0811 23:23:10.151558 26953 solver.cpp:228] Iteration 13230, loss = 2.37681
I0811 23:23:10.151641 26953 solver.cpp:244]     Train net output #0: loss = 2.37681 (* 1 = 2.37681 loss)
I0811 23:23:11.567211 26953 sgd_solver.cpp:106] Iteration 13230, lr = 0.01
I0811 23:23:29.974825 26953 solver.cpp:228] Iteration 13240, loss = 2.36151
I0811 23:23:29.975002 26953 solver.cpp:244]     Train net output #0: loss = 2.36151 (* 1 = 2.36151 loss)
I0811 23:23:31.379398 26953 sgd_solver.cpp:106] Iteration 13240, lr = 0.01
I0811 23:23:49.745396 26953 solver.cpp:228] Iteration 13250, loss = 2.3137
I0811 23:23:49.745470 26953 solver.cpp:244]     Train net output #0: loss = 2.3137 (* 1 = 2.3137 loss)
I0811 23:23:51.139173 26953 sgd_solver.cpp:106] Iteration 13250, lr = 0.01
I0811 23:24:09.546210 26953 solver.cpp:228] Iteration 13260, loss = 2.25742
I0811 23:24:09.546466 26953 solver.cpp:244]     Train net output #0: loss = 2.25742 (* 1 = 2.25742 loss)
I0811 23:24:10.939817 26953 sgd_solver.cpp:106] Iteration 13260, lr = 0.01
I0811 23:24:29.303215 26953 solver.cpp:228] Iteration 13270, loss = 2.34912
I0811 23:24:29.303272 26953 solver.cpp:244]     Train net output #0: loss = 2.34912 (* 1 = 2.34912 loss)
I0811 23:24:30.694064 26953 sgd_solver.cpp:106] Iteration 13270, lr = 0.01
I0811 23:24:49.157575 26953 solver.cpp:228] Iteration 13280, loss = 2.34764
I0811 23:24:49.157766 26953 solver.cpp:244]     Train net output #0: loss = 2.34764 (* 1 = 2.34764 loss)
I0811 23:24:50.575940 26953 sgd_solver.cpp:106] Iteration 13280, lr = 0.01
I0811 23:25:08.922703 26953 solver.cpp:228] Iteration 13290, loss = 2.43526
I0811 23:25:08.922786 26953 solver.cpp:244]     Train net output #0: loss = 2.43526 (* 1 = 2.43526 loss)
I0811 23:25:10.320871 26953 sgd_solver.cpp:106] Iteration 13290, lr = 0.01
I0811 23:25:28.133916 26953 solver.cpp:337] Iteration 13300, Testing net (#0)
I0811 23:25:28.728718 26953 solver.cpp:404]     Test net output #0: accuracy = 0.472
I0811 23:25:28.728793 26953 solver.cpp:404]     Test net output #1: loss = 2.39901 (* 1 = 2.39901 loss)
I0811 23:25:29.319509 26953 solver.cpp:228] Iteration 13300, loss = 2.26064
I0811 23:25:29.319588 26953 solver.cpp:244]     Train net output #0: loss = 2.26064 (* 1 = 2.26064 loss)
I0811 23:25:30.674394 26953 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0811 23:25:49.041889 26953 solver.cpp:228] Iteration 13310, loss = 2.17804
I0811 23:25:49.041960 26953 solver.cpp:244]     Train net output #0: loss = 2.17804 (* 1 = 2.17804 loss)
I0811 23:25:50.456223 26953 sgd_solver.cpp:106] Iteration 13310, lr = 0.01
I0811 23:26:08.805310 26953 solver.cpp:228] Iteration 13320, loss = 2.38385
I0811 23:26:08.805539 26953 solver.cpp:244]     Train net output #0: loss = 2.38385 (* 1 = 2.38385 loss)
I0811 23:26:10.212146 26953 sgd_solver.cpp:106] Iteration 13320, lr = 0.01
I0811 23:26:28.602926 26953 solver.cpp:228] Iteration 13330, loss = 2.15308
I0811 23:26:28.602999 26953 solver.cpp:244]     Train net output #0: loss = 2.15308 (* 1 = 2.15308 loss)
I0811 23:26:29.995349 26953 sgd_solver.cpp:106] Iteration 13330, lr = 0.01
I0811 23:26:48.404021 26953 solver.cpp:228] Iteration 13340, loss = 2.48117
I0811 23:26:48.409293 26953 solver.cpp:244]     Train net output #0: loss = 2.48117 (* 1 = 2.48117 loss)
I0811 23:26:49.804113 26953 sgd_solver.cpp:106] Iteration 13340, lr = 0.01
I0811 23:27:08.168793 26953 solver.cpp:228] Iteration 13350, loss = 2.52282
I0811 23:27:08.168879 26953 solver.cpp:244]     Train net output #0: loss = 2.52282 (* 1 = 2.52282 loss)
I0811 23:27:09.573905 26953 sgd_solver.cpp:106] Iteration 13350, lr = 0.01
I0811 23:27:27.927433 26953 solver.cpp:228] Iteration 13360, loss = 2.37775
I0811 23:27:27.927579 26953 solver.cpp:244]     Train net output #0: loss = 2.37775 (* 1 = 2.37775 loss)
I0811 23:27:29.323431 26953 sgd_solver.cpp:106] Iteration 13360, lr = 0.01
I0811 23:27:47.828079 26953 solver.cpp:228] Iteration 13370, loss = 2.52494
I0811 23:27:47.828191 26953 solver.cpp:244]     Train net output #0: loss = 2.52494 (* 1 = 2.52494 loss)
I0811 23:27:49.236974 26953 sgd_solver.cpp:106] Iteration 13370, lr = 0.01
I0811 23:28:07.600298 26953 solver.cpp:228] Iteration 13380, loss = 2.46653
I0811 23:28:07.600536 26953 solver.cpp:244]     Train net output #0: loss = 2.46653 (* 1 = 2.46653 loss)
I0811 23:28:09.003269 26953 sgd_solver.cpp:106] Iteration 13380, lr = 0.01
I0811 23:28:27.395027 26953 solver.cpp:228] Iteration 13390, loss = 2.42744
I0811 23:28:27.395105 26953 solver.cpp:244]     Train net output #0: loss = 2.42744 (* 1 = 2.42744 loss)
I0811 23:28:28.787314 26953 sgd_solver.cpp:106] Iteration 13390, lr = 0.01
I0811 23:28:46.640154 26953 solver.cpp:337] Iteration 13400, Testing net (#0)
I0811 23:28:47.230448 26953 solver.cpp:404]     Test net output #0: accuracy = 0.498
I0811 23:28:47.230506 26953 solver.cpp:404]     Test net output #1: loss = 2.27425 (* 1 = 2.27425 loss)
I0811 23:28:47.803431 26953 solver.cpp:228] Iteration 13400, loss = 2.2452
I0811 23:28:47.803493 26953 solver.cpp:244]     Train net output #0: loss = 2.2452 (* 1 = 2.2452 loss)
I0811 23:28:49.177611 26953 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0811 23:29:07.597952 26953 solver.cpp:228] Iteration 13410, loss = 2.51642
I0811 23:29:07.598019 26953 solver.cpp:244]     Train net output #0: loss = 2.51642 (* 1 = 2.51642 loss)
I0811 23:29:09.006701 26953 sgd_solver.cpp:106] Iteration 13410, lr = 0.01
I0811 23:29:27.386942 26953 solver.cpp:228] Iteration 13420, loss = 2.24389
I0811 23:29:27.387197 26953 solver.cpp:244]     Train net output #0: loss = 2.24389 (* 1 = 2.24389 loss)
I0811 23:29:28.783464 26953 sgd_solver.cpp:106] Iteration 13420, lr = 0.01
I0811 23:29:47.198211 26953 solver.cpp:228] Iteration 13430, loss = 2.29757
I0811 23:29:47.198309 26953 solver.cpp:244]     Train net output #0: loss = 2.29757 (* 1 = 2.29757 loss)
I0811 23:29:48.598240 26953 sgd_solver.cpp:106] Iteration 13430, lr = 0.01
I0811 23:30:07.048832 26953 solver.cpp:228] Iteration 13440, loss = 2.44067
I0811 23:30:07.049063 26953 solver.cpp:244]     Train net output #0: loss = 2.44067 (* 1 = 2.44067 loss)
I0811 23:30:08.451628 26953 sgd_solver.cpp:106] Iteration 13440, lr = 0.01
I0811 23:30:26.789593 26953 solver.cpp:228] Iteration 13450, loss = 2.39162
I0811 23:30:26.789672 26953 solver.cpp:244]     Train net output #0: loss = 2.39162 (* 1 = 2.39162 loss)
I0811 23:30:28.197829 26953 sgd_solver.cpp:106] Iteration 13450, lr = 0.01
I0811 23:30:46.592959 26953 solver.cpp:228] Iteration 13460, loss = 2.29594
I0811 23:30:46.593109 26953 solver.cpp:244]     Train net output #0: loss = 2.29594 (* 1 = 2.29594 loss)
I0811 23:30:47.999034 26953 sgd_solver.cpp:106] Iteration 13460, lr = 0.01
I0811 23:31:06.409678 26953 solver.cpp:228] Iteration 13470, loss = 2.53193
I0811 23:31:06.409745 26953 solver.cpp:244]     Train net output #0: loss = 2.53193 (* 1 = 2.53193 loss)
I0811 23:31:07.838732 26953 sgd_solver.cpp:106] Iteration 13470, lr = 0.01
I0811 23:31:26.217978 26953 solver.cpp:228] Iteration 13480, loss = 2.37735
I0811 23:31:26.218230 26953 solver.cpp:244]     Train net output #0: loss = 2.37735 (* 1 = 2.37735 loss)
I0811 23:31:27.635409 26953 sgd_solver.cpp:106] Iteration 13480, lr = 0.01
I0811 23:31:46.034987 26953 solver.cpp:228] Iteration 13490, loss = 2.3216
I0811 23:31:46.035048 26953 solver.cpp:244]     Train net output #0: loss = 2.3216 (* 1 = 2.3216 loss)
I0811 23:31:47.437600 26953 sgd_solver.cpp:106] Iteration 13490, lr = 0.01
I0811 23:32:05.225661 26953 solver.cpp:337] Iteration 13500, Testing net (#0)
I0811 23:32:05.814508 26953 solver.cpp:404]     Test net output #0: accuracy = 0.488
I0811 23:32:05.814585 26953 solver.cpp:404]     Test net output #1: loss = 2.32792 (* 1 = 2.32792 loss)
I0811 23:32:06.394469 26953 solver.cpp:228] Iteration 13500, loss = 2.32065
I0811 23:32:06.394561 26953 solver.cpp:244]     Train net output #0: loss = 2.32065 (* 1 = 2.32065 loss)
I0811 23:32:07.769762 26953 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0811 23:32:26.211940 26953 solver.cpp:228] Iteration 13510, loss = 2.41756
I0811 23:32:26.212005 26953 solver.cpp:244]     Train net output #0: loss = 2.41756 (* 1 = 2.41756 loss)
I0811 23:32:27.609635 26953 sgd_solver.cpp:106] Iteration 13510, lr = 0.01
I0811 23:32:45.969110 26953 solver.cpp:228] Iteration 13520, loss = 2.36238
I0811 23:32:45.969352 26953 solver.cpp:244]     Train net output #0: loss = 2.36238 (* 1 = 2.36238 loss)
I0811 23:32:47.357802 26953 sgd_solver.cpp:106] Iteration 13520, lr = 0.01
I0811 23:33:05.727344 26953 solver.cpp:228] Iteration 13530, loss = 2.36758
I0811 23:33:05.727408 26953 solver.cpp:244]     Train net output #0: loss = 2.36758 (* 1 = 2.36758 loss)
I0811 23:33:07.139273 26953 sgd_solver.cpp:106] Iteration 13530, lr = 0.01
I0811 23:33:25.525642 26953 solver.cpp:228] Iteration 13540, loss = 2.26794
I0811 23:33:25.525842 26953 solver.cpp:244]     Train net output #0: loss = 2.26794 (* 1 = 2.26794 loss)
I0811 23:33:26.919700 26953 sgd_solver.cpp:106] Iteration 13540, lr = 0.01
I0811 23:33:45.322690 26953 solver.cpp:228] Iteration 13550, loss = 2.18702
I0811 23:33:45.322772 26953 solver.cpp:244]     Train net output #0: loss = 2.18702 (* 1 = 2.18702 loss)
I0811 23:33:46.715361 26953 sgd_solver.cpp:106] Iteration 13550, lr = 0.01
I0811 23:34:05.091980 26953 solver.cpp:228] Iteration 13560, loss = 2.35125
I0811 23:34:05.092216 26953 solver.cpp:244]     Train net output #0: loss = 2.35125 (* 1 = 2.35125 loss)
I0811 23:34:06.495117 26953 sgd_solver.cpp:106] Iteration 13560, lr = 0.01
I0811 23:34:24.844352 26953 solver.cpp:228] Iteration 13570, loss = 2.49158
I0811 23:34:24.844416 26953 solver.cpp:244]     Train net output #0: loss = 2.49158 (* 1 = 2.49158 loss)
I0811 23:34:26.250125 26953 sgd_solver.cpp:106] Iteration 13570, lr = 0.01
I0811 23:34:44.625357 26953 solver.cpp:228] Iteration 13580, loss = 2.31748
I0811 23:34:44.625620 26953 solver.cpp:244]     Train net output #0: loss = 2.31748 (* 1 = 2.31748 loss)
I0811 23:34:46.036355 26953 sgd_solver.cpp:106] Iteration 13580, lr = 0.01
I0811 23:35:04.415295 26953 solver.cpp:228] Iteration 13590, loss = 2.32158
I0811 23:35:04.415360 26953 solver.cpp:244]     Train net output #0: loss = 2.32158 (* 1 = 2.32158 loss)
I0811 23:35:05.805011 26953 sgd_solver.cpp:106] Iteration 13590, lr = 0.01
I0811 23:35:23.603430 26953 solver.cpp:337] Iteration 13600, Testing net (#0)
I0811 23:35:24.186884 26953 solver.cpp:404]     Test net output #0: accuracy = 0.486
I0811 23:35:24.186945 26953 solver.cpp:404]     Test net output #1: loss = 2.36592 (* 1 = 2.36592 loss)
I0811 23:35:24.768431 26953 solver.cpp:228] Iteration 13600, loss = 2.40661
I0811 23:35:24.768528 26953 solver.cpp:244]     Train net output #0: loss = 2.40661 (* 1 = 2.40661 loss)
I0811 23:35:26.134595 26953 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0811 23:35:44.529450 26953 solver.cpp:228] Iteration 13610, loss = 2.44127
I0811 23:35:44.529551 26953 solver.cpp:244]     Train net output #0: loss = 2.44127 (* 1 = 2.44127 loss)
I0811 23:35:45.925017 26953 sgd_solver.cpp:106] Iteration 13610, lr = 0.01
I0811 23:36:04.348567 26953 solver.cpp:228] Iteration 13620, loss = 2.49475
I0811 23:36:04.348716 26953 solver.cpp:244]     Train net output #0: loss = 2.49475 (* 1 = 2.49475 loss)
I0811 23:36:05.749392 26953 sgd_solver.cpp:106] Iteration 13620, lr = 0.01
I0811 23:36:24.111091 26953 solver.cpp:228] Iteration 13630, loss = 2.40514
I0811 23:36:24.111191 26953 solver.cpp:244]     Train net output #0: loss = 2.40514 (* 1 = 2.40514 loss)
I0811 23:36:25.517132 26953 sgd_solver.cpp:106] Iteration 13630, lr = 0.01
I0811 23:36:43.866392 26953 solver.cpp:228] Iteration 13640, loss = 2.36823
I0811 23:36:43.866631 26953 solver.cpp:244]     Train net output #0: loss = 2.36823 (* 1 = 2.36823 loss)
I0811 23:36:45.249027 26953 sgd_solver.cpp:106] Iteration 13640, lr = 0.01
I0811 23:37:03.675626 26953 solver.cpp:228] Iteration 13650, loss = 2.39338
I0811 23:37:03.675712 26953 solver.cpp:244]     Train net output #0: loss = 2.39338 (* 1 = 2.39338 loss)
I0811 23:37:05.075875 26953 sgd_solver.cpp:106] Iteration 13650, lr = 0.01
I0811 23:37:23.444088 26953 solver.cpp:228] Iteration 13660, loss = 2.44345
I0811 23:37:23.444313 26953 solver.cpp:244]     Train net output #0: loss = 2.44345 (* 1 = 2.44345 loss)
I0811 23:37:24.844878 26953 sgd_solver.cpp:106] Iteration 13660, lr = 0.01
I0811 23:37:43.262884 26953 solver.cpp:228] Iteration 13670, loss = 2.17321
I0811 23:37:43.262958 26953 solver.cpp:244]     Train net output #0: loss = 2.17321 (* 1 = 2.17321 loss)
I0811 23:37:44.663501 26953 sgd_solver.cpp:106] Iteration 13670, lr = 0.01
I0811 23:38:03.039363 26953 solver.cpp:228] Iteration 13680, loss = 2.631
I0811 23:38:03.039605 26953 solver.cpp:244]     Train net output #0: loss = 2.631 (* 1 = 2.631 loss)
I0811 23:38:04.441812 26953 sgd_solver.cpp:106] Iteration 13680, lr = 0.01
I0811 23:38:22.798393 26953 solver.cpp:228] Iteration 13690, loss = 2.52176
I0811 23:38:22.798486 26953 solver.cpp:244]     Train net output #0: loss = 2.52176 (* 1 = 2.52176 loss)
I0811 23:38:24.214404 26953 sgd_solver.cpp:106] Iteration 13690, lr = 0.01
I0811 23:38:42.001500 26953 solver.cpp:337] Iteration 13700, Testing net (#0)
I0811 23:38:42.592346 26953 solver.cpp:404]     Test net output #0: accuracy = 0.51
I0811 23:38:42.592417 26953 solver.cpp:404]     Test net output #1: loss = 2.29452 (* 1 = 2.29452 loss)
I0811 23:38:43.158009 26953 solver.cpp:228] Iteration 13700, loss = 2.36669
I0811 23:38:43.158118 26953 solver.cpp:244]     Train net output #0: loss = 2.36669 (* 1 = 2.36669 loss)
I0811 23:38:44.536463 26953 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0811 23:39:02.948145 26953 solver.cpp:228] Iteration 13710, loss = 2.39702
I0811 23:39:02.948230 26953 solver.cpp:244]     Train net output #0: loss = 2.39702 (* 1 = 2.39702 loss)
I0811 23:39:04.346397 26953 sgd_solver.cpp:106] Iteration 13710, lr = 0.01
I0811 23:39:22.711179 26953 solver.cpp:228] Iteration 13720, loss = 2.55573
I0811 23:39:22.711457 26953 solver.cpp:244]     Train net output #0: loss = 2.55573 (* 1 = 2.55573 loss)
I0811 23:39:24.123819 26953 sgd_solver.cpp:106] Iteration 13720, lr = 0.01
I0811 23:39:42.507073 26953 solver.cpp:228] Iteration 13730, loss = 2.33163
I0811 23:39:42.507139 26953 solver.cpp:244]     Train net output #0: loss = 2.33163 (* 1 = 2.33163 loss)
I0811 23:39:43.907560 26953 sgd_solver.cpp:106] Iteration 13730, lr = 0.01
I0811 23:40:02.304270 26953 solver.cpp:228] Iteration 13740, loss = 2.24198
I0811 23:40:02.304425 26953 solver.cpp:244]     Train net output #0: loss = 2.24198 (* 1 = 2.24198 loss)
I0811 23:40:03.697505 26953 sgd_solver.cpp:106] Iteration 13740, lr = 0.01
I0811 23:40:22.084853 26953 solver.cpp:228] Iteration 13750, loss = 2.38791
I0811 23:40:22.084931 26953 solver.cpp:244]     Train net output #0: loss = 2.38791 (* 1 = 2.38791 loss)
I0811 23:40:23.491641 26953 sgd_solver.cpp:106] Iteration 13750, lr = 0.01
I0811 23:40:41.900427 26953 solver.cpp:228] Iteration 13760, loss = 2.40283
I0811 23:40:41.900588 26953 solver.cpp:244]     Train net output #0: loss = 2.40283 (* 1 = 2.40283 loss)
I0811 23:40:43.299986 26953 sgd_solver.cpp:106] Iteration 13760, lr = 0.01
I0811 23:41:01.651995 26953 solver.cpp:228] Iteration 13770, loss = 2.44132
I0811 23:41:01.652055 26953 solver.cpp:244]     Train net output #0: loss = 2.44132 (* 1 = 2.44132 loss)
I0811 23:41:03.035152 26953 sgd_solver.cpp:106] Iteration 13770, lr = 0.01
I0811 23:41:21.395380 26953 solver.cpp:228] Iteration 13780, loss = 2.29502
I0811 23:41:21.395586 26953 solver.cpp:244]     Train net output #0: loss = 2.29502 (* 1 = 2.29502 loss)
I0811 23:41:22.787456 26953 sgd_solver.cpp:106] Iteration 13780, lr = 0.01
I0811 23:41:41.187301 26953 solver.cpp:228] Iteration 13790, loss = 2.30537
I0811 23:41:41.187382 26953 solver.cpp:244]     Train net output #0: loss = 2.30537 (* 1 = 2.30537 loss)
I0811 23:41:42.587891 26953 sgd_solver.cpp:106] Iteration 13790, lr = 0.01
I0811 23:42:00.383960 26953 solver.cpp:337] Iteration 13800, Testing net (#0)
I0811 23:42:00.976444 26953 solver.cpp:404]     Test net output #0: accuracy = 0.504
I0811 23:42:00.976518 26953 solver.cpp:404]     Test net output #1: loss = 2.3599 (* 1 = 2.3599 loss)
I0811 23:42:01.549304 26953 solver.cpp:228] Iteration 13800, loss = 2.43178
I0811 23:42:01.549398 26953 solver.cpp:244]     Train net output #0: loss = 2.43178 (* 1 = 2.43178 loss)
I0811 23:42:02.914440 26953 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0811 23:42:21.327478 26953 solver.cpp:228] Iteration 13810, loss = 2.31235
I0811 23:42:21.327544 26953 solver.cpp:244]     Train net output #0: loss = 2.31235 (* 1 = 2.31235 loss)
I0811 23:42:22.721138 26953 sgd_solver.cpp:106] Iteration 13810, lr = 0.01
I0811 23:42:41.099501 26953 solver.cpp:228] Iteration 13820, loss = 2.35289
I0811 23:42:41.099721 26953 solver.cpp:244]     Train net output #0: loss = 2.35289 (* 1 = 2.35289 loss)
I0811 23:42:42.498512 26953 sgd_solver.cpp:106] Iteration 13820, lr = 0.01
I0811 23:43:00.898111 26953 solver.cpp:228] Iteration 13830, loss = 2.30997
I0811 23:43:00.898180 26953 solver.cpp:244]     Train net output #0: loss = 2.30997 (* 1 = 2.30997 loss)
I0811 23:43:02.312708 26953 sgd_solver.cpp:106] Iteration 13830, lr = 0.01
I0811 23:43:20.686774 26953 solver.cpp:228] Iteration 13840, loss = 2.46375
I0811 23:43:20.687003 26953 solver.cpp:244]     Train net output #0: loss = 2.46375 (* 1 = 2.46375 loss)
I0811 23:43:22.077138 26953 sgd_solver.cpp:106] Iteration 13840, lr = 0.01
I0811 23:43:40.437149 26953 solver.cpp:228] Iteration 13850, loss = 2.08016
I0811 23:43:40.437237 26953 solver.cpp:244]     Train net output #0: loss = 2.08016 (* 1 = 2.08016 loss)
I0811 23:43:41.855983 26953 sgd_solver.cpp:106] Iteration 13850, lr = 0.01
I0811 23:44:00.224109 26953 solver.cpp:228] Iteration 13860, loss = 2.37145
I0811 23:44:00.224334 26953 solver.cpp:244]     Train net output #0: loss = 2.37145 (* 1 = 2.37145 loss)
I0811 23:44:01.626366 26953 sgd_solver.cpp:106] Iteration 13860, lr = 0.01
I0811 23:44:20.061007 26953 solver.cpp:228] Iteration 13870, loss = 2.28838
I0811 23:44:20.061061 26953 solver.cpp:244]     Train net output #0: loss = 2.28838 (* 1 = 2.28838 loss)
I0811 23:44:21.484354 26953 sgd_solver.cpp:106] Iteration 13870, lr = 0.01
I0811 23:44:39.815562 26953 solver.cpp:228] Iteration 13880, loss = 2.29909
I0811 23:44:39.815721 26953 solver.cpp:244]     Train net output #0: loss = 2.29909 (* 1 = 2.29909 loss)
I0811 23:44:41.236521 26953 sgd_solver.cpp:106] Iteration 13880, lr = 0.01
I0811 23:44:59.642004 26953 solver.cpp:228] Iteration 13890, loss = 2.30276
I0811 23:44:59.642076 26953 solver.cpp:244]     Train net output #0: loss = 2.30276 (* 1 = 2.30276 loss)
I0811 23:45:01.036607 26953 sgd_solver.cpp:106] Iteration 13890, lr = 0.01
I0811 23:45:18.852037 26953 solver.cpp:337] Iteration 13900, Testing net (#0)
I0811 23:45:19.451838 26953 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0811 23:45:19.451910 26953 solver.cpp:404]     Test net output #1: loss = 2.23629 (* 1 = 2.23629 loss)
I0811 23:45:20.019307 26953 solver.cpp:228] Iteration 13900, loss = 2.38909
I0811 23:45:20.019371 26953 solver.cpp:244]     Train net output #0: loss = 2.38909 (* 1 = 2.38909 loss)
I0811 23:45:21.401319 26953 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0811 23:45:39.782757 26953 solver.cpp:228] Iteration 13910, loss = 2.43965
I0811 23:45:39.782829 26953 solver.cpp:244]     Train net output #0: loss = 2.43965 (* 1 = 2.43965 loss)
I0811 23:45:41.167812 26953 sgd_solver.cpp:106] Iteration 13910, lr = 0.01
I0811 23:45:59.566217 26953 solver.cpp:228] Iteration 13920, loss = 2.36889
I0811 23:45:59.566436 26953 solver.cpp:244]     Train net output #0: loss = 2.36889 (* 1 = 2.36889 loss)
I0811 23:46:00.969920 26953 sgd_solver.cpp:106] Iteration 13920, lr = 0.01
I0811 23:46:19.333333 26953 solver.cpp:228] Iteration 13930, loss = 2.38963
I0811 23:46:19.333400 26953 solver.cpp:244]     Train net output #0: loss = 2.38963 (* 1 = 2.38963 loss)
I0811 23:46:20.728823 26953 sgd_solver.cpp:106] Iteration 13930, lr = 0.01
I0811 23:46:39.072082 26953 solver.cpp:228] Iteration 13940, loss = 2.46473
I0811 23:46:39.072221 26953 solver.cpp:244]     Train net output #0: loss = 2.46473 (* 1 = 2.46473 loss)
I0811 23:46:40.474747 26953 sgd_solver.cpp:106] Iteration 13940, lr = 0.01
I0811 23:46:58.847862 26953 solver.cpp:228] Iteration 13950, loss = 2.33312
I0811 23:46:58.847929 26953 solver.cpp:244]     Train net output #0: loss = 2.33312 (* 1 = 2.33312 loss)
I0811 23:47:00.249111 26953 sgd_solver.cpp:106] Iteration 13950, lr = 0.01
I0811 23:47:18.662823 26953 solver.cpp:228] Iteration 13960, loss = 2.24519
I0811 23:47:18.663040 26953 solver.cpp:244]     Train net output #0: loss = 2.24519 (* 1 = 2.24519 loss)
I0811 23:47:20.060931 26953 sgd_solver.cpp:106] Iteration 13960, lr = 0.01
I0811 23:47:38.459990 26953 solver.cpp:228] Iteration 13970, loss = 2.396
I0811 23:47:38.460067 26953 solver.cpp:244]     Train net output #0: loss = 2.396 (* 1 = 2.396 loss)
I0811 23:47:39.884946 26953 sgd_solver.cpp:106] Iteration 13970, lr = 0.01
I0811 23:47:58.240103 26953 solver.cpp:228] Iteration 13980, loss = 2.45316
I0811 23:47:58.240329 26953 solver.cpp:244]     Train net output #0: loss = 2.45316 (* 1 = 2.45316 loss)
I0811 23:47:59.649544 26953 sgd_solver.cpp:106] Iteration 13980, lr = 0.01
I0811 23:48:18.063674 26953 solver.cpp:228] Iteration 13990, loss = 2.32263
I0811 23:48:18.063732 26953 solver.cpp:244]     Train net output #0: loss = 2.32263 (* 1 = 2.32263 loss)
I0811 23:48:19.456514 26953 sgd_solver.cpp:106] Iteration 13990, lr = 0.01
I0811 23:48:37.257087 26953 solver.cpp:337] Iteration 14000, Testing net (#0)
I0811 23:48:37.844511 26953 solver.cpp:404]     Test net output #0: accuracy = 0.452
I0811 23:48:37.844575 26953 solver.cpp:404]     Test net output #1: loss = 2.5463 (* 1 = 2.5463 loss)
I0811 23:48:38.417948 26953 solver.cpp:228] Iteration 14000, loss = 2.32693
I0811 23:48:38.418030 26953 solver.cpp:244]     Train net output #0: loss = 2.32693 (* 1 = 2.32693 loss)
I0811 23:48:39.794257 26953 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0811 23:48:58.192705 26953 solver.cpp:228] Iteration 14010, loss = 2.48064
I0811 23:48:58.192775 26953 solver.cpp:244]     Train net output #0: loss = 2.48064 (* 1 = 2.48064 loss)
I0811 23:48:59.582005 26953 sgd_solver.cpp:106] Iteration 14010, lr = 0.01
I0811 23:49:17.974241 26953 solver.cpp:228] Iteration 14020, loss = 2.37925
I0811 23:49:17.974467 26953 solver.cpp:244]     Train net output #0: loss = 2.37925 (* 1 = 2.37925 loss)
I0811 23:49:19.391412 26953 sgd_solver.cpp:106] Iteration 14020, lr = 0.01
I0811 23:49:37.777057 26953 solver.cpp:228] Iteration 14030, loss = 2.25528
I0811 23:49:37.777135 26953 solver.cpp:244]     Train net output #0: loss = 2.25528 (* 1 = 2.25528 loss)
I0811 23:49:39.173634 26953 sgd_solver.cpp:106] Iteration 14030, lr = 0.01
I0811 23:49:57.573504 26953 solver.cpp:228] Iteration 14040, loss = 2.29934
I0811 23:49:57.573729 26953 solver.cpp:244]     Train net output #0: loss = 2.29934 (* 1 = 2.29934 loss)
I0811 23:49:58.962594 26953 sgd_solver.cpp:106] Iteration 14040, lr = 0.01
I0811 23:50:17.375491 26953 solver.cpp:228] Iteration 14050, loss = 2.51216
I0811 23:50:17.375563 26953 solver.cpp:244]     Train net output #0: loss = 2.51216 (* 1 = 2.51216 loss)
I0811 23:50:18.766445 26953 sgd_solver.cpp:106] Iteration 14050, lr = 0.01
I0811 23:50:37.119204 26953 solver.cpp:228] Iteration 14060, loss = 2.30469
I0811 23:50:37.120664 26953 solver.cpp:244]     Train net output #0: loss = 2.30469 (* 1 = 2.30469 loss)
I0811 23:50:38.528658 26953 sgd_solver.cpp:106] Iteration 14060, lr = 0.01
I0811 23:50:56.941817 26953 solver.cpp:228] Iteration 14070, loss = 2.30633
I0811 23:50:56.941890 26953 solver.cpp:244]     Train net output #0: loss = 2.30633 (* 1 = 2.30633 loss)
I0811 23:50:58.349282 26953 sgd_solver.cpp:106] Iteration 14070, lr = 0.01
I0811 23:51:16.744956 26953 solver.cpp:228] Iteration 14080, loss = 2.42743
I0811 23:51:16.745231 26953 solver.cpp:244]     Train net output #0: loss = 2.42743 (* 1 = 2.42743 loss)
I0811 23:51:18.144335 26953 sgd_solver.cpp:106] Iteration 14080, lr = 0.01
I0811 23:51:36.498905 26953 solver.cpp:228] Iteration 14090, loss = 2.22757
I0811 23:51:36.498989 26953 solver.cpp:244]     Train net output #0: loss = 2.22757 (* 1 = 2.22757 loss)
I0811 23:51:37.915947 26953 sgd_solver.cpp:106] Iteration 14090, lr = 0.01
I0811 23:51:55.706090 26953 solver.cpp:337] Iteration 14100, Testing net (#0)
I0811 23:51:56.295003 26953 solver.cpp:404]     Test net output #0: accuracy = 0.47
I0811 23:51:56.295078 26953 solver.cpp:404]     Test net output #1: loss = 2.38907 (* 1 = 2.38907 loss)
I0811 23:51:56.876113 26953 solver.cpp:228] Iteration 14100, loss = 2.37339
I0811 23:51:56.876193 26953 solver.cpp:244]     Train net output #0: loss = 2.37339 (* 1 = 2.37339 loss)
I0811 23:51:58.241575 26953 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0811 23:52:16.648191 26953 solver.cpp:228] Iteration 14110, loss = 2.49586
I0811 23:52:16.648257 26953 solver.cpp:244]     Train net output #0: loss = 2.49586 (* 1 = 2.49586 loss)
I0811 23:52:18.065287 26953 sgd_solver.cpp:106] Iteration 14110, lr = 0.01
I0811 23:52:36.455147 26953 solver.cpp:228] Iteration 14120, loss = 2.3753
I0811 23:52:36.455301 26953 solver.cpp:244]     Train net output #0: loss = 2.3753 (* 1 = 2.3753 loss)
I0811 23:52:37.846436 26953 sgd_solver.cpp:106] Iteration 14120, lr = 0.01
I0811 23:52:56.238509 26953 solver.cpp:228] Iteration 14130, loss = 2.39179
I0811 23:52:56.238582 26953 solver.cpp:244]     Train net output #0: loss = 2.39179 (* 1 = 2.39179 loss)
I0811 23:52:57.634897 26953 sgd_solver.cpp:106] Iteration 14130, lr = 0.01
I0811 23:53:15.990026 26953 solver.cpp:228] Iteration 14140, loss = 2.34679
I0811 23:53:15.990272 26953 solver.cpp:244]     Train net output #0: loss = 2.34679 (* 1 = 2.34679 loss)
I0811 23:53:17.411447 26953 sgd_solver.cpp:106] Iteration 14140, lr = 0.01
I0811 23:53:35.795595 26953 solver.cpp:228] Iteration 14150, loss = 2.26309
I0811 23:53:35.795680 26953 solver.cpp:244]     Train net output #0: loss = 2.26309 (* 1 = 2.26309 loss)
I0811 23:53:37.193336 26953 sgd_solver.cpp:106] Iteration 14150, lr = 0.01
I0811 23:53:55.594844 26953 solver.cpp:228] Iteration 14160, loss = 2.22084
I0811 23:53:55.595038 26953 solver.cpp:244]     Train net output #0: loss = 2.22084 (* 1 = 2.22084 loss)
I0811 23:53:56.990377 26953 sgd_solver.cpp:106] Iteration 14160, lr = 0.01
I0811 23:54:15.411952 26953 solver.cpp:228] Iteration 14170, loss = 2.26726
I0811 23:54:15.412050 26953 solver.cpp:244]     Train net output #0: loss = 2.26726 (* 1 = 2.26726 loss)
I0811 23:54:16.812727 26953 sgd_solver.cpp:106] Iteration 14170, lr = 0.01
I0811 23:54:35.160032 26953 solver.cpp:228] Iteration 14180, loss = 2.29135
I0811 23:54:35.160246 26953 solver.cpp:244]     Train net output #0: loss = 2.29135 (* 1 = 2.29135 loss)
I0811 23:54:36.566396 26953 sgd_solver.cpp:106] Iteration 14180, lr = 0.01
I0811 23:54:54.963279 26953 solver.cpp:228] Iteration 14190, loss = 2.61744
I0811 23:54:54.963348 26953 solver.cpp:244]     Train net output #0: loss = 2.61744 (* 1 = 2.61744 loss)
I0811 23:54:56.367383 26953 sgd_solver.cpp:106] Iteration 14190, lr = 0.01
I0811 23:55:14.170166 26953 solver.cpp:337] Iteration 14200, Testing net (#0)
I0811 23:55:14.761045 26953 solver.cpp:404]     Test net output #0: accuracy = 0.472
I0811 23:55:14.761116 26953 solver.cpp:404]     Test net output #1: loss = 2.26319 (* 1 = 2.26319 loss)
I0811 23:55:15.339380 26953 solver.cpp:228] Iteration 14200, loss = 2.20033
I0811 23:55:15.339476 26953 solver.cpp:244]     Train net output #0: loss = 2.20033 (* 1 = 2.20033 loss)
I0811 23:55:16.724696 26953 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0811 23:55:35.110222 26953 solver.cpp:228] Iteration 14210, loss = 2.2637
I0811 23:55:35.110282 26953 solver.cpp:244]     Train net output #0: loss = 2.2637 (* 1 = 2.2637 loss)
I0811 23:55:36.520546 26953 sgd_solver.cpp:106] Iteration 14210, lr = 0.01
I0811 23:55:54.919652 26953 solver.cpp:228] Iteration 14220, loss = 2.29481
I0811 23:55:54.919891 26953 solver.cpp:244]     Train net output #0: loss = 2.29481 (* 1 = 2.29481 loss)
I0811 23:55:56.319963 26953 sgd_solver.cpp:106] Iteration 14220, lr = 0.01
I0811 23:56:14.698523 26953 solver.cpp:228] Iteration 14230, loss = 2.3671
I0811 23:56:14.698595 26953 solver.cpp:244]     Train net output #0: loss = 2.3671 (* 1 = 2.3671 loss)
I0811 23:56:16.094681 26953 sgd_solver.cpp:106] Iteration 14230, lr = 0.01
I0811 23:56:34.448977 26953 solver.cpp:228] Iteration 14240, loss = 2.35745
I0811 23:56:34.449131 26953 solver.cpp:244]     Train net output #0: loss = 2.35745 (* 1 = 2.35745 loss)
I0811 23:56:35.847559 26953 sgd_solver.cpp:106] Iteration 14240, lr = 0.01
I0811 23:56:54.278635 26953 solver.cpp:228] Iteration 14250, loss = 2.35406
I0811 23:56:54.278704 26953 solver.cpp:244]     Train net output #0: loss = 2.35406 (* 1 = 2.35406 loss)
I0811 23:56:55.673784 26953 sgd_solver.cpp:106] Iteration 14250, lr = 0.01
I0811 23:57:14.047948 26953 solver.cpp:228] Iteration 14260, loss = 2.29926
I0811 23:57:14.048171 26953 solver.cpp:244]     Train net output #0: loss = 2.29926 (* 1 = 2.29926 loss)
I0811 23:57:15.453874 26953 sgd_solver.cpp:106] Iteration 14260, lr = 0.01
I0811 23:57:33.864150 26953 solver.cpp:228] Iteration 14270, loss = 2.56296
I0811 23:57:33.864212 26953 solver.cpp:244]     Train net output #0: loss = 2.56296 (* 1 = 2.56296 loss)
I0811 23:57:35.260056 26953 sgd_solver.cpp:106] Iteration 14270, lr = 0.01
I0811 23:57:53.671712 26953 solver.cpp:228] Iteration 14280, loss = 2.32217
I0811 23:57:53.671866 26953 solver.cpp:244]     Train net output #0: loss = 2.32217 (* 1 = 2.32217 loss)
I0811 23:57:55.075424 26953 sgd_solver.cpp:106] Iteration 14280, lr = 0.01
I0811 23:58:13.454192 26953 solver.cpp:228] Iteration 14290, loss = 2.18523
I0811 23:58:13.454267 26953 solver.cpp:244]     Train net output #0: loss = 2.18523 (* 1 = 2.18523 loss)
I0811 23:58:14.859431 26953 sgd_solver.cpp:106] Iteration 14290, lr = 0.01
I0811 23:58:32.643826 26953 solver.cpp:337] Iteration 14300, Testing net (#0)
I0811 23:58:33.229796 26953 solver.cpp:404]     Test net output #0: accuracy = 0.454
I0811 23:58:33.229861 26953 solver.cpp:404]     Test net output #1: loss = 2.3833 (* 1 = 2.3833 loss)
I0811 23:58:33.796547 26953 solver.cpp:228] Iteration 14300, loss = 2.28836
I0811 23:58:33.796604 26953 solver.cpp:244]     Train net output #0: loss = 2.28836 (* 1 = 2.28836 loss)
I0811 23:58:35.172654 26953 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0811 23:58:53.608093 26953 solver.cpp:228] Iteration 14310, loss = 2.33853
I0811 23:58:53.608170 26953 solver.cpp:244]     Train net output #0: loss = 2.33853 (* 1 = 2.33853 loss)
I0811 23:58:55.001629 26953 sgd_solver.cpp:106] Iteration 14310, lr = 0.01
I0811 23:59:13.350464 26953 solver.cpp:228] Iteration 14320, loss = 2.33533
I0811 23:59:13.350658 26953 solver.cpp:244]     Train net output #0: loss = 2.33533 (* 1 = 2.33533 loss)
I0811 23:59:14.766584 26953 sgd_solver.cpp:106] Iteration 14320, lr = 0.01
I0811 23:59:33.140858 26953 solver.cpp:228] Iteration 14330, loss = 2.38699
I0811 23:59:33.140940 26953 solver.cpp:244]     Train net output #0: loss = 2.38699 (* 1 = 2.38699 loss)
I0811 23:59:34.536273 26953 sgd_solver.cpp:106] Iteration 14330, lr = 0.01
I0811 23:59:52.951714 26953 solver.cpp:228] Iteration 14340, loss = 2.42379
I0811 23:59:52.951957 26953 solver.cpp:244]     Train net output #0: loss = 2.42379 (* 1 = 2.42379 loss)
I0811 23:59:54.349684 26953 sgd_solver.cpp:106] Iteration 14340, lr = 0.01
I0812 00:00:12.736929 26953 solver.cpp:228] Iteration 14350, loss = 2.23115
I0812 00:00:12.737001 26953 solver.cpp:244]     Train net output #0: loss = 2.23115 (* 1 = 2.23115 loss)
I0812 00:00:14.132378 26953 sgd_solver.cpp:106] Iteration 14350, lr = 0.01
I0812 00:00:32.552353 26953 solver.cpp:228] Iteration 14360, loss = 2.33213
I0812 00:00:32.552547 26953 solver.cpp:244]     Train net output #0: loss = 2.33213 (* 1 = 2.33213 loss)
I0812 00:00:33.945518 26953 sgd_solver.cpp:106] Iteration 14360, lr = 0.01
I0812 00:00:52.324331 26953 solver.cpp:228] Iteration 14370, loss = 2.14473
I0812 00:00:52.324398 26953 solver.cpp:244]     Train net output #0: loss = 2.14473 (* 1 = 2.14473 loss)
I0812 00:00:53.735613 26953 sgd_solver.cpp:106] Iteration 14370, lr = 0.01
I0812 00:01:12.123503 26953 solver.cpp:228] Iteration 14380, loss = 2.4276
I0812 00:01:12.123705 26953 solver.cpp:244]     Train net output #0: loss = 2.4276 (* 1 = 2.4276 loss)
I0812 00:01:13.534214 26953 sgd_solver.cpp:106] Iteration 14380, lr = 0.01
I0812 00:01:31.903414 26953 solver.cpp:228] Iteration 14390, loss = 2.25779
I0812 00:01:31.903496 26953 solver.cpp:244]     Train net output #0: loss = 2.25779 (* 1 = 2.25779 loss)
I0812 00:01:33.307258 26953 sgd_solver.cpp:106] Iteration 14390, lr = 0.01
I0812 00:01:51.101522 26953 solver.cpp:337] Iteration 14400, Testing net (#0)
I0812 00:01:51.692616 26953 solver.cpp:404]     Test net output #0: accuracy = 0.464
I0812 00:01:51.692670 26953 solver.cpp:404]     Test net output #1: loss = 2.4125 (* 1 = 2.4125 loss)
I0812 00:01:52.254926 26953 solver.cpp:228] Iteration 14400, loss = 2.3808
I0812 00:01:52.255025 26953 solver.cpp:244]     Train net output #0: loss = 2.3808 (* 1 = 2.3808 loss)
I0812 00:01:53.626570 26953 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0812 00:02:12.006003 26953 solver.cpp:228] Iteration 14410, loss = 2.43303
I0812 00:02:12.006064 26953 solver.cpp:244]     Train net output #0: loss = 2.43303 (* 1 = 2.43303 loss)
I0812 00:02:13.391158 26953 sgd_solver.cpp:106] Iteration 14410, lr = 0.01
I0812 00:02:31.764518 26953 solver.cpp:228] Iteration 14420, loss = 2.38885
I0812 00:02:31.764662 26953 solver.cpp:244]     Train net output #0: loss = 2.38885 (* 1 = 2.38885 loss)
I0812 00:02:33.164726 26953 sgd_solver.cpp:106] Iteration 14420, lr = 0.01
I0812 00:02:51.594688 26953 solver.cpp:228] Iteration 14430, loss = 2.31291
I0812 00:02:51.594775 26953 solver.cpp:244]     Train net output #0: loss = 2.31291 (* 1 = 2.31291 loss)
I0812 00:02:52.992934 26953 sgd_solver.cpp:106] Iteration 14430, lr = 0.01
I0812 00:03:11.355085 26953 solver.cpp:228] Iteration 14440, loss = 2.3099
I0812 00:03:11.355262 26953 solver.cpp:244]     Train net output #0: loss = 2.3099 (* 1 = 2.3099 loss)
I0812 00:03:12.778017 26953 sgd_solver.cpp:106] Iteration 14440, lr = 0.01
I0812 00:03:31.146633 26953 solver.cpp:228] Iteration 14450, loss = 2.32587
I0812 00:03:31.146693 26953 solver.cpp:244]     Train net output #0: loss = 2.32587 (* 1 = 2.32587 loss)
I0812 00:03:32.548540 26953 sgd_solver.cpp:106] Iteration 14450, lr = 0.01
I0812 00:03:50.898495 26953 solver.cpp:228] Iteration 14460, loss = 2.35803
I0812 00:03:50.898731 26953 solver.cpp:244]     Train net output #0: loss = 2.35803 (* 1 = 2.35803 loss)
I0812 00:03:52.298686 26953 sgd_solver.cpp:106] Iteration 14460, lr = 0.01
I0812 00:04:10.719039 26953 solver.cpp:228] Iteration 14470, loss = 2.43856
I0812 00:04:10.719122 26953 solver.cpp:244]     Train net output #0: loss = 2.43856 (* 1 = 2.43856 loss)
I0812 00:04:12.138619 26953 sgd_solver.cpp:106] Iteration 14470, lr = 0.01
I0812 00:04:30.582473 26953 solver.cpp:228] Iteration 14480, loss = 2.24165
I0812 00:04:30.582700 26953 solver.cpp:244]     Train net output #0: loss = 2.24165 (* 1 = 2.24165 loss)
I0812 00:04:31.970234 26953 sgd_solver.cpp:106] Iteration 14480, lr = 0.01
I0812 00:04:50.364038 26953 solver.cpp:228] Iteration 14490, loss = 2.22038
I0812 00:04:50.364094 26953 solver.cpp:244]     Train net output #0: loss = 2.22038 (* 1 = 2.22038 loss)
I0812 00:04:51.768470 26953 sgd_solver.cpp:106] Iteration 14490, lr = 0.01
I0812 00:05:09.568204 26953 solver.cpp:337] Iteration 14500, Testing net (#0)
I0812 00:05:10.158717 26953 solver.cpp:404]     Test net output #0: accuracy = 0.466
I0812 00:05:10.158802 26953 solver.cpp:404]     Test net output #1: loss = 2.38669 (* 1 = 2.38669 loss)
I0812 00:05:10.756181 26953 solver.cpp:228] Iteration 14500, loss = 2.33789
I0812 00:05:10.756237 26953 solver.cpp:244]     Train net output #0: loss = 2.33789 (* 1 = 2.33789 loss)
I0812 00:05:12.116561 26953 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0812 00:05:30.572204 26953 solver.cpp:228] Iteration 14510, loss = 2.35397
I0812 00:05:30.572270 26953 solver.cpp:244]     Train net output #0: loss = 2.35397 (* 1 = 2.35397 loss)
I0812 00:05:31.979447 26953 sgd_solver.cpp:106] Iteration 14510, lr = 0.01
I0812 00:05:50.314906 26953 solver.cpp:228] Iteration 14520, loss = 2.29867
I0812 00:05:50.315104 26953 solver.cpp:244]     Train net output #0: loss = 2.29867 (* 1 = 2.29867 loss)
I0812 00:05:51.716590 26953 sgd_solver.cpp:106] Iteration 14520, lr = 0.01
I0812 00:06:10.059155 26953 solver.cpp:228] Iteration 14530, loss = 2.16958
I0812 00:06:10.059222 26953 solver.cpp:244]     Train net output #0: loss = 2.16958 (* 1 = 2.16958 loss)
I0812 00:06:11.451944 26953 sgd_solver.cpp:106] Iteration 14530, lr = 0.01
I0812 00:06:29.838706 26953 solver.cpp:228] Iteration 14540, loss = 2.24539
I0812 00:06:29.838934 26953 solver.cpp:244]     Train net output #0: loss = 2.24539 (* 1 = 2.24539 loss)
I0812 00:06:31.245976 26953 sgd_solver.cpp:106] Iteration 14540, lr = 0.01
I0812 00:06:49.649302 26953 solver.cpp:228] Iteration 14550, loss = 2.28778
I0812 00:06:49.649374 26953 solver.cpp:244]     Train net output #0: loss = 2.28778 (* 1 = 2.28778 loss)
I0812 00:06:51.060734 26953 sgd_solver.cpp:106] Iteration 14550, lr = 0.01
I0812 00:07:09.402055 26953 solver.cpp:228] Iteration 14560, loss = 2.36332
I0812 00:07:09.402217 26953 solver.cpp:244]     Train net output #0: loss = 2.36332 (* 1 = 2.36332 loss)
I0812 00:07:10.816401 26953 sgd_solver.cpp:106] Iteration 14560, lr = 0.01
I0812 00:07:29.204697 26953 solver.cpp:228] Iteration 14570, loss = 2.46375
I0812 00:07:29.204766 26953 solver.cpp:244]     Train net output #0: loss = 2.46375 (* 1 = 2.46375 loss)
I0812 00:07:30.603549 26953 sgd_solver.cpp:106] Iteration 14570, lr = 0.01
I0812 00:07:48.990795 26953 solver.cpp:228] Iteration 14580, loss = 2.35713
I0812 00:07:48.990980 26953 solver.cpp:244]     Train net output #0: loss = 2.35713 (* 1 = 2.35713 loss)
I0812 00:07:50.384783 26953 sgd_solver.cpp:106] Iteration 14580, lr = 0.01
I0812 00:08:08.755786 26953 solver.cpp:228] Iteration 14590, loss = 2.31845
I0812 00:08:08.755861 26953 solver.cpp:244]     Train net output #0: loss = 2.31845 (* 1 = 2.31845 loss)
I0812 00:08:10.154917 26953 sgd_solver.cpp:106] Iteration 14590, lr = 0.01
I0812 00:08:27.937291 26953 solver.cpp:337] Iteration 14600, Testing net (#0)
I0812 00:08:28.536892 26953 solver.cpp:404]     Test net output #0: accuracy = 0.49
I0812 00:08:28.536967 26953 solver.cpp:404]     Test net output #1: loss = 2.3404 (* 1 = 2.3404 loss)
I0812 00:08:29.102536 26953 solver.cpp:228] Iteration 14600, loss = 2.4716
I0812 00:08:29.102645 26953 solver.cpp:244]     Train net output #0: loss = 2.4716 (* 1 = 2.4716 loss)
I0812 00:08:30.475354 26953 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0812 00:08:48.842620 26953 solver.cpp:228] Iteration 14610, loss = 2.27008
I0812 00:08:48.842691 26953 solver.cpp:244]     Train net output #0: loss = 2.27008 (* 1 = 2.27008 loss)
I0812 00:08:50.240098 26953 sgd_solver.cpp:106] Iteration 14610, lr = 0.01
I0812 00:09:08.602659 26953 solver.cpp:228] Iteration 14620, loss = 2.21509
I0812 00:09:08.602856 26953 solver.cpp:244]     Train net output #0: loss = 2.21509 (* 1 = 2.21509 loss)
I0812 00:09:10.006634 26953 sgd_solver.cpp:106] Iteration 14620, lr = 0.01
I0812 00:09:28.380517 26953 solver.cpp:228] Iteration 14630, loss = 2.28821
I0812 00:09:28.380589 26953 solver.cpp:244]     Train net output #0: loss = 2.28821 (* 1 = 2.28821 loss)
I0812 00:09:29.778444 26953 sgd_solver.cpp:106] Iteration 14630, lr = 0.01
I0812 00:09:48.120687 26953 solver.cpp:228] Iteration 14640, loss = 2.37009
I0812 00:09:48.120928 26953 solver.cpp:244]     Train net output #0: loss = 2.37009 (* 1 = 2.37009 loss)
I0812 00:09:49.521901 26953 sgd_solver.cpp:106] Iteration 14640, lr = 0.01
I0812 00:10:07.860246 26953 solver.cpp:228] Iteration 14650, loss = 2.4185
I0812 00:10:07.860318 26953 solver.cpp:244]     Train net output #0: loss = 2.4185 (* 1 = 2.4185 loss)
I0812 00:10:09.252349 26953 sgd_solver.cpp:106] Iteration 14650, lr = 0.01
I0812 00:10:27.697047 26953 solver.cpp:228] Iteration 14660, loss = 2.4357
I0812 00:10:27.697327 26953 solver.cpp:244]     Train net output #0: loss = 2.4357 (* 1 = 2.4357 loss)
I0812 00:10:29.097743 26953 sgd_solver.cpp:106] Iteration 14660, lr = 0.01
I0812 00:10:47.482417 26953 solver.cpp:228] Iteration 14670, loss = 2.20572
I0812 00:10:47.482487 26953 solver.cpp:244]     Train net output #0: loss = 2.20572 (* 1 = 2.20572 loss)
I0812 00:10:48.890848 26953 sgd_solver.cpp:106] Iteration 14670, lr = 0.01
I0812 00:11:07.272621 26953 solver.cpp:228] Iteration 14680, loss = 2.30003
I0812 00:11:07.272801 26953 solver.cpp:244]     Train net output #0: loss = 2.30003 (* 1 = 2.30003 loss)
I0812 00:11:08.677497 26953 sgd_solver.cpp:106] Iteration 14680, lr = 0.01
I0812 00:11:27.104959 26953 solver.cpp:228] Iteration 14690, loss = 2.43528
I0812 00:11:27.105017 26953 solver.cpp:244]     Train net output #0: loss = 2.43528 (* 1 = 2.43528 loss)
I0812 00:11:28.516773 26953 sgd_solver.cpp:106] Iteration 14690, lr = 0.01
I0812 00:11:46.312038 26953 solver.cpp:337] Iteration 14700, Testing net (#0)
I0812 00:11:46.902014 26953 solver.cpp:404]     Test net output #0: accuracy = 0.456
I0812 00:11:46.902086 26953 solver.cpp:404]     Test net output #1: loss = 2.3816 (* 1 = 2.3816 loss)
I0812 00:11:47.477805 26953 solver.cpp:228] Iteration 14700, loss = 2.33262
I0812 00:11:47.477885 26953 solver.cpp:244]     Train net output #0: loss = 2.33262 (* 1 = 2.33262 loss)
I0812 00:11:48.848769 26953 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0812 00:12:07.247798 26953 solver.cpp:228] Iteration 14710, loss = 2.37661
I0812 00:12:07.247866 26953 solver.cpp:244]     Train net output #0: loss = 2.37661 (* 1 = 2.37661 loss)
I0812 00:12:08.624778 26953 sgd_solver.cpp:106] Iteration 14710, lr = 0.01
I0812 00:12:26.981344 26953 solver.cpp:228] Iteration 14720, loss = 2.39954
I0812 00:12:26.981583 26953 solver.cpp:244]     Train net output #0: loss = 2.39954 (* 1 = 2.39954 loss)
I0812 00:12:28.391010 26953 sgd_solver.cpp:106] Iteration 14720, lr = 0.01
I0812 00:12:46.781827 26953 solver.cpp:228] Iteration 14730, loss = 2.4153
I0812 00:12:46.781903 26953 solver.cpp:244]     Train net output #0: loss = 2.4153 (* 1 = 2.4153 loss)
I0812 00:12:48.183154 26953 sgd_solver.cpp:106] Iteration 14730, lr = 0.01
I0812 00:13:06.577003 26953 solver.cpp:228] Iteration 14740, loss = 2.46906
I0812 00:13:06.577272 26953 solver.cpp:244]     Train net output #0: loss = 2.46906 (* 1 = 2.46906 loss)
I0812 00:13:07.971871 26953 sgd_solver.cpp:106] Iteration 14740, lr = 0.01
I0812 00:13:26.348992 26953 solver.cpp:228] Iteration 14750, loss = 2.53842
I0812 00:13:26.349093 26953 solver.cpp:244]     Train net output #0: loss = 2.53842 (* 1 = 2.53842 loss)
I0812 00:13:27.763823 26953 sgd_solver.cpp:106] Iteration 14750, lr = 0.01
I0812 00:13:46.125049 26953 solver.cpp:228] Iteration 14760, loss = 2.12668
I0812 00:13:46.125277 26953 solver.cpp:244]     Train net output #0: loss = 2.12668 (* 1 = 2.12668 loss)
I0812 00:13:47.515730 26953 sgd_solver.cpp:106] Iteration 14760, lr = 0.01
I0812 00:14:05.902961 26953 solver.cpp:228] Iteration 14770, loss = 2.26566
I0812 00:14:05.903038 26953 solver.cpp:244]     Train net output #0: loss = 2.26566 (* 1 = 2.26566 loss)
I0812 00:14:07.299427 26953 sgd_solver.cpp:106] Iteration 14770, lr = 0.01
I0812 00:14:25.734792 26953 solver.cpp:228] Iteration 14780, loss = 2.25187
I0812 00:14:25.734954 26953 solver.cpp:244]     Train net output #0: loss = 2.25187 (* 1 = 2.25187 loss)
I0812 00:14:27.130512 26953 sgd_solver.cpp:106] Iteration 14780, lr = 0.01
I0812 00:14:45.465709 26953 solver.cpp:228] Iteration 14790, loss = 2.38187
I0812 00:14:45.465785 26953 solver.cpp:244]     Train net output #0: loss = 2.38187 (* 1 = 2.38187 loss)
I0812 00:14:46.866830 26953 sgd_solver.cpp:106] Iteration 14790, lr = 0.01
I0812 00:15:04.679584 26953 solver.cpp:337] Iteration 14800, Testing net (#0)
I0812 00:15:05.269915 26953 solver.cpp:404]     Test net output #0: accuracy = 0.464
I0812 00:15:05.269996 26953 solver.cpp:404]     Test net output #1: loss = 2.32463 (* 1 = 2.32463 loss)
I0812 00:15:05.844503 26953 solver.cpp:228] Iteration 14800, loss = 2.47746
I0812 00:15:05.844597 26953 solver.cpp:244]     Train net output #0: loss = 2.47746 (* 1 = 2.47746 loss)
I0812 00:15:07.220372 26953 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0812 00:15:25.609606 26953 solver.cpp:228] Iteration 14810, loss = 2.48471
I0812 00:15:25.609678 26953 solver.cpp:244]     Train net output #0: loss = 2.48471 (* 1 = 2.48471 loss)
I0812 00:15:27.005369 26953 sgd_solver.cpp:106] Iteration 14810, lr = 0.01
I0812 00:15:45.348382 26953 solver.cpp:228] Iteration 14820, loss = 2.14119
I0812 00:15:45.348598 26953 solver.cpp:244]     Train net output #0: loss = 2.14119 (* 1 = 2.14119 loss)
I0812 00:15:46.746356 26953 sgd_solver.cpp:106] Iteration 14820, lr = 0.01
I0812 00:16:05.101301 26953 solver.cpp:228] Iteration 14830, loss = 2.42513
I0812 00:16:05.101397 26953 solver.cpp:244]     Train net output #0: loss = 2.42513 (* 1 = 2.42513 loss)
I0812 00:16:06.507520 26953 sgd_solver.cpp:106] Iteration 14830, lr = 0.01
I0812 00:16:24.890628 26953 solver.cpp:228] Iteration 14840, loss = 2.32265
I0812 00:16:24.890868 26953 solver.cpp:244]     Train net output #0: loss = 2.32265 (* 1 = 2.32265 loss)
I0812 00:16:26.292711 26953 sgd_solver.cpp:106] Iteration 14840, lr = 0.01
I0812 00:16:44.693492 26953 solver.cpp:228] Iteration 14850, loss = 2.19144
I0812 00:16:44.693572 26953 solver.cpp:244]     Train net output #0: loss = 2.19144 (* 1 = 2.19144 loss)
I0812 00:16:46.095263 26953 sgd_solver.cpp:106] Iteration 14850, lr = 0.01
I0812 00:17:04.454833 26953 solver.cpp:228] Iteration 14860, loss = 2.15046
I0812 00:17:04.454974 26953 solver.cpp:244]     Train net output #0: loss = 2.15046 (* 1 = 2.15046 loss)
I0812 00:17:05.867898 26953 sgd_solver.cpp:106] Iteration 14860, lr = 0.01
I0812 00:17:24.292349 26953 solver.cpp:228] Iteration 14870, loss = 2.36162
I0812 00:17:24.292419 26953 solver.cpp:244]     Train net output #0: loss = 2.36162 (* 1 = 2.36162 loss)
I0812 00:17:25.685904 26953 sgd_solver.cpp:106] Iteration 14870, lr = 0.01
I0812 00:17:44.086637 26953 solver.cpp:228] Iteration 14880, loss = 2.39804
I0812 00:17:44.086897 26953 solver.cpp:244]     Train net output #0: loss = 2.39804 (* 1 = 2.39804 loss)
I0812 00:17:45.498736 26953 sgd_solver.cpp:106] Iteration 14880, lr = 0.01
I0812 00:18:03.837502 26953 solver.cpp:228] Iteration 14890, loss = 2.22745
I0812 00:18:03.837563 26953 solver.cpp:244]     Train net output #0: loss = 2.22745 (* 1 = 2.22745 loss)
I0812 00:18:05.232751 26953 sgd_solver.cpp:106] Iteration 14890, lr = 0.01
I0812 00:18:23.043768 26953 solver.cpp:337] Iteration 14900, Testing net (#0)
I0812 00:18:23.631978 26953 solver.cpp:404]     Test net output #0: accuracy = 0.44
I0812 00:18:23.632050 26953 solver.cpp:404]     Test net output #1: loss = 2.71508 (* 1 = 2.71508 loss)
I0812 00:18:24.229034 26953 solver.cpp:228] Iteration 14900, loss = 2.13305
I0812 00:18:24.229104 26953 solver.cpp:244]     Train net output #0: loss = 2.13305 (* 1 = 2.13305 loss)
I0812 00:18:25.579293 26953 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0812 00:18:43.943418 26953 solver.cpp:228] Iteration 14910, loss = 2.32007
I0812 00:18:43.943478 26953 solver.cpp:244]     Train net output #0: loss = 2.32007 (* 1 = 2.32007 loss)
I0812 00:18:45.339082 26953 sgd_solver.cpp:106] Iteration 14910, lr = 0.01
I0812 00:19:03.711357 26953 solver.cpp:228] Iteration 14920, loss = 2.47752
I0812 00:19:03.711619 26953 solver.cpp:244]     Train net output #0: loss = 2.47752 (* 1 = 2.47752 loss)
I0812 00:19:05.116331 26953 sgd_solver.cpp:106] Iteration 14920, lr = 0.01
I0812 00:19:23.556277 26953 solver.cpp:228] Iteration 14930, loss = 2.23316
I0812 00:19:23.556351 26953 solver.cpp:244]     Train net output #0: loss = 2.23316 (* 1 = 2.23316 loss)
I0812 00:19:24.965822 26953 sgd_solver.cpp:106] Iteration 14930, lr = 0.01
I0812 00:19:43.361685 26953 solver.cpp:228] Iteration 14940, loss = 2.36083
I0812 00:19:43.361915 26953 solver.cpp:244]     Train net output #0: loss = 2.36083 (* 1 = 2.36083 loss)
I0812 00:19:44.767213 26953 sgd_solver.cpp:106] Iteration 14940, lr = 0.01
I0812 00:20:03.137173 26953 solver.cpp:228] Iteration 14950, loss = 2.34566
I0812 00:20:03.137250 26953 solver.cpp:244]     Train net output #0: loss = 2.34566 (* 1 = 2.34566 loss)
I0812 00:20:04.534474 26953 sgd_solver.cpp:106] Iteration 14950, lr = 0.01
I0812 00:20:23.016316 26953 solver.cpp:228] Iteration 14960, loss = 2.38974
I0812 00:20:23.016445 26953 solver.cpp:244]     Train net output #0: loss = 2.38974 (* 1 = 2.38974 loss)
I0812 00:20:24.431478 26953 sgd_solver.cpp:106] Iteration 14960, lr = 0.01
I0812 00:20:42.783200 26953 solver.cpp:228] Iteration 14970, loss = 2.16468
I0812 00:20:42.783272 26953 solver.cpp:244]     Train net output #0: loss = 2.16468 (* 1 = 2.16468 loss)
I0812 00:20:44.187103 26953 sgd_solver.cpp:106] Iteration 14970, lr = 0.01
I0812 00:21:02.599395 26953 solver.cpp:228] Iteration 14980, loss = 2.31749
I0812 00:21:02.599632 26953 solver.cpp:244]     Train net output #0: loss = 2.31749 (* 1 = 2.31749 loss)
I0812 00:21:03.991204 26953 sgd_solver.cpp:106] Iteration 14980, lr = 0.01
I0812 00:21:22.430127 26953 solver.cpp:228] Iteration 14990, loss = 2.33814
I0812 00:21:22.430196 26953 solver.cpp:244]     Train net output #0: loss = 2.33814 (* 1 = 2.33814 loss)
I0812 00:21:23.829439 26953 sgd_solver.cpp:106] Iteration 14990, lr = 0.01
I0812 00:21:41.611737 26953 solver.cpp:337] Iteration 15000, Testing net (#0)
I0812 00:21:42.204735 26953 solver.cpp:404]     Test net output #0: accuracy = 0.512
I0812 00:21:42.204848 26953 solver.cpp:404]     Test net output #1: loss = 2.2912 (* 1 = 2.2912 loss)
I0812 00:21:42.785658 26953 solver.cpp:228] Iteration 15000, loss = 2.27148
I0812 00:21:42.785748 26953 solver.cpp:244]     Train net output #0: loss = 2.27148 (* 1 = 2.27148 loss)
I0812 00:21:44.143015 26953 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0812 00:22:02.523459 26953 solver.cpp:228] Iteration 15010, loss = 2.18938
I0812 00:22:02.523543 26953 solver.cpp:244]     Train net output #0: loss = 2.18938 (* 1 = 2.18938 loss)
I0812 00:22:03.924068 26953 sgd_solver.cpp:106] Iteration 15010, lr = 0.01
I0812 00:22:22.305701 26953 solver.cpp:228] Iteration 15020, loss = 2.50733
I0812 00:22:22.305896 26953 solver.cpp:244]     Train net output #0: loss = 2.50733 (* 1 = 2.50733 loss)
I0812 00:22:23.707100 26953 sgd_solver.cpp:106] Iteration 15020, lr = 0.01
I0812 00:22:42.079759 26953 solver.cpp:228] Iteration 15030, loss = 2.30792
I0812 00:22:42.079829 26953 solver.cpp:244]     Train net output #0: loss = 2.30792 (* 1 = 2.30792 loss)
I0812 00:22:43.495338 26953 sgd_solver.cpp:106] Iteration 15030, lr = 0.01
I0812 00:23:01.886911 26953 solver.cpp:228] Iteration 15040, loss = 2.36251
I0812 00:23:01.887061 26953 solver.cpp:244]     Train net output #0: loss = 2.36251 (* 1 = 2.36251 loss)
I0812 00:23:03.296409 26953 sgd_solver.cpp:106] Iteration 15040, lr = 0.01
I0812 00:23:21.687063 26953 solver.cpp:228] Iteration 15050, loss = 2.20356
I0812 00:23:21.687122 26953 solver.cpp:244]     Train net output #0: loss = 2.20356 (* 1 = 2.20356 loss)
I0812 00:23:23.097972 26953 sgd_solver.cpp:106] Iteration 15050, lr = 0.01
I0812 00:23:41.465912 26953 solver.cpp:228] Iteration 15060, loss = 2.29432
I0812 00:23:41.466156 26953 solver.cpp:244]     Train net output #0: loss = 2.29432 (* 1 = 2.29432 loss)
I0812 00:23:42.858163 26953 sgd_solver.cpp:106] Iteration 15060, lr = 0.01
I0812 00:24:01.235999 26953 solver.cpp:228] Iteration 15070, loss = 2.33812
I0812 00:24:01.236064 26953 solver.cpp:244]     Train net output #0: loss = 2.33812 (* 1 = 2.33812 loss)
I0812 00:24:02.626312 26953 sgd_solver.cpp:106] Iteration 15070, lr = 0.01
I0812 00:24:21.044510 26953 solver.cpp:228] Iteration 15080, loss = 2.4614
I0812 00:24:21.044706 26953 solver.cpp:244]     Train net output #0: loss = 2.4614 (* 1 = 2.4614 loss)
I0812 00:24:22.467408 26953 sgd_solver.cpp:106] Iteration 15080, lr = 0.01
I0812 00:24:40.877377 26953 solver.cpp:228] Iteration 15090, loss = 2.35994
I0812 00:24:40.877460 26953 solver.cpp:244]     Train net output #0: loss = 2.35994 (* 1 = 2.35994 loss)
I0812 00:24:42.272279 26953 sgd_solver.cpp:106] Iteration 15090, lr = 0.01
I0812 00:25:00.095695 26953 solver.cpp:337] Iteration 15100, Testing net (#0)
I0812 00:25:00.685770 26953 solver.cpp:404]     Test net output #0: accuracy = 0.514
I0812 00:25:00.685837 26953 solver.cpp:404]     Test net output #1: loss = 2.3074 (* 1 = 2.3074 loss)
I0812 00:25:01.262744 26953 solver.cpp:228] Iteration 15100, loss = 2.33791
I0812 00:25:01.262822 26953 solver.cpp:244]     Train net output #0: loss = 2.33791 (* 1 = 2.33791 loss)
I0812 00:25:02.634897 26953 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0812 00:25:21.025336 26953 solver.cpp:228] Iteration 15110, loss = 2.27086
I0812 00:25:21.025398 26953 solver.cpp:244]     Train net output #0: loss = 2.27086 (* 1 = 2.27086 loss)
I0812 00:25:22.420649 26953 sgd_solver.cpp:106] Iteration 15110, lr = 0.01
I0812 00:25:40.901070 26953 solver.cpp:228] Iteration 15120, loss = 2.27052
I0812 00:25:40.901257 26953 solver.cpp:244]     Train net output #0: loss = 2.27052 (* 1 = 2.27052 loss)
I0812 00:25:42.300874 26953 sgd_solver.cpp:106] Iteration 15120, lr = 0.01
I0812 00:26:00.661633 26953 solver.cpp:228] Iteration 15130, loss = 2.34778
I0812 00:26:00.661698 26953 solver.cpp:244]     Train net output #0: loss = 2.34778 (* 1 = 2.34778 loss)
I0812 00:26:02.068509 26953 sgd_solver.cpp:106] Iteration 15130, lr = 0.01
I0812 00:26:20.469359 26953 solver.cpp:228] Iteration 15140, loss = 2.27011
I0812 00:26:20.469593 26953 solver.cpp:244]     Train net output #0: loss = 2.27011 (* 1 = 2.27011 loss)
I0812 00:26:21.878620 26953 sgd_solver.cpp:106] Iteration 15140, lr = 0.01
I0812 00:26:40.257807 26953 solver.cpp:228] Iteration 15150, loss = 2.19008
I0812 00:26:40.257868 26953 solver.cpp:244]     Train net output #0: loss = 2.19008 (* 1 = 2.19008 loss)
I0812 00:26:41.650524 26953 sgd_solver.cpp:106] Iteration 15150, lr = 0.01
I0812 00:27:00.006507 26953 solver.cpp:228] Iteration 15160, loss = 2.29367
I0812 00:27:00.006702 26953 solver.cpp:244]     Train net output #0: loss = 2.29367 (* 1 = 2.29367 loss)
I0812 00:27:01.430289 26953 sgd_solver.cpp:106] Iteration 15160, lr = 0.01
I0812 00:27:19.823716 26953 solver.cpp:228] Iteration 15170, loss = 2.42286
I0812 00:27:19.823799 26953 solver.cpp:244]     Train net output #0: loss = 2.42286 (* 1 = 2.42286 loss)
I0812 00:27:21.228657 26953 sgd_solver.cpp:106] Iteration 15170, lr = 0.01
I0812 00:27:39.617928 26953 solver.cpp:228] Iteration 15180, loss = 2.19601
I0812 00:27:39.618132 26953 solver.cpp:244]     Train net output #0: loss = 2.19601 (* 1 = 2.19601 loss)
I0812 00:27:41.033773 26953 sgd_solver.cpp:106] Iteration 15180, lr = 0.01
I0812 00:27:59.384215 26953 solver.cpp:228] Iteration 15190, loss = 2.2848
I0812 00:27:59.384285 26953 solver.cpp:244]     Train net output #0: loss = 2.2848 (* 1 = 2.2848 loss)
I0812 00:28:00.783881 26953 sgd_solver.cpp:106] Iteration 15190, lr = 0.01
I0812 00:28:18.621968 26953 solver.cpp:337] Iteration 15200, Testing net (#0)
I0812 00:28:19.207710 26953 solver.cpp:404]     Test net output #0: accuracy = 0.44
I0812 00:28:19.207763 26953 solver.cpp:404]     Test net output #1: loss = 2.41244 (* 1 = 2.41244 loss)
I0812 00:28:19.785059 26953 solver.cpp:228] Iteration 15200, loss = 2.25794
I0812 00:28:19.785142 26953 solver.cpp:244]     Train net output #0: loss = 2.25794 (* 1 = 2.25794 loss)
I0812 00:28:21.150625 26953 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0812 00:28:39.544654 26953 solver.cpp:228] Iteration 15210, loss = 2.3853
I0812 00:28:39.544734 26953 solver.cpp:244]     Train net output #0: loss = 2.3853 (* 1 = 2.3853 loss)
I0812 00:28:40.942013 26953 sgd_solver.cpp:106] Iteration 15210, lr = 0.01
I0812 00:28:59.320421 26953 solver.cpp:228] Iteration 15220, loss = 2.32981
I0812 00:28:59.320582 26953 solver.cpp:244]     Train net output #0: loss = 2.32981 (* 1 = 2.32981 loss)
I0812 00:29:00.740224 26953 sgd_solver.cpp:106] Iteration 15220, lr = 0.01
I0812 00:29:19.185504 26953 solver.cpp:228] Iteration 15230, loss = 2.295
I0812 00:29:19.185598 26953 solver.cpp:244]     Train net output #0: loss = 2.295 (* 1 = 2.295 loss)
I0812 00:29:20.577457 26953 sgd_solver.cpp:106] Iteration 15230, lr = 0.01
I0812 00:29:38.924526 26953 solver.cpp:228] Iteration 15240, loss = 2.38944
I0812 00:29:38.924671 26953 solver.cpp:244]     Train net output #0: loss = 2.38944 (* 1 = 2.38944 loss)
I0812 00:29:40.325906 26953 sgd_solver.cpp:106] Iteration 15240, lr = 0.01
I0812 00:29:58.685645 26953 solver.cpp:228] Iteration 15250, loss = 2.43556
I0812 00:29:58.685721 26953 solver.cpp:244]     Train net output #0: loss = 2.43556 (* 1 = 2.43556 loss)
I0812 00:30:00.093446 26953 sgd_solver.cpp:106] Iteration 15250, lr = 0.01
I0812 00:30:18.509831 26953 solver.cpp:228] Iteration 15260, loss = 2.19668
I0812 00:30:18.510067 26953 solver.cpp:244]     Train net output #0: loss = 2.19668 (* 1 = 2.19668 loss)
I0812 00:30:19.903928 26953 sgd_solver.cpp:106] Iteration 15260, lr = 0.01
I0812 00:30:38.285117 26953 solver.cpp:228] Iteration 15270, loss = 2.25377
I0812 00:30:38.285221 26953 solver.cpp:244]     Train net output #0: loss = 2.25377 (* 1 = 2.25377 loss)
I0812 00:30:39.694280 26953 sgd_solver.cpp:106] Iteration 15270, lr = 0.01
I0812 00:30:58.054507 26953 solver.cpp:228] Iteration 15280, loss = 2.41169
I0812 00:30:58.054711 26953 solver.cpp:244]     Train net output #0: loss = 2.41169 (* 1 = 2.41169 loss)
I0812 00:30:59.463209 26953 sgd_solver.cpp:106] Iteration 15280, lr = 0.01
I0812 00:31:17.828132 26953 solver.cpp:228] Iteration 15290, loss = 2.24356
I0812 00:31:17.828205 26953 solver.cpp:244]     Train net output #0: loss = 2.24356 (* 1 = 2.24356 loss)
I0812 00:31:19.233721 26953 sgd_solver.cpp:106] Iteration 15290, lr = 0.01
I0812 00:31:37.051297 26953 solver.cpp:337] Iteration 15300, Testing net (#0)
I0812 00:31:37.642555 26953 solver.cpp:404]     Test net output #0: accuracy = 0.456
I0812 00:31:37.642624 26953 solver.cpp:404]     Test net output #1: loss = 2.37558 (* 1 = 2.37558 loss)
I0812 00:31:38.210398 26953 solver.cpp:228] Iteration 15300, loss = 2.21461
I0812 00:31:38.210495 26953 solver.cpp:244]     Train net output #0: loss = 2.21461 (* 1 = 2.21461 loss)
I0812 00:31:39.603374 26953 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0812 00:31:57.930058 26953 solver.cpp:228] Iteration 15310, loss = 2.40419
I0812 00:31:57.930130 26953 solver.cpp:244]     Train net output #0: loss = 2.40419 (* 1 = 2.40419 loss)
I0812 00:31:59.337430 26953 sgd_solver.cpp:106] Iteration 15310, lr = 0.01
I0812 00:32:17.777720 26953 solver.cpp:228] Iteration 15320, loss = 2.41381
I0812 00:32:17.777966 26953 solver.cpp:244]     Train net output #0: loss = 2.41381 (* 1 = 2.41381 loss)
I0812 00:32:19.174037 26953 sgd_solver.cpp:106] Iteration 15320, lr = 0.01
I0812 00:32:37.582343 26953 solver.cpp:228] Iteration 15330, loss = 2.41612
I0812 00:32:37.582412 26953 solver.cpp:244]     Train net output #0: loss = 2.41612 (* 1 = 2.41612 loss)
I0812 00:32:38.977867 26953 sgd_solver.cpp:106] Iteration 15330, lr = 0.01
I0812 00:32:57.401659 26953 solver.cpp:228] Iteration 15340, loss = 2.36618
I0812 00:32:57.401913 26953 solver.cpp:244]     Train net output #0: loss = 2.36618 (* 1 = 2.36618 loss)
I0812 00:32:58.812932 26953 sgd_solver.cpp:106] Iteration 15340, lr = 0.01
I0812 00:33:17.210089 26953 solver.cpp:228] Iteration 15350, loss = 2.33909
I0812 00:33:17.210149 26953 solver.cpp:244]     Train net output #0: loss = 2.33909 (* 1 = 2.33909 loss)
I0812 00:33:18.611980 26953 sgd_solver.cpp:106] Iteration 15350, lr = 0.01
I0812 00:33:36.979871 26953 solver.cpp:228] Iteration 15360, loss = 2.34855
I0812 00:33:36.980123 26953 solver.cpp:244]     Train net output #0: loss = 2.34855 (* 1 = 2.34855 loss)
I0812 00:33:38.380136 26953 sgd_solver.cpp:106] Iteration 15360, lr = 0.01
I0812 00:33:56.729071 26953 solver.cpp:228] Iteration 15370, loss = 2.35941
I0812 00:33:56.729152 26953 solver.cpp:244]     Train net output #0: loss = 2.35941 (* 1 = 2.35941 loss)
I0812 00:33:58.130522 26953 sgd_solver.cpp:106] Iteration 15370, lr = 0.01
I0812 00:34:16.531937 26953 solver.cpp:228] Iteration 15380, loss = 2.23054
I0812 00:34:16.532156 26953 solver.cpp:244]     Train net output #0: loss = 2.23054 (* 1 = 2.23054 loss)
I0812 00:34:17.924823 26953 sgd_solver.cpp:106] Iteration 15380, lr = 0.01
I0812 00:34:36.322319 26953 solver.cpp:228] Iteration 15390, loss = 2.1892
I0812 00:34:36.322396 26953 solver.cpp:244]     Train net output #0: loss = 2.1892 (* 1 = 2.1892 loss)
I0812 00:34:37.736129 26953 sgd_solver.cpp:106] Iteration 15390, lr = 0.01
I0812 00:34:55.489883 26953 solver.cpp:337] Iteration 15400, Testing net (#0)
I0812 00:34:56.079018 26953 solver.cpp:404]     Test net output #0: accuracy = 0.482
I0812 00:34:56.079108 26953 solver.cpp:404]     Test net output #1: loss = 2.54393 (* 1 = 2.54393 loss)
I0812 00:34:56.645691 26953 solver.cpp:228] Iteration 15400, loss = 2.42771
I0812 00:34:56.645792 26953 solver.cpp:244]     Train net output #0: loss = 2.42771 (* 1 = 2.42771 loss)
I0812 00:34:58.045310 26953 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0812 00:35:16.446622 26953 solver.cpp:228] Iteration 15410, loss = 2.47884
I0812 00:35:16.446696 26953 solver.cpp:244]     Train net output #0: loss = 2.47884 (* 1 = 2.47884 loss)
I0812 00:35:17.840618 26953 sgd_solver.cpp:106] Iteration 15410, lr = 0.01
I0812 00:35:36.216951 26953 solver.cpp:228] Iteration 15420, loss = 2.51797
I0812 00:35:36.217109 26953 solver.cpp:244]     Train net output #0: loss = 2.51797 (* 1 = 2.51797 loss)
I0812 00:35:37.631124 26953 sgd_solver.cpp:106] Iteration 15420, lr = 0.01
I0812 00:35:55.971235 26953 solver.cpp:228] Iteration 15430, loss = 2.41377
I0812 00:35:55.971305 26953 solver.cpp:244]     Train net output #0: loss = 2.41377 (* 1 = 2.41377 loss)
I0812 00:35:57.369874 26953 sgd_solver.cpp:106] Iteration 15430, lr = 0.01
I0812 00:36:15.827044 26953 solver.cpp:228] Iteration 15440, loss = 2.41928
I0812 00:36:15.827294 26953 solver.cpp:244]     Train net output #0: loss = 2.41928 (* 1 = 2.41928 loss)
I0812 00:36:17.235563 26953 sgd_solver.cpp:106] Iteration 15440, lr = 0.01
I0812 00:36:35.621397 26953 solver.cpp:228] Iteration 15450, loss = 2.3357
I0812 00:36:35.621451 26953 solver.cpp:244]     Train net output #0: loss = 2.3357 (* 1 = 2.3357 loss)
I0812 00:36:37.027961 26953 sgd_solver.cpp:106] Iteration 15450, lr = 0.01
I0812 00:36:55.414119 26953 solver.cpp:228] Iteration 15460, loss = 2.17144
I0812 00:36:55.414366 26953 solver.cpp:244]     Train net output #0: loss = 2.17144 (* 1 = 2.17144 loss)
I0812 00:36:56.821609 26953 sgd_solver.cpp:106] Iteration 15460, lr = 0.01
I0812 00:37:15.259567 26953 solver.cpp:228] Iteration 15470, loss = 2.39882
I0812 00:37:15.259640 26953 solver.cpp:244]     Train net output #0: loss = 2.39882 (* 1 = 2.39882 loss)
I0812 00:37:16.659608 26953 sgd_solver.cpp:106] Iteration 15470, lr = 0.01
I0812 00:37:35.033520 26953 solver.cpp:228] Iteration 15480, loss = 2.31977
I0812 00:37:35.033679 26953 solver.cpp:244]     Train net output #0: loss = 2.31977 (* 1 = 2.31977 loss)
I0812 00:37:36.443367 26953 sgd_solver.cpp:106] Iteration 15480, lr = 0.01
I0812 00:37:54.782616 26953 solver.cpp:228] Iteration 15490, loss = 2.20237
I0812 00:37:54.782677 26953 solver.cpp:244]     Train net output #0: loss = 2.20237 (* 1 = 2.20237 loss)
I0812 00:37:56.175611 26953 sgd_solver.cpp:106] Iteration 15490, lr = 0.01
I0812 00:38:14.024816 26953 solver.cpp:337] Iteration 15500, Testing net (#0)
I0812 00:38:14.618552 26953 solver.cpp:404]     Test net output #0: accuracy = 0.494
I0812 00:38:14.618623 26953 solver.cpp:404]     Test net output #1: loss = 2.28475 (* 1 = 2.28475 loss)
I0812 00:38:15.218706 26953 solver.cpp:228] Iteration 15500, loss = 2.13483
I0812 00:38:15.218778 26953 solver.cpp:244]     Train net output #0: loss = 2.13483 (* 1 = 2.13483 loss)
I0812 00:38:16.579531 26953 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0812 00:38:36.104960 26953 solver.cpp:228] Iteration 15510, loss = 2.35209
I0812 00:38:36.105034 26953 solver.cpp:244]     Train net output #0: loss = 2.35209 (* 1 = 2.35209 loss)
I0812 00:38:37.511903 26953 sgd_solver.cpp:106] Iteration 15510, lr = 0.01
I0812 00:38:55.907131 26953 solver.cpp:228] Iteration 15520, loss = 2.2675
I0812 00:38:55.907282 26953 solver.cpp:244]     Train net output #0: loss = 2.2675 (* 1 = 2.2675 loss)
I0812 00:38:57.314844 26953 sgd_solver.cpp:106] Iteration 15520, lr = 0.01
I0812 00:39:15.727502 26953 solver.cpp:228] Iteration 15530, loss = 2.29564
I0812 00:39:15.727598 26953 solver.cpp:244]     Train net output #0: loss = 2.29564 (* 1 = 2.29564 loss)
I0812 00:39:17.126904 26953 sgd_solver.cpp:106] Iteration 15530, lr = 0.01
I0812 00:39:35.506181 26953 solver.cpp:228] Iteration 15540, loss = 2.42029
I0812 00:39:35.506387 26953 solver.cpp:244]     Train net output #0: loss = 2.42029 (* 1 = 2.42029 loss)
I0812 00:39:36.911263 26953 sgd_solver.cpp:106] Iteration 15540, lr = 0.01
I0812 00:39:55.286363 26953 solver.cpp:228] Iteration 15550, loss = 2.18255
I0812 00:39:55.286456 26953 solver.cpp:244]     Train net output #0: loss = 2.18255 (* 1 = 2.18255 loss)
I0812 00:39:56.692741 26953 sgd_solver.cpp:106] Iteration 15550, lr = 0.01
I0812 00:40:15.152887 26953 solver.cpp:228] Iteration 15560, loss = 2.34273
I0812 00:40:15.153090 26953 solver.cpp:244]     Train net output #0: loss = 2.34273 (* 1 = 2.34273 loss)
I0812 00:40:16.577018 26953 sgd_solver.cpp:106] Iteration 15560, lr = 0.01
I0812 00:40:34.955166 26953 solver.cpp:228] Iteration 15570, loss = 2.39911
I0812 00:40:34.955240 26953 solver.cpp:244]     Train net output #0: loss = 2.39911 (* 1 = 2.39911 loss)
I0812 00:40:36.373777 26953 sgd_solver.cpp:106] Iteration 15570, lr = 0.01
I0812 00:40:54.772519 26953 solver.cpp:228] Iteration 15580, loss = 2.38477
I0812 00:40:54.772760 26953 solver.cpp:244]     Train net output #0: loss = 2.38477 (* 1 = 2.38477 loss)
I0812 00:40:56.178725 26953 sgd_solver.cpp:106] Iteration 15580, lr = 0.01
I0812 00:41:14.576925 26953 solver.cpp:228] Iteration 15590, loss = 2.41846
I0812 00:41:14.576994 26953 solver.cpp:244]     Train net output #0: loss = 2.41846 (* 1 = 2.41846 loss)
I0812 00:41:15.980048 26953 sgd_solver.cpp:106] Iteration 15590, lr = 0.01
I0812 00:41:33.795322 26953 solver.cpp:337] Iteration 15600, Testing net (#0)
I0812 00:41:34.395603 26953 solver.cpp:404]     Test net output #0: accuracy = 0.448
I0812 00:41:34.395666 26953 solver.cpp:404]     Test net output #1: loss = 2.4546 (* 1 = 2.4546 loss)
I0812 00:41:34.962635 26953 solver.cpp:228] Iteration 15600, loss = 2.2826
I0812 00:41:34.962736 26953 solver.cpp:244]     Train net output #0: loss = 2.2826 (* 1 = 2.2826 loss)
I0812 00:41:36.353883 26953 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0812 00:41:54.720746 26953 solver.cpp:228] Iteration 15610, loss = 2.28558
I0812 00:41:54.720818 26953 solver.cpp:244]     Train net output #0: loss = 2.28558 (* 1 = 2.28558 loss)
I0812 00:41:56.103935 26953 sgd_solver.cpp:106] Iteration 15610, lr = 0.01
I0812 00:42:14.452189 26953 solver.cpp:228] Iteration 15620, loss = 2.17984
I0812 00:42:14.452394 26953 solver.cpp:244]     Train net output #0: loss = 2.17984 (* 1 = 2.17984 loss)
I0812 00:42:15.854024 26953 sgd_solver.cpp:106] Iteration 15620, lr = 0.01
I0812 00:42:34.232776 26953 solver.cpp:228] Iteration 15630, loss = 2.20723
I0812 00:42:34.232854 26953 solver.cpp:244]     Train net output #0: loss = 2.20723 (* 1 = 2.20723 loss)
I0812 00:42:35.632824 26953 sgd_solver.cpp:106] Iteration 15630, lr = 0.01
I0812 00:42:54.101853 26953 solver.cpp:228] Iteration 15640, loss = 2.27755
I0812 00:42:54.102087 26953 solver.cpp:244]     Train net output #0: loss = 2.27755 (* 1 = 2.27755 loss)
I0812 00:42:55.514106 26953 sgd_solver.cpp:106] Iteration 15640, lr = 0.01
I0812 00:43:13.852521 26953 solver.cpp:228] Iteration 15650, loss = 2.27092
I0812 00:43:13.852579 26953 solver.cpp:244]     Train net output #0: loss = 2.27092 (* 1 = 2.27092 loss)
I0812 00:43:15.259799 26953 sgd_solver.cpp:106] Iteration 15650, lr = 0.01
I0812 00:43:33.653185 26953 solver.cpp:228] Iteration 15660, loss = 2.35592
I0812 00:43:33.653362 26953 solver.cpp:244]     Train net output #0: loss = 2.35592 (* 1 = 2.35592 loss)
I0812 00:43:35.057466 26953 sgd_solver.cpp:106] Iteration 15660, lr = 0.01
I0812 00:43:53.457588 26953 solver.cpp:228] Iteration 15670, loss = 2.36655
I0812 00:43:53.457651 26953 solver.cpp:244]     Train net output #0: loss = 2.36655 (* 1 = 2.36655 loss)
I0812 00:43:54.880139 26953 sgd_solver.cpp:106] Iteration 15670, lr = 0.01
I0812 00:44:13.226608 26953 solver.cpp:228] Iteration 15680, loss = 2.28228
I0812 00:44:13.226836 26953 solver.cpp:244]     Train net output #0: loss = 2.28228 (* 1 = 2.28228 loss)
I0812 00:44:14.642915 26953 sgd_solver.cpp:106] Iteration 15680, lr = 0.01
I0812 00:44:33.037825 26953 solver.cpp:228] Iteration 15690, loss = 2.22725
I0812 00:44:33.037891 26953 solver.cpp:244]     Train net output #0: loss = 2.22725 (* 1 = 2.22725 loss)
I0812 00:44:34.438308 26953 sgd_solver.cpp:106] Iteration 15690, lr = 0.01
I0812 00:44:52.259464 26953 solver.cpp:337] Iteration 15700, Testing net (#0)
I0812 00:44:52.850626 26953 solver.cpp:404]     Test net output #0: accuracy = 0.49
I0812 00:44:52.850698 26953 solver.cpp:404]     Test net output #1: loss = 2.34647 (* 1 = 2.34647 loss)
I0812 00:44:53.412482 26953 solver.cpp:228] Iteration 15700, loss = 2.31274
I0812 00:44:53.412555 26953 solver.cpp:244]     Train net output #0: loss = 2.31274 (* 1 = 2.31274 loss)
I0812 00:44:54.799893 26953 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0812 00:45:13.210575 26953 solver.cpp:228] Iteration 15710, loss = 2.4241
I0812 00:45:13.210640 26953 solver.cpp:244]     Train net output #0: loss = 2.4241 (* 1 = 2.4241 loss)
I0812 00:45:14.604148 26953 sgd_solver.cpp:106] Iteration 15710, lr = 0.01
I0812 00:45:32.990504 26953 solver.cpp:228] Iteration 15720, loss = 2.19375
I0812 00:45:32.990754 26953 solver.cpp:244]     Train net output #0: loss = 2.19375 (* 1 = 2.19375 loss)
I0812 00:45:34.390172 26953 sgd_solver.cpp:106] Iteration 15720, lr = 0.01
I0812 00:45:52.724992 26953 solver.cpp:228] Iteration 15730, loss = 2.23241
I0812 00:45:52.725070 26953 solver.cpp:244]     Train net output #0: loss = 2.23241 (* 1 = 2.23241 loss)
I0812 00:45:54.129061 26953 sgd_solver.cpp:106] Iteration 15730, lr = 0.01
I0812 00:46:12.493587 26953 solver.cpp:228] Iteration 15740, loss = 2.2214
I0812 00:46:12.493886 26953 solver.cpp:244]     Train net output #0: loss = 2.2214 (* 1 = 2.2214 loss)
I0812 00:46:13.905241 26953 sgd_solver.cpp:106] Iteration 15740, lr = 0.01
I0812 00:46:32.332495 26953 solver.cpp:228] Iteration 15750, loss = 2.13878
I0812 00:46:32.332563 26953 solver.cpp:244]     Train net output #0: loss = 2.13878 (* 1 = 2.13878 loss)
I0812 00:46:33.738987 26953 sgd_solver.cpp:106] Iteration 15750, lr = 0.01
I0812 00:46:52.149785 26953 solver.cpp:228] Iteration 15760, loss = 2.35371
I0812 00:46:52.149953 26953 solver.cpp:244]     Train net output #0: loss = 2.35371 (* 1 = 2.35371 loss)
I0812 00:46:53.580391 26953 sgd_solver.cpp:106] Iteration 15760, lr = 0.01
I0812 00:47:11.946640 26953 solver.cpp:228] Iteration 15770, loss = 2.203
I0812 00:47:11.946698 26953 solver.cpp:244]     Train net output #0: loss = 2.203 (* 1 = 2.203 loss)
I0812 00:47:13.350644 26953 sgd_solver.cpp:106] Iteration 15770, lr = 0.01
I0812 00:47:31.767263 26953 solver.cpp:228] Iteration 15780, loss = 2.36386
I0812 00:47:31.767525 26953 solver.cpp:244]     Train net output #0: loss = 2.36386 (* 1 = 2.36386 loss)
I0812 00:47:33.188904 26953 sgd_solver.cpp:106] Iteration 15780, lr = 0.01
I0812 00:47:51.573799 26953 solver.cpp:228] Iteration 15790, loss = 2.31747
I0812 00:47:51.573859 26953 solver.cpp:244]     Train net output #0: loss = 2.31747 (* 1 = 2.31747 loss)
I0812 00:47:52.971990 26953 sgd_solver.cpp:106] Iteration 15790, lr = 0.01
I0812 00:48:10.823776 26953 solver.cpp:337] Iteration 15800, Testing net (#0)
I0812 00:48:11.420141 26953 solver.cpp:404]     Test net output #0: accuracy = 0.466
I0812 00:48:11.420208 26953 solver.cpp:404]     Test net output #1: loss = 2.38416 (* 1 = 2.38416 loss)
I0812 00:48:11.991369 26953 solver.cpp:228] Iteration 15800, loss = 2.51382
I0812 00:48:11.991437 26953 solver.cpp:244]     Train net output #0: loss = 2.51382 (* 1 = 2.51382 loss)
I0812 00:48:13.363569 26953 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0812 00:48:31.745084 26953 solver.cpp:228] Iteration 15810, loss = 2.26615
I0812 00:48:31.745164 26953 solver.cpp:244]     Train net output #0: loss = 2.26615 (* 1 = 2.26615 loss)
I0812 00:48:33.166033 26953 sgd_solver.cpp:106] Iteration 15810, lr = 0.01
I0812 00:48:51.594064 26953 solver.cpp:228] Iteration 15820, loss = 2.20242
I0812 00:48:51.594318 26953 solver.cpp:244]     Train net output #0: loss = 2.20242 (* 1 = 2.20242 loss)
I0812 00:48:52.985186 26953 sgd_solver.cpp:106] Iteration 15820, lr = 0.01
I0812 00:49:11.363457 26953 solver.cpp:228] Iteration 15830, loss = 2.19107
I0812 00:49:11.363513 26953 solver.cpp:244]     Train net output #0: loss = 2.19107 (* 1 = 2.19107 loss)
I0812 00:49:12.778560 26953 sgd_solver.cpp:106] Iteration 15830, lr = 0.01
I0812 00:49:31.123004 26953 solver.cpp:228] Iteration 15840, loss = 2.31306
I0812 00:49:31.123162 26953 solver.cpp:244]     Train net output #0: loss = 2.31306 (* 1 = 2.31306 loss)
I0812 00:49:32.523762 26953 sgd_solver.cpp:106] Iteration 15840, lr = 0.01
I0812 00:49:50.933524 26953 solver.cpp:228] Iteration 15850, loss = 2.11229
I0812 00:49:50.933607 26953 solver.cpp:244]     Train net output #0: loss = 2.11229 (* 1 = 2.11229 loss)
I0812 00:49:52.311764 26953 sgd_solver.cpp:106] Iteration 15850, lr = 0.01
I0812 00:50:10.706058 26953 solver.cpp:228] Iteration 15860, loss = 2.31394
I0812 00:50:10.706256 26953 solver.cpp:244]     Train net output #0: loss = 2.31394 (* 1 = 2.31394 loss)
I0812 00:50:12.127632 26953 sgd_solver.cpp:106] Iteration 15860, lr = 0.01
I0812 00:50:30.502856 26953 solver.cpp:228] Iteration 15870, loss = 2.21629
I0812 00:50:30.502943 26953 solver.cpp:244]     Train net output #0: loss = 2.21629 (* 1 = 2.21629 loss)
I0812 00:50:31.895236 26953 sgd_solver.cpp:106] Iteration 15870, lr = 0.01
I0812 00:50:50.310470 26953 solver.cpp:228] Iteration 15880, loss = 2.24695
I0812 00:50:50.310677 26953 solver.cpp:244]     Train net output #0: loss = 2.24695 (* 1 = 2.24695 loss)
I0812 00:50:51.707482 26953 sgd_solver.cpp:106] Iteration 15880, lr = 0.01
I0812 00:51:10.121135 26953 solver.cpp:228] Iteration 15890, loss = 2.29438
I0812 00:51:10.121213 26953 solver.cpp:244]     Train net output #0: loss = 2.29438 (* 1 = 2.29438 loss)
I0812 00:51:11.515373 26953 sgd_solver.cpp:106] Iteration 15890, lr = 0.01
I0812 00:51:29.326176 26953 solver.cpp:337] Iteration 15900, Testing net (#0)
I0812 00:51:29.917172 26953 solver.cpp:404]     Test net output #0: accuracy = 0.502
I0812 00:51:29.917243 26953 solver.cpp:404]     Test net output #1: loss = 2.24976 (* 1 = 2.24976 loss)
I0812 00:51:30.497257 26953 solver.cpp:228] Iteration 15900, loss = 2.09633
I0812 00:51:30.497355 26953 solver.cpp:244]     Train net output #0: loss = 2.09633 (* 1 = 2.09633 loss)
I0812 00:51:31.857914 26953 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0812 00:51:50.256702 26953 solver.cpp:228] Iteration 15910, loss = 2.25981
I0812 00:51:50.256762 26953 solver.cpp:244]     Train net output #0: loss = 2.25981 (* 1 = 2.25981 loss)
I0812 00:51:51.645068 26953 sgd_solver.cpp:106] Iteration 15910, lr = 0.01
I0812 00:52:10.023908 26953 solver.cpp:228] Iteration 15920, loss = 2.53705
I0812 00:52:10.024062 26953 solver.cpp:244]     Train net output #0: loss = 2.53705 (* 1 = 2.53705 loss)
I0812 00:52:11.441730 26953 sgd_solver.cpp:106] Iteration 15920, lr = 0.01
I0812 00:52:29.900578 26953 solver.cpp:228] Iteration 15930, loss = 2.16786
I0812 00:52:29.900655 26953 solver.cpp:244]     Train net output #0: loss = 2.16786 (* 1 = 2.16786 loss)
I0812 00:52:31.304198 26953 sgd_solver.cpp:106] Iteration 15930, lr = 0.01
I0812 00:52:49.656805 26953 solver.cpp:228] Iteration 15940, loss = 2.40931
I0812 00:52:49.657047 26953 solver.cpp:244]     Train net output #0: loss = 2.40931 (* 1 = 2.40931 loss)
I0812 00:52:51.081985 26953 sgd_solver.cpp:106] Iteration 15940, lr = 0.01
I0812 00:53:09.447079 26953 solver.cpp:228] Iteration 15950, loss = 2.18806
I0812 00:53:09.447161 26953 solver.cpp:244]     Train net output #0: loss = 2.18806 (* 1 = 2.18806 loss)
I0812 00:53:10.840281 26953 sgd_solver.cpp:106] Iteration 15950, lr = 0.01
I0812 00:53:29.261525 26953 solver.cpp:228] Iteration 15960, loss = 2.277
I0812 00:53:29.261716 26953 solver.cpp:244]     Train net output #0: loss = 2.277 (* 1 = 2.277 loss)
I0812 00:53:30.663470 26953 sgd_solver.cpp:106] Iteration 15960, lr = 0.01
I0812 00:53:49.050030 26953 solver.cpp:228] Iteration 15970, loss = 2.09805
I0812 00:53:49.050112 26953 solver.cpp:244]     Train net output #0: loss = 2.09805 (* 1 = 2.09805 loss)
I0812 00:53:50.454934 26953 sgd_solver.cpp:106] Iteration 15970, lr = 0.01
I0812 00:54:08.902146 26953 solver.cpp:228] Iteration 15980, loss = 2.19339
I0812 00:54:08.902334 26953 solver.cpp:244]     Train net output #0: loss = 2.19339 (* 1 = 2.19339 loss)
I0812 00:54:10.296632 26953 sgd_solver.cpp:106] Iteration 15980, lr = 0.01
I0812 00:54:28.643399 26953 solver.cpp:228] Iteration 15990, loss = 2.3152
I0812 00:54:28.643471 26953 solver.cpp:244]     Train net output #0: loss = 2.3152 (* 1 = 2.3152 loss)
I0812 00:54:30.059633 26953 sgd_solver.cpp:106] Iteration 15990, lr = 0.01
I0812 00:54:47.850958 26953 solver.cpp:337] Iteration 16000, Testing net (#0)
I0812 00:54:48.435045 26953 solver.cpp:404]     Test net output #0: accuracy = 0.5
I0812 00:54:48.435098 26953 solver.cpp:404]     Test net output #1: loss = 2.36458 (* 1 = 2.36458 loss)
I0812 00:54:49.004009 26953 solver.cpp:228] Iteration 16000, loss = 2.17692
I0812 00:54:49.004087 26953 solver.cpp:244]     Train net output #0: loss = 2.17692 (* 1 = 2.17692 loss)
I0812 00:54:50.377264 26953 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0812 00:55:08.782205 26953 solver.cpp:228] Iteration 16010, loss = 2.21174
I0812 00:55:08.782281 26953 solver.cpp:244]     Train net output #0: loss = 2.21174 (* 1 = 2.21174 loss)
I0812 00:55:10.188001 26953 sgd_solver.cpp:106] Iteration 16010, lr = 0.01
I0812 00:55:28.589627 26953 solver.cpp:228] Iteration 16020, loss = 2.23987
I0812 00:55:28.589905 26953 solver.cpp:244]     Train net output #0: loss = 2.23987 (* 1 = 2.23987 loss)
I0812 00:55:30.009996 26953 sgd_solver.cpp:106] Iteration 16020, lr = 0.01
I0812 00:55:48.394943 26953 solver.cpp:228] Iteration 16030, loss = 2.02438
I0812 00:55:48.395026 26953 solver.cpp:244]     Train net output #0: loss = 2.02438 (* 1 = 2.02438 loss)
I0812 00:55:49.792820 26953 sgd_solver.cpp:106] Iteration 16030, lr = 0.01
I0812 00:56:08.222158 26953 solver.cpp:228] Iteration 16040, loss = 2.33977
I0812 00:56:08.222379 26953 solver.cpp:244]     Train net output #0: loss = 2.33977 (* 1 = 2.33977 loss)
I0812 00:56:09.624373 26953 sgd_solver.cpp:106] Iteration 16040, lr = 0.01
I0812 00:56:27.989773 26953 solver.cpp:228] Iteration 16050, loss = 2.26633
I0812 00:56:27.989857 26953 solver.cpp:244]     Train net output #0: loss = 2.26633 (* 1 = 2.26633 loss)
I0812 00:56:29.401958 26953 sgd_solver.cpp:106] Iteration 16050, lr = 0.01
I0812 00:56:47.791954 26953 solver.cpp:228] Iteration 16060, loss = 2.20463
I0812 00:56:47.792201 26953 solver.cpp:244]     Train net output #0: loss = 2.20463 (* 1 = 2.20463 loss)
I0812 00:56:49.186678 26953 sgd_solver.cpp:106] Iteration 16060, lr = 0.01
I0812 00:57:07.558156 26953 solver.cpp:228] Iteration 16070, loss = 2.55206
I0812 00:57:07.558215 26953 solver.cpp:244]     Train net output #0: loss = 2.55206 (* 1 = 2.55206 loss)
I0812 00:57:08.951871 26953 sgd_solver.cpp:106] Iteration 16070, lr = 0.01
I0812 00:57:27.346267 26953 solver.cpp:228] Iteration 16080, loss = 2.17945
I0812 00:57:27.346511 26953 solver.cpp:244]     Train net output #0: loss = 2.17945 (* 1 = 2.17945 loss)
I0812 00:57:28.764216 26953 sgd_solver.cpp:106] Iteration 16080, lr = 0.01
I0812 00:57:47.223623 26953 solver.cpp:228] Iteration 16090, loss = 2.27917
I0812 00:57:47.223713 26953 solver.cpp:244]     Train net output #0: loss = 2.27917 (* 1 = 2.27917 loss)
I0812 00:57:48.628053 26953 sgd_solver.cpp:106] Iteration 16090, lr = 0.01
I0812 00:58:06.425382 26953 solver.cpp:337] Iteration 16100, Testing net (#0)
I0812 00:58:07.014920 26953 solver.cpp:404]     Test net output #0: accuracy = 0.492
I0812 00:58:07.014986 26953 solver.cpp:404]     Test net output #1: loss = 2.26303 (* 1 = 2.26303 loss)
I0812 00:58:07.582360 26953 solver.cpp:228] Iteration 16100, loss = 2.23728
I0812 00:58:07.582439 26953 solver.cpp:244]     Train net output #0: loss = 2.23728 (* 1 = 2.23728 loss)
I0812 00:58:08.968842 26953 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0812 00:58:27.418601 26953 solver.cpp:228] Iteration 16110, loss = 2.35869
I0812 00:58:27.418694 26953 solver.cpp:244]     Train net output #0: loss = 2.35869 (* 1 = 2.35869 loss)
I0812 00:58:28.818246 26953 sgd_solver.cpp:106] Iteration 16110, lr = 0.01
I0812 00:58:47.208315 26953 solver.cpp:228] Iteration 16120, loss = 2.29548
I0812 00:58:47.208557 26953 solver.cpp:244]     Train net output #0: loss = 2.29548 (* 1 = 2.29548 loss)
I0812 00:58:48.602227 26953 sgd_solver.cpp:106] Iteration 16120, lr = 0.01
I0812 00:59:06.942636 26953 solver.cpp:228] Iteration 16130, loss = 2.22012
I0812 00:59:06.942708 26953 solver.cpp:244]     Train net output #0: loss = 2.22012 (* 1 = 2.22012 loss)
I0812 00:59:08.356629 26953 sgd_solver.cpp:106] Iteration 16130, lr = 0.01
I0812 00:59:26.819437 26953 solver.cpp:228] Iteration 16140, loss = 2.09517
I0812 00:59:26.819682 26953 solver.cpp:244]     Train net output #0: loss = 2.09517 (* 1 = 2.09517 loss)
I0812 00:59:28.221009 26953 sgd_solver.cpp:106] Iteration 16140, lr = 0.01
I0812 00:59:46.582638 26953 solver.cpp:228] Iteration 16150, loss = 2.35429
I0812 00:59:46.582728 26953 solver.cpp:244]     Train net output #0: loss = 2.35429 (* 1 = 2.35429 loss)
I0812 00:59:47.980103 26953 sgd_solver.cpp:106] Iteration 16150, lr = 0.01
I0812 01:00:06.382576 26953 solver.cpp:228] Iteration 16160, loss = 2.19717
I0812 01:00:06.382807 26953 solver.cpp:244]     Train net output #0: loss = 2.19717 (* 1 = 2.19717 loss)
I0812 01:00:07.786531 26953 sgd_solver.cpp:106] Iteration 16160, lr = 0.01
I0812 01:00:26.183585 26953 solver.cpp:228] Iteration 16170, loss = 2.44308
I0812 01:00:26.183657 26953 solver.cpp:244]     Train net output #0: loss = 2.44308 (* 1 = 2.44308 loss)
I0812 01:00:27.600199 26953 sgd_solver.cpp:106] Iteration 16170, lr = 0.01
I0812 01:00:45.986994 26953 solver.cpp:228] Iteration 16180, loss = 2.31224
I0812 01:00:45.987198 26953 solver.cpp:244]     Train net output #0: loss = 2.31224 (* 1 = 2.31224 loss)
I0812 01:00:47.376533 26953 sgd_solver.cpp:106] Iteration 16180, lr = 0.01
I0812 01:01:05.736517 26953 solver.cpp:228] Iteration 16190, loss = 2.3626
I0812 01:01:05.736588 26953 solver.cpp:244]     Train net output #0: loss = 2.3626 (* 1 = 2.3626 loss)
I0812 01:01:07.124814 26953 sgd_solver.cpp:106] Iteration 16190, lr = 0.01
I0812 01:01:24.939929 26953 solver.cpp:337] Iteration 16200, Testing net (#0)
I0812 01:01:25.528748 26953 solver.cpp:404]     Test net output #0: accuracy = 0.484
I0812 01:01:25.528805 26953 solver.cpp:404]     Test net output #1: loss = 2.21589 (* 1 = 2.21589 loss)
I0812 01:01:26.099581 26953 solver.cpp:228] Iteration 16200, loss = 2.26836
I0812 01:01:26.099663 26953 solver.cpp:244]     Train net output #0: loss = 2.26836 (* 1 = 2.26836 loss)
I0812 01:01:27.482918 26953 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0812 01:01:45.871651 26953 solver.cpp:228] Iteration 16210, loss = 2.2
I0812 01:01:45.871726 26953 solver.cpp:244]     Train net output #0: loss = 2.2 (* 1 = 2.2 loss)
I0812 01:01:47.289324 26953 sgd_solver.cpp:106] Iteration 16210, lr = 0.01
I0812 01:02:05.712224 26953 solver.cpp:228] Iteration 16220, loss = 2.36227
I0812 01:02:05.712373 26953 solver.cpp:244]     Train net output #0: loss = 2.36227 (* 1 = 2.36227 loss)
I0812 01:02:07.109261 26953 sgd_solver.cpp:106] Iteration 16220, lr = 0.01
I0812 01:02:25.504411 26953 solver.cpp:228] Iteration 16230, loss = 2.19615
I0812 01:02:25.504482 26953 solver.cpp:244]     Train net output #0: loss = 2.19615 (* 1 = 2.19615 loss)
I0812 01:02:26.936529 26953 sgd_solver.cpp:106] Iteration 16230, lr = 0.01
I0812 01:02:45.328274 26953 solver.cpp:228] Iteration 16240, loss = 2.2501
I0812 01:02:45.328451 26953 solver.cpp:244]     Train net output #0: loss = 2.2501 (* 1 = 2.2501 loss)
I0812 01:02:46.730581 26953 sgd_solver.cpp:106] Iteration 16240, lr = 0.01
I0812 01:03:05.143486 26953 solver.cpp:228] Iteration 16250, loss = 2.23728
I0812 01:03:05.143554 26953 solver.cpp:244]     Train net output #0: loss = 2.23728 (* 1 = 2.23728 loss)
I0812 01:03:06.556239 26953 sgd_solver.cpp:106] Iteration 16250, lr = 0.01
I0812 01:03:24.916364 26953 solver.cpp:228] Iteration 16260, loss = 2.15346
I0812 01:03:24.916594 26953 solver.cpp:244]     Train net output #0: loss = 2.15346 (* 1 = 2.15346 loss)
I0812 01:03:26.284118 26953 sgd_solver.cpp:106] Iteration 16260, lr = 0.01
I0812 01:03:44.647033 26953 solver.cpp:228] Iteration 16270, loss = 2.35196
I0812 01:03:44.647090 26953 solver.cpp:244]     Train net output #0: loss = 2.35196 (* 1 = 2.35196 loss)
I0812 01:03:46.042979 26953 sgd_solver.cpp:106] Iteration 16270, lr = 0.01
I0812 01:04:04.483878 26953 solver.cpp:228] Iteration 16280, loss = 2.2076
I0812 01:04:04.484125 26953 solver.cpp:244]     Train net output #0: loss = 2.2076 (* 1 = 2.2076 loss)
I0812 01:04:05.896463 26953 sgd_solver.cpp:106] Iteration 16280, lr = 0.01
I0812 01:04:24.238066 26953 solver.cpp:228] Iteration 16290, loss = 2.19704
I0812 01:04:24.238144 26953 solver.cpp:244]     Train net output #0: loss = 2.19704 (* 1 = 2.19704 loss)
I0812 01:04:25.655755 26953 sgd_solver.cpp:106] Iteration 16290, lr = 0.01
I0812 01:04:43.469471 26953 solver.cpp:337] Iteration 16300, Testing net (#0)
I0812 01:04:44.061008 26953 solver.cpp:404]     Test net output #0: accuracy = 0.486
I0812 01:04:44.061070 26953 solver.cpp:404]     Test net output #1: loss = 2.31796 (* 1 = 2.31796 loss)
I0812 01:04:44.640416 26953 solver.cpp:228] Iteration 16300, loss = 2.24745
I0812 01:04:44.640483 26953 solver.cpp:244]     Train net output #0: loss = 2.24745 (* 1 = 2.24745 loss)
I0812 01:04:45.995353 26953 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0812 01:05:04.436756 26953 solver.cpp:228] Iteration 16310, loss = 2.33059
I0812 01:05:04.436836 26953 solver.cpp:244]     Train net output #0: loss = 2.33059 (* 1 = 2.33059 loss)
I0812 01:05:05.842579 26953 sgd_solver.cpp:106] Iteration 16310, lr = 0.01
I0812 01:05:24.202633 26953 solver.cpp:228] Iteration 16320, loss = 2.20177
I0812 01:05:24.202868 26953 solver.cpp:244]     Train net output #0: loss = 2.20177 (* 1 = 2.20177 loss)
I0812 01:05:25.612887 26953 sgd_solver.cpp:106] Iteration 16320, lr = 0.01
I0812 01:05:44.064419 26953 solver.cpp:228] Iteration 16330, loss = 2.30534
I0812 01:05:44.064496 26953 solver.cpp:244]     Train net output #0: loss = 2.30534 (* 1 = 2.30534 loss)
I0812 01:05:45.459764 26953 sgd_solver.cpp:106] Iteration 16330, lr = 0.01
I0812 01:06:03.808192 26953 solver.cpp:228] Iteration 16340, loss = 2.23401
I0812 01:06:03.808431 26953 solver.cpp:244]     Train net output #0: loss = 2.23401 (* 1 = 2.23401 loss)
I0812 01:06:05.216915 26953 sgd_solver.cpp:106] Iteration 16340, lr = 0.01
I0812 01:06:23.589154 26953 solver.cpp:228] Iteration 16350, loss = 2.28324
I0812 01:06:23.589227 26953 solver.cpp:244]     Train net output #0: loss = 2.28324 (* 1 = 2.28324 loss)
I0812 01:06:25.006438 26953 sgd_solver.cpp:106] Iteration 16350, lr = 0.01
I0812 01:06:43.418479 26953 solver.cpp:228] Iteration 16360, loss = 2.33389
I0812 01:06:43.418736 26953 solver.cpp:244]     Train net output #0: loss = 2.33389 (* 1 = 2.33389 loss)
I0812 01:06:44.820021 26953 sgd_solver.cpp:106] Iteration 16360, lr = 0.01
I0812 01:07:03.175509 26953 solver.cpp:228] Iteration 16370, loss = 2.29781
I0812 01:07:03.175571 26953 solver.cpp:244]     Train net output #0: loss = 2.29781 (* 1 = 2.29781 loss)
I0812 01:07:04.580623 26953 sgd_solver.cpp:106] Iteration 16370, lr = 0.01
I0812 01:07:22.925257 26953 solver.cpp:228] Iteration 16380, loss = 2.09898
I0812 01:07:22.925393 26953 solver.cpp:244]     Train net output #0: loss = 2.09898 (* 1 = 2.09898 loss)
I0812 01:07:24.335304 26953 sgd_solver.cpp:106] Iteration 16380, lr = 0.01
I0812 01:07:42.770885 26953 solver.cpp:228] Iteration 16390, loss = 2.19461
I0812 01:07:42.770953 26953 solver.cpp:244]     Train net output #0: loss = 2.19461 (* 1 = 2.19461 loss)
I0812 01:07:44.173437 26953 sgd_solver.cpp:106] Iteration 16390, lr = 0.01
I0812 01:08:01.981113 26953 solver.cpp:337] Iteration 16400, Testing net (#0)
I0812 01:08:02.564906 26953 solver.cpp:404]     Test net output #0: accuracy = 0.51
I0812 01:08:02.564970 26953 solver.cpp:404]     Test net output #1: loss = 2.18115 (* 1 = 2.18115 loss)
I0812 01:08:03.156055 26953 solver.cpp:228] Iteration 16400, loss = 2.45151
I0812 01:08:03.156141 26953 solver.cpp:244]     Train net output #0: loss = 2.45151 (* 1 = 2.45151 loss)
I0812 01:08:04.528837 26953 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0812 01:08:23.005491 26953 solver.cpp:228] Iteration 16410, loss = 2.13707
I0812 01:08:23.005550 26953 solver.cpp:244]     Train net output #0: loss = 2.13707 (* 1 = 2.13707 loss)
I0812 01:08:24.398164 26953 sgd_solver.cpp:106] Iteration 16410, lr = 0.01
I0812 01:08:42.772225 26953 solver.cpp:228] Iteration 16420, loss = 2.24804
I0812 01:08:42.772377 26953 solver.cpp:244]     Train net output #0: loss = 2.24804 (* 1 = 2.24804 loss)
I0812 01:08:44.184089 26953 sgd_solver.cpp:106] Iteration 16420, lr = 0.01
I0812 01:09:02.564414 26953 solver.cpp:228] Iteration 16430, loss = 2.42866
I0812 01:09:02.564483 26953 solver.cpp:244]     Train net output #0: loss = 2.42866 (* 1 = 2.42866 loss)
I0812 01:09:03.959493 26953 sgd_solver.cpp:106] Iteration 16430, lr = 0.01
I0812 01:09:22.391324 26953 solver.cpp:228] Iteration 16440, loss = 2.19893
I0812 01:09:22.391578 26953 solver.cpp:244]     Train net output #0: loss = 2.19893 (* 1 = 2.19893 loss)
I0812 01:09:23.800000 26953 sgd_solver.cpp:106] Iteration 16440, lr = 0.01
I0812 01:09:42.148911 26953 solver.cpp:228] Iteration 16450, loss = 2.22923
I0812 01:09:42.148995 26953 solver.cpp:244]     Train net output #0: loss = 2.22923 (* 1 = 2.22923 loss)
I0812 01:09:43.553385 26953 sgd_solver.cpp:106] Iteration 16450, lr = 0.01
I0812 01:10:01.963981 26953 solver.cpp:228] Iteration 16460, loss = 2.45658
I0812 01:10:01.964179 26953 solver.cpp:244]     Train net output #0: loss = 2.45658 (* 1 = 2.45658 loss)
I0812 01:10:03.359354 26953 sgd_solver.cpp:106] Iteration 16460, lr = 0.01
I0812 01:10:21.763767 26953 solver.cpp:228] Iteration 16470, loss = 2.11856
I0812 01:10:21.763841 26953 solver.cpp:244]     Train net output #0: loss = 2.11856 (* 1 = 2.11856 loss)
I0812 01:10:23.175155 26953 sgd_solver.cpp:106] Iteration 16470, lr = 0.01
I0812 01:10:41.571970 26953 solver.cpp:228] Iteration 16480, loss = 2.18312
I0812 01:10:41.572207 26953 solver.cpp:244]     Train net output #0: loss = 2.18312 (* 1 = 2.18312 loss)
I0812 01:10:42.959295 26953 sgd_solver.cpp:106] Iteration 16480, lr = 0.01
I0812 01:11:01.338240 26953 solver.cpp:228] Iteration 16490, loss = 2.18626
I0812 01:11:01.338300 26953 solver.cpp:244]     Train net output #0: loss = 2.18626 (* 1 = 2.18626 loss)
I0812 01:11:02.730680 26953 sgd_solver.cpp:106] Iteration 16490, lr = 0.01
I0812 01:11:20.569737 26953 solver.cpp:337] Iteration 16500, Testing net (#0)
I0812 01:11:21.160372 26953 solver.cpp:404]     Test net output #0: accuracy = 0.514
I0812 01:11:21.160444 26953 solver.cpp:404]     Test net output #1: loss = 2.14273 (* 1 = 2.14273 loss)
I0812 01:11:21.729387 26953 solver.cpp:228] Iteration 16500, loss = 2.3513
I0812 01:11:21.729460 26953 solver.cpp:244]     Train net output #0: loss = 2.3513 (* 1 = 2.3513 loss)
I0812 01:11:23.114281 26953 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0812 01:11:41.450826 26953 solver.cpp:228] Iteration 16510, loss = 2.20568
I0812 01:11:41.450886 26953 solver.cpp:244]     Train net output #0: loss = 2.20568 (* 1 = 2.20568 loss)
I0812 01:11:42.853642 26953 sgd_solver.cpp:106] Iteration 16510, lr = 0.01
I0812 01:12:01.237699 26953 solver.cpp:228] Iteration 16520, loss = 2.092
I0812 01:12:01.237889 26953 solver.cpp:244]     Train net output #0: loss = 2.092 (* 1 = 2.092 loss)
I0812 01:12:02.643225 26953 sgd_solver.cpp:106] Iteration 16520, lr = 0.01
I0812 01:12:21.069913 26953 solver.cpp:228] Iteration 16530, loss = 2.43108
I0812 01:12:21.069975 26953 solver.cpp:244]     Train net output #0: loss = 2.43108 (* 1 = 2.43108 loss)
I0812 01:12:22.498461 26953 sgd_solver.cpp:106] Iteration 16530, lr = 0.01
I0812 01:12:40.892658 26953 solver.cpp:228] Iteration 16540, loss = 2.29861
I0812 01:12:40.892851 26953 solver.cpp:244]     Train net output #0: loss = 2.29861 (* 1 = 2.29861 loss)
I0812 01:12:42.303521 26953 sgd_solver.cpp:106] Iteration 16540, lr = 0.01
I0812 01:13:00.713908 26953 solver.cpp:228] Iteration 16550, loss = 2.10351
I0812 01:13:00.713978 26953 solver.cpp:244]     Train net output #0: loss = 2.10351 (* 1 = 2.10351 loss)
I0812 01:13:02.122259 26953 sgd_solver.cpp:106] Iteration 16550, lr = 0.01
I0812 01:13:20.485368 26953 solver.cpp:228] Iteration 16560, loss = 2.19286
I0812 01:13:20.485563 26953 solver.cpp:244]     Train net output #0: loss = 2.19286 (* 1 = 2.19286 loss)
I0812 01:13:21.888660 26953 sgd_solver.cpp:106] Iteration 16560, lr = 0.01
I0812 01:13:40.283578 26953 solver.cpp:228] Iteration 16570, loss = 2.16106
I0812 01:13:40.283639 26953 solver.cpp:244]     Train net output #0: loss = 2.16106 (* 1 = 2.16106 loss)
I0812 01:13:41.681149 26953 sgd_solver.cpp:106] Iteration 16570, lr = 0.01
I0812 01:14:00.046661 26953 solver.cpp:228] Iteration 16580, loss = 2.32819
I0812 01:14:00.046810 26953 solver.cpp:244]     Train net output #0: loss = 2.32819 (* 1 = 2.32819 loss)
I0812 01:14:01.453362 26953 sgd_solver.cpp:106] Iteration 16580, lr = 0.01
I0812 01:14:19.828459 26953 solver.cpp:228] Iteration 16590, loss = 2.25617
I0812 01:14:19.828538 26953 solver.cpp:244]     Train net output #0: loss = 2.25617 (* 1 = 2.25617 loss)
I0812 01:14:21.238620 26953 sgd_solver.cpp:106] Iteration 16590, lr = 0.01
I0812 01:14:39.034212 26953 solver.cpp:337] Iteration 16600, Testing net (#0)
I0812 01:14:39.624694 26953 solver.cpp:404]     Test net output #0: accuracy = 0.556
I0812 01:14:39.624763 26953 solver.cpp:404]     Test net output #1: loss = 2.03957 (* 1 = 2.03957 loss)
I0812 01:14:40.207799 26953 solver.cpp:228] Iteration 16600, loss = 2.34433
I0812 01:14:40.207875 26953 solver.cpp:244]     Train net output #0: loss = 2.34433 (* 1 = 2.34433 loss)
I0812 01:14:41.559892 26953 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0812 01:14:59.990031 26953 solver.cpp:228] Iteration 16610, loss = 2.19459
I0812 01:14:59.990103 26953 solver.cpp:244]     Train net output #0: loss = 2.19459 (* 1 = 2.19459 loss)
I0812 01:15:01.378762 26953 sgd_solver.cpp:106] Iteration 16610, lr = 0.01
I0812 01:15:19.751291 26953 solver.cpp:228] Iteration 16620, loss = 2.13452
I0812 01:15:19.751583 26953 solver.cpp:244]     Train net output #0: loss = 2.13452 (* 1 = 2.13452 loss)
I0812 01:15:21.163069 26953 sgd_solver.cpp:106] Iteration 16620, lr = 0.01
I0812 01:15:39.536460 26953 solver.cpp:228] Iteration 16630, loss = 2.53202
I0812 01:15:39.536540 26953 solver.cpp:244]     Train net output #0: loss = 2.53202 (* 1 = 2.53202 loss)
I0812 01:15:40.933115 26953 sgd_solver.cpp:106] Iteration 16630, lr = 0.01
I0812 01:15:59.368465 26953 solver.cpp:228] Iteration 16640, loss = 2.28244
I0812 01:15:59.368623 26953 solver.cpp:244]     Train net output #0: loss = 2.28244 (* 1 = 2.28244 loss)
I0812 01:16:00.786103 26953 sgd_solver.cpp:106] Iteration 16640, lr = 0.01
I0812 01:16:19.141885 26953 solver.cpp:228] Iteration 16650, loss = 2.28337
I0812 01:16:19.141945 26953 solver.cpp:244]     Train net output #0: loss = 2.28337 (* 1 = 2.28337 loss)
I0812 01:16:20.557847 26953 sgd_solver.cpp:106] Iteration 16650, lr = 0.01
I0812 01:16:38.932829 26953 solver.cpp:228] Iteration 16660, loss = 2.34816
I0812 01:16:38.933728 26953 solver.cpp:244]     Train net output #0: loss = 2.34816 (* 1 = 2.34816 loss)
I0812 01:16:40.326896 26953 sgd_solver.cpp:106] Iteration 16660, lr = 0.01
I0812 01:16:58.746640 26953 solver.cpp:228] Iteration 16670, loss = 2.47109
I0812 01:16:58.746724 26953 solver.cpp:244]     Train net output #0: loss = 2.47109 (* 1 = 2.47109 loss)
I0812 01:17:00.150147 26953 sgd_solver.cpp:106] Iteration 16670, lr = 0.01
I0812 01:17:18.507436 26953 solver.cpp:228] Iteration 16680, loss = 2.23853
I0812 01:17:18.507689 26953 solver.cpp:244]     Train net output #0: loss = 2.23853 (* 1 = 2.23853 loss)
I0812 01:17:19.908957 26953 sgd_solver.cpp:106] Iteration 16680, lr = 0.01
I0812 01:17:38.314841 26953 solver.cpp:228] Iteration 16690, loss = 2.18688
I0812 01:17:38.314921 26953 solver.cpp:244]     Train net output #0: loss = 2.18688 (* 1 = 2.18688 loss)
I0812 01:17:39.706079 26953 sgd_solver.cpp:106] Iteration 16690, lr = 0.01
I0812 01:17:57.509809 26953 solver.cpp:337] Iteration 16700, Testing net (#0)
I0812 01:17:58.103729 26953 solver.cpp:404]     Test net output #0: accuracy = 0.512
I0812 01:17:58.103814 26953 solver.cpp:404]     Test net output #1: loss = 2.08508 (* 1 = 2.08508 loss)
I0812 01:17:58.681143 26953 solver.cpp:228] Iteration 16700, loss = 2.30795
I0812 01:17:58.681241 26953 solver.cpp:244]     Train net output #0: loss = 2.30795 (* 1 = 2.30795 loss)
I0812 01:18:00.049195 26953 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0812 01:18:18.465193 26953 solver.cpp:228] Iteration 16710, loss = 2.38112
I0812 01:18:18.465273 26953 solver.cpp:244]     Train net output #0: loss = 2.38112 (* 1 = 2.38112 loss)
I0812 01:18:19.875138 26953 sgd_solver.cpp:106] Iteration 16710, lr = 0.01
I0812 01:18:38.289666 26953 solver.cpp:228] Iteration 16720, loss = 2.05591
I0812 01:18:38.289885 26953 solver.cpp:244]     Train net output #0: loss = 2.05591 (* 1 = 2.05591 loss)
I0812 01:18:39.695127 26953 sgd_solver.cpp:106] Iteration 16720, lr = 0.01
I0812 01:18:58.086951 26953 solver.cpp:228] Iteration 16730, loss = 2.2561
I0812 01:18:58.087033 26953 solver.cpp:244]     Train net output #0: loss = 2.2561 (* 1 = 2.2561 loss)
I0812 01:18:59.497566 26953 sgd_solver.cpp:106] Iteration 16730, lr = 0.01
I0812 01:19:17.962566 26953 solver.cpp:228] Iteration 16740, loss = 2.20752
I0812 01:19:17.962790 26953 solver.cpp:244]     Train net output #0: loss = 2.20752 (* 1 = 2.20752 loss)
I0812 01:19:19.370226 26953 sgd_solver.cpp:106] Iteration 16740, lr = 0.01
I0812 01:19:37.705189 26953 solver.cpp:228] Iteration 16750, loss = 2.27131
I0812 01:19:37.705265 26953 solver.cpp:244]     Train net output #0: loss = 2.27131 (* 1 = 2.27131 loss)
I0812 01:19:39.112354 26953 sgd_solver.cpp:106] Iteration 16750, lr = 0.01
I0812 01:19:57.480528 26953 solver.cpp:228] Iteration 16760, loss = 2.33614
I0812 01:19:57.480782 26953 solver.cpp:244]     Train net output #0: loss = 2.33614 (* 1 = 2.33614 loss)
I0812 01:19:58.884110 26953 sgd_solver.cpp:106] Iteration 16760, lr = 0.01
I0812 01:20:17.318697 26953 solver.cpp:228] Iteration 16770, loss = 2.30816
I0812 01:20:17.318778 26953 solver.cpp:244]     Train net output #0: loss = 2.30816 (* 1 = 2.30816 loss)
I0812 01:20:18.741719 26953 sgd_solver.cpp:106] Iteration 16770, lr = 0.01
I0812 01:20:37.127665 26953 solver.cpp:228] Iteration 16780, loss = 1.96616
I0812 01:20:37.127856 26953 solver.cpp:244]     Train net output #0: loss = 1.96616 (* 1 = 1.96616 loss)
I0812 01:20:38.519831 26953 sgd_solver.cpp:106] Iteration 16780, lr = 0.01
I0812 01:20:56.936470 26953 solver.cpp:228] Iteration 16790, loss = 2.00755
I0812 01:20:56.936563 26953 solver.cpp:244]     Train net output #0: loss = 2.00755 (* 1 = 2.00755 loss)
I0812 01:20:58.329834 26953 sgd_solver.cpp:106] Iteration 16790, lr = 0.01
I0812 01:21:16.171196 26953 solver.cpp:337] Iteration 16800, Testing net (#0)
I0812 01:21:16.758540 26953 solver.cpp:404]     Test net output #0: accuracy = 0.518
I0812 01:21:16.758608 26953 solver.cpp:404]     Test net output #1: loss = 2.11283 (* 1 = 2.11283 loss)
I0812 01:21:17.341121 26953 solver.cpp:228] Iteration 16800, loss = 2.28348
I0812 01:21:17.341217 26953 solver.cpp:244]     Train net output #0: loss = 2.28348 (* 1 = 2.28348 loss)
I0812 01:21:18.707438 26953 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0812 01:21:37.088062 26953 solver.cpp:228] Iteration 16810, loss = 2.47503
I0812 01:21:37.088140 26953 solver.cpp:244]     Train net output #0: loss = 2.47503 (* 1 = 2.47503 loss)
I0812 01:21:38.480654 26953 sgd_solver.cpp:106] Iteration 16810, lr = 0.01
I0812 01:21:56.908018 26953 solver.cpp:228] Iteration 16820, loss = 2.16116
I0812 01:21:56.908184 26953 solver.cpp:244]     Train net output #0: loss = 2.16116 (* 1 = 2.16116 loss)
I0812 01:21:58.328395 26953 sgd_solver.cpp:106] Iteration 16820, lr = 0.01
I0812 01:22:16.707267 26953 solver.cpp:228] Iteration 16830, loss = 2.21454
I0812 01:22:16.707337 26953 solver.cpp:244]     Train net output #0: loss = 2.21454 (* 1 = 2.21454 loss)
I0812 01:22:18.110550 26953 sgd_solver.cpp:106] Iteration 16830, lr = 0.01
I0812 01:22:36.526105 26953 solver.cpp:228] Iteration 16840, loss = 2.23862
I0812 01:22:36.526350 26953 solver.cpp:244]     Train net output #0: loss = 2.23862 (* 1 = 2.23862 loss)
I0812 01:22:37.913877 26953 sgd_solver.cpp:106] Iteration 16840, lr = 0.01
I0812 01:22:56.316424 26953 solver.cpp:228] Iteration 16850, loss = 2.10589
I0812 01:22:56.316493 26953 solver.cpp:244]     Train net output #0: loss = 2.10589 (* 1 = 2.10589 loss)
I0812 01:22:57.721315 26953 sgd_solver.cpp:106] Iteration 16850, lr = 0.01
I0812 01:23:16.079051 26953 solver.cpp:228] Iteration 16860, loss = 2.03813
I0812 01:23:16.079300 26953 solver.cpp:244]     Train net output #0: loss = 2.03813 (* 1 = 2.03813 loss)
I0812 01:23:17.487766 26953 sgd_solver.cpp:106] Iteration 16860, lr = 0.01
I0812 01:23:35.919914 26953 solver.cpp:228] Iteration 16870, loss = 2.22211
I0812 01:23:35.919992 26953 solver.cpp:244]     Train net output #0: loss = 2.22211 (* 1 = 2.22211 loss)
I0812 01:23:37.333220 26953 sgd_solver.cpp:106] Iteration 16870, lr = 0.01
I0812 01:23:55.702466 26953 solver.cpp:228] Iteration 16880, loss = 2.18477
I0812 01:23:55.702673 26953 solver.cpp:244]     Train net output #0: loss = 2.18477 (* 1 = 2.18477 loss)
I0812 01:23:57.108690 26953 sgd_solver.cpp:106] Iteration 16880, lr = 0.01
I0812 01:24:15.468411 26953 solver.cpp:228] Iteration 16890, loss = 2.31682
I0812 01:24:15.468482 26953 solver.cpp:244]     Train net output #0: loss = 2.31682 (* 1 = 2.31682 loss)
I0812 01:24:16.869699 26953 sgd_solver.cpp:106] Iteration 16890, lr = 0.01
I0812 01:24:34.704629 26953 solver.cpp:337] Iteration 16900, Testing net (#0)
I0812 01:24:35.291147 26953 solver.cpp:404]     Test net output #0: accuracy = 0.486
I0812 01:24:35.291352 26953 solver.cpp:404]     Test net output #1: loss = 2.36273 (* 1 = 2.36273 loss)
I0812 01:24:35.850448 26953 solver.cpp:228] Iteration 16900, loss = 2.34987
I0812 01:24:35.850534 26953 solver.cpp:244]     Train net output #0: loss = 2.34987 (* 1 = 2.34987 loss)
I0812 01:24:37.238318 26953 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0812 01:24:55.587868 26953 solver.cpp:228] Iteration 16910, loss = 2.33899
I0812 01:24:55.587949 26953 solver.cpp:244]     Train net output #0: loss = 2.33899 (* 1 = 2.33899 loss)
I0812 01:24:57.006858 26953 sgd_solver.cpp:106] Iteration 16910, lr = 0.01
I0812 01:25:15.403221 26953 solver.cpp:228] Iteration 16920, loss = 2.26058
I0812 01:25:15.403481 26953 solver.cpp:244]     Train net output #0: loss = 2.26058 (* 1 = 2.26058 loss)
I0812 01:25:16.807071 26953 sgd_solver.cpp:106] Iteration 16920, lr = 0.01
I0812 01:25:35.223122 26953 solver.cpp:228] Iteration 16930, loss = 2.15227
I0812 01:25:35.223194 26953 solver.cpp:244]     Train net output #0: loss = 2.15227 (* 1 = 2.15227 loss)
I0812 01:25:36.639060 26953 sgd_solver.cpp:106] Iteration 16930, lr = 0.01
I0812 01:25:54.985100 26953 solver.cpp:228] Iteration 16940, loss = 2.28831
I0812 01:25:54.985364 26953 solver.cpp:244]     Train net output #0: loss = 2.28831 (* 1 = 2.28831 loss)
I0812 01:25:56.384039 26953 sgd_solver.cpp:106] Iteration 16940, lr = 0.01
I0812 01:26:14.765106 26953 solver.cpp:228] Iteration 16950, loss = 2.26278
I0812 01:26:14.765173 26953 solver.cpp:244]     Train net output #0: loss = 2.26278 (* 1 = 2.26278 loss)
I0812 01:26:16.171656 26953 sgd_solver.cpp:106] Iteration 16950, lr = 0.01
I0812 01:26:34.621482 26953 solver.cpp:228] Iteration 16960, loss = 2.23776
I0812 01:26:34.621712 26953 solver.cpp:244]     Train net output #0: loss = 2.23776 (* 1 = 2.23776 loss)
I0812 01:26:36.019999 26953 sgd_solver.cpp:106] Iteration 16960, lr = 0.01
I0812 01:26:54.434609 26953 solver.cpp:228] Iteration 16970, loss = 2.10671
I0812 01:26:54.434697 26953 solver.cpp:244]     Train net output #0: loss = 2.10671 (* 1 = 2.10671 loss)
I0812 01:26:55.818513 26953 sgd_solver.cpp:106] Iteration 16970, lr = 0.01
I0812 01:27:14.255378 26953 solver.cpp:228] Iteration 16980, loss = 2.10821
I0812 01:27:14.255635 26953 solver.cpp:244]     Train net output #0: loss = 2.10821 (* 1 = 2.10821 loss)
I0812 01:27:15.651414 26953 sgd_solver.cpp:106] Iteration 16980, lr = 0.01
I0812 01:27:34.018602 26953 solver.cpp:228] Iteration 16990, loss = 2.19198
I0812 01:27:34.018669 26953 solver.cpp:244]     Train net output #0: loss = 2.19198 (* 1 = 2.19198 loss)
I0812 01:27:35.423739 26953 sgd_solver.cpp:106] Iteration 16990, lr = 0.01
I0812 01:27:53.231596 26953 solver.cpp:337] Iteration 17000, Testing net (#0)
I0812 01:27:53.818030 26953 solver.cpp:404]     Test net output #0: accuracy = 0.474
I0812 01:27:53.818087 26953 solver.cpp:404]     Test net output #1: loss = 2.40191 (* 1 = 2.40191 loss)
I0812 01:27:54.395956 26953 solver.cpp:228] Iteration 17000, loss = 2.32368
I0812 01:27:54.396044 26953 solver.cpp:244]     Train net output #0: loss = 2.32368 (* 1 = 2.32368 loss)
I0812 01:27:55.766513 26953 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0812 01:28:14.166584 26953 solver.cpp:228] Iteration 17010, loss = 2.3373
I0812 01:28:14.166647 26953 solver.cpp:244]     Train net output #0: loss = 2.3373 (* 1 = 2.3373 loss)
I0812 01:28:15.583255 26953 sgd_solver.cpp:106] Iteration 17010, lr = 0.01
I0812 01:28:33.959946 26953 solver.cpp:228] Iteration 17020, loss = 2.08483
I0812 01:28:33.960091 26953 solver.cpp:244]     Train net output #0: loss = 2.08483 (* 1 = 2.08483 loss)
I0812 01:28:35.349973 26953 sgd_solver.cpp:106] Iteration 17020, lr = 0.01
I0812 01:28:53.788924 26953 solver.cpp:228] Iteration 17030, loss = 2.15654
I0812 01:28:53.788983 26953 solver.cpp:244]     Train net output #0: loss = 2.15654 (* 1 = 2.15654 loss)
I0812 01:28:55.193012 26953 sgd_solver.cpp:106] Iteration 17030, lr = 0.01
I0812 01:29:13.553620 26953 solver.cpp:228] Iteration 17040, loss = 2.09913
I0812 01:29:13.553892 26953 solver.cpp:244]     Train net output #0: loss = 2.09913 (* 1 = 2.09913 loss)
I0812 01:29:14.957144 26953 sgd_solver.cpp:106] Iteration 17040, lr = 0.01
I0812 01:29:33.298087 26953 solver.cpp:228] Iteration 17050, loss = 2.28641
I0812 01:29:33.298149 26953 solver.cpp:244]     Train net output #0: loss = 2.28641 (* 1 = 2.28641 loss)
I0812 01:29:34.703943 26953 sgd_solver.cpp:106] Iteration 17050, lr = 0.01
I0812 01:29:53.114202 26953 solver.cpp:228] Iteration 17060, loss = 2.15334
I0812 01:29:53.114456 26953 solver.cpp:244]     Train net output #0: loss = 2.15334 (* 1 = 2.15334 loss)
I0812 01:29:54.512135 26953 sgd_solver.cpp:106] Iteration 17060, lr = 0.01
I0812 01:30:12.914891 26953 solver.cpp:228] Iteration 17070, loss = 2.29953
I0812 01:30:12.914952 26953 solver.cpp:244]     Train net output #0: loss = 2.29953 (* 1 = 2.29953 loss)
I0812 01:30:14.322285 26953 sgd_solver.cpp:106] Iteration 17070, lr = 0.01
I0812 01:30:32.700181 26953 solver.cpp:228] Iteration 17080, loss = 2.06443
I0812 01:30:32.700357 26953 solver.cpp:244]     Train net output #0: loss = 2.06443 (* 1 = 2.06443 loss)
I0812 01:30:34.096369 26953 sgd_solver.cpp:106] Iteration 17080, lr = 0.01
I0812 01:30:52.456912 26953 solver.cpp:228] Iteration 17090, loss = 2.23999
I0812 01:30:52.456974 26953 solver.cpp:244]     Train net output #0: loss = 2.23999 (* 1 = 2.23999 loss)
I0812 01:30:53.847864 26953 sgd_solver.cpp:106] Iteration 17090, lr = 0.01
I0812 01:31:11.636293 26953 solver.cpp:337] Iteration 17100, Testing net (#0)
I0812 01:31:12.222968 26953 solver.cpp:404]     Test net output #0: accuracy = 0.494
I0812 01:31:12.223040 26953 solver.cpp:404]     Test net output #1: loss = 2.21218 (* 1 = 2.21218 loss)
I0812 01:31:12.783773 26953 solver.cpp:228] Iteration 17100, loss = 2.31794
I0812 01:31:12.783851 26953 solver.cpp:244]     Train net output #0: loss = 2.31794 (* 1 = 2.31794 loss)
I0812 01:31:14.172015 26953 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0812 01:31:32.556545 26953 solver.cpp:228] Iteration 17110, loss = 2.12672
I0812 01:31:32.556614 26953 solver.cpp:244]     Train net output #0: loss = 2.12672 (* 1 = 2.12672 loss)
I0812 01:31:33.959317 26953 sgd_solver.cpp:106] Iteration 17110, lr = 0.01
I0812 01:31:52.396580 26953 solver.cpp:228] Iteration 17120, loss = 2.25478
I0812 01:31:52.396766 26953 solver.cpp:244]     Train net output #0: loss = 2.25478 (* 1 = 2.25478 loss)
I0812 01:31:53.790253 26953 sgd_solver.cpp:106] Iteration 17120, lr = 0.01
I0812 01:32:12.204512 26953 solver.cpp:228] Iteration 17130, loss = 2.20456
I0812 01:32:12.204584 26953 solver.cpp:244]     Train net output #0: loss = 2.20456 (* 1 = 2.20456 loss)
I0812 01:32:13.623394 26953 sgd_solver.cpp:106] Iteration 17130, lr = 0.01
I0812 01:32:31.997159 26953 solver.cpp:228] Iteration 17140, loss = 2.19425
I0812 01:32:31.997396 26953 solver.cpp:244]     Train net output #0: loss = 2.19425 (* 1 = 2.19425 loss)
I0812 01:32:33.388402 26953 sgd_solver.cpp:106] Iteration 17140, lr = 0.01
I0812 01:32:51.828019 26953 solver.cpp:228] Iteration 17150, loss = 2.21362
I0812 01:32:51.828105 26953 solver.cpp:244]     Train net output #0: loss = 2.21362 (* 1 = 2.21362 loss)
I0812 01:32:53.216303 26953 sgd_solver.cpp:106] Iteration 17150, lr = 0.01
I0812 01:33:11.576292 26953 solver.cpp:228] Iteration 17160, loss = 2.27582
I0812 01:33:11.576439 26953 solver.cpp:244]     Train net output #0: loss = 2.27582 (* 1 = 2.27582 loss)
I0812 01:33:12.995769 26953 sgd_solver.cpp:106] Iteration 17160, lr = 0.01
I0812 01:33:31.408695 26953 solver.cpp:228] Iteration 17170, loss = 2.13814
I0812 01:33:31.408753 26953 solver.cpp:244]     Train net output #0: loss = 2.13814 (* 1 = 2.13814 loss)
I0812 01:33:32.804610 26953 sgd_solver.cpp:106] Iteration 17170, lr = 0.01
I0812 01:33:51.183689 26953 solver.cpp:228] Iteration 17180, loss = 2.35867
I0812 01:33:51.183940 26953 solver.cpp:244]     Train net output #0: loss = 2.35867 (* 1 = 2.35867 loss)
I0812 01:33:52.590032 26953 sgd_solver.cpp:106] Iteration 17180, lr = 0.01
I0812 01:34:10.962883 26953 solver.cpp:228] Iteration 17190, loss = 2.15711
I0812 01:34:10.962957 26953 solver.cpp:244]     Train net output #0: loss = 2.15711 (* 1 = 2.15711 loss)
I0812 01:34:12.367857 26953 sgd_solver.cpp:106] Iteration 17190, lr = 0.01
I0812 01:34:30.178004 26953 solver.cpp:337] Iteration 17200, Testing net (#0)
I0812 01:34:30.765229 26953 solver.cpp:404]     Test net output #0: accuracy = 0.512
I0812 01:34:30.765295 26953 solver.cpp:404]     Test net output #1: loss = 2.19941 (* 1 = 2.19941 loss)
I0812 01:34:31.327359 26953 solver.cpp:228] Iteration 17200, loss = 2.02998
I0812 01:34:31.327460 26953 solver.cpp:244]     Train net output #0: loss = 2.02998 (* 1 = 2.02998 loss)
I0812 01:34:32.694363 26953 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0812 01:34:51.121215 26953 solver.cpp:228] Iteration 17210, loss = 2.21429
I0812 01:34:51.121282 26953 solver.cpp:244]     Train net output #0: loss = 2.21429 (* 1 = 2.21429 loss)
I0812 01:34:52.520762 26953 sgd_solver.cpp:106] Iteration 17210, lr = 0.01
I0812 01:35:10.884996 26953 solver.cpp:228] Iteration 17220, loss = 2.12402
I0812 01:35:10.885303 26953 solver.cpp:244]     Train net output #0: loss = 2.12402 (* 1 = 2.12402 loss)
I0812 01:35:12.302507 26953 sgd_solver.cpp:106] Iteration 17220, lr = 0.01
I0812 01:35:30.677007 26953 solver.cpp:228] Iteration 17230, loss = 2.09866
I0812 01:35:30.677110 26953 solver.cpp:244]     Train net output #0: loss = 2.09866 (* 1 = 2.09866 loss)
I0812 01:35:32.082283 26953 sgd_solver.cpp:106] Iteration 17230, lr = 0.01
I0812 01:35:50.498591 26953 solver.cpp:228] Iteration 17240, loss = 2.1847
I0812 01:35:50.498843 26953 solver.cpp:244]     Train net output #0: loss = 2.1847 (* 1 = 2.1847 loss)
I0812 01:35:51.920356 26953 sgd_solver.cpp:106] Iteration 17240, lr = 0.01
I0812 01:36:10.318272 26953 solver.cpp:228] Iteration 17250, loss = 2.12638
I0812 01:36:10.318333 26953 solver.cpp:244]     Train net output #0: loss = 2.12638 (* 1 = 2.12638 loss)
I0812 01:36:11.729789 26953 sgd_solver.cpp:106] Iteration 17250, lr = 0.01
I0812 01:36:30.061336 26953 solver.cpp:228] Iteration 17260, loss = 2.05039
I0812 01:36:30.061995 26953 solver.cpp:244]     Train net output #0: loss = 2.05039 (* 1 = 2.05039 loss)
I0812 01:36:31.461859 26953 sgd_solver.cpp:106] Iteration 17260, lr = 0.01
I0812 01:36:49.867329 26953 solver.cpp:228] Iteration 17270, loss = 2.2659
I0812 01:36:49.867424 26953 solver.cpp:244]     Train net output #0: loss = 2.2659 (* 1 = 2.2659 loss)
I0812 01:36:51.288558 26953 sgd_solver.cpp:106] Iteration 17270, lr = 0.01
I0812 01:37:09.615931 26953 solver.cpp:228] Iteration 17280, loss = 2.23473
I0812 01:37:09.616075 26953 solver.cpp:244]     Train net output #0: loss = 2.23473 (* 1 = 2.23473 loss)
I0812 01:37:11.018389 26953 sgd_solver.cpp:106] Iteration 17280, lr = 0.01
I0812 01:37:29.482610 26953 solver.cpp:228] Iteration 17290, loss = 2.2226
I0812 01:37:29.482676 26953 solver.cpp:244]     Train net output #0: loss = 2.2226 (* 1 = 2.2226 loss)
I0812 01:37:30.870738 26953 sgd_solver.cpp:106] Iteration 17290, lr = 0.01
I0812 01:37:48.666934 26953 solver.cpp:337] Iteration 17300, Testing net (#0)
I0812 01:37:49.256768 26953 solver.cpp:404]     Test net output #0: accuracy = 0.48
I0812 01:37:49.256845 26953 solver.cpp:404]     Test net output #1: loss = 2.39102 (* 1 = 2.39102 loss)
I0812 01:37:49.820425 26953 solver.cpp:228] Iteration 17300, loss = 2.34221
I0812 01:37:49.820515 26953 solver.cpp:244]     Train net output #0: loss = 2.34221 (* 1 = 2.34221 loss)
I0812 01:37:51.217733 26953 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0812 01:38:09.672778 26953 solver.cpp:228] Iteration 17310, loss = 2.22424
I0812 01:38:09.672849 26953 solver.cpp:244]     Train net output #0: loss = 2.22424 (* 1 = 2.22424 loss)
I0812 01:38:11.076154 26953 sgd_solver.cpp:106] Iteration 17310, lr = 0.01
I0812 01:38:29.455961 26953 solver.cpp:228] Iteration 17320, loss = 2.2613
I0812 01:38:29.456166 26953 solver.cpp:244]     Train net output #0: loss = 2.2613 (* 1 = 2.2613 loss)
I0812 01:38:30.866206 26953 sgd_solver.cpp:106] Iteration 17320, lr = 0.01
I0812 01:38:49.207624 26953 solver.cpp:228] Iteration 17330, loss = 2.26207
I0812 01:38:49.207700 26953 solver.cpp:244]     Train net output #0: loss = 2.26207 (* 1 = 2.26207 loss)
I0812 01:38:50.606395 26953 sgd_solver.cpp:106] Iteration 17330, lr = 0.01
I0812 01:39:08.954027 26953 solver.cpp:228] Iteration 17340, loss = 2.39414
I0812 01:39:08.954218 26953 solver.cpp:244]     Train net output #0: loss = 2.39414 (* 1 = 2.39414 loss)
I0812 01:39:10.350692 26953 sgd_solver.cpp:106] Iteration 17340, lr = 0.01
I0812 01:39:28.736961 26953 solver.cpp:228] Iteration 17350, loss = 2.2745
I0812 01:39:28.737048 26953 solver.cpp:244]     Train net output #0: loss = 2.2745 (* 1 = 2.2745 loss)
I0812 01:39:30.133524 26953 sgd_solver.cpp:106] Iteration 17350, lr = 0.01
I0812 01:39:48.542137 26953 solver.cpp:228] Iteration 17360, loss = 2.29736
I0812 01:39:48.542389 26953 solver.cpp:244]     Train net output #0: loss = 2.29736 (* 1 = 2.29736 loss)
I0812 01:39:49.956409 26953 sgd_solver.cpp:106] Iteration 17360, lr = 0.01
I0812 01:40:08.312463 26953 solver.cpp:228] Iteration 17370, loss = 2.19206
I0812 01:40:08.312547 26953 solver.cpp:244]     Train net output #0: loss = 2.19206 (* 1 = 2.19206 loss)
I0812 01:40:09.725620 26953 sgd_solver.cpp:106] Iteration 17370, lr = 0.01
I0812 01:40:28.104665 26953 solver.cpp:228] Iteration 17380, loss = 2.35712
I0812 01:40:28.104940 26953 solver.cpp:244]     Train net output #0: loss = 2.35712 (* 1 = 2.35712 loss)
I0812 01:40:29.485748 26953 sgd_solver.cpp:106] Iteration 17380, lr = 0.01
I0812 01:40:47.903966 26953 solver.cpp:228] Iteration 17390, loss = 2.12401
I0812 01:40:47.904067 26953 solver.cpp:244]     Train net output #0: loss = 2.12401 (* 1 = 2.12401 loss)
I0812 01:40:49.309020 26953 sgd_solver.cpp:106] Iteration 17390, lr = 0.01
I0812 01:41:07.056471 26953 solver.cpp:337] Iteration 17400, Testing net (#0)
I0812 01:41:07.648244 26953 solver.cpp:404]     Test net output #0: accuracy = 0.526
I0812 01:41:07.648308 26953 solver.cpp:404]     Test net output #1: loss = 2.15966 (* 1 = 2.15966 loss)
I0812 01:41:08.222354 26953 solver.cpp:228] Iteration 17400, loss = 2.1403
I0812 01:41:08.222426 26953 solver.cpp:244]     Train net output #0: loss = 2.1403 (* 1 = 2.1403 loss)
I0812 01:41:09.594002 26953 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0812 01:41:28.021209 26953 solver.cpp:228] Iteration 17410, loss = 2.1906
I0812 01:41:28.021281 26953 solver.cpp:244]     Train net output #0: loss = 2.1906 (* 1 = 2.1906 loss)
I0812 01:41:29.418774 26953 sgd_solver.cpp:106] Iteration 17410, lr = 0.01
I0812 01:41:47.792848 26953 solver.cpp:228] Iteration 17420, loss = 2.24205
I0812 01:41:47.793038 26953 solver.cpp:244]     Train net output #0: loss = 2.24205 (* 1 = 2.24205 loss)
I0812 01:41:49.189311 26953 sgd_solver.cpp:106] Iteration 17420, lr = 0.01
I0812 01:42:07.575763 26953 solver.cpp:228] Iteration 17430, loss = 2.14257
I0812 01:42:07.575822 26953 solver.cpp:244]     Train net output #0: loss = 2.14257 (* 1 = 2.14257 loss)
I0812 01:42:08.967720 26953 sgd_solver.cpp:106] Iteration 17430, lr = 0.01
I0812 01:42:27.334230 26953 solver.cpp:228] Iteration 17440, loss = 2.26482
I0812 01:42:27.334478 26953 solver.cpp:244]     Train net output #0: loss = 2.26482 (* 1 = 2.26482 loss)
I0812 01:42:28.729022 26953 sgd_solver.cpp:106] Iteration 17440, lr = 0.01
I0812 01:42:47.130782 26953 solver.cpp:228] Iteration 17450, loss = 2.2403
I0812 01:42:47.130862 26953 solver.cpp:244]     Train net output #0: loss = 2.2403 (* 1 = 2.2403 loss)
I0812 01:42:48.530063 26953 sgd_solver.cpp:106] Iteration 17450, lr = 0.01
I0812 01:43:06.903218 26953 solver.cpp:228] Iteration 17460, loss = 2.27407
I0812 01:43:06.903450 26953 solver.cpp:244]     Train net output #0: loss = 2.27407 (* 1 = 2.27407 loss)
I0812 01:43:08.299485 26953 sgd_solver.cpp:106] Iteration 17460, lr = 0.01
I0812 01:43:26.655828 26953 solver.cpp:228] Iteration 17470, loss = 2.20006
I0812 01:43:26.655905 26953 solver.cpp:244]     Train net output #0: loss = 2.20006 (* 1 = 2.20006 loss)
I0812 01:43:28.068922 26953 sgd_solver.cpp:106] Iteration 17470, lr = 0.01
I0812 01:43:46.491030 26953 solver.cpp:228] Iteration 17480, loss = 2.1833
I0812 01:43:46.491309 26953 solver.cpp:244]     Train net output #0: loss = 2.1833 (* 1 = 2.1833 loss)
I0812 01:43:47.894383 26953 sgd_solver.cpp:106] Iteration 17480, lr = 0.01
I0812 01:44:06.282371 26953 solver.cpp:228] Iteration 17490, loss = 2.19934
I0812 01:44:06.282436 26953 solver.cpp:244]     Train net output #0: loss = 2.19934 (* 1 = 2.19934 loss)
I0812 01:44:07.721753 26953 sgd_solver.cpp:106] Iteration 17490, lr = 0.01
I0812 01:44:25.486085 26953 solver.cpp:337] Iteration 17500, Testing net (#0)
I0812 01:44:26.078289 26953 solver.cpp:404]     Test net output #0: accuracy = 0.504
I0812 01:44:26.078357 26953 solver.cpp:404]     Test net output #1: loss = 2.23761 (* 1 = 2.23761 loss)
I0812 01:44:26.656560 26953 solver.cpp:228] Iteration 17500, loss = 2.21636
I0812 01:44:26.656647 26953 solver.cpp:244]     Train net output #0: loss = 2.21636 (* 1 = 2.21636 loss)
I0812 01:44:28.029180 26953 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0812 01:44:46.420542 26953 solver.cpp:228] Iteration 17510, loss = 2.18895
I0812 01:44:46.420619 26953 solver.cpp:244]     Train net output #0: loss = 2.18895 (* 1 = 2.18895 loss)
I0812 01:44:47.836705 26953 sgd_solver.cpp:106] Iteration 17510, lr = 0.01
I0812 01:45:06.173828 26953 solver.cpp:228] Iteration 17520, loss = 2.15143
I0812 01:45:06.174005 26953 solver.cpp:244]     Train net output #0: loss = 2.15143 (* 1 = 2.15143 loss)
I0812 01:45:07.591332 26953 sgd_solver.cpp:106] Iteration 17520, lr = 0.01
I0812 01:45:25.982497 26953 solver.cpp:228] Iteration 17530, loss = 2.18793
I0812 01:45:25.982587 26953 solver.cpp:244]     Train net output #0: loss = 2.18793 (* 1 = 2.18793 loss)
I0812 01:45:27.377786 26953 sgd_solver.cpp:106] Iteration 17530, lr = 0.01
I0812 01:45:45.759917 26953 solver.cpp:228] Iteration 17540, loss = 2.15876
I0812 01:45:45.760064 26953 solver.cpp:244]     Train net output #0: loss = 2.15876 (* 1 = 2.15876 loss)
I0812 01:45:47.146474 26953 sgd_solver.cpp:106] Iteration 17540, lr = 0.01
I0812 01:46:05.513422 26953 solver.cpp:228] Iteration 17550, loss = 2.21016
I0812 01:46:05.513490 26953 solver.cpp:244]     Train net output #0: loss = 2.21016 (* 1 = 2.21016 loss)
I0812 01:46:06.923439 26953 sgd_solver.cpp:106] Iteration 17550, lr = 0.01
I0812 01:46:25.281347 26953 solver.cpp:228] Iteration 17560, loss = 2.14397
I0812 01:46:25.281561 26953 solver.cpp:244]     Train net output #0: loss = 2.14397 (* 1 = 2.14397 loss)
I0812 01:46:26.670120 26953 sgd_solver.cpp:106] Iteration 17560, lr = 0.01
I0812 01:46:45.072392 26953 solver.cpp:228] Iteration 17570, loss = 2.13926
I0812 01:46:45.072463 26953 solver.cpp:244]     Train net output #0: loss = 2.13926 (* 1 = 2.13926 loss)
I0812 01:46:46.460803 26953 sgd_solver.cpp:106] Iteration 17570, lr = 0.01
I0812 01:47:04.850713 26953 solver.cpp:228] Iteration 17580, loss = 2.26223
I0812 01:47:04.850970 26953 solver.cpp:244]     Train net output #0: loss = 2.26223 (* 1 = 2.26223 loss)
I0812 01:47:06.257369 26953 sgd_solver.cpp:106] Iteration 17580, lr = 0.01
I0812 01:47:24.647090 26953 solver.cpp:228] Iteration 17590, loss = 2.09768
I0812 01:47:24.647157 26953 solver.cpp:244]     Train net output #0: loss = 2.09768 (* 1 = 2.09768 loss)
I0812 01:47:26.050462 26953 sgd_solver.cpp:106] Iteration 17590, lr = 0.01
I0812 01:47:43.889353 26953 solver.cpp:337] Iteration 17600, Testing net (#0)
I0812 01:47:44.480026 26953 solver.cpp:404]     Test net output #0: accuracy = 0.488
I0812 01:47:44.480095 26953 solver.cpp:404]     Test net output #1: loss = 2.21415 (* 1 = 2.21415 loss)
I0812 01:47:45.071630 26953 solver.cpp:228] Iteration 17600, loss = 2.36115
I0812 01:47:45.071702 26953 solver.cpp:244]     Train net output #0: loss = 2.36115 (* 1 = 2.36115 loss)
I0812 01:47:46.430385 26953 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0812 01:48:04.810022 26953 solver.cpp:228] Iteration 17610, loss = 2.24218
I0812 01:48:04.810096 26953 solver.cpp:244]     Train net output #0: loss = 2.24218 (* 1 = 2.24218 loss)
I0812 01:48:06.237422 26953 sgd_solver.cpp:106] Iteration 17610, lr = 0.01
I0812 01:48:24.603411 26953 solver.cpp:228] Iteration 17620, loss = 2.16368
I0812 01:48:24.603620 26953 solver.cpp:244]     Train net output #0: loss = 2.16368 (* 1 = 2.16368 loss)
I0812 01:48:25.997763 26953 sgd_solver.cpp:106] Iteration 17620, lr = 0.01
I0812 01:48:44.421732 26953 solver.cpp:228] Iteration 17630, loss = 2.15939
I0812 01:48:44.421810 26953 solver.cpp:244]     Train net output #0: loss = 2.15939 (* 1 = 2.15939 loss)
I0812 01:48:45.826751 26953 sgd_solver.cpp:106] Iteration 17630, lr = 0.01
I0812 01:49:04.152248 26953 solver.cpp:228] Iteration 17640, loss = 2.27309
I0812 01:49:04.152449 26953 solver.cpp:244]     Train net output #0: loss = 2.27309 (* 1 = 2.27309 loss)
I0812 01:49:05.580653 26953 sgd_solver.cpp:106] Iteration 17640, lr = 0.01
I0812 01:49:24.007007 26953 solver.cpp:228] Iteration 17650, loss = 2.35584
I0812 01:49:24.007086 26953 solver.cpp:244]     Train net output #0: loss = 2.35584 (* 1 = 2.35584 loss)
I0812 01:49:25.396975 26953 sgd_solver.cpp:106] Iteration 17650, lr = 0.01
I0812 01:49:43.819208 26953 solver.cpp:228] Iteration 17660, loss = 2.35263
I0812 01:49:43.819469 26953 solver.cpp:244]     Train net output #0: loss = 2.35263 (* 1 = 2.35263 loss)
I0812 01:49:45.217605 26953 sgd_solver.cpp:106] Iteration 17660, lr = 0.01
I0812 01:50:03.592401 26953 solver.cpp:228] Iteration 17670, loss = 2.06504
I0812 01:50:03.592474 26953 solver.cpp:244]     Train net output #0: loss = 2.06504 (* 1 = 2.06504 loss)
I0812 01:50:04.997959 26953 sgd_solver.cpp:106] Iteration 17670, lr = 0.01
I0812 01:50:23.396615 26953 solver.cpp:228] Iteration 17680, loss = 2.22719
I0812 01:50:23.396776 26953 solver.cpp:244]     Train net output #0: loss = 2.22719 (* 1 = 2.22719 loss)
I0812 01:50:24.790197 26953 sgd_solver.cpp:106] Iteration 17680, lr = 0.01
I0812 01:50:43.195436 26953 solver.cpp:228] Iteration 17690, loss = 2.34448
I0812 01:50:43.195497 26953 solver.cpp:244]     Train net output #0: loss = 2.34448 (* 1 = 2.34448 loss)
I0812 01:50:44.597848 26953 sgd_solver.cpp:106] Iteration 17690, lr = 0.01
I0812 01:51:02.396637 26953 solver.cpp:337] Iteration 17700, Testing net (#0)
I0812 01:51:02.988031 26953 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0812 01:51:02.988140 26953 solver.cpp:404]     Test net output #1: loss = 2.30964 (* 1 = 2.30964 loss)
I0812 01:51:03.562113 26953 solver.cpp:228] Iteration 17700, loss = 2.27968
I0812 01:51:03.562202 26953 solver.cpp:244]     Train net output #0: loss = 2.27968 (* 1 = 2.27968 loss)
I0812 01:51:04.932755 26953 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0812 01:51:23.359091 26953 solver.cpp:228] Iteration 17710, loss = 2.06695
I0812 01:51:23.359180 26953 solver.cpp:244]     Train net output #0: loss = 2.06695 (* 1 = 2.06695 loss)
I0812 01:51:24.753551 26953 sgd_solver.cpp:106] Iteration 17710, lr = 0.01
I0812 01:51:43.129694 26953 solver.cpp:228] Iteration 17720, loss = 2.3275
I0812 01:51:43.129930 26953 solver.cpp:244]     Train net output #0: loss = 2.3275 (* 1 = 2.3275 loss)
I0812 01:51:44.542626 26953 sgd_solver.cpp:106] Iteration 17720, lr = 0.01
I0812 01:52:02.926367 26953 solver.cpp:228] Iteration 17730, loss = 2.2912
I0812 01:52:02.926436 26953 solver.cpp:244]     Train net output #0: loss = 2.2912 (* 1 = 2.2912 loss)
I0812 01:52:04.339587 26953 sgd_solver.cpp:106] Iteration 17730, lr = 0.01
I0812 01:52:22.741109 26953 solver.cpp:228] Iteration 17740, loss = 2.0266
I0812 01:52:22.741288 26953 solver.cpp:244]     Train net output #0: loss = 2.0266 (* 1 = 2.0266 loss)
I0812 01:52:24.161991 26953 sgd_solver.cpp:106] Iteration 17740, lr = 0.01
I0812 01:52:42.512316 26953 solver.cpp:228] Iteration 17750, loss = 2.11401
I0812 01:52:42.512387 26953 solver.cpp:244]     Train net output #0: loss = 2.11401 (* 1 = 2.11401 loss)
I0812 01:52:43.918751 26953 sgd_solver.cpp:106] Iteration 17750, lr = 0.01
I0812 01:53:02.320564 26953 solver.cpp:228] Iteration 17760, loss = 2.14042
I0812 01:53:02.320703 26953 solver.cpp:244]     Train net output #0: loss = 2.14042 (* 1 = 2.14042 loss)
I0812 01:53:03.712801 26953 sgd_solver.cpp:106] Iteration 17760, lr = 0.01
I0812 01:53:22.083345 26953 solver.cpp:228] Iteration 17770, loss = 2.23161
I0812 01:53:22.083425 26953 solver.cpp:244]     Train net output #0: loss = 2.23161 (* 1 = 2.23161 loss)
I0812 01:53:23.489401 26953 sgd_solver.cpp:106] Iteration 17770, lr = 0.01
I0812 01:53:41.837976 26953 solver.cpp:228] Iteration 17780, loss = 2.1411
I0812 01:53:41.838237 26953 solver.cpp:244]     Train net output #0: loss = 2.1411 (* 1 = 2.1411 loss)
I0812 01:53:43.242501 26953 sgd_solver.cpp:106] Iteration 17780, lr = 0.01
I0812 01:54:01.633560 26953 solver.cpp:228] Iteration 17790, loss = 2.22965
I0812 01:54:01.633628 26953 solver.cpp:244]     Train net output #0: loss = 2.22965 (* 1 = 2.22965 loss)
I0812 01:54:03.031874 26953 sgd_solver.cpp:106] Iteration 17790, lr = 0.01
I0812 01:54:20.849653 26953 solver.cpp:337] Iteration 17800, Testing net (#0)
I0812 01:54:21.443822 26953 solver.cpp:404]     Test net output #0: accuracy = 0.47
I0812 01:54:21.443892 26953 solver.cpp:404]     Test net output #1: loss = 2.403 (* 1 = 2.403 loss)
I0812 01:54:22.012238 26953 solver.cpp:228] Iteration 17800, loss = 2.14925
I0812 01:54:22.012325 26953 solver.cpp:244]     Train net output #0: loss = 2.14925 (* 1 = 2.14925 loss)
I0812 01:54:23.392354 26953 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0812 01:54:41.737006 26953 solver.cpp:228] Iteration 17810, loss = 2.25965
I0812 01:54:41.737072 26953 solver.cpp:244]     Train net output #0: loss = 2.25965 (* 1 = 2.25965 loss)
I0812 01:54:43.135979 26953 sgd_solver.cpp:106] Iteration 17810, lr = 0.01
I0812 01:55:01.506389 26953 solver.cpp:228] Iteration 17820, loss = 2.06925
I0812 01:55:01.506546 26953 solver.cpp:244]     Train net output #0: loss = 2.06925 (* 1 = 2.06925 loss)
I0812 01:55:02.916643 26953 sgd_solver.cpp:106] Iteration 17820, lr = 0.01
I0812 01:55:21.265293 26953 solver.cpp:228] Iteration 17830, loss = 2.25362
I0812 01:55:21.265373 26953 solver.cpp:244]     Train net output #0: loss = 2.25362 (* 1 = 2.25362 loss)
I0812 01:55:22.660439 26953 sgd_solver.cpp:106] Iteration 17830, lr = 0.01
I0812 01:55:41.109361 26953 solver.cpp:228] Iteration 17840, loss = 2.00988
I0812 01:55:41.109587 26953 solver.cpp:244]     Train net output #0: loss = 2.00988 (* 1 = 2.00988 loss)
I0812 01:55:42.504568 26953 sgd_solver.cpp:106] Iteration 17840, lr = 0.01
I0812 01:56:00.876443 26953 solver.cpp:228] Iteration 17850, loss = 2.27181
I0812 01:56:00.876508 26953 solver.cpp:244]     Train net output #0: loss = 2.27181 (* 1 = 2.27181 loss)
I0812 01:56:02.303630 26953 sgd_solver.cpp:106] Iteration 17850, lr = 0.01
I0812 01:56:20.693249 26953 solver.cpp:228] Iteration 17860, loss = 2.28892
I0812 01:56:20.693511 26953 solver.cpp:244]     Train net output #0: loss = 2.28892 (* 1 = 2.28892 loss)
I0812 01:56:22.084499 26953 sgd_solver.cpp:106] Iteration 17860, lr = 0.01
I0812 01:56:40.480234 26953 solver.cpp:228] Iteration 17870, loss = 2.0356
I0812 01:56:40.480291 26953 solver.cpp:244]     Train net output #0: loss = 2.0356 (* 1 = 2.0356 loss)
I0812 01:56:41.895133 26953 sgd_solver.cpp:106] Iteration 17870, lr = 0.01
I0812 01:57:00.250088 26953 solver.cpp:228] Iteration 17880, loss = 2.21207
I0812 01:57:00.250383 26953 solver.cpp:244]     Train net output #0: loss = 2.21207 (* 1 = 2.21207 loss)
I0812 01:57:01.652704 26953 sgd_solver.cpp:106] Iteration 17880, lr = 0.01
I0812 01:57:20.024438 26953 solver.cpp:228] Iteration 17890, loss = 2.41787
I0812 01:57:20.024554 26953 solver.cpp:244]     Train net output #0: loss = 2.41787 (* 1 = 2.41787 loss)
I0812 01:57:21.417858 26953 sgd_solver.cpp:106] Iteration 17890, lr = 0.01
I0812 01:57:39.239866 26953 solver.cpp:337] Iteration 17900, Testing net (#0)
I0812 01:57:39.831506 26953 solver.cpp:404]     Test net output #0: accuracy = 0.514
I0812 01:57:39.831569 26953 solver.cpp:404]     Test net output #1: loss = 2.18267 (* 1 = 2.18267 loss)
I0812 01:57:40.406847 26953 solver.cpp:228] Iteration 17900, loss = 2.40313
I0812 01:57:40.406919 26953 solver.cpp:244]     Train net output #0: loss = 2.40313 (* 1 = 2.40313 loss)
I0812 01:57:41.786520 26953 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0812 01:58:00.187049 26953 solver.cpp:228] Iteration 17910, loss = 2.17996
I0812 01:58:00.187124 26953 solver.cpp:244]     Train net output #0: loss = 2.17996 (* 1 = 2.17996 loss)
I0812 01:58:01.585911 26953 sgd_solver.cpp:106] Iteration 17910, lr = 0.01
I0812 01:58:19.962116 26953 solver.cpp:228] Iteration 17920, loss = 2.11368
I0812 01:58:19.962316 26953 solver.cpp:244]     Train net output #0: loss = 2.11368 (* 1 = 2.11368 loss)
I0812 01:58:21.352130 26953 sgd_solver.cpp:106] Iteration 17920, lr = 0.01
I0812 01:58:39.723183 26953 solver.cpp:228] Iteration 17930, loss = 2.32941
I0812 01:58:39.723253 26953 solver.cpp:244]     Train net output #0: loss = 2.32941 (* 1 = 2.32941 loss)
I0812 01:58:41.125430 26953 sgd_solver.cpp:106] Iteration 17930, lr = 0.01
I0812 01:58:59.518092 26953 solver.cpp:228] Iteration 17940, loss = 2.29377
I0812 01:58:59.518321 26953 solver.cpp:244]     Train net output #0: loss = 2.29377 (* 1 = 2.29377 loss)
I0812 01:59:00.934393 26953 sgd_solver.cpp:106] Iteration 17940, lr = 0.01
I0812 01:59:19.312036 26953 solver.cpp:228] Iteration 17950, loss = 2.41505
I0812 01:59:19.312108 26953 solver.cpp:244]     Train net output #0: loss = 2.41505 (* 1 = 2.41505 loss)
I0812 01:59:20.710253 26953 sgd_solver.cpp:106] Iteration 17950, lr = 0.01
I0812 01:59:39.115681 26953 solver.cpp:228] Iteration 17960, loss = 2.27331
I0812 01:59:39.115931 26953 solver.cpp:244]     Train net output #0: loss = 2.27331 (* 1 = 2.27331 loss)
I0812 01:59:40.508812 26953 sgd_solver.cpp:106] Iteration 17960, lr = 0.01
I0812 01:59:58.879947 26953 solver.cpp:228] Iteration 17970, loss = 2.08167
I0812 01:59:58.880017 26953 solver.cpp:244]     Train net output #0: loss = 2.08167 (* 1 = 2.08167 loss)
I0812 02:00:00.300128 26953 sgd_solver.cpp:106] Iteration 17970, lr = 0.01
I0812 02:00:18.681236 26953 solver.cpp:228] Iteration 17980, loss = 2.44678
I0812 02:00:18.681450 26953 solver.cpp:244]     Train net output #0: loss = 2.44678 (* 1 = 2.44678 loss)
I0812 02:00:20.082049 26953 sgd_solver.cpp:106] Iteration 17980, lr = 0.01
I0812 02:00:38.485313 26953 solver.cpp:228] Iteration 17990, loss = 2.20412
I0812 02:00:38.485381 26953 solver.cpp:244]     Train net output #0: loss = 2.20412 (* 1 = 2.20412 loss)
I0812 02:00:39.896311 26953 sgd_solver.cpp:106] Iteration 17990, lr = 0.01
I0812 02:00:57.669520 26953 solver.cpp:337] Iteration 18000, Testing net (#0)
I0812 02:00:58.267568 26953 solver.cpp:404]     Test net output #0: accuracy = 0.442
I0812 02:00:58.267634 26953 solver.cpp:404]     Test net output #1: loss = 2.46311 (* 1 = 2.46311 loss)
I0812 02:00:58.832104 26953 solver.cpp:228] Iteration 18000, loss = 2.27188
I0812 02:00:58.832183 26953 solver.cpp:244]     Train net output #0: loss = 2.27188 (* 1 = 2.27188 loss)
I0812 02:01:00.219003 26953 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0812 02:01:18.627614 26953 solver.cpp:228] Iteration 18010, loss = 2.11069
I0812 02:01:18.627696 26953 solver.cpp:244]     Train net output #0: loss = 2.11069 (* 1 = 2.11069 loss)
I0812 02:01:20.025110 26953 sgd_solver.cpp:106] Iteration 18010, lr = 0.01
I0812 02:01:38.401458 26953 solver.cpp:228] Iteration 18020, loss = 2.10182
I0812 02:01:38.401604 26953 solver.cpp:244]     Train net output #0: loss = 2.10182 (* 1 = 2.10182 loss)
I0812 02:01:39.802191 26953 sgd_solver.cpp:106] Iteration 18020, lr = 0.01
I0812 02:01:58.171605 26953 solver.cpp:228] Iteration 18030, loss = 2.19242
I0812 02:01:58.171679 26953 solver.cpp:244]     Train net output #0: loss = 2.19242 (* 1 = 2.19242 loss)
I0812 02:01:59.575844 26953 sgd_solver.cpp:106] Iteration 18030, lr = 0.01
I0812 02:02:17.987591 26953 solver.cpp:228] Iteration 18040, loss = 2.23541
I0812 02:02:17.987851 26953 solver.cpp:244]     Train net output #0: loss = 2.23541 (* 1 = 2.23541 loss)
I0812 02:02:19.396082 26953 sgd_solver.cpp:106] Iteration 18040, lr = 0.01
I0812 02:02:37.791312 26953 solver.cpp:228] Iteration 18050, loss = 2.09925
I0812 02:02:37.791385 26953 solver.cpp:244]     Train net output #0: loss = 2.09925 (* 1 = 2.09925 loss)
I0812 02:02:39.188489 26953 sgd_solver.cpp:106] Iteration 18050, lr = 0.01
I0812 02:02:57.537677 26953 solver.cpp:228] Iteration 18060, loss = 2.10915
I0812 02:02:57.537955 26953 solver.cpp:244]     Train net output #0: loss = 2.10915 (* 1 = 2.10915 loss)
I0812 02:02:58.966075 26953 sgd_solver.cpp:106] Iteration 18060, lr = 0.01
I0812 02:03:17.397482 26953 solver.cpp:228] Iteration 18070, loss = 2.17273
I0812 02:03:17.397552 26953 solver.cpp:244]     Train net output #0: loss = 2.17273 (* 1 = 2.17273 loss)
I0812 02:03:18.783540 26953 sgd_solver.cpp:106] Iteration 18070, lr = 0.01
I0812 02:03:37.153712 26953 solver.cpp:228] Iteration 18080, loss = 2.12385
I0812 02:03:37.153945 26953 solver.cpp:244]     Train net output #0: loss = 2.12385 (* 1 = 2.12385 loss)
I0812 02:03:38.553354 26953 sgd_solver.cpp:106] Iteration 18080, lr = 0.01
I0812 02:03:56.921457 26953 solver.cpp:228] Iteration 18090, loss = 2.22526
I0812 02:03:56.921522 26953 solver.cpp:244]     Train net output #0: loss = 2.22526 (* 1 = 2.22526 loss)
I0812 02:03:58.336024 26953 sgd_solver.cpp:106] Iteration 18090, lr = 0.01
I0812 02:04:16.138557 26953 solver.cpp:337] Iteration 18100, Testing net (#0)
I0812 02:04:16.725930 26953 solver.cpp:404]     Test net output #0: accuracy = 0.508
I0812 02:04:16.725986 26953 solver.cpp:404]     Test net output #1: loss = 2.25078 (* 1 = 2.25078 loss)
I0812 02:04:17.296723 26953 solver.cpp:228] Iteration 18100, loss = 2.2367
I0812 02:04:17.296818 26953 solver.cpp:244]     Train net output #0: loss = 2.2367 (* 1 = 2.2367 loss)
I0812 02:04:18.663221 26953 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0812 02:04:37.037641 26953 solver.cpp:228] Iteration 18110, loss = 2.23123
I0812 02:04:37.037719 26953 solver.cpp:244]     Train net output #0: loss = 2.23123 (* 1 = 2.23123 loss)
I0812 02:04:38.440302 26953 sgd_solver.cpp:106] Iteration 18110, lr = 0.01
I0812 02:04:56.801069 26953 solver.cpp:228] Iteration 18120, loss = 2.17871
I0812 02:04:56.801337 26953 solver.cpp:244]     Train net output #0: loss = 2.17871 (* 1 = 2.17871 loss)
I0812 02:04:58.203182 26953 sgd_solver.cpp:106] Iteration 18120, lr = 0.01
I0812 02:05:16.626914 26953 solver.cpp:228] Iteration 18130, loss = 2.27638
I0812 02:05:16.626984 26953 solver.cpp:244]     Train net output #0: loss = 2.27638 (* 1 = 2.27638 loss)
I0812 02:05:18.026558 26953 sgd_solver.cpp:106] Iteration 18130, lr = 0.01
I0812 02:05:36.405355 26953 solver.cpp:228] Iteration 18140, loss = 2.19516
I0812 02:05:36.405562 26953 solver.cpp:244]     Train net output #0: loss = 2.19516 (* 1 = 2.19516 loss)
I0812 02:05:37.819944 26953 sgd_solver.cpp:106] Iteration 18140, lr = 0.01
I0812 02:05:56.203797 26953 solver.cpp:228] Iteration 18150, loss = 2.33714
I0812 02:05:56.203871 26953 solver.cpp:244]     Train net output #0: loss = 2.33714 (* 1 = 2.33714 loss)
I0812 02:05:57.609591 26953 sgd_solver.cpp:106] Iteration 18150, lr = 0.01
I0812 02:06:16.014614 26953 solver.cpp:228] Iteration 18160, loss = 2.16205
I0812 02:06:16.014873 26953 solver.cpp:244]     Train net output #0: loss = 2.16205 (* 1 = 2.16205 loss)
I0812 02:06:17.416970 26953 sgd_solver.cpp:106] Iteration 18160, lr = 0.01
I0812 02:06:35.782869 26953 solver.cpp:228] Iteration 18170, loss = 2.14639
I0812 02:06:35.782941 26953 solver.cpp:244]     Train net output #0: loss = 2.14639 (* 1 = 2.14639 loss)
I0812 02:06:37.182703 26953 sgd_solver.cpp:106] Iteration 18170, lr = 0.01
I0812 02:06:55.542081 26953 solver.cpp:228] Iteration 18180, loss = 2.25184
I0812 02:06:55.542318 26953 solver.cpp:244]     Train net output #0: loss = 2.25184 (* 1 = 2.25184 loss)
I0812 02:06:56.947125 26953 sgd_solver.cpp:106] Iteration 18180, lr = 0.01
I0812 02:07:15.320518 26953 solver.cpp:228] Iteration 18190, loss = 2.15189
I0812 02:07:15.320585 26953 solver.cpp:244]     Train net output #0: loss = 2.15189 (* 1 = 2.15189 loss)
I0812 02:07:16.720046 26953 sgd_solver.cpp:106] Iteration 18190, lr = 0.01
I0812 02:07:34.523514 26953 solver.cpp:337] Iteration 18200, Testing net (#0)
I0812 02:07:35.114181 26953 solver.cpp:404]     Test net output #0: accuracy = 0.48
I0812 02:07:35.114259 26953 solver.cpp:404]     Test net output #1: loss = 2.31753 (* 1 = 2.31753 loss)
I0812 02:07:35.686689 26953 solver.cpp:228] Iteration 18200, loss = 1.98473
I0812 02:07:35.686799 26953 solver.cpp:244]     Train net output #0: loss = 1.98473 (* 1 = 1.98473 loss)
I0812 02:07:37.074743 26953 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0812 02:07:55.466159 26953 solver.cpp:228] Iteration 18210, loss = 2.18958
I0812 02:07:55.466233 26953 solver.cpp:244]     Train net output #0: loss = 2.18958 (* 1 = 2.18958 loss)
I0812 02:07:56.869451 26953 sgd_solver.cpp:106] Iteration 18210, lr = 0.01
I0812 02:08:15.243507 26953 solver.cpp:228] Iteration 18220, loss = 2.23488
I0812 02:08:15.243865 26953 solver.cpp:244]     Train net output #0: loss = 2.23488 (* 1 = 2.23488 loss)
I0812 02:08:16.639593 26953 sgd_solver.cpp:106] Iteration 18220, lr = 0.01
I0812 02:08:35.047389 26953 solver.cpp:228] Iteration 18230, loss = 2.22126
I0812 02:08:35.047462 26953 solver.cpp:244]     Train net output #0: loss = 2.22126 (* 1 = 2.22126 loss)
I0812 02:08:36.461483 26953 sgd_solver.cpp:106] Iteration 18230, lr = 0.01
I0812 02:08:54.810096 26953 solver.cpp:228] Iteration 18240, loss = 2.27576
I0812 02:08:54.810245 26953 solver.cpp:244]     Train net output #0: loss = 2.27576 (* 1 = 2.27576 loss)
I0812 02:08:56.216411 26953 sgd_solver.cpp:106] Iteration 18240, lr = 0.01
I0812 02:09:14.633640 26953 solver.cpp:228] Iteration 18250, loss = 2.2809
I0812 02:09:14.633713 26953 solver.cpp:244]     Train net output #0: loss = 2.2809 (* 1 = 2.2809 loss)
I0812 02:09:16.035882 26953 sgd_solver.cpp:106] Iteration 18250, lr = 0.01
I0812 02:09:34.426065 26953 solver.cpp:228] Iteration 18260, loss = 2.14148
I0812 02:09:34.426295 26953 solver.cpp:244]     Train net output #0: loss = 2.14148 (* 1 = 2.14148 loss)
I0812 02:09:35.830796 26953 sgd_solver.cpp:106] Iteration 18260, lr = 0.01
I0812 02:09:54.218049 26953 solver.cpp:228] Iteration 18270, loss = 2.07945
I0812 02:09:54.218127 26953 solver.cpp:244]     Train net output #0: loss = 2.07945 (* 1 = 2.07945 loss)
I0812 02:09:55.616458 26953 sgd_solver.cpp:106] Iteration 18270, lr = 0.01
I0812 02:10:13.997890 26953 solver.cpp:228] Iteration 18280, loss = 2.10698
I0812 02:10:13.998106 26953 solver.cpp:244]     Train net output #0: loss = 2.10698 (* 1 = 2.10698 loss)
I0812 02:10:15.391304 26953 sgd_solver.cpp:106] Iteration 18280, lr = 0.01
I0812 02:10:33.794440 26953 solver.cpp:228] Iteration 18290, loss = 2.28801
I0812 02:10:33.794503 26953 solver.cpp:244]     Train net output #0: loss = 2.28801 (* 1 = 2.28801 loss)
I0812 02:10:35.193094 26953 sgd_solver.cpp:106] Iteration 18290, lr = 0.01
I0812 02:10:53.007958 26953 solver.cpp:337] Iteration 18300, Testing net (#0)
I0812 02:10:53.595742 26953 solver.cpp:404]     Test net output #0: accuracy = 0.486
I0812 02:10:53.595816 26953 solver.cpp:404]     Test net output #1: loss = 2.30678 (* 1 = 2.30678 loss)
I0812 02:10:54.171622 26953 solver.cpp:228] Iteration 18300, loss = 2.31563
I0812 02:10:54.171728 26953 solver.cpp:244]     Train net output #0: loss = 2.31563 (* 1 = 2.31563 loss)
I0812 02:10:55.540709 26953 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0812 02:11:13.963968 26953 solver.cpp:228] Iteration 18310, loss = 2.00397
I0812 02:11:13.964033 26953 solver.cpp:244]     Train net output #0: loss = 2.00397 (* 1 = 2.00397 loss)
I0812 02:11:15.351666 26953 sgd_solver.cpp:106] Iteration 18310, lr = 0.01
I0812 02:11:33.725661 26953 solver.cpp:228] Iteration 18320, loss = 2.13671
I0812 02:11:33.725829 26953 solver.cpp:244]     Train net output #0: loss = 2.13671 (* 1 = 2.13671 loss)
I0812 02:11:35.141520 26953 sgd_solver.cpp:106] Iteration 18320, lr = 0.01
I0812 02:11:53.522789 26953 solver.cpp:228] Iteration 18330, loss = 2.22368
I0812 02:11:53.522846 26953 solver.cpp:244]     Train net output #0: loss = 2.22368 (* 1 = 2.22368 loss)
I0812 02:11:54.918784 26953 sgd_solver.cpp:106] Iteration 18330, lr = 0.01
I0812 02:12:13.332365 26953 solver.cpp:228] Iteration 18340, loss = 2.0724
I0812 02:12:13.332499 26953 solver.cpp:244]     Train net output #0: loss = 2.0724 (* 1 = 2.0724 loss)
I0812 02:12:14.737859 26953 sgd_solver.cpp:106] Iteration 18340, lr = 0.01
I0812 02:12:33.082702 26953 solver.cpp:228] Iteration 18350, loss = 2.25688
I0812 02:12:33.082810 26953 solver.cpp:244]     Train net output #0: loss = 2.25688 (* 1 = 2.25688 loss)
I0812 02:12:34.489089 26953 sgd_solver.cpp:106] Iteration 18350, lr = 0.01
I0812 02:12:52.849448 26953 solver.cpp:228] Iteration 18360, loss = 2.24026
I0812 02:12:52.849721 26953 solver.cpp:244]     Train net output #0: loss = 2.24026 (* 1 = 2.24026 loss)
I0812 02:12:54.244073 26953 sgd_solver.cpp:106] Iteration 18360, lr = 0.01
I0812 02:13:12.710732 26953 solver.cpp:228] Iteration 18370, loss = 2.19798
I0812 02:13:12.710809 26953 solver.cpp:244]     Train net output #0: loss = 2.19798 (* 1 = 2.19798 loss)
I0812 02:13:14.116143 26953 sgd_solver.cpp:106] Iteration 18370, lr = 0.01
I0812 02:13:32.501895 26953 solver.cpp:228] Iteration 18380, loss = 2.07021
I0812 02:13:32.502127 26953 solver.cpp:244]     Train net output #0: loss = 2.07021 (* 1 = 2.07021 loss)
I0812 02:13:33.907526 26953 sgd_solver.cpp:106] Iteration 18380, lr = 0.01
I0812 02:13:52.335170 26953 solver.cpp:228] Iteration 18390, loss = 2.35894
I0812 02:13:52.335235 26953 solver.cpp:244]     Train net output #0: loss = 2.35894 (* 1 = 2.35894 loss)
I0812 02:13:53.726328 26953 sgd_solver.cpp:106] Iteration 18390, lr = 0.01
I0812 02:14:11.502625 26953 solver.cpp:337] Iteration 18400, Testing net (#0)
I0812 02:14:12.091027 26953 solver.cpp:404]     Test net output #0: accuracy = 0.508
I0812 02:14:12.091100 26953 solver.cpp:404]     Test net output #1: loss = 2.20434 (* 1 = 2.20434 loss)
I0812 02:14:12.654204 26953 solver.cpp:228] Iteration 18400, loss = 2.10253
I0812 02:14:12.654275 26953 solver.cpp:244]     Train net output #0: loss = 2.10253 (* 1 = 2.10253 loss)
I0812 02:14:14.039027 26953 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0812 02:14:32.409395 26953 solver.cpp:228] Iteration 18410, loss = 2.44062
I0812 02:14:32.409468 26953 solver.cpp:244]     Train net output #0: loss = 2.44062 (* 1 = 2.44062 loss)
I0812 02:14:33.820461 26953 sgd_solver.cpp:106] Iteration 18410, lr = 0.01
I0812 02:14:52.236011 26953 solver.cpp:228] Iteration 18420, loss = 2.13163
I0812 02:14:52.237306 26953 solver.cpp:244]     Train net output #0: loss = 2.13163 (* 1 = 2.13163 loss)
I0812 02:14:53.634807 26953 sgd_solver.cpp:106] Iteration 18420, lr = 0.01
I0812 02:15:12.001130 26953 solver.cpp:228] Iteration 18430, loss = 2.13287
I0812 02:15:12.001209 26953 solver.cpp:244]     Train net output #0: loss = 2.13287 (* 1 = 2.13287 loss)
I0812 02:15:13.394170 26953 sgd_solver.cpp:106] Iteration 18430, lr = 0.01
I0812 02:15:31.740229 26953 solver.cpp:228] Iteration 18440, loss = 2.17514
I0812 02:15:31.740386 26953 solver.cpp:244]     Train net output #0: loss = 2.17514 (* 1 = 2.17514 loss)
I0812 02:15:33.171162 26953 sgd_solver.cpp:106] Iteration 18440, lr = 0.01
I0812 02:15:51.546677 26953 solver.cpp:228] Iteration 18450, loss = 2.09279
I0812 02:15:51.546747 26953 solver.cpp:244]     Train net output #0: loss = 2.09279 (* 1 = 2.09279 loss)
I0812 02:15:52.956146 26953 sgd_solver.cpp:106] Iteration 18450, lr = 0.01
I0812 02:16:11.383213 26953 solver.cpp:228] Iteration 18460, loss = 2.16402
I0812 02:16:11.383360 26953 solver.cpp:244]     Train net output #0: loss = 2.16402 (* 1 = 2.16402 loss)
I0812 02:16:12.796460 26953 sgd_solver.cpp:106] Iteration 18460, lr = 0.01
I0812 02:16:31.138296 26953 solver.cpp:228] Iteration 18470, loss = 2.04092
I0812 02:16:31.138368 26953 solver.cpp:244]     Train net output #0: loss = 2.04092 (* 1 = 2.04092 loss)
I0812 02:16:32.546726 26953 sgd_solver.cpp:106] Iteration 18470, lr = 0.01
I0812 02:16:50.969657 26953 solver.cpp:228] Iteration 18480, loss = 2.1384
I0812 02:16:50.969820 26953 solver.cpp:244]     Train net output #0: loss = 2.1384 (* 1 = 2.1384 loss)
I0812 02:16:52.362663 26953 sgd_solver.cpp:106] Iteration 18480, lr = 0.01
I0812 02:17:10.727202 26953 solver.cpp:228] Iteration 18490, loss = 2.36605
I0812 02:17:10.727262 26953 solver.cpp:244]     Train net output #0: loss = 2.36605 (* 1 = 2.36605 loss)
I0812 02:17:12.134557 26953 sgd_solver.cpp:106] Iteration 18490, lr = 0.01
I0812 02:17:29.919059 26953 solver.cpp:337] Iteration 18500, Testing net (#0)
I0812 02:17:30.504276 26953 solver.cpp:404]     Test net output #0: accuracy = 0.492
I0812 02:17:30.504334 26953 solver.cpp:404]     Test net output #1: loss = 2.23247 (* 1 = 2.23247 loss)
I0812 02:17:31.083333 26953 solver.cpp:228] Iteration 18500, loss = 2.16203
I0812 02:17:31.083410 26953 solver.cpp:244]     Train net output #0: loss = 2.16203 (* 1 = 2.16203 loss)
I0812 02:17:32.466848 26953 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0812 02:17:50.862468 26953 solver.cpp:228] Iteration 18510, loss = 2.20623
I0812 02:17:50.862534 26953 solver.cpp:244]     Train net output #0: loss = 2.20623 (* 1 = 2.20623 loss)
I0812 02:17:52.269881 26953 sgd_solver.cpp:106] Iteration 18510, lr = 0.01
I0812 02:18:10.675644 26953 solver.cpp:228] Iteration 18520, loss = 2.30126
I0812 02:18:10.675853 26953 solver.cpp:244]     Train net output #0: loss = 2.30126 (* 1 = 2.30126 loss)
I0812 02:18:12.084589 26953 sgd_solver.cpp:106] Iteration 18520, lr = 0.01
I0812 02:18:30.435241 26953 solver.cpp:228] Iteration 18530, loss = 2.14389
I0812 02:18:30.435312 26953 solver.cpp:244]     Train net output #0: loss = 2.14389 (* 1 = 2.14389 loss)
I0812 02:18:31.841691 26953 sgd_solver.cpp:106] Iteration 18530, lr = 0.01
I0812 02:18:50.259107 26953 solver.cpp:228] Iteration 18540, loss = 2.25221
I0812 02:18:50.260043 26953 solver.cpp:244]     Train net output #0: loss = 2.25221 (* 1 = 2.25221 loss)
I0812 02:18:51.632539 26953 sgd_solver.cpp:106] Iteration 18540, lr = 0.01
I0812 02:19:10.053143 26953 solver.cpp:228] Iteration 18550, loss = 2.18309
I0812 02:19:10.053247 26953 solver.cpp:244]     Train net output #0: loss = 2.18309 (* 1 = 2.18309 loss)
I0812 02:19:11.442900 26953 sgd_solver.cpp:106] Iteration 18550, lr = 0.01
I0812 02:19:29.806831 26953 solver.cpp:228] Iteration 18560, loss = 2.18777
I0812 02:19:29.807031 26953 solver.cpp:244]     Train net output #0: loss = 2.18777 (* 1 = 2.18777 loss)
I0812 02:19:31.219256 26953 sgd_solver.cpp:106] Iteration 18560, lr = 0.01
I0812 02:19:49.598701 26953 solver.cpp:228] Iteration 18570, loss = 2.14121
I0812 02:19:49.598775 26953 solver.cpp:244]     Train net output #0: loss = 2.14121 (* 1 = 2.14121 loss)
I0812 02:19:51.005656 26953 sgd_solver.cpp:106] Iteration 18570, lr = 0.01
I0812 02:20:09.376868 26953 solver.cpp:228] Iteration 18580, loss = 2.18075
I0812 02:20:09.377107 26953 solver.cpp:244]     Train net output #0: loss = 2.18075 (* 1 = 2.18075 loss)
I0812 02:20:10.767082 26953 sgd_solver.cpp:106] Iteration 18580, lr = 0.01
I0812 02:20:29.134347 26953 solver.cpp:228] Iteration 18590, loss = 2.11713
I0812 02:20:29.134426 26953 solver.cpp:244]     Train net output #0: loss = 2.11713 (* 1 = 2.11713 loss)
I0812 02:20:30.548197 26953 sgd_solver.cpp:106] Iteration 18590, lr = 0.01
I0812 02:20:48.425830 26953 solver.cpp:337] Iteration 18600, Testing net (#0)
I0812 02:20:49.012068 26953 solver.cpp:404]     Test net output #0: accuracy = 0.472
I0812 02:20:49.012140 26953 solver.cpp:404]     Test net output #1: loss = 2.39871 (* 1 = 2.39871 loss)
I0812 02:20:49.573065 26953 solver.cpp:228] Iteration 18600, loss = 2.19321
I0812 02:20:49.573140 26953 solver.cpp:244]     Train net output #0: loss = 2.19321 (* 1 = 2.19321 loss)
I0812 02:20:50.966256 26953 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0812 02:21:09.340435 26953 solver.cpp:228] Iteration 18610, loss = 2.08614
I0812 02:21:09.340515 26953 solver.cpp:244]     Train net output #0: loss = 2.08614 (* 1 = 2.08614 loss)
I0812 02:21:10.737416 26953 sgd_solver.cpp:106] Iteration 18610, lr = 0.01
I0812 02:21:29.123710 26953 solver.cpp:228] Iteration 18620, loss = 2.28728
I0812 02:21:29.123920 26953 solver.cpp:244]     Train net output #0: loss = 2.28728 (* 1 = 2.28728 loss)
I0812 02:21:30.530939 26953 sgd_solver.cpp:106] Iteration 18620, lr = 0.01
I0812 02:21:48.936636 26953 solver.cpp:228] Iteration 18630, loss = 2.10681
I0812 02:21:48.936717 26953 solver.cpp:244]     Train net output #0: loss = 2.10681 (* 1 = 2.10681 loss)
I0812 02:21:50.342036 26953 sgd_solver.cpp:106] Iteration 18630, lr = 0.01
I0812 02:22:08.722293 26953 solver.cpp:228] Iteration 18640, loss = 2.08337
I0812 02:22:08.722533 26953 solver.cpp:244]     Train net output #0: loss = 2.08337 (* 1 = 2.08337 loss)
I0812 02:22:10.130342 26953 sgd_solver.cpp:106] Iteration 18640, lr = 0.01
I0812 02:22:28.471582 26953 solver.cpp:228] Iteration 18650, loss = 2.18638
I0812 02:22:28.471654 26953 solver.cpp:244]     Train net output #0: loss = 2.18638 (* 1 = 2.18638 loss)
I0812 02:22:29.878782 26953 sgd_solver.cpp:106] Iteration 18650, lr = 0.01
I0812 02:22:48.318869 26953 solver.cpp:228] Iteration 18660, loss = 2.15452
I0812 02:22:48.319026 26953 solver.cpp:244]     Train net output #0: loss = 2.15452 (* 1 = 2.15452 loss)
I0812 02:22:49.710130 26953 sgd_solver.cpp:106] Iteration 18660, lr = 0.01
I0812 02:23:08.082025 26953 solver.cpp:228] Iteration 18670, loss = 2.23013
I0812 02:23:08.082095 26953 solver.cpp:244]     Train net output #0: loss = 2.23013 (* 1 = 2.23013 loss)
I0812 02:23:09.507033 26953 sgd_solver.cpp:106] Iteration 18670, lr = 0.01
I0812 02:23:27.882210 26953 solver.cpp:228] Iteration 18680, loss = 2.17697
I0812 02:23:27.882472 26953 solver.cpp:244]     Train net output #0: loss = 2.17697 (* 1 = 2.17697 loss)
I0812 02:23:29.294622 26953 sgd_solver.cpp:106] Iteration 18680, lr = 0.01
I0812 02:23:47.702901 26953 solver.cpp:228] Iteration 18690, loss = 2.2664
I0812 02:23:47.702971 26953 solver.cpp:244]     Train net output #0: loss = 2.2664 (* 1 = 2.2664 loss)
I0812 02:23:49.101831 26953 sgd_solver.cpp:106] Iteration 18690, lr = 0.01
I0812 02:24:06.889852 26953 solver.cpp:337] Iteration 18700, Testing net (#0)
I0812 02:24:07.486824 26953 solver.cpp:404]     Test net output #0: accuracy = 0.464
I0812 02:24:07.486889 26953 solver.cpp:404]     Test net output #1: loss = 2.30764 (* 1 = 2.30764 loss)
I0812 02:24:08.057899 26953 solver.cpp:228] Iteration 18700, loss = 2.15134
I0812 02:24:08.057996 26953 solver.cpp:244]     Train net output #0: loss = 2.15134 (* 1 = 2.15134 loss)
I0812 02:24:09.425185 26953 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0812 02:24:27.840593 26953 solver.cpp:228] Iteration 18710, loss = 2.20417
I0812 02:24:27.840670 26953 solver.cpp:244]     Train net output #0: loss = 2.20417 (* 1 = 2.20417 loss)
I0812 02:24:29.238819 26953 sgd_solver.cpp:106] Iteration 18710, lr = 0.01
I0812 02:24:47.633452 26953 solver.cpp:228] Iteration 18720, loss = 2.27062
I0812 02:24:47.633708 26953 solver.cpp:244]     Train net output #0: loss = 2.27062 (* 1 = 2.27062 loss)
I0812 02:24:49.026612 26953 sgd_solver.cpp:106] Iteration 18720, lr = 0.01
I0812 02:25:07.396520 26953 solver.cpp:228] Iteration 18730, loss = 2.11854
I0812 02:25:07.396603 26953 solver.cpp:244]     Train net output #0: loss = 2.11854 (* 1 = 2.11854 loss)
I0812 02:25:08.803473 26953 sgd_solver.cpp:106] Iteration 18730, lr = 0.01
I0812 02:25:27.246553 26953 solver.cpp:228] Iteration 18740, loss = 2.14593
I0812 02:25:27.246805 26953 solver.cpp:244]     Train net output #0: loss = 2.14593 (* 1 = 2.14593 loss)
I0812 02:25:28.634646 26953 sgd_solver.cpp:106] Iteration 18740, lr = 0.01
I0812 02:25:47.027597 26953 solver.cpp:228] Iteration 18750, loss = 2.17194
I0812 02:25:47.027658 26953 solver.cpp:244]     Train net output #0: loss = 2.17194 (* 1 = 2.17194 loss)
I0812 02:25:48.437443 26953 sgd_solver.cpp:106] Iteration 18750, lr = 0.01
I0812 02:26:06.798846 26953 solver.cpp:228] Iteration 18760, loss = 2.24821
I0812 02:26:06.799110 26953 solver.cpp:244]     Train net output #0: loss = 2.24821 (* 1 = 2.24821 loss)
I0812 02:26:08.193675 26953 sgd_solver.cpp:106] Iteration 18760, lr = 0.01
I0812 02:26:26.561611 26953 solver.cpp:228] Iteration 18770, loss = 2.20691
I0812 02:26:26.561689 26953 solver.cpp:244]     Train net output #0: loss = 2.20691 (* 1 = 2.20691 loss)
I0812 02:26:27.961437 26953 sgd_solver.cpp:106] Iteration 18770, lr = 0.01
I0812 02:26:46.362661 26953 solver.cpp:228] Iteration 18780, loss = 2.19558
I0812 02:26:46.362898 26953 solver.cpp:244]     Train net output #0: loss = 2.19558 (* 1 = 2.19558 loss)
I0812 02:26:47.764570 26953 sgd_solver.cpp:106] Iteration 18780, lr = 0.01
I0812 02:27:06.120983 26953 solver.cpp:228] Iteration 18790, loss = 2.25852
I0812 02:27:06.121054 26953 solver.cpp:244]     Train net output #0: loss = 2.25852 (* 1 = 2.25852 loss)
I0812 02:27:07.527798 26953 sgd_solver.cpp:106] Iteration 18790, lr = 0.01
I0812 02:27:25.325090 26953 solver.cpp:337] Iteration 18800, Testing net (#0)
I0812 02:27:25.920892 26953 solver.cpp:404]     Test net output #0: accuracy = 0.524
I0812 02:27:25.920948 26953 solver.cpp:404]     Test net output #1: loss = 2.24527 (* 1 = 2.24527 loss)
I0812 02:27:26.496337 26953 solver.cpp:228] Iteration 18800, loss = 2.10103
I0812 02:27:26.496415 26953 solver.cpp:244]     Train net output #0: loss = 2.10103 (* 1 = 2.10103 loss)
I0812 02:27:27.863219 26953 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0812 02:27:46.283398 26953 solver.cpp:228] Iteration 18810, loss = 2.22292
I0812 02:27:46.283478 26953 solver.cpp:244]     Train net output #0: loss = 2.22292 (* 1 = 2.22292 loss)
I0812 02:27:47.682178 26953 sgd_solver.cpp:106] Iteration 18810, lr = 0.01
I0812 02:28:06.071687 26953 solver.cpp:228] Iteration 18820, loss = 2.24218
I0812 02:28:06.071849 26953 solver.cpp:244]     Train net output #0: loss = 2.24218 (* 1 = 2.24218 loss)
I0812 02:28:07.469427 26953 sgd_solver.cpp:106] Iteration 18820, lr = 0.01
I0812 02:28:25.881894 26953 solver.cpp:228] Iteration 18830, loss = 2.34805
I0812 02:28:25.881973 26953 solver.cpp:244]     Train net output #0: loss = 2.34805 (* 1 = 2.34805 loss)
I0812 02:28:27.285902 26953 sgd_solver.cpp:106] Iteration 18830, lr = 0.01
I0812 02:28:45.675034 26953 solver.cpp:228] Iteration 18840, loss = 2.2356
I0812 02:28:45.675302 26953 solver.cpp:244]     Train net output #0: loss = 2.2356 (* 1 = 2.2356 loss)
I0812 02:28:47.075877 26953 sgd_solver.cpp:106] Iteration 18840, lr = 0.01
I0812 02:29:05.443979 26953 solver.cpp:228] Iteration 18850, loss = 2.19787
I0812 02:29:05.444041 26953 solver.cpp:244]     Train net output #0: loss = 2.19787 (* 1 = 2.19787 loss)
I0812 02:29:06.849026 26953 sgd_solver.cpp:106] Iteration 18850, lr = 0.01
I0812 02:29:25.264809 26953 solver.cpp:228] Iteration 18860, loss = 2.02652
I0812 02:29:25.265010 26953 solver.cpp:244]     Train net output #0: loss = 2.02652 (* 1 = 2.02652 loss)
I0812 02:29:26.655879 26953 sgd_solver.cpp:106] Iteration 18860, lr = 0.01
I0812 02:29:45.077838 26953 solver.cpp:228] Iteration 18870, loss = 2.17045
I0812 02:29:45.077910 26953 solver.cpp:244]     Train net output #0: loss = 2.17045 (* 1 = 2.17045 loss)
I0812 02:29:46.478708 26953 sgd_solver.cpp:106] Iteration 18870, lr = 0.01
I0812 02:30:04.827188 26953 solver.cpp:228] Iteration 18880, loss = 2.36175
I0812 02:30:04.827414 26953 solver.cpp:244]     Train net output #0: loss = 2.36175 (* 1 = 2.36175 loss)
I0812 02:30:06.232872 26953 sgd_solver.cpp:106] Iteration 18880, lr = 0.01
I0812 02:30:24.629114 26953 solver.cpp:228] Iteration 18890, loss = 2.1582
I0812 02:30:24.629204 26953 solver.cpp:244]     Train net output #0: loss = 2.1582 (* 1 = 2.1582 loss)
I0812 02:30:26.028610 26953 sgd_solver.cpp:106] Iteration 18890, lr = 0.01
I0812 02:30:43.844277 26953 solver.cpp:337] Iteration 18900, Testing net (#0)
I0812 02:30:44.433040 26953 solver.cpp:404]     Test net output #0: accuracy = 0.522
I0812 02:30:44.433092 26953 solver.cpp:404]     Test net output #1: loss = 2.22559 (* 1 = 2.22559 loss)
I0812 02:30:45.019176 26953 solver.cpp:228] Iteration 18900, loss = 2.08715
I0812 02:30:45.019243 26953 solver.cpp:244]     Train net output #0: loss = 2.08715 (* 1 = 2.08715 loss)
I0812 02:30:46.382968 26953 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0812 02:31:04.821478 26953 solver.cpp:228] Iteration 18910, loss = 2.21494
I0812 02:31:04.821554 26953 solver.cpp:244]     Train net output #0: loss = 2.21494 (* 1 = 2.21494 loss)
I0812 02:31:06.218199 26953 sgd_solver.cpp:106] Iteration 18910, lr = 0.01
I0812 02:31:24.611577 26953 solver.cpp:228] Iteration 18920, loss = 2.20369
I0812 02:31:24.611773 26953 solver.cpp:244]     Train net output #0: loss = 2.20369 (* 1 = 2.20369 loss)
I0812 02:31:26.017508 26953 sgd_solver.cpp:106] Iteration 18920, lr = 0.01
I0812 02:31:44.378024 26953 solver.cpp:228] Iteration 18930, loss = 2.15608
I0812 02:31:44.378103 26953 solver.cpp:244]     Train net output #0: loss = 2.15608 (* 1 = 2.15608 loss)
I0812 02:31:45.769057 26953 sgd_solver.cpp:106] Iteration 18930, lr = 0.01
I0812 02:32:04.195396 26953 solver.cpp:228] Iteration 18940, loss = 2.16876
I0812 02:32:04.195636 26953 solver.cpp:244]     Train net output #0: loss = 2.16876 (* 1 = 2.16876 loss)
I0812 02:32:05.596817 26953 sgd_solver.cpp:106] Iteration 18940, lr = 0.01
I0812 02:32:23.983541 26953 solver.cpp:228] Iteration 18950, loss = 2.11569
I0812 02:32:23.983614 26953 solver.cpp:244]     Train net output #0: loss = 2.11569 (* 1 = 2.11569 loss)
I0812 02:32:25.385038 26953 sgd_solver.cpp:106] Iteration 18950, lr = 0.01
I0812 02:32:43.739158 26953 solver.cpp:228] Iteration 18960, loss = 2.10412
I0812 02:32:43.739348 26953 solver.cpp:244]     Train net output #0: loss = 2.10412 (* 1 = 2.10412 loss)
I0812 02:32:45.127934 26953 sgd_solver.cpp:106] Iteration 18960, lr = 0.01
I0812 02:33:03.534595 26953 solver.cpp:228] Iteration 18970, loss = 2.22769
I0812 02:33:03.534683 26953 solver.cpp:244]     Train net output #0: loss = 2.22769 (* 1 = 2.22769 loss)
I0812 02:33:04.927119 26953 sgd_solver.cpp:106] Iteration 18970, lr = 0.01
I0812 02:33:23.315379 26953 solver.cpp:228] Iteration 18980, loss = 2.38667
I0812 02:33:23.315521 26953 solver.cpp:244]     Train net output #0: loss = 2.38667 (* 1 = 2.38667 loss)
I0812 02:33:24.719347 26953 sgd_solver.cpp:106] Iteration 18980, lr = 0.01
I0812 02:33:43.095973 26953 solver.cpp:228] Iteration 18990, loss = 2.08232
I0812 02:33:43.096041 26953 solver.cpp:244]     Train net output #0: loss = 2.08232 (* 1 = 2.08232 loss)
I0812 02:33:44.506234 26953 sgd_solver.cpp:106] Iteration 18990, lr = 0.01
I0812 02:34:02.282994 26953 solver.cpp:337] Iteration 19000, Testing net (#0)
I0812 02:34:02.875265 26953 solver.cpp:404]     Test net output #0: accuracy = 0.518
I0812 02:34:02.875339 26953 solver.cpp:404]     Test net output #1: loss = 2.13992 (* 1 = 2.13992 loss)
I0812 02:34:03.445521 26953 solver.cpp:228] Iteration 19000, loss = 2.26199
I0812 02:34:03.445605 26953 solver.cpp:244]     Train net output #0: loss = 2.26199 (* 1 = 2.26199 loss)
I0812 02:34:04.820431 26953 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0812 02:34:23.248030 26953 solver.cpp:228] Iteration 19010, loss = 2.26555
I0812 02:34:23.248121 26953 solver.cpp:244]     Train net output #0: loss = 2.26555 (* 1 = 2.26555 loss)
I0812 02:34:24.661329 26953 sgd_solver.cpp:106] Iteration 19010, lr = 0.01
I0812 02:34:43.126713 26953 solver.cpp:228] Iteration 19020, loss = 2.25165
I0812 02:34:43.126870 26953 solver.cpp:244]     Train net output #0: loss = 2.25165 (* 1 = 2.25165 loss)
I0812 02:34:44.544773 26953 sgd_solver.cpp:106] Iteration 19020, lr = 0.01
I0812 02:35:02.911120 26953 solver.cpp:228] Iteration 19030, loss = 2.21814
I0812 02:35:02.911187 26953 solver.cpp:244]     Train net output #0: loss = 2.21814 (* 1 = 2.21814 loss)
I0812 02:35:04.309468 26953 sgd_solver.cpp:106] Iteration 19030, lr = 0.01
I0812 02:35:22.676712 26953 solver.cpp:228] Iteration 19040, loss = 2.26534
I0812 02:35:22.676911 26953 solver.cpp:244]     Train net output #0: loss = 2.26534 (* 1 = 2.26534 loss)
I0812 02:35:24.088565 26953 sgd_solver.cpp:106] Iteration 19040, lr = 0.01
I0812 02:35:42.514968 26953 solver.cpp:228] Iteration 19050, loss = 2.23409
I0812 02:35:42.515045 26953 solver.cpp:244]     Train net output #0: loss = 2.23409 (* 1 = 2.23409 loss)
I0812 02:35:43.921319 26953 sgd_solver.cpp:106] Iteration 19050, lr = 0.01
I0812 02:36:02.293903 26953 solver.cpp:228] Iteration 19060, loss = 2.1778
I0812 02:36:02.294076 26953 solver.cpp:244]     Train net output #0: loss = 2.1778 (* 1 = 2.1778 loss)
I0812 02:36:03.696995 26953 sgd_solver.cpp:106] Iteration 19060, lr = 0.01
I0812 02:36:22.063109 26953 solver.cpp:228] Iteration 19070, loss = 2.08528
I0812 02:36:22.063186 26953 solver.cpp:244]     Train net output #0: loss = 2.08528 (* 1 = 2.08528 loss)
I0812 02:36:23.466366 26953 sgd_solver.cpp:106] Iteration 19070, lr = 0.01
I0812 02:36:41.884730 26953 solver.cpp:228] Iteration 19080, loss = 2.17288
I0812 02:36:41.885005 26953 solver.cpp:244]     Train net output #0: loss = 2.17288 (* 1 = 2.17288 loss)
I0812 02:36:43.280267 26953 sgd_solver.cpp:106] Iteration 19080, lr = 0.01
I0812 02:37:01.677642 26953 solver.cpp:228] Iteration 19090, loss = 2.27465
I0812 02:37:01.677702 26953 solver.cpp:244]     Train net output #0: loss = 2.27465 (* 1 = 2.27465 loss)
I0812 02:37:03.094055 26953 sgd_solver.cpp:106] Iteration 19090, lr = 0.01
I0812 02:37:20.902493 26953 solver.cpp:337] Iteration 19100, Testing net (#0)
I0812 02:37:21.494907 26953 solver.cpp:404]     Test net output #0: accuracy = 0.494
I0812 02:37:21.494979 26953 solver.cpp:404]     Test net output #1: loss = 2.23423 (* 1 = 2.23423 loss)
I0812 02:37:22.063655 26953 solver.cpp:228] Iteration 19100, loss = 2.15438
I0812 02:37:22.063730 26953 solver.cpp:244]     Train net output #0: loss = 2.15438 (* 1 = 2.15438 loss)
I0812 02:37:23.434664 26953 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0812 02:37:41.857838 26953 solver.cpp:228] Iteration 19110, loss = 2.04965
I0812 02:37:41.857918 26953 solver.cpp:244]     Train net output #0: loss = 2.04965 (* 1 = 2.04965 loss)
I0812 02:37:43.265326 26953 sgd_solver.cpp:106] Iteration 19110, lr = 0.01
I0812 02:38:01.674182 26953 solver.cpp:228] Iteration 19120, loss = 2.32127
I0812 02:38:01.674387 26953 solver.cpp:244]     Train net output #0: loss = 2.32127 (* 1 = 2.32127 loss)
I0812 02:38:03.064765 26953 sgd_solver.cpp:106] Iteration 19120, lr = 0.01
I0812 02:38:21.477136 26953 solver.cpp:228] Iteration 19130, loss = 2.24706
I0812 02:38:21.477218 26953 solver.cpp:244]     Train net output #0: loss = 2.24706 (* 1 = 2.24706 loss)
I0812 02:38:22.871624 26953 sgd_solver.cpp:106] Iteration 19130, lr = 0.01
I0812 02:38:41.239747 26953 solver.cpp:228] Iteration 19140, loss = 2.14587
I0812 02:38:41.239974 26953 solver.cpp:244]     Train net output #0: loss = 2.14587 (* 1 = 2.14587 loss)
I0812 02:38:42.642628 26953 sgd_solver.cpp:106] Iteration 19140, lr = 0.01
I0812 02:39:01.058480 26953 solver.cpp:228] Iteration 19150, loss = 2.26757
I0812 02:39:01.058545 26953 solver.cpp:244]     Train net output #0: loss = 2.26757 (* 1 = 2.26757 loss)
I0812 02:39:02.447851 26953 sgd_solver.cpp:106] Iteration 19150, lr = 0.01
I0812 02:39:20.831070 26953 solver.cpp:228] Iteration 19160, loss = 2.0322
I0812 02:39:20.831264 26953 solver.cpp:244]     Train net output #0: loss = 2.0322 (* 1 = 2.0322 loss)
I0812 02:39:22.233332 26953 sgd_solver.cpp:106] Iteration 19160, lr = 0.01
I0812 02:39:40.614125 26953 solver.cpp:228] Iteration 19170, loss = 2.37221
I0812 02:39:40.614186 26953 solver.cpp:244]     Train net output #0: loss = 2.37221 (* 1 = 2.37221 loss)
I0812 02:39:42.025823 26953 sgd_solver.cpp:106] Iteration 19170, lr = 0.01
I0812 02:40:00.418038 26953 solver.cpp:228] Iteration 19180, loss = 2.3167
I0812 02:40:00.418315 26953 solver.cpp:244]     Train net output #0: loss = 2.3167 (* 1 = 2.3167 loss)
I0812 02:40:01.816486 26953 sgd_solver.cpp:106] Iteration 19180, lr = 0.01
I0812 02:40:20.264562 26953 solver.cpp:228] Iteration 19190, loss = 2.22415
I0812 02:40:20.264622 26953 solver.cpp:244]     Train net output #0: loss = 2.22415 (* 1 = 2.22415 loss)
I0812 02:40:21.667029 26953 sgd_solver.cpp:106] Iteration 19190, lr = 0.01
I0812 02:40:39.425706 26953 solver.cpp:337] Iteration 19200, Testing net (#0)
I0812 02:40:40.019381 26953 solver.cpp:404]     Test net output #0: accuracy = 0.488
I0812 02:40:40.019464 26953 solver.cpp:404]     Test net output #1: loss = 2.16722 (* 1 = 2.16722 loss)
I0812 02:40:40.589542 26953 solver.cpp:228] Iteration 19200, loss = 2.14078
I0812 02:40:40.589615 26953 solver.cpp:244]     Train net output #0: loss = 2.14078 (* 1 = 2.14078 loss)
I0812 02:40:41.973227 26953 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0812 02:41:00.382566 26953 solver.cpp:228] Iteration 19210, loss = 2.31046
I0812 02:41:00.382628 26953 solver.cpp:244]     Train net output #0: loss = 2.31046 (* 1 = 2.31046 loss)
I0812 02:41:01.773289 26953 sgd_solver.cpp:106] Iteration 19210, lr = 0.01
I0812 02:41:20.156636 26953 solver.cpp:228] Iteration 19220, loss = 2.24354
I0812 02:41:20.156821 26953 solver.cpp:244]     Train net output #0: loss = 2.24354 (* 1 = 2.24354 loss)
I0812 02:41:21.564857 26953 sgd_solver.cpp:106] Iteration 19220, lr = 0.01
I0812 02:41:39.945691 26953 solver.cpp:228] Iteration 19230, loss = 2.16969
I0812 02:41:39.945761 26953 solver.cpp:244]     Train net output #0: loss = 2.16969 (* 1 = 2.16969 loss)
I0812 02:41:41.337916 26953 sgd_solver.cpp:106] Iteration 19230, lr = 0.01
I0812 02:41:59.771159 26953 solver.cpp:228] Iteration 19240, loss = 2.17629
I0812 02:41:59.771416 26953 solver.cpp:244]     Train net output #0: loss = 2.17629 (* 1 = 2.17629 loss)
I0812 02:42:01.165582 26953 sgd_solver.cpp:106] Iteration 19240, lr = 0.01
I0812 02:42:19.557689 26953 solver.cpp:228] Iteration 19250, loss = 2.05994
I0812 02:42:19.557765 26953 solver.cpp:244]     Train net output #0: loss = 2.05994 (* 1 = 2.05994 loss)
I0812 02:42:20.950533 26953 sgd_solver.cpp:106] Iteration 19250, lr = 0.01
I0812 02:42:39.329258 26953 solver.cpp:228] Iteration 19260, loss = 2.02887
I0812 02:42:39.329499 26953 solver.cpp:244]     Train net output #0: loss = 2.02887 (* 1 = 2.02887 loss)
I0812 02:42:40.731894 26953 sgd_solver.cpp:106] Iteration 19260, lr = 0.01
I0812 02:42:59.189272 26953 solver.cpp:228] Iteration 19270, loss = 2.03142
I0812 02:42:59.189343 26953 solver.cpp:244]     Train net output #0: loss = 2.03142 (* 1 = 2.03142 loss)
I0812 02:43:00.586421 26953 sgd_solver.cpp:106] Iteration 19270, lr = 0.01
I0812 02:43:18.958407 26953 solver.cpp:228] Iteration 19280, loss = 1.96488
I0812 02:43:18.958641 26953 solver.cpp:244]     Train net output #0: loss = 1.96488 (* 1 = 1.96488 loss)
I0812 02:43:20.371378 26953 sgd_solver.cpp:106] Iteration 19280, lr = 0.01
I0812 02:43:38.770926 26953 solver.cpp:228] Iteration 19290, loss = 2.20411
I0812 02:43:38.770997 26953 solver.cpp:244]     Train net output #0: loss = 2.20411 (* 1 = 2.20411 loss)
I0812 02:43:40.170956 26953 sgd_solver.cpp:106] Iteration 19290, lr = 0.01
I0812 02:43:58.019106 26953 solver.cpp:337] Iteration 19300, Testing net (#0)
I0812 02:43:58.610054 26953 solver.cpp:404]     Test net output #0: accuracy = 0.504
I0812 02:43:58.610116 26953 solver.cpp:404]     Test net output #1: loss = 2.26893 (* 1 = 2.26893 loss)
I0812 02:43:59.175160 26953 solver.cpp:228] Iteration 19300, loss = 2.05939
I0812 02:43:59.175261 26953 solver.cpp:244]     Train net output #0: loss = 2.05939 (* 1 = 2.05939 loss)
I0812 02:44:00.551342 26953 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0812 02:44:18.978416 26953 solver.cpp:228] Iteration 19310, loss = 2.14817
I0812 02:44:18.978489 26953 solver.cpp:244]     Train net output #0: loss = 2.14817 (* 1 = 2.14817 loss)
I0812 02:44:20.383687 26953 sgd_solver.cpp:106] Iteration 19310, lr = 0.01
I0812 02:44:38.772305 26953 solver.cpp:228] Iteration 19320, loss = 2.17738
I0812 02:44:38.772505 26953 solver.cpp:244]     Train net output #0: loss = 2.17738 (* 1 = 2.17738 loss)
I0812 02:44:40.177609 26953 sgd_solver.cpp:106] Iteration 19320, lr = 0.01
I0812 02:44:58.546555 26953 solver.cpp:228] Iteration 19330, loss = 2.20363
I0812 02:44:58.546629 26953 solver.cpp:244]     Train net output #0: loss = 2.20363 (* 1 = 2.20363 loss)
I0812 02:44:59.958129 26953 sgd_solver.cpp:106] Iteration 19330, lr = 0.01
I0812 02:45:18.390069 26953 solver.cpp:228] Iteration 19340, loss = 2.39542
I0812 02:45:18.390298 26953 solver.cpp:244]     Train net output #0: loss = 2.39542 (* 1 = 2.39542 loss)
I0812 02:45:19.788161 26953 sgd_solver.cpp:106] Iteration 19340, lr = 0.01
I0812 02:45:38.175276 26953 solver.cpp:228] Iteration 19350, loss = 2.02437
I0812 02:45:38.175354 26953 solver.cpp:244]     Train net output #0: loss = 2.02437 (* 1 = 2.02437 loss)
I0812 02:45:39.589124 26953 sgd_solver.cpp:106] Iteration 19350, lr = 0.01
I0812 02:45:57.975673 26953 solver.cpp:228] Iteration 19360, loss = 2.41125
I0812 02:45:57.975900 26953 solver.cpp:244]     Train net output #0: loss = 2.41125 (* 1 = 2.41125 loss)
I0812 02:45:59.360796 26953 sgd_solver.cpp:106] Iteration 19360, lr = 0.01
I0812 02:46:17.793784 26953 solver.cpp:228] Iteration 19370, loss = 2.15408
I0812 02:46:17.793853 26953 solver.cpp:244]     Train net output #0: loss = 2.15408 (* 1 = 2.15408 loss)
I0812 02:46:19.194098 26953 sgd_solver.cpp:106] Iteration 19370, lr = 0.01
I0812 02:46:37.542114 26953 solver.cpp:228] Iteration 19380, loss = 2.12425
I0812 02:46:37.542346 26953 solver.cpp:244]     Train net output #0: loss = 2.12425 (* 1 = 2.12425 loss)
I0812 02:46:38.955713 26953 sgd_solver.cpp:106] Iteration 19380, lr = 0.01
I0812 02:46:57.324137 26953 solver.cpp:228] Iteration 19390, loss = 2.09269
I0812 02:46:57.324206 26953 solver.cpp:244]     Train net output #0: loss = 2.09269 (* 1 = 2.09269 loss)
I0812 02:46:58.723767 26953 sgd_solver.cpp:106] Iteration 19390, lr = 0.01
I0812 02:47:16.531517 26953 solver.cpp:337] Iteration 19400, Testing net (#0)
I0812 02:47:17.122016 26953 solver.cpp:404]     Test net output #0: accuracy = 0.51
I0812 02:47:17.122087 26953 solver.cpp:404]     Test net output #1: loss = 2.23752 (* 1 = 2.23752 loss)
I0812 02:47:17.711858 26953 solver.cpp:228] Iteration 19400, loss = 2.12439
I0812 02:47:17.711941 26953 solver.cpp:244]     Train net output #0: loss = 2.12439 (* 1 = 2.12439 loss)
I0812 02:47:19.082279 26953 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0812 02:47:37.458678 26953 solver.cpp:228] Iteration 19410, loss = 2.10109
I0812 02:47:37.458745 26953 solver.cpp:244]     Train net output #0: loss = 2.10109 (* 1 = 2.10109 loss)
I0812 02:47:38.861132 26953 sgd_solver.cpp:106] Iteration 19410, lr = 0.01
I0812 02:47:57.250939 26953 solver.cpp:228] Iteration 19420, loss = 2.29003
I0812 02:47:57.251176 26953 solver.cpp:244]     Train net output #0: loss = 2.29003 (* 1 = 2.29003 loss)
I0812 02:47:58.637794 26953 sgd_solver.cpp:106] Iteration 19420, lr = 0.01
I0812 02:48:17.088558 26953 solver.cpp:228] Iteration 19430, loss = 2.17782
I0812 02:48:17.088629 26953 solver.cpp:244]     Train net output #0: loss = 2.17782 (* 1 = 2.17782 loss)
I0812 02:48:18.491417 26953 sgd_solver.cpp:106] Iteration 19430, lr = 0.01
I0812 02:48:36.857519 26953 solver.cpp:228] Iteration 19440, loss = 2.07468
I0812 02:48:36.857785 26953 solver.cpp:244]     Train net output #0: loss = 2.07468 (* 1 = 2.07468 loss)
I0812 02:48:38.277005 26953 sgd_solver.cpp:106] Iteration 19440, lr = 0.01
I0812 02:48:56.718919 26953 solver.cpp:228] Iteration 19450, loss = 2.11466
I0812 02:48:56.718996 26953 solver.cpp:244]     Train net output #0: loss = 2.11466 (* 1 = 2.11466 loss)
I0812 02:48:58.106756 26953 sgd_solver.cpp:106] Iteration 19450, lr = 0.01
I0812 02:49:16.473690 26953 solver.cpp:228] Iteration 19460, loss = 2.19069
I0812 02:49:16.473844 26953 solver.cpp:244]     Train net output #0: loss = 2.19069 (* 1 = 2.19069 loss)
I0812 02:49:17.907213 26953 sgd_solver.cpp:106] Iteration 19460, lr = 0.01
I0812 02:49:36.298451 26953 solver.cpp:228] Iteration 19470, loss = 2.31327
I0812 02:49:36.298523 26953 solver.cpp:244]     Train net output #0: loss = 2.31327 (* 1 = 2.31327 loss)
I0812 02:49:37.689189 26953 sgd_solver.cpp:106] Iteration 19470, lr = 0.01
I0812 02:49:56.074882 26953 solver.cpp:228] Iteration 19480, loss = 2.20925
I0812 02:49:56.075132 26953 solver.cpp:244]     Train net output #0: loss = 2.20925 (* 1 = 2.20925 loss)
I0812 02:49:57.461905 26953 sgd_solver.cpp:106] Iteration 19480, lr = 0.01
I0812 02:50:15.852767 26953 solver.cpp:228] Iteration 19490, loss = 2.12843
I0812 02:50:15.852841 26953 solver.cpp:244]     Train net output #0: loss = 2.12843 (* 1 = 2.12843 loss)
I0812 02:50:17.249601 26953 sgd_solver.cpp:106] Iteration 19490, lr = 0.01
I0812 02:50:35.055215 26953 solver.cpp:337] Iteration 19500, Testing net (#0)
I0812 02:50:35.647297 26953 solver.cpp:404]     Test net output #0: accuracy = 0.51
I0812 02:50:35.647375 26953 solver.cpp:404]     Test net output #1: loss = 2.28629 (* 1 = 2.28629 loss)
I0812 02:50:36.227237 26953 solver.cpp:228] Iteration 19500, loss = 2.22436
I0812 02:50:36.227331 26953 solver.cpp:244]     Train net output #0: loss = 2.22436 (* 1 = 2.22436 loss)
I0812 02:50:37.587290 26953 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0812 02:50:55.995538 26953 solver.cpp:228] Iteration 19510, loss = 2.25901
I0812 02:50:55.995620 26953 solver.cpp:244]     Train net output #0: loss = 2.25901 (* 1 = 2.25901 loss)
I0812 02:50:57.404814 26953 sgd_solver.cpp:106] Iteration 19510, lr = 0.01
I0812 02:51:15.826325 26953 solver.cpp:228] Iteration 19520, loss = 2.17019
I0812 02:51:15.826539 26953 solver.cpp:244]     Train net output #0: loss = 2.17019 (* 1 = 2.17019 loss)
I0812 02:51:17.226315 26953 sgd_solver.cpp:106] Iteration 19520, lr = 0.01
I0812 02:51:35.621199 26953 solver.cpp:228] Iteration 19530, loss = 2.34521
I0812 02:51:35.621273 26953 solver.cpp:244]     Train net output #0: loss = 2.34521 (* 1 = 2.34521 loss)
I0812 02:51:37.023138 26953 sgd_solver.cpp:106] Iteration 19530, lr = 0.01
I0812 02:51:55.402101 26953 solver.cpp:228] Iteration 19540, loss = 2.09362
I0812 02:51:55.402359 26953 solver.cpp:244]     Train net output #0: loss = 2.09362 (* 1 = 2.09362 loss)
I0812 02:51:56.804718 26953 sgd_solver.cpp:106] Iteration 19540, lr = 0.01
I0812 02:52:15.167220 26953 solver.cpp:228] Iteration 19550, loss = 2.10931
I0812 02:52:15.167290 26953 solver.cpp:244]     Train net output #0: loss = 2.10931 (* 1 = 2.10931 loss)
I0812 02:52:16.572098 26953 sgd_solver.cpp:106] Iteration 19550, lr = 0.01
I0812 02:52:34.997793 26953 solver.cpp:228] Iteration 19560, loss = 2.2587
I0812 02:52:34.997942 26953 solver.cpp:244]     Train net output #0: loss = 2.2587 (* 1 = 2.2587 loss)
I0812 02:52:36.395295 26953 sgd_solver.cpp:106] Iteration 19560, lr = 0.01
I0812 02:52:54.781720 26953 solver.cpp:228] Iteration 19570, loss = 2.17488
I0812 02:52:54.781797 26953 solver.cpp:244]     Train net output #0: loss = 2.17488 (* 1 = 2.17488 loss)
I0812 02:52:56.178328 26953 sgd_solver.cpp:106] Iteration 19570, lr = 0.01
I0812 02:53:14.523636 26953 solver.cpp:228] Iteration 19580, loss = 2.18764
I0812 02:53:14.523820 26953 solver.cpp:244]     Train net output #0: loss = 2.18764 (* 1 = 2.18764 loss)
I0812 02:53:15.938431 26953 sgd_solver.cpp:106] Iteration 19580, lr = 0.01
I0812 02:53:34.316893 26953 solver.cpp:228] Iteration 19590, loss = 2.18244
I0812 02:53:34.316957 26953 solver.cpp:244]     Train net output #0: loss = 2.18244 (* 1 = 2.18244 loss)
I0812 02:53:35.728549 26953 sgd_solver.cpp:106] Iteration 19590, lr = 0.01
I0812 02:53:53.556375 26953 solver.cpp:337] Iteration 19600, Testing net (#0)
I0812 02:53:54.150689 26953 solver.cpp:404]     Test net output #0: accuracy = 0.5
I0812 02:53:54.150753 26953 solver.cpp:404]     Test net output #1: loss = 2.32848 (* 1 = 2.32848 loss)
I0812 02:53:54.720067 26953 solver.cpp:228] Iteration 19600, loss = 2.12614
I0812 02:53:54.720160 26953 solver.cpp:244]     Train net output #0: loss = 2.12614 (* 1 = 2.12614 loss)
I0812 02:53:56.095814 26953 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0812 02:54:14.452103 26953 solver.cpp:228] Iteration 19610, loss = 2.08685
I0812 02:54:14.452186 26953 solver.cpp:244]     Train net output #0: loss = 2.08685 (* 1 = 2.08685 loss)
I0812 02:54:15.843855 26953 sgd_solver.cpp:106] Iteration 19610, lr = 0.01
I0812 02:54:34.269565 26953 solver.cpp:228] Iteration 19620, loss = 2.18889
I0812 02:54:34.269724 26953 solver.cpp:244]     Train net output #0: loss = 2.18889 (* 1 = 2.18889 loss)
I0812 02:54:35.684343 26953 sgd_solver.cpp:106] Iteration 19620, lr = 0.01
I0812 02:54:54.031376 26953 solver.cpp:228] Iteration 19630, loss = 2.19526
I0812 02:54:54.031443 26953 solver.cpp:244]     Train net output #0: loss = 2.19526 (* 1 = 2.19526 loss)
I0812 02:54:55.431862 26953 sgd_solver.cpp:106] Iteration 19630, lr = 0.01
I0812 02:55:13.823211 26953 solver.cpp:228] Iteration 19640, loss = 2.26965
I0812 02:55:13.823446 26953 solver.cpp:244]     Train net output #0: loss = 2.26965 (* 1 = 2.26965 loss)
I0812 02:55:15.229712 26953 sgd_solver.cpp:106] Iteration 19640, lr = 0.01
I0812 02:55:33.612540 26953 solver.cpp:228] Iteration 19650, loss = 2.06844
I0812 02:55:33.612604 26953 solver.cpp:244]     Train net output #0: loss = 2.06844 (* 1 = 2.06844 loss)
I0812 02:55:35.011744 26953 sgd_solver.cpp:106] Iteration 19650, lr = 0.01
I0812 02:55:53.432446 26953 solver.cpp:228] Iteration 19660, loss = 2.18026
I0812 02:55:53.432716 26953 solver.cpp:244]     Train net output #0: loss = 2.18026 (* 1 = 2.18026 loss)
I0812 02:55:54.824923 26953 sgd_solver.cpp:106] Iteration 19660, lr = 0.01
I0812 02:56:13.163892 26953 solver.cpp:228] Iteration 19670, loss = 2.04147
I0812 02:56:13.163960 26953 solver.cpp:244]     Train net output #0: loss = 2.04147 (* 1 = 2.04147 loss)
I0812 02:56:14.564592 26953 sgd_solver.cpp:106] Iteration 19670, lr = 0.01
I0812 02:56:32.945803 26953 solver.cpp:228] Iteration 19680, loss = 2.17313
I0812 02:56:32.946034 26953 solver.cpp:244]     Train net output #0: loss = 2.17313 (* 1 = 2.17313 loss)
I0812 02:56:34.345815 26953 sgd_solver.cpp:106] Iteration 19680, lr = 0.01
I0812 02:56:52.787665 26953 solver.cpp:228] Iteration 19690, loss = 2.09895
I0812 02:56:52.787727 26953 solver.cpp:244]     Train net output #0: loss = 2.09895 (* 1 = 2.09895 loss)
I0812 02:56:54.179518 26953 sgd_solver.cpp:106] Iteration 19690, lr = 0.01
I0812 02:57:11.949013 26953 solver.cpp:337] Iteration 19700, Testing net (#0)
I0812 02:57:12.545210 26953 solver.cpp:404]     Test net output #0: accuracy = 0.508
I0812 02:57:12.545282 26953 solver.cpp:404]     Test net output #1: loss = 2.25699 (* 1 = 2.25699 loss)
I0812 02:57:13.107724 26953 solver.cpp:228] Iteration 19700, loss = 2.01769
I0812 02:57:13.107797 26953 solver.cpp:244]     Train net output #0: loss = 2.01769 (* 1 = 2.01769 loss)
I0812 02:57:14.499516 26953 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0812 02:57:32.873394 26953 solver.cpp:228] Iteration 19710, loss = 2.10985
I0812 02:57:32.873467 26953 solver.cpp:244]     Train net output #0: loss = 2.10985 (* 1 = 2.10985 loss)
I0812 02:57:34.272513 26953 sgd_solver.cpp:106] Iteration 19710, lr = 0.01
I0812 02:57:52.676327 26953 solver.cpp:228] Iteration 19720, loss = 2.06734
I0812 02:57:52.676548 26953 solver.cpp:244]     Train net output #0: loss = 2.06734 (* 1 = 2.06734 loss)
I0812 02:57:54.094820 26953 sgd_solver.cpp:106] Iteration 19720, lr = 0.01
I0812 02:58:12.570544 26953 solver.cpp:228] Iteration 19730, loss = 2.11516
I0812 02:58:12.570622 26953 solver.cpp:244]     Train net output #0: loss = 2.11516 (* 1 = 2.11516 loss)
I0812 02:58:13.975880 26953 sgd_solver.cpp:106] Iteration 19730, lr = 0.01
I0812 02:58:32.344045 26953 solver.cpp:228] Iteration 19740, loss = 2.13589
I0812 02:58:32.344298 26953 solver.cpp:244]     Train net output #0: loss = 2.13589 (* 1 = 2.13589 loss)
I0812 02:58:33.740257 26953 sgd_solver.cpp:106] Iteration 19740, lr = 0.01
I0812 02:58:52.130787 26953 solver.cpp:228] Iteration 19750, loss = 2.08525
I0812 02:58:52.130854 26953 solver.cpp:244]     Train net output #0: loss = 2.08525 (* 1 = 2.08525 loss)
I0812 02:58:53.538595 26953 sgd_solver.cpp:106] Iteration 19750, lr = 0.01
I0812 02:59:11.948225 26953 solver.cpp:228] Iteration 19760, loss = 2.19564
I0812 02:59:11.948453 26953 solver.cpp:244]     Train net output #0: loss = 2.19564 (* 1 = 2.19564 loss)
I0812 02:59:13.355903 26953 sgd_solver.cpp:106] Iteration 19760, lr = 0.01
I0812 02:59:31.759204 26953 solver.cpp:228] Iteration 19770, loss = 2.0569
I0812 02:59:31.759269 26953 solver.cpp:244]     Train net output #0: loss = 2.0569 (* 1 = 2.0569 loss)
I0812 02:59:33.173908 26953 sgd_solver.cpp:106] Iteration 19770, lr = 0.01
I0812 02:59:51.536674 26953 solver.cpp:228] Iteration 19780, loss = 2.22827
I0812 02:59:51.536828 26953 solver.cpp:244]     Train net output #0: loss = 2.22827 (* 1 = 2.22827 loss)
I0812 02:59:52.938421 26953 sgd_solver.cpp:106] Iteration 19780, lr = 0.01
I0812 03:00:11.386525 26953 solver.cpp:228] Iteration 19790, loss = 2.14929
I0812 03:00:11.386590 26953 solver.cpp:244]     Train net output #0: loss = 2.14929 (* 1 = 2.14929 loss)
I0812 03:00:12.788812 26953 sgd_solver.cpp:106] Iteration 19790, lr = 0.01
I0812 03:00:30.523821 26953 solver.cpp:337] Iteration 19800, Testing net (#0)
I0812 03:00:31.114737 26953 solver.cpp:404]     Test net output #0: accuracy = 0.526
I0812 03:00:31.114836 26953 solver.cpp:404]     Test net output #1: loss = 1.97464 (* 1 = 1.97464 loss)
I0812 03:00:31.690078 26953 solver.cpp:228] Iteration 19800, loss = 2.0106
I0812 03:00:31.690174 26953 solver.cpp:244]     Train net output #0: loss = 2.0106 (* 1 = 2.0106 loss)
I0812 03:00:33.068542 26953 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0812 03:00:51.486752 26953 solver.cpp:228] Iteration 19810, loss = 2.04251
I0812 03:00:51.486814 26953 solver.cpp:244]     Train net output #0: loss = 2.04251 (* 1 = 2.04251 loss)
I0812 03:00:52.886289 26953 sgd_solver.cpp:106] Iteration 19810, lr = 0.01
I0812 03:01:11.274953 26953 solver.cpp:228] Iteration 19820, loss = 2.19894
I0812 03:01:11.275130 26953 solver.cpp:244]     Train net output #0: loss = 2.19894 (* 1 = 2.19894 loss)
I0812 03:01:12.687741 26953 sgd_solver.cpp:106] Iteration 19820, lr = 0.01
I0812 03:01:31.089596 26953 solver.cpp:228] Iteration 19830, loss = 2.25456
I0812 03:01:31.089665 26953 solver.cpp:244]     Train net output #0: loss = 2.25456 (* 1 = 2.25456 loss)
I0812 03:01:32.497447 26953 sgd_solver.cpp:106] Iteration 19830, lr = 0.01
I0812 03:01:50.972343 26953 solver.cpp:228] Iteration 19840, loss = 1.96874
I0812 03:01:50.972487 26953 solver.cpp:244]     Train net output #0: loss = 1.96874 (* 1 = 1.96874 loss)
I0812 03:01:52.368332 26953 sgd_solver.cpp:106] Iteration 19840, lr = 0.01
I0812 03:02:10.721031 26953 solver.cpp:228] Iteration 19850, loss = 2.12529
I0812 03:02:10.721101 26953 solver.cpp:244]     Train net output #0: loss = 2.12529 (* 1 = 2.12529 loss)
I0812 03:02:12.135200 26953 sgd_solver.cpp:106] Iteration 19850, lr = 0.01
I0812 03:02:30.537431 26953 solver.cpp:228] Iteration 19860, loss = 2.17452
I0812 03:02:30.537578 26953 solver.cpp:244]     Train net output #0: loss = 2.17452 (* 1 = 2.17452 loss)
I0812 03:02:31.931079 26953 sgd_solver.cpp:106] Iteration 19860, lr = 0.01
I0812 03:02:50.354409 26953 solver.cpp:228] Iteration 19870, loss = 2.35811
I0812 03:02:50.354470 26953 solver.cpp:244]     Train net output #0: loss = 2.35811 (* 1 = 2.35811 loss)
I0812 03:02:51.766918 26953 sgd_solver.cpp:106] Iteration 19870, lr = 0.01
I0812 03:03:10.143460 26953 solver.cpp:228] Iteration 19880, loss = 2.16347
I0812 03:03:10.143651 26953 solver.cpp:244]     Train net output #0: loss = 2.16347 (* 1 = 2.16347 loss)
I0812 03:03:11.524479 26953 sgd_solver.cpp:106] Iteration 19880, lr = 0.01
I0812 03:03:29.893291 26953 solver.cpp:228] Iteration 19890, loss = 2.15197
I0812 03:03:29.893350 26953 solver.cpp:244]     Train net output #0: loss = 2.15197 (* 1 = 2.15197 loss)
I0812 03:03:31.289952 26953 sgd_solver.cpp:106] Iteration 19890, lr = 0.01
I0812 03:03:49.143702 26953 solver.cpp:337] Iteration 19900, Testing net (#0)
I0812 03:03:49.737104 26953 solver.cpp:404]     Test net output #0: accuracy = 0.494
I0812 03:03:49.737174 26953 solver.cpp:404]     Test net output #1: loss = 2.25001 (* 1 = 2.25001 loss)
I0812 03:03:50.307238 26953 solver.cpp:228] Iteration 19900, loss = 2.17796
I0812 03:03:50.307296 26953 solver.cpp:244]     Train net output #0: loss = 2.17796 (* 1 = 2.17796 loss)
I0812 03:03:51.679072 26953 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0812 03:04:10.055493 26953 solver.cpp:228] Iteration 19910, loss = 2.23849
I0812 03:04:10.055670 26953 solver.cpp:244]     Train net output #0: loss = 2.23849 (* 1 = 2.23849 loss)
I0812 03:04:11.440886 26953 sgd_solver.cpp:106] Iteration 19910, lr = 0.01
I0812 03:04:29.861801 26953 solver.cpp:228] Iteration 19920, loss = 2.25312
I0812 03:04:29.862048 26953 solver.cpp:244]     Train net output #0: loss = 2.25312 (* 1 = 2.25312 loss)
I0812 03:04:31.266108 26953 sgd_solver.cpp:106] Iteration 19920, lr = 0.01
I0812 03:04:49.648674 26953 solver.cpp:228] Iteration 19930, loss = 2.26632
I0812 03:04:49.648744 26953 solver.cpp:244]     Train net output #0: loss = 2.26632 (* 1 = 2.26632 loss)
I0812 03:04:51.051973 26953 sgd_solver.cpp:106] Iteration 19930, lr = 0.01
I0812 03:05:09.459900 26953 solver.cpp:228] Iteration 19940, loss = 2.05529
I0812 03:05:09.460124 26953 solver.cpp:244]     Train net output #0: loss = 2.05529 (* 1 = 2.05529 loss)
I0812 03:05:10.853672 26953 sgd_solver.cpp:106] Iteration 19940, lr = 0.01
I0812 03:05:29.217335 26953 solver.cpp:228] Iteration 19950, loss = 2.25047
I0812 03:05:29.217413 26953 solver.cpp:244]     Train net output #0: loss = 2.25047 (* 1 = 2.25047 loss)
I0812 03:05:30.613688 26953 sgd_solver.cpp:106] Iteration 19950, lr = 0.01
I0812 03:05:49.000344 26953 solver.cpp:228] Iteration 19960, loss = 2.06924
I0812 03:05:49.000499 26953 solver.cpp:244]     Train net output #0: loss = 2.06924 (* 1 = 2.06924 loss)
I0812 03:05:50.386868 26953 sgd_solver.cpp:106] Iteration 19960, lr = 0.01
I0812 03:06:08.749600 26953 solver.cpp:228] Iteration 19970, loss = 1.99489
I0812 03:06:08.749670 26953 solver.cpp:244]     Train net output #0: loss = 1.99489 (* 1 = 1.99489 loss)
I0812 03:06:10.153789 26953 sgd_solver.cpp:106] Iteration 19970, lr = 0.01
I0812 03:06:28.560124 26953 solver.cpp:228] Iteration 19980, loss = 2.29178
I0812 03:06:28.560397 26953 solver.cpp:244]     Train net output #0: loss = 2.29178 (* 1 = 2.29178 loss)
I0812 03:06:29.965203 26953 sgd_solver.cpp:106] Iteration 19980, lr = 0.01
I0812 03:06:48.367416 26953 solver.cpp:228] Iteration 19990, loss = 2.2235
I0812 03:06:48.367491 26953 solver.cpp:244]     Train net output #0: loss = 2.2235 (* 1 = 2.2235 loss)
I0812 03:06:49.776883 26953 sgd_solver.cpp:106] Iteration 19990, lr = 0.01
I0812 03:07:07.569661 26953 solver.cpp:454] Snapshotting to binary proto file caffe_alexnet_train_iter_20000.caffemodel
I0812 03:07:25.240216 26953 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe_alexnet_train_iter_20000.solverstate
I0812 03:07:25.595612 26953 solver.cpp:337] Iteration 20000, Testing net (#0)
I0812 03:07:26.274314 26953 solver.cpp:404]     Test net output #0: accuracy = 0.476
I0812 03:07:26.274380 26953 solver.cpp:404]     Test net output #1: loss = 2.28657 (* 1 = 2.28657 loss)
I0812 03:07:26.881263 26953 solver.cpp:228] Iteration 20000, loss = 2.14968
I0812 03:07:26.881341 26953 solver.cpp:244]     Train net output #0: loss = 2.14968 (* 1 = 2.14968 loss)
I0812 03:07:28.256104 26953 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0812 03:07:46.586072 26953 solver.cpp:228] Iteration 20010, loss = 2.24125
I0812 03:07:46.586282 26953 solver.cpp:244]     Train net output #0: loss = 2.24125 (* 1 = 2.24125 loss)
I0812 03:07:47.987005 26953 sgd_solver.cpp:106] Iteration 20010, lr = 0.01
I0812 03:08:06.362234 26953 solver.cpp:228] Iteration 20020, loss = 2.18075
I0812 03:08:06.362306 26953 solver.cpp:244]     Train net output #0: loss = 2.18075 (* 1 = 2.18075 loss)
I0812 03:08:07.751909 26953 sgd_solver.cpp:106] Iteration 20020, lr = 0.01
I0812 03:08:26.142874 26953 solver.cpp:228] Iteration 20030, loss = 2.22803
I0812 03:08:26.143086 26953 solver.cpp:244]     Train net output #0: loss = 2.22803 (* 1 = 2.22803 loss)
I0812 03:08:27.552091 26953 sgd_solver.cpp:106] Iteration 20030, lr = 0.01
I0812 03:08:45.902187 26953 solver.cpp:228] Iteration 20040, loss = 2.09698
I0812 03:08:45.902264 26953 solver.cpp:244]     Train net output #0: loss = 2.09698 (* 1 = 2.09698 loss)
I0812 03:08:47.318161 26953 sgd_solver.cpp:106] Iteration 20040, lr = 0.01
I0812 03:09:05.702023 26953 solver.cpp:228] Iteration 20050, loss = 2.17733
I0812 03:09:05.702234 26953 solver.cpp:244]     Train net output #0: loss = 2.17733 (* 1 = 2.17733 loss)
I0812 03:09:07.108042 26953 sgd_solver.cpp:106] Iteration 20050, lr = 0.01
I0812 03:09:25.503538 26953 solver.cpp:228] Iteration 20060, loss = 2.3768
I0812 03:09:25.503607 26953 solver.cpp:244]     Train net output #0: loss = 2.3768 (* 1 = 2.3768 loss)
I0812 03:09:26.912272 26953 sgd_solver.cpp:106] Iteration 20060, lr = 0.01
I0812 03:09:45.297165 26953 solver.cpp:228] Iteration 20070, loss = 1.95839
I0812 03:09:45.297446 26953 solver.cpp:244]     Train net output #0: loss = 1.95839 (* 1 = 1.95839 loss)
I0812 03:09:46.697281 26953 sgd_solver.cpp:106] Iteration 20070, lr = 0.01
I0812 03:10:05.090950 26953 solver.cpp:228] Iteration 20080, loss = 2.22989
I0812 03:10:05.091032 26953 solver.cpp:244]     Train net output #0: loss = 2.22989 (* 1 = 2.22989 loss)
I0812 03:10:06.482288 26953 sgd_solver.cpp:106] Iteration 20080, lr = 0.01
I0812 03:10:24.880071 26953 solver.cpp:228] Iteration 20090, loss = 2.07669
I0812 03:10:24.880254 26953 solver.cpp:244]     Train net output #0: loss = 2.07669 (* 1 = 2.07669 loss)
I0812 03:10:26.283836 26953 sgd_solver.cpp:106] Iteration 20090, lr = 0.01
I0812 03:10:44.079010 26953 solver.cpp:337] Iteration 20100, Testing net (#0)
I0812 03:10:44.668423 26953 solver.cpp:404]     Test net output #0: accuracy = 0.496
I0812 03:10:44.668496 26953 solver.cpp:404]     Test net output #1: loss = 2.18875 (* 1 = 2.18875 loss)
I0812 03:10:45.243700 26953 solver.cpp:228] Iteration 20100, loss = 2.22264
I0812 03:10:45.243799 26953 solver.cpp:244]     Train net output #0: loss = 2.22264 (* 1 = 2.22264 loss)
I0812 03:10:46.624325 26953 sgd_solver.cpp:106] Iteration 20100, lr = 0.01
I0812 03:11:05.049484 26953 solver.cpp:228] Iteration 20110, loss = 2.26657
I0812 03:11:05.049688 26953 solver.cpp:244]     Train net output #0: loss = 2.26657 (* 1 = 2.26657 loss)
I0812 03:11:06.448755 26953 sgd_solver.cpp:106] Iteration 20110, lr = 0.01
I0812 03:11:24.860874 26953 solver.cpp:228] Iteration 20120, loss = 2.06043
I0812 03:11:24.860934 26953 solver.cpp:244]     Train net output #0: loss = 2.06043 (* 1 = 2.06043 loss)
I0812 03:11:26.269573 26953 sgd_solver.cpp:106] Iteration 20120, lr = 0.01
I0812 03:11:44.660244 26953 solver.cpp:228] Iteration 20130, loss = 2.23629
I0812 03:11:44.660413 26953 solver.cpp:244]     Train net output #0: loss = 2.23629 (* 1 = 2.23629 loss)
I0812 03:11:46.067718 26953 sgd_solver.cpp:106] Iteration 20130, lr = 0.01
I0812 03:12:04.486946 26953 solver.cpp:228] Iteration 20140, loss = 2.31425
I0812 03:12:04.487009 26953 solver.cpp:244]     Train net output #0: loss = 2.31425 (* 1 = 2.31425 loss)
I0812 03:12:05.886812 26953 sgd_solver.cpp:106] Iteration 20140, lr = 0.01
I0812 03:12:24.251090 26953 solver.cpp:228] Iteration 20150, loss = 1.93952
I0812 03:12:24.251358 26953 solver.cpp:244]     Train net output #0: loss = 1.93952 (* 1 = 1.93952 loss)
I0812 03:12:25.658874 26953 sgd_solver.cpp:106] Iteration 20150, lr = 0.01
I0812 03:12:44.079741 26953 solver.cpp:228] Iteration 20160, loss = 2.1822
I0812 03:12:44.079812 26953 solver.cpp:244]     Train net output #0: loss = 2.1822 (* 1 = 2.1822 loss)
I0812 03:12:45.480844 26953 sgd_solver.cpp:106] Iteration 20160, lr = 0.01
I0812 03:13:03.851375 26953 solver.cpp:228] Iteration 20170, loss = 2.02095
I0812 03:13:03.851620 26953 solver.cpp:244]     Train net output #0: loss = 2.02095 (* 1 = 2.02095 loss)
I0812 03:13:05.267071 26953 sgd_solver.cpp:106] Iteration 20170, lr = 0.01
I0812 03:13:23.687003 26953 solver.cpp:228] Iteration 20180, loss = 2.07927
I0812 03:13:23.687082 26953 solver.cpp:244]     Train net output #0: loss = 2.07927 (* 1 = 2.07927 loss)
I0812 03:13:25.069851 26953 sgd_solver.cpp:106] Iteration 20180, lr = 0.01
I0812 03:13:43.463719 26953 solver.cpp:228] Iteration 20190, loss = 2.21698
I0812 03:13:43.463964 26953 solver.cpp:244]     Train net output #0: loss = 2.21698 (* 1 = 2.21698 loss)
I0812 03:13:44.868191 26953 sgd_solver.cpp:106] Iteration 20190, lr = 0.01
I0812 03:14:02.681351 26953 solver.cpp:337] Iteration 20200, Testing net (#0)
I0812 03:14:03.267091 26953 solver.cpp:404]     Test net output #0: accuracy = 0.494
I0812 03:14:03.267154 26953 solver.cpp:404]     Test net output #1: loss = 2.26537 (* 1 = 2.26537 loss)
I0812 03:14:03.844724 26953 solver.cpp:228] Iteration 20200, loss = 2.12315
I0812 03:14:03.844812 26953 solver.cpp:244]     Train net output #0: loss = 2.12315 (* 1 = 2.12315 loss)
I0812 03:14:05.215270 26953 sgd_solver.cpp:106] Iteration 20200, lr = 0.01
I0812 03:14:23.652568 26953 solver.cpp:228] Iteration 20210, loss = 2.13387
I0812 03:14:23.652770 26953 solver.cpp:244]     Train net output #0: loss = 2.13387 (* 1 = 2.13387 loss)
I0812 03:14:25.047986 26953 sgd_solver.cpp:106] Iteration 20210, lr = 0.01
I0812 03:14:43.405123 26953 solver.cpp:228] Iteration 20220, loss = 2.11311
I0812 03:14:43.405208 26953 solver.cpp:244]     Train net output #0: loss = 2.11311 (* 1 = 2.11311 loss)
I0812 03:14:44.822257 26953 sgd_solver.cpp:106] Iteration 20220, lr = 0.01
I0812 03:15:03.174496 26953 solver.cpp:228] Iteration 20230, loss = 2.17026
I0812 03:15:03.174767 26953 solver.cpp:244]     Train net output #0: loss = 2.17026 (* 1 = 2.17026 loss)
I0812 03:15:04.591148 26953 sgd_solver.cpp:106] Iteration 20230, lr = 0.01
I0812 03:15:22.964347 26953 solver.cpp:228] Iteration 20240, loss = 2.1552
I0812 03:15:22.964411 26953 solver.cpp:244]     Train net output #0: loss = 2.1552 (* 1 = 2.1552 loss)
I0812 03:15:24.368990 26953 sgd_solver.cpp:106] Iteration 20240, lr = 0.01
I0812 03:15:42.775152 26953 solver.cpp:228] Iteration 20250, loss = 2.24619
I0812 03:15:42.775364 26953 solver.cpp:244]     Train net output #0: loss = 2.24619 (* 1 = 2.24619 loss)
I0812 03:15:44.192816 26953 sgd_solver.cpp:106] Iteration 20250, lr = 0.01
I0812 03:16:02.538426 26953 solver.cpp:228] Iteration 20260, loss = 1.97522
I0812 03:16:02.538496 26953 solver.cpp:244]     Train net output #0: loss = 1.97522 (* 1 = 1.97522 loss)
I0812 03:16:03.943866 26953 sgd_solver.cpp:106] Iteration 20260, lr = 0.01
I0812 03:16:22.382592 26953 solver.cpp:228] Iteration 20270, loss = 1.98651
I0812 03:16:22.382823 26953 solver.cpp:244]     Train net output #0: loss = 1.98651 (* 1 = 1.98651 loss)
I0812 03:16:23.773473 26953 sgd_solver.cpp:106] Iteration 20270, lr = 0.01
I0812 03:16:42.156437 26953 solver.cpp:228] Iteration 20280, loss = 2.08652
I0812 03:16:42.156504 26953 solver.cpp:244]     Train net output #0: loss = 2.08652 (* 1 = 2.08652 loss)
I0812 03:16:43.569805 26953 sgd_solver.cpp:106] Iteration 20280, lr = 0.01
I0812 03:17:01.947710 26953 solver.cpp:228] Iteration 20290, loss = 2.19841
I0812 03:17:01.948006 26953 solver.cpp:244]     Train net output #0: loss = 2.19841 (* 1 = 2.19841 loss)
I0812 03:17:03.353816 26953 sgd_solver.cpp:106] Iteration 20290, lr = 0.01
I0812 03:17:21.150723 26953 solver.cpp:337] Iteration 20300, Testing net (#0)
I0812 03:17:21.738562 26953 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0812 03:17:21.738620 26953 solver.cpp:404]     Test net output #1: loss = 2.29687 (* 1 = 2.29687 loss)
I0812 03:17:22.298889 26953 solver.cpp:228] Iteration 20300, loss = 2.14676
I0812 03:17:22.298970 26953 solver.cpp:244]     Train net output #0: loss = 2.14676 (* 1 = 2.14676 loss)
I0812 03:17:23.689502 26953 sgd_solver.cpp:106] Iteration 20300, lr = 0.01
I0812 03:17:42.079370 26953 solver.cpp:228] Iteration 20310, loss = 2.12639
I0812 03:17:42.079586 26953 solver.cpp:244]     Train net output #0: loss = 2.12639 (* 1 = 2.12639 loss)
I0812 03:17:43.486690 26953 sgd_solver.cpp:106] Iteration 20310, lr = 0.01
I0812 03:18:01.870839 26953 solver.cpp:228] Iteration 20320, loss = 2.0643
I0812 03:18:01.870896 26953 solver.cpp:244]     Train net output #0: loss = 2.0643 (* 1 = 2.0643 loss)
I0812 03:18:03.265283 26953 sgd_solver.cpp:106] Iteration 20320, lr = 0.01
I0812 03:18:21.718518 26953 solver.cpp:228] Iteration 20330, loss = 2.00319
I0812 03:18:21.718761 26953 solver.cpp:244]     Train net output #0: loss = 2.00319 (* 1 = 2.00319 loss)
I0812 03:18:23.128711 26953 sgd_solver.cpp:106] Iteration 20330, lr = 0.01
I0812 03:18:41.457705 26953 solver.cpp:228] Iteration 20340, loss = 1.87463
I0812 03:18:41.457761 26953 solver.cpp:244]     Train net output #0: loss = 1.87463 (* 1 = 1.87463 loss)
I0812 03:18:42.870304 26953 sgd_solver.cpp:106] Iteration 20340, lr = 0.01
I0812 03:19:01.242102 26953 solver.cpp:228] Iteration 20350, loss = 2.21963
I0812 03:19:01.242310 26953 solver.cpp:244]     Train net output #0: loss = 2.21963 (* 1 = 2.21963 loss)
I0812 03:19:02.647565 26953 sgd_solver.cpp:106] Iteration 20350, lr = 0.01
I0812 03:19:21.059468 26953 solver.cpp:228] Iteration 20360, loss = 1.93589
I0812 03:19:21.059537 26953 solver.cpp:244]     Train net output #0: loss = 1.93589 (* 1 = 1.93589 loss)
I0812 03:19:22.444365 26953 sgd_solver.cpp:106] Iteration 20360, lr = 0.01
I0812 03:19:40.816807 26953 solver.cpp:228] Iteration 20370, loss = 2.08807
I0812 03:19:40.817010 26953 solver.cpp:244]     Train net output #0: loss = 2.08807 (* 1 = 2.08807 loss)
I0812 03:19:42.230362 26953 sgd_solver.cpp:106] Iteration 20370, lr = 0.01
I0812 03:20:00.562970 26953 solver.cpp:228] Iteration 20380, loss = 2.08707
I0812 03:20:00.563046 26953 solver.cpp:244]     Train net output #0: loss = 2.08707 (* 1 = 2.08707 loss)
I0812 03:20:01.964442 26953 sgd_solver.cpp:106] Iteration 20380, lr = 0.01
I0812 03:20:20.373740 26953 solver.cpp:228] Iteration 20390, loss = 2.15895
I0812 03:20:20.373963 26953 solver.cpp:244]     Train net output #0: loss = 2.15895 (* 1 = 2.15895 loss)
I0812 03:20:21.763583 26953 sgd_solver.cpp:106] Iteration 20390, lr = 0.01
I0812 03:20:39.567174 26953 solver.cpp:337] Iteration 20400, Testing net (#0)
I0812 03:20:40.155803 26953 solver.cpp:404]     Test net output #0: accuracy = 0.502
I0812 03:20:40.155872 26953 solver.cpp:404]     Test net output #1: loss = 2.15754 (* 1 = 2.15754 loss)
I0812 03:20:40.729048 26953 solver.cpp:228] Iteration 20400, loss = 2.28695
I0812 03:20:40.729118 26953 solver.cpp:244]     Train net output #0: loss = 2.28695 (* 1 = 2.28695 loss)
I0812 03:20:42.105928 26953 sgd_solver.cpp:106] Iteration 20400, lr = 0.01
I0812 03:21:00.481741 26953 solver.cpp:228] Iteration 20410, loss = 2.20612
I0812 03:21:00.482887 26953 solver.cpp:244]     Train net output #0: loss = 2.20612 (* 1 = 2.20612 loss)
I0812 03:21:01.905624 26953 sgd_solver.cpp:106] Iteration 20410, lr = 0.01
I0812 03:21:20.290298 26953 solver.cpp:228] Iteration 20420, loss = 2.24402
I0812 03:21:20.290369 26953 solver.cpp:244]     Train net output #0: loss = 2.24402 (* 1 = 2.24402 loss)
I0812 03:21:21.698576 26953 sgd_solver.cpp:106] Iteration 20420, lr = 0.01
I0812 03:21:40.093575 26953 solver.cpp:228] Iteration 20430, loss = 2.05512
I0812 03:21:40.093709 26953 solver.cpp:244]     Train net output #0: loss = 2.05512 (* 1 = 2.05512 loss)
I0812 03:21:41.492993 26953 sgd_solver.cpp:106] Iteration 20430, lr = 0.01
I0812 03:21:59.830816 26953 solver.cpp:228] Iteration 20440, loss = 2.18507
I0812 03:21:59.830873 26953 solver.cpp:244]     Train net output #0: loss = 2.18507 (* 1 = 2.18507 loss)
I0812 03:22:01.244076 26953 sgd_solver.cpp:106] Iteration 20440, lr = 0.01
I0812 03:22:19.647419 26953 solver.cpp:228] Iteration 20450, loss = 2.33152
I0812 03:22:19.647567 26953 solver.cpp:244]     Train net output #0: loss = 2.33152 (* 1 = 2.33152 loss)
I0812 03:22:21.053635 26953 sgd_solver.cpp:106] Iteration 20450, lr = 0.01
I0812 03:22:39.442400 26953 solver.cpp:228] Iteration 20460, loss = 2.13162
I0812 03:22:39.442471 26953 solver.cpp:244]     Train net output #0: loss = 2.13162 (* 1 = 2.13162 loss)
I0812 03:22:40.840922 26953 sgd_solver.cpp:106] Iteration 20460, lr = 0.01
I0812 03:22:59.198756 26953 solver.cpp:228] Iteration 20470, loss = 2.23738
I0812 03:22:59.198921 26953 solver.cpp:244]     Train net output #0: loss = 2.23738 (* 1 = 2.23738 loss)
I0812 03:23:00.625892 26953 sgd_solver.cpp:106] Iteration 20470, lr = 0.01
I0812 03:23:19.047171 26953 solver.cpp:228] Iteration 20480, loss = 2.09342
I0812 03:23:19.047243 26953 solver.cpp:244]     Train net output #0: loss = 2.09342 (* 1 = 2.09342 loss)
I0812 03:23:20.444174 26953 sgd_solver.cpp:106] Iteration 20480, lr = 0.01
I0812 03:23:38.831323 26953 solver.cpp:228] Iteration 20490, loss = 2.19148
I0812 03:23:38.831503 26953 solver.cpp:244]     Train net output #0: loss = 2.19148 (* 1 = 2.19148 loss)
I0812 03:23:40.244671 26953 sgd_solver.cpp:106] Iteration 20490, lr = 0.01
I0812 03:23:57.998049 26953 solver.cpp:337] Iteration 20500, Testing net (#0)
I0812 03:23:58.588912 26953 solver.cpp:404]     Test net output #0: accuracy = 0.526
I0812 03:23:58.588979 26953 solver.cpp:404]     Test net output #1: loss = 2.10443 (* 1 = 2.10443 loss)
I0812 03:23:59.166155 26953 solver.cpp:228] Iteration 20500, loss = 2.01895
I0812 03:23:59.166210 26953 solver.cpp:244]     Train net output #0: loss = 2.01895 (* 1 = 2.01895 loss)
I0812 03:24:00.534703 26953 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I0812 03:24:18.912894 26953 solver.cpp:228] Iteration 20510, loss = 2.0482
I0812 03:24:18.913267 26953 solver.cpp:244]     Train net output #0: loss = 2.0482 (* 1 = 2.0482 loss)
I0812 03:24:20.301646 26953 sgd_solver.cpp:106] Iteration 20510, lr = 0.01
I0812 03:24:38.664350 26953 solver.cpp:228] Iteration 20520, loss = 1.96775
I0812 03:24:38.664422 26953 solver.cpp:244]     Train net output #0: loss = 1.96775 (* 1 = 1.96775 loss)
I0812 03:24:40.078449 26953 sgd_solver.cpp:106] Iteration 20520, lr = 0.01
I0812 03:24:58.426386 26953 solver.cpp:228] Iteration 20530, loss = 2.13729
I0812 03:24:58.426676 26953 solver.cpp:244]     Train net output #0: loss = 2.13729 (* 1 = 2.13729 loss)
I0812 03:24:59.831153 26953 sgd_solver.cpp:106] Iteration 20530, lr = 0.01
I0812 03:25:18.220049 26953 solver.cpp:228] Iteration 20540, loss = 2.30967
I0812 03:25:18.220126 26953 solver.cpp:244]     Train net output #0: loss = 2.30967 (* 1 = 2.30967 loss)
I0812 03:25:19.617153 26953 sgd_solver.cpp:106] Iteration 20540, lr = 0.01
I0812 03:25:38.093559 26953 solver.cpp:228] Iteration 20550, loss = 2.08146
I0812 03:25:38.094148 26953 solver.cpp:244]     Train net output #0: loss = 2.08146 (* 1 = 2.08146 loss)
I0812 03:25:39.501657 26953 sgd_solver.cpp:106] Iteration 20550, lr = 0.01
I0812 03:25:57.850967 26953 solver.cpp:228] Iteration 20560, loss = 2.25933
I0812 03:25:57.851049 26953 solver.cpp:244]     Train net output #0: loss = 2.25933 (* 1 = 2.25933 loss)
I0812 03:25:59.257309 26953 sgd_solver.cpp:106] Iteration 20560, lr = 0.01
I0812 03:26:17.596477 26953 solver.cpp:228] Iteration 20570, loss = 2.29044
I0812 03:26:17.596638 26953 solver.cpp:244]     Train net output #0: loss = 2.29044 (* 1 = 2.29044 loss)
I0812 03:26:19.010632 26953 sgd_solver.cpp:106] Iteration 20570, lr = 0.01
I0812 03:26:37.401137 26953 solver.cpp:228] Iteration 20580, loss = 2.0662
I0812 03:26:37.401224 26953 solver.cpp:244]     Train net output #0: loss = 2.0662 (* 1 = 2.0662 loss)
I0812 03:26:38.801326 26953 sgd_solver.cpp:106] Iteration 20580, lr = 0.01
I0812 03:26:57.211681 26953 solver.cpp:228] Iteration 20590, loss = 2.34081
I0812 03:26:57.211904 26953 solver.cpp:244]     Train net output #0: loss = 2.34081 (* 1 = 2.34081 loss)
I0812 03:26:58.626711 26953 sgd_solver.cpp:106] Iteration 20590, lr = 0.01
I0812 03:27:16.413630 26953 solver.cpp:337] Iteration 20600, Testing net (#0)
I0812 03:27:17.004910 26953 solver.cpp:404]     Test net output #0: accuracy = 0.528
I0812 03:27:17.004974 26953 solver.cpp:404]     Test net output #1: loss = 2.18794 (* 1 = 2.18794 loss)
I0812 03:27:17.577222 26953 solver.cpp:228] Iteration 20600, loss = 2.06023
I0812 03:27:17.577314 26953 solver.cpp:244]     Train net output #0: loss = 2.06023 (* 1 = 2.06023 loss)
I0812 03:27:18.957525 26953 sgd_solver.cpp:106] Iteration 20600, lr = 0.01
I0812 03:27:37.386811 26953 solver.cpp:228] Iteration 20610, loss = 2.27657
I0812 03:27:37.386968 26953 solver.cpp:244]     Train net output #0: loss = 2.27657 (* 1 = 2.27657 loss)
I0812 03:27:38.794641 26953 sgd_solver.cpp:106] Iteration 20610, lr = 0.01
I0812 03:27:57.216392 26953 solver.cpp:228] Iteration 20620, loss = 2.05379
I0812 03:27:57.216488 26953 solver.cpp:244]     Train net output #0: loss = 2.05379 (* 1 = 2.05379 loss)
I0812 03:27:58.612735 26953 sgd_solver.cpp:106] Iteration 20620, lr = 0.01
I0812 03:28:16.998829 26953 solver.cpp:228] Iteration 20630, loss = 2.2963
I0812 03:28:16.999027 26953 solver.cpp:244]     Train net output #0: loss = 2.2963 (* 1 = 2.2963 loss)
I0812 03:28:18.401118 26953 sgd_solver.cpp:106] Iteration 20630, lr = 0.01
I0812 03:28:36.773057 26953 solver.cpp:228] Iteration 20640, loss = 2.11982
I0812 03:28:36.773128 26953 solver.cpp:244]     Train net output #0: loss = 2.11982 (* 1 = 2.11982 loss)
I0812 03:28:38.172399 26953 sgd_solver.cpp:106] Iteration 20640, lr = 0.01
I0812 03:28:56.532774 26953 solver.cpp:228] Iteration 20650, loss = 2.20125
I0812 03:28:56.532973 26953 solver.cpp:244]     Train net output #0: loss = 2.20125 (* 1 = 2.20125 loss)
I0812 03:28:57.947604 26953 sgd_solver.cpp:106] Iteration 20650, lr = 0.01
I0812 03:29:16.381068 26953 solver.cpp:228] Iteration 20660, loss = 2.10541
I0812 03:29:16.381150 26953 solver.cpp:244]     Train net output #0: loss = 2.10541 (* 1 = 2.10541 loss)
I0812 03:29:17.782701 26953 sgd_solver.cpp:106] Iteration 20660, lr = 0.01
I0812 03:29:36.157341 26953 solver.cpp:228] Iteration 20670, loss = 2.06419
I0812 03:29:36.157618 26953 solver.cpp:244]     Train net output #0: loss = 2.06419 (* 1 = 2.06419 loss)
I0812 03:29:37.564952 26953 sgd_solver.cpp:106] Iteration 20670, lr = 0.01
I0812 03:29:55.904342 26953 solver.cpp:228] Iteration 20680, loss = 2.10109
I0812 03:29:55.904415 26953 solver.cpp:244]     Train net output #0: loss = 2.10109 (* 1 = 2.10109 loss)
I0812 03:29:57.306042 26953 sgd_solver.cpp:106] Iteration 20680, lr = 0.01
I0812 03:30:15.671988 26953 solver.cpp:228] Iteration 20690, loss = 2.1374
I0812 03:30:15.672161 26953 solver.cpp:244]     Train net output #0: loss = 2.1374 (* 1 = 2.1374 loss)
I0812 03:30:17.066860 26953 sgd_solver.cpp:106] Iteration 20690, lr = 0.01
I0812 03:30:34.885655 26953 solver.cpp:337] Iteration 20700, Testing net (#0)
I0812 03:30:35.473420 26953 solver.cpp:404]     Test net output #0: accuracy = 0.522
I0812 03:30:35.473507 26953 solver.cpp:404]     Test net output #1: loss = 2.0872 (* 1 = 2.0872 loss)
I0812 03:30:36.069319 26953 solver.cpp:228] Iteration 20700, loss = 2.3121
I0812 03:30:36.069396 26953 solver.cpp:244]     Train net output #0: loss = 2.3121 (* 1 = 2.3121 loss)
I0812 03:30:37.430378 26953 sgd_solver.cpp:106] Iteration 20700, lr = 0.01
I0812 03:30:55.789463 26953 solver.cpp:228] Iteration 20710, loss = 2.14757
I0812 03:30:55.789695 26953 solver.cpp:244]     Train net output #0: loss = 2.14757 (* 1 = 2.14757 loss)
I0812 03:30:57.196671 26953 sgd_solver.cpp:106] Iteration 20710, lr = 0.01
I0812 03:31:15.551296 26953 solver.cpp:228] Iteration 20720, loss = 2.05517
I0812 03:31:15.551367 26953 solver.cpp:244]     Train net output #0: loss = 2.05517 (* 1 = 2.05517 loss)
I0812 03:31:16.936966 26953 sgd_solver.cpp:106] Iteration 20720, lr = 0.01
I0812 03:31:35.369499 26953 solver.cpp:228] Iteration 20730, loss = 2.08934
I0812 03:31:35.369722 26953 solver.cpp:244]     Train net output #0: loss = 2.08934 (* 1 = 2.08934 loss)
I0812 03:31:36.766391 26953 sgd_solver.cpp:106] Iteration 20730, lr = 0.01
I0812 03:31:55.129621 26953 solver.cpp:228] Iteration 20740, loss = 2.19325
I0812 03:31:55.129693 26953 solver.cpp:244]     Train net output #0: loss = 2.19325 (* 1 = 2.19325 loss)
I0812 03:31:56.531325 26953 sgd_solver.cpp:106] Iteration 20740, lr = 0.01
I0812 03:32:14.912566 26953 solver.cpp:228] Iteration 20750, loss = 2.16199
I0812 03:32:14.912696 26953 solver.cpp:244]     Train net output #0: loss = 2.16199 (* 1 = 2.16199 loss)
I0812 03:32:16.313366 26953 sgd_solver.cpp:106] Iteration 20750, lr = 0.01
I0812 03:32:34.726106 26953 solver.cpp:228] Iteration 20760, loss = 2.20195
I0812 03:32:34.726182 26953 solver.cpp:244]     Train net output #0: loss = 2.20195 (* 1 = 2.20195 loss)
I0812 03:32:36.144043 26953 sgd_solver.cpp:106] Iteration 20760, lr = 0.01
I0812 03:32:54.515358 26953 solver.cpp:228] Iteration 20770, loss = 2.13345
I0812 03:32:54.515594 26953 solver.cpp:244]     Train net output #0: loss = 2.13345 (* 1 = 2.13345 loss)
I0812 03:32:55.914505 26953 sgd_solver.cpp:106] Iteration 20770, lr = 0.01
I0812 03:33:14.317433 26953 solver.cpp:228] Iteration 20780, loss = 2.03355
I0812 03:33:14.317503 26953 solver.cpp:244]     Train net output #0: loss = 2.03355 (* 1 = 2.03355 loss)
I0812 03:33:15.711379 26953 sgd_solver.cpp:106] Iteration 20780, lr = 0.01
I0812 03:33:34.065531 26953 solver.cpp:228] Iteration 20790, loss = 2.26812
I0812 03:33:34.065776 26953 solver.cpp:244]     Train net output #0: loss = 2.26812 (* 1 = 2.26812 loss)
I0812 03:33:35.463395 26953 sgd_solver.cpp:106] Iteration 20790, lr = 0.01
I0812 03:33:53.260475 26953 solver.cpp:337] Iteration 20800, Testing net (#0)
I0812 03:33:53.851945 26953 solver.cpp:404]     Test net output #0: accuracy = 0.514
I0812 03:33:53.852008 26953 solver.cpp:404]     Test net output #1: loss = 2.26974 (* 1 = 2.26974 loss)
I0812 03:33:54.428936 26953 solver.cpp:228] Iteration 20800, loss = 2.17319
I0812 03:33:54.429038 26953 solver.cpp:244]     Train net output #0: loss = 2.17319 (* 1 = 2.17319 loss)
I0812 03:33:55.805359 26953 sgd_solver.cpp:106] Iteration 20800, lr = 0.01
I0812 03:34:14.167464 26953 solver.cpp:228] Iteration 20810, loss = 2.16507
I0812 03:34:14.167654 26953 solver.cpp:244]     Train net output #0: loss = 2.16507 (* 1 = 2.16507 loss)
I0812 03:34:15.577358 26953 sgd_solver.cpp:106] Iteration 20810, lr = 0.01
I0812 03:34:34.028748 26953 solver.cpp:228] Iteration 20820, loss = 2.04124
I0812 03:34:34.028818 26953 solver.cpp:244]     Train net output #0: loss = 2.04124 (* 1 = 2.04124 loss)
I0812 03:34:35.427112 26953 sgd_solver.cpp:106] Iteration 20820, lr = 0.01
I0812 03:34:53.794242 26953 solver.cpp:228] Iteration 20830, loss = 2.0439
I0812 03:34:53.794386 26953 solver.cpp:244]     Train net output #0: loss = 2.0439 (* 1 = 2.0439 loss)
I0812 03:34:55.211915 26953 sgd_solver.cpp:106] Iteration 20830, lr = 0.01
I0812 03:35:13.566774 26953 solver.cpp:228] Iteration 20840, loss = 2.15887
I0812 03:35:13.566850 26953 solver.cpp:244]     Train net output #0: loss = 2.15887 (* 1 = 2.15887 loss)
I0812 03:35:14.965258 26953 sgd_solver.cpp:106] Iteration 20840, lr = 0.01
I0812 03:35:33.390508 26953 solver.cpp:228] Iteration 20850, loss = 2.15028
I0812 03:35:33.390714 26953 solver.cpp:244]     Train net output #0: loss = 2.15028 (* 1 = 2.15028 loss)
I0812 03:35:34.791347 26953 sgd_solver.cpp:106] Iteration 20850, lr = 0.01
I0812 03:35:53.155938 26953 solver.cpp:228] Iteration 20860, loss = 2.33676
I0812 03:35:53.156005 26953 solver.cpp:244]     Train net output #0: loss = 2.33676 (* 1 = 2.33676 loss)
I0812 03:35:54.561489 26953 sgd_solver.cpp:106] Iteration 20860, lr = 0.01
I0812 03:36:12.947835 26953 solver.cpp:228] Iteration 20870, loss = 2.0351
I0812 03:36:12.948115 26953 solver.cpp:244]     Train net output #0: loss = 2.0351 (* 1 = 2.0351 loss)
I0812 03:36:14.338786 26953 sgd_solver.cpp:106] Iteration 20870, lr = 0.01
I0812 03:36:32.736946 26953 solver.cpp:228] Iteration 20880, loss = 2.00658
I0812 03:36:32.737013 26953 solver.cpp:244]     Train net output #0: loss = 2.00658 (* 1 = 2.00658 loss)
I0812 03:36:34.152511 26953 sgd_solver.cpp:106] Iteration 20880, lr = 0.01
I0812 03:36:52.506567 26953 solver.cpp:228] Iteration 20890, loss = 2.15272
I0812 03:36:52.506801 26953 solver.cpp:244]     Train net output #0: loss = 2.15272 (* 1 = 2.15272 loss)
I0812 03:36:53.918289 26953 sgd_solver.cpp:106] Iteration 20890, lr = 0.01
I0812 03:37:11.721945 26953 solver.cpp:337] Iteration 20900, Testing net (#0)
I0812 03:37:12.315564 26953 solver.cpp:404]     Test net output #0: accuracy = 0.536
I0812 03:37:12.315641 26953 solver.cpp:404]     Test net output #1: loss = 2.11845 (* 1 = 2.11845 loss)
I0812 03:37:12.896780 26953 solver.cpp:228] Iteration 20900, loss = 2.09192
I0812 03:37:12.896868 26953 solver.cpp:244]     Train net output #0: loss = 2.09192 (* 1 = 2.09192 loss)
I0812 03:37:14.249310 26953 sgd_solver.cpp:106] Iteration 20900, lr = 0.01
I0812 03:37:32.642122 26953 solver.cpp:228] Iteration 20910, loss = 2.14678
I0812 03:37:32.642324 26953 solver.cpp:244]     Train net output #0: loss = 2.14678 (* 1 = 2.14678 loss)
I0812 03:37:34.039415 26953 sgd_solver.cpp:106] Iteration 20910, lr = 0.01
I0812 03:37:52.410328 26953 solver.cpp:228] Iteration 20920, loss = 2.11183
I0812 03:37:52.410392 26953 solver.cpp:244]     Train net output #0: loss = 2.11183 (* 1 = 2.11183 loss)
I0812 03:37:53.804728 26953 sgd_solver.cpp:106] Iteration 20920, lr = 0.01
I0812 03:38:12.171095 26953 solver.cpp:228] Iteration 20930, loss = 2.07082
I0812 03:38:12.171272 26953 solver.cpp:244]     Train net output #0: loss = 2.07082 (* 1 = 2.07082 loss)
I0812 03:38:13.574625 26953 sgd_solver.cpp:106] Iteration 20930, lr = 0.01
I0812 03:38:31.989377 26953 solver.cpp:228] Iteration 20940, loss = 2.01854
I0812 03:38:31.989446 26953 solver.cpp:244]     Train net output #0: loss = 2.01854 (* 1 = 2.01854 loss)
I0812 03:38:33.390887 26953 sgd_solver.cpp:106] Iteration 20940, lr = 0.01
I0812 03:38:51.786844 26953 solver.cpp:228] Iteration 20950, loss = 2.06228
I0812 03:38:51.787103 26953 solver.cpp:244]     Train net output #0: loss = 2.06228 (* 1 = 2.06228 loss)
I0812 03:38:53.195509 26953 sgd_solver.cpp:106] Iteration 20950, lr = 0.01
I0812 03:39:11.547297 26953 solver.cpp:228] Iteration 20960, loss = 2.02479
I0812 03:39:11.547387 26953 solver.cpp:244]     Train net output #0: loss = 2.02479 (* 1 = 2.02479 loss)
I0812 03:39:12.942370 26953 sgd_solver.cpp:106] Iteration 20960, lr = 0.01
I0812 03:39:31.322970 26953 solver.cpp:228] Iteration 20970, loss = 2.15618
I0812 03:39:31.323189 26953 solver.cpp:244]     Train net output #0: loss = 2.15618 (* 1 = 2.15618 loss)
I0812 03:39:32.712777 26953 sgd_solver.cpp:106] Iteration 20970, lr = 0.01
I0812 03:39:51.138423 26953 solver.cpp:228] Iteration 20980, loss = 2.1185
I0812 03:39:51.138495 26953 solver.cpp:244]     Train net output #0: loss = 2.1185 (* 1 = 2.1185 loss)
I0812 03:39:52.543997 26953 sgd_solver.cpp:106] Iteration 20980, lr = 0.01
I0812 03:40:10.874524 26953 solver.cpp:228] Iteration 20990, loss = 2.02967
I0812 03:40:10.874764 26953 solver.cpp:244]     Train net output #0: loss = 2.02967 (* 1 = 2.02967 loss)
I0812 03:40:12.290910 26953 sgd_solver.cpp:106] Iteration 20990, lr = 0.01
I0812 03:40:30.079227 26953 solver.cpp:337] Iteration 21000, Testing net (#0)
I0812 03:40:30.667048 26953 solver.cpp:404]     Test net output #0: accuracy = 0.484
I0812 03:40:30.667125 26953 solver.cpp:404]     Test net output #1: loss = 2.24085 (* 1 = 2.24085 loss)
I0812 03:40:31.245754 26953 solver.cpp:228] Iteration 21000, loss = 2.07737
I0812 03:40:31.245832 26953 solver.cpp:244]     Train net output #0: loss = 2.07737 (* 1 = 2.07737 loss)
I0812 03:40:32.614488 26953 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I0812 03:40:51.012379 26953 solver.cpp:228] Iteration 21010, loss = 2.20934
I0812 03:40:51.012616 26953 solver.cpp:244]     Train net output #0: loss = 2.20934 (* 1 = 2.20934 loss)
I0812 03:40:52.418588 26953 sgd_solver.cpp:106] Iteration 21010, lr = 0.01
I0812 03:41:10.818542 26953 solver.cpp:228] Iteration 21020, loss = 2.10362
I0812 03:41:10.818614 26953 solver.cpp:244]     Train net output #0: loss = 2.10362 (* 1 = 2.10362 loss)
I0812 03:41:12.212471 26953 sgd_solver.cpp:106] Iteration 21020, lr = 0.01
I0812 03:41:30.580736 26953 solver.cpp:228] Iteration 21030, loss = 2.04224
I0812 03:41:30.580987 26953 solver.cpp:244]     Train net output #0: loss = 2.04224 (* 1 = 2.04224 loss)
I0812 03:41:31.985024 26953 sgd_solver.cpp:106] Iteration 21030, lr = 0.01
I0812 03:41:50.392231 26953 solver.cpp:228] Iteration 21040, loss = 1.91806
I0812 03:41:50.392290 26953 solver.cpp:244]     Train net output #0: loss = 1.91806 (* 1 = 1.91806 loss)
I0812 03:41:51.784445 26953 sgd_solver.cpp:106] Iteration 21040, lr = 0.01
I0812 03:42:10.148192 26953 solver.cpp:228] Iteration 21050, loss = 2.18986
I0812 03:42:10.148406 26953 solver.cpp:244]     Train net output #0: loss = 2.18986 (* 1 = 2.18986 loss)
I0812 03:42:11.551311 26953 sgd_solver.cpp:106] Iteration 21050, lr = 0.01
I0812 03:42:29.901722 26953 solver.cpp:228] Iteration 21060, loss = 2.26338
I0812 03:42:29.901793 26953 solver.cpp:244]     Train net output #0: loss = 2.26338 (* 1 = 2.26338 loss)
I0812 03:42:31.327383 26953 sgd_solver.cpp:106] Iteration 21060, lr = 0.01
I0812 03:42:49.801513 26953 solver.cpp:228] Iteration 21070, loss = 2.13161
I0812 03:42:49.801764 26953 solver.cpp:244]     Train net output #0: loss = 2.13161 (* 1 = 2.13161 loss)
I0812 03:42:51.198668 26953 sgd_solver.cpp:106] Iteration 21070, lr = 0.01
I0812 03:43:09.556605 26953 solver.cpp:228] Iteration 21080, loss = 2.27127
I0812 03:43:09.556677 26953 solver.cpp:244]     Train net output #0: loss = 2.27127 (* 1 = 2.27127 loss)
I0812 03:43:10.964702 26953 sgd_solver.cpp:106] Iteration 21080, lr = 0.01
I0812 03:43:29.339216 26953 solver.cpp:228] Iteration 21090, loss = 2.2149
I0812 03:43:29.339501 26953 solver.cpp:244]     Train net output #0: loss = 2.2149 (* 1 = 2.2149 loss)
I0812 03:43:30.735246 26953 sgd_solver.cpp:106] Iteration 21090, lr = 0.01
I0812 03:43:48.569655 26953 solver.cpp:337] Iteration 21100, Testing net (#0)
I0812 03:43:49.159729 26953 solver.cpp:404]     Test net output #0: accuracy = 0.542
I0812 03:43:49.159795 26953 solver.cpp:404]     Test net output #1: loss = 2.05433 (* 1 = 2.05433 loss)
I0812 03:43:49.738373 26953 solver.cpp:228] Iteration 21100, loss = 2.36994
I0812 03:43:49.738464 26953 solver.cpp:244]     Train net output #0: loss = 2.36994 (* 1 = 2.36994 loss)
I0812 03:43:51.117918 26953 sgd_solver.cpp:106] Iteration 21100, lr = 0.01
I0812 03:44:09.470450 26953 solver.cpp:228] Iteration 21110, loss = 1.91432
I0812 03:44:09.470635 26953 solver.cpp:244]     Train net output #0: loss = 1.91432 (* 1 = 1.91432 loss)
I0812 03:44:10.868649 26953 sgd_solver.cpp:106] Iteration 21110, lr = 0.01
I0812 03:44:29.274085 26953 solver.cpp:228] Iteration 21120, loss = 2.00306
I0812 03:44:29.274157 26953 solver.cpp:244]     Train net output #0: loss = 2.00306 (* 1 = 2.00306 loss)
I0812 03:44:30.668570 26953 sgd_solver.cpp:106] Iteration 21120, lr = 0.01
I0812 03:44:49.054150 26953 solver.cpp:228] Iteration 21130, loss = 2.23087
I0812 03:44:49.054361 26953 solver.cpp:244]     Train net output #0: loss = 2.23087 (* 1 = 2.23087 loss)
I0812 03:44:50.469112 26953 sgd_solver.cpp:106] Iteration 21130, lr = 0.01
I0812 03:45:08.847872 26953 solver.cpp:228] Iteration 21140, loss = 2.18015
I0812 03:45:08.847955 26953 solver.cpp:244]     Train net output #0: loss = 2.18015 (* 1 = 2.18015 loss)
I0812 03:45:10.238770 26953 sgd_solver.cpp:106] Iteration 21140, lr = 0.01
I0812 03:45:28.615211 26953 solver.cpp:228] Iteration 21150, loss = 2.27274
I0812 03:45:28.615384 26953 solver.cpp:244]     Train net output #0: loss = 2.27274 (* 1 = 2.27274 loss)
I0812 03:45:30.011643 26953 sgd_solver.cpp:106] Iteration 21150, lr = 0.01
I0812 03:45:48.424420 26953 solver.cpp:228] Iteration 21160, loss = 2.14126
I0812 03:45:48.424494 26953 solver.cpp:244]     Train net output #0: loss = 2.14126 (* 1 = 2.14126 loss)
I0812 03:45:49.818259 26953 sgd_solver.cpp:106] Iteration 21160, lr = 0.01
I0812 03:46:08.189388 26953 solver.cpp:228] Iteration 21170, loss = 2.25649
I0812 03:46:08.189566 26953 solver.cpp:244]     Train net output #0: loss = 2.25649 (* 1 = 2.25649 loss)
I0812 03:46:09.587421 26953 sgd_solver.cpp:106] Iteration 21170, lr = 0.01
I0812 03:46:27.978235 26953 solver.cpp:228] Iteration 21180, loss = 2.25633
I0812 03:46:27.978315 26953 solver.cpp:244]     Train net output #0: loss = 2.25633 (* 1 = 2.25633 loss)
I0812 03:46:29.385220 26953 sgd_solver.cpp:106] Iteration 21180, lr = 0.01
I0812 03:46:47.723717 26953 solver.cpp:228] Iteration 21190, loss = 2.14467
I0812 03:46:47.723928 26953 solver.cpp:244]     Train net output #0: loss = 2.14467 (* 1 = 2.14467 loss)
I0812 03:46:49.124366 26953 sgd_solver.cpp:106] Iteration 21190, lr = 0.01
I0812 03:47:06.907029 26953 solver.cpp:337] Iteration 21200, Testing net (#0)
I0812 03:47:07.493449 26953 solver.cpp:404]     Test net output #0: accuracy = 0.508
I0812 03:47:07.493515 26953 solver.cpp:404]     Test net output #1: loss = 2.13272 (* 1 = 2.13272 loss)
I0812 03:47:08.056968 26953 solver.cpp:228] Iteration 21200, loss = 2.02275
I0812 03:47:08.057065 26953 solver.cpp:244]     Train net output #0: loss = 2.02275 (* 1 = 2.02275 loss)
I0812 03:47:09.438599 26953 sgd_solver.cpp:106] Iteration 21200, lr = 0.01
I0812 03:47:27.803205 26953 solver.cpp:228] Iteration 21210, loss = 2.10528
I0812 03:47:27.803459 26953 solver.cpp:244]     Train net output #0: loss = 2.10528 (* 1 = 2.10528 loss)
I0812 03:47:29.213186 26953 sgd_solver.cpp:106] Iteration 21210, lr = 0.01
I0812 03:47:47.552125 26953 solver.cpp:228] Iteration 21220, loss = 2.15019
I0812 03:47:47.552199 26953 solver.cpp:244]     Train net output #0: loss = 2.15019 (* 1 = 2.15019 loss)
I0812 03:47:48.943960 26953 sgd_solver.cpp:106] Iteration 21220, lr = 0.01
I0812 03:48:07.347355 26953 solver.cpp:228] Iteration 21230, loss = 1.89896
I0812 03:48:07.347673 26953 solver.cpp:244]     Train net output #0: loss = 1.89896 (* 1 = 1.89896 loss)
I0812 03:48:08.748864 26953 sgd_solver.cpp:106] Iteration 21230, lr = 0.01
I0812 03:48:27.118077 26953 solver.cpp:228] Iteration 21240, loss = 2.1138
I0812 03:48:27.118177 26953 solver.cpp:244]     Train net output #0: loss = 2.1138 (* 1 = 2.1138 loss)
I0812 03:48:28.536331 26953 sgd_solver.cpp:106] Iteration 21240, lr = 0.01
I0812 03:48:46.883518 26953 solver.cpp:228] Iteration 21250, loss = 2.03541
I0812 03:48:46.883821 26953 solver.cpp:244]     Train net output #0: loss = 2.03541 (* 1 = 2.03541 loss)
I0812 03:48:48.288959 26953 sgd_solver.cpp:106] Iteration 21250, lr = 0.01
I0812 03:49:06.642933 26953 solver.cpp:228] Iteration 21260, loss = 2.17386
I0812 03:49:06.643023 26953 solver.cpp:244]     Train net output #0: loss = 2.17386 (* 1 = 2.17386 loss)
I0812 03:49:08.041697 26953 sgd_solver.cpp:106] Iteration 21260, lr = 0.01
I0812 03:49:26.397372 26953 solver.cpp:228] Iteration 21270, loss = 2.05201
I0812 03:49:26.397603 26953 solver.cpp:244]     Train net output #0: loss = 2.05201 (* 1 = 2.05201 loss)
I0812 03:49:27.792199 26953 sgd_solver.cpp:106] Iteration 21270, lr = 0.01
I0812 03:49:46.234123 26953 solver.cpp:228] Iteration 21280, loss = 1.98894
I0812 03:49:46.234200 26953 solver.cpp:244]     Train net output #0: loss = 1.98894 (* 1 = 1.98894 loss)
I0812 03:49:47.637357 26953 sgd_solver.cpp:106] Iteration 21280, lr = 0.01
I0812 03:50:05.980819 26953 solver.cpp:228] Iteration 21290, loss = 2.17989
I0812 03:50:05.980954 26953 solver.cpp:244]     Train net output #0: loss = 2.17989 (* 1 = 2.17989 loss)
I0812 03:50:07.385890 26953 sgd_solver.cpp:106] Iteration 21290, lr = 0.01
I0812 03:50:25.153653 26953 solver.cpp:337] Iteration 21300, Testing net (#0)
I0812 03:50:25.740770 26953 solver.cpp:404]     Test net output #0: accuracy = 0.472
I0812 03:50:25.740854 26953 solver.cpp:404]     Test net output #1: loss = 2.31221 (* 1 = 2.31221 loss)
I0812 03:50:26.334336 26953 solver.cpp:228] Iteration 21300, loss = 2.18284
I0812 03:50:26.334411 26953 solver.cpp:244]     Train net output #0: loss = 2.18284 (* 1 = 2.18284 loss)
I0812 03:50:27.687502 26953 sgd_solver.cpp:106] Iteration 21300, lr = 0.01
I0812 03:50:46.080862 26953 solver.cpp:228] Iteration 21310, loss = 2.16691
I0812 03:50:46.081070 26953 solver.cpp:244]     Train net output #0: loss = 2.16691 (* 1 = 2.16691 loss)
I0812 03:50:47.500951 26953 sgd_solver.cpp:106] Iteration 21310, lr = 0.01
I0812 03:51:05.901283 26953 solver.cpp:228] Iteration 21320, loss = 2.00599
I0812 03:51:05.901391 26953 solver.cpp:244]     Train net output #0: loss = 2.00599 (* 1 = 2.00599 loss)
I0812 03:51:07.278210 26953 sgd_solver.cpp:106] Iteration 21320, lr = 0.01
I0812 03:51:25.679378 26953 solver.cpp:228] Iteration 21330, loss = 2.17245
I0812 03:51:25.679541 26953 solver.cpp:244]     Train net output #0: loss = 2.17245 (* 1 = 2.17245 loss)
I0812 03:51:27.080799 26953 sgd_solver.cpp:106] Iteration 21330, lr = 0.01
I0812 03:51:45.443219 26953 solver.cpp:228] Iteration 21340, loss = 2.11913
I0812 03:51:45.443285 26953 solver.cpp:244]     Train net output #0: loss = 2.11913 (* 1 = 2.11913 loss)
I0812 03:51:46.856120 26953 sgd_solver.cpp:106] Iteration 21340, lr = 0.01
I0812 03:52:05.216753 26953 solver.cpp:228] Iteration 21350, loss = 2.15465
I0812 03:52:05.216962 26953 solver.cpp:244]     Train net output #0: loss = 2.15465 (* 1 = 2.15465 loss)
I0812 03:52:06.616279 26953 sgd_solver.cpp:106] Iteration 21350, lr = 0.01
I0812 03:52:25.014454 26953 solver.cpp:228] Iteration 21360, loss = 2.21813
I0812 03:52:25.014528 26953 solver.cpp:244]     Train net output #0: loss = 2.21813 (* 1 = 2.21813 loss)
I0812 03:52:26.414275 26953 sgd_solver.cpp:106] Iteration 21360, lr = 0.01
I0812 03:52:44.783249 26953 solver.cpp:228] Iteration 21370, loss = 2.03154
I0812 03:52:44.783478 26953 solver.cpp:244]     Train net output #0: loss = 2.03154 (* 1 = 2.03154 loss)
I0812 03:52:46.179859 26953 sgd_solver.cpp:106] Iteration 21370, lr = 0.01
I0812 03:53:04.574959 26953 solver.cpp:228] Iteration 21380, loss = 2.12403
I0812 03:53:04.575031 26953 solver.cpp:244]     Train net output #0: loss = 2.12403 (* 1 = 2.12403 loss)
I0812 03:53:05.967561 26953 sgd_solver.cpp:106] Iteration 21380, lr = 0.01
I0812 03:53:24.342118 26953 solver.cpp:228] Iteration 21390, loss = 2.18388
I0812 03:53:24.342355 26953 solver.cpp:244]     Train net output #0: loss = 2.18388 (* 1 = 2.18388 loss)
I0812 03:53:25.749270 26953 sgd_solver.cpp:106] Iteration 21390, lr = 0.01
I0812 03:53:43.555871 26953 solver.cpp:337] Iteration 21400, Testing net (#0)
I0812 03:53:44.148141 26953 solver.cpp:404]     Test net output #0: accuracy = 0.524
I0812 03:53:44.148221 26953 solver.cpp:404]     Test net output #1: loss = 2.21412 (* 1 = 2.21412 loss)
I0812 03:53:44.731544 26953 solver.cpp:228] Iteration 21400, loss = 2.058
I0812 03:53:44.731609 26953 solver.cpp:244]     Train net output #0: loss = 2.058 (* 1 = 2.058 loss)
I0812 03:53:46.092923 26953 sgd_solver.cpp:106] Iteration 21400, lr = 0.01
I0812 03:54:04.454881 26953 solver.cpp:228] Iteration 21410, loss = 2.06069
I0812 03:54:04.455096 26953 solver.cpp:244]     Train net output #0: loss = 2.06069 (* 1 = 2.06069 loss)
I0812 03:54:05.874799 26953 sgd_solver.cpp:106] Iteration 21410, lr = 0.01
I0812 03:54:24.279865 26953 solver.cpp:228] Iteration 21420, loss = 2.10123
I0812 03:54:24.279937 26953 solver.cpp:244]     Train net output #0: loss = 2.10123 (* 1 = 2.10123 loss)
I0812 03:54:25.694399 26953 sgd_solver.cpp:106] Iteration 21420, lr = 0.01
I0812 03:54:44.086566 26953 solver.cpp:228] Iteration 21430, loss = 2.18919
I0812 03:54:44.086802 26953 solver.cpp:244]     Train net output #0: loss = 2.18919 (* 1 = 2.18919 loss)
I0812 03:54:45.500355 26953 sgd_solver.cpp:106] Iteration 21430, lr = 0.01
I0812 03:55:03.882158 26953 solver.cpp:228] Iteration 21440, loss = 2.22829
I0812 03:55:03.882225 26953 solver.cpp:244]     Train net output #0: loss = 2.22829 (* 1 = 2.22829 loss)
I0812 03:55:05.272874 26953 sgd_solver.cpp:106] Iteration 21440, lr = 0.01
I0812 03:55:23.707118 26953 solver.cpp:228] Iteration 21450, loss = 2.22362
I0812 03:55:23.707366 26953 solver.cpp:244]     Train net output #0: loss = 2.22362 (* 1 = 2.22362 loss)
I0812 03:55:25.096668 26953 sgd_solver.cpp:106] Iteration 21450, lr = 0.01
I0812 03:55:43.500557 26953 solver.cpp:228] Iteration 21460, loss = 2.02487
I0812 03:55:43.500643 26953 solver.cpp:244]     Train net output #0: loss = 2.02487 (* 1 = 2.02487 loss)
I0812 03:55:44.886862 26953 sgd_solver.cpp:106] Iteration 21460, lr = 0.01
I0812 03:56:03.264055 26953 solver.cpp:228] Iteration 21470, loss = 2.18902
I0812 03:56:03.264324 26953 solver.cpp:244]     Train net output #0: loss = 2.18902 (* 1 = 2.18902 loss)
I0812 03:56:04.675506 26953 sgd_solver.cpp:106] Iteration 21470, lr = 0.01
I0812 03:56:23.058874 26953 solver.cpp:228] Iteration 21480, loss = 2.18594
I0812 03:56:23.058946 26953 solver.cpp:244]     Train net output #0: loss = 2.18594 (* 1 = 2.18594 loss)
I0812 03:56:24.458587 26953 sgd_solver.cpp:106] Iteration 21480, lr = 0.01
I0812 03:56:42.871546 26953 solver.cpp:228] Iteration 21490, loss = 1.9134
I0812 03:56:42.871718 26953 solver.cpp:244]     Train net output #0: loss = 1.9134 (* 1 = 1.9134 loss)
I0812 03:56:44.261991 26953 sgd_solver.cpp:106] Iteration 21490, lr = 0.01
I0812 03:57:02.059834 26953 solver.cpp:337] Iteration 21500, Testing net (#0)
I0812 03:57:02.649998 26953 solver.cpp:404]     Test net output #0: accuracy = 0.48
I0812 03:57:02.650061 26953 solver.cpp:404]     Test net output #1: loss = 2.23113 (* 1 = 2.23113 loss)
I0812 03:57:03.214524 26953 solver.cpp:228] Iteration 21500, loss = 2.01462
I0812 03:57:03.214618 26953 solver.cpp:244]     Train net output #0: loss = 2.01462 (* 1 = 2.01462 loss)
I0812 03:57:04.597277 26953 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I0812 03:57:23.018637 26953 solver.cpp:228] Iteration 21510, loss = 1.97885
I0812 03:57:23.018879 26953 solver.cpp:244]     Train net output #0: loss = 1.97885 (* 1 = 1.97885 loss)
I0812 03:57:24.413926 26953 sgd_solver.cpp:106] Iteration 21510, lr = 0.01
I0812 03:57:42.772799 26953 solver.cpp:228] Iteration 21520, loss = 2.18034
I0812 03:57:42.772871 26953 solver.cpp:244]     Train net output #0: loss = 2.18034 (* 1 = 2.18034 loss)
I0812 03:57:44.181700 26953 sgd_solver.cpp:106] Iteration 21520, lr = 0.01
I0812 03:58:02.520282 26953 solver.cpp:228] Iteration 21530, loss = 2.09598
I0812 03:58:02.520480 26953 solver.cpp:244]     Train net output #0: loss = 2.09598 (* 1 = 2.09598 loss)
I0812 03:58:03.924015 26953 sgd_solver.cpp:106] Iteration 21530, lr = 0.01
I0812 03:58:22.343739 26953 solver.cpp:228] Iteration 21540, loss = 2.088
I0812 03:58:22.343811 26953 solver.cpp:244]     Train net output #0: loss = 2.088 (* 1 = 2.088 loss)
I0812 03:58:23.738906 26953 sgd_solver.cpp:106] Iteration 21540, lr = 0.01
I0812 03:58:42.130277 26953 solver.cpp:228] Iteration 21550, loss = 2.01901
I0812 03:58:42.130533 26953 solver.cpp:244]     Train net output #0: loss = 2.01901 (* 1 = 2.01901 loss)
I0812 03:58:43.542695 26953 sgd_solver.cpp:106] Iteration 21550, lr = 0.01
I0812 03:59:01.906659 26953 solver.cpp:228] Iteration 21560, loss = 2.0876
I0812 03:59:01.906723 26953 solver.cpp:244]     Train net output #0: loss = 2.0876 (* 1 = 2.0876 loss)
I0812 03:59:03.293597 26953 sgd_solver.cpp:106] Iteration 21560, lr = 0.01
I0812 03:59:21.683132 26953 solver.cpp:228] Iteration 21570, loss = 2.04923
I0812 03:59:21.683357 26953 solver.cpp:244]     Train net output #0: loss = 2.04923 (* 1 = 2.04923 loss)
I0812 03:59:23.071229 26953 sgd_solver.cpp:106] Iteration 21570, lr = 0.01
I0812 03:59:41.428941 26953 solver.cpp:228] Iteration 21580, loss = 2.02421
I0812 03:59:41.429030 26953 solver.cpp:244]     Train net output #0: loss = 2.02421 (* 1 = 2.02421 loss)
I0812 03:59:42.818898 26953 sgd_solver.cpp:106] Iteration 21580, lr = 0.01
I0812 04:00:01.217713 26953 solver.cpp:228] Iteration 21590, loss = 1.9743
I0812 04:00:01.217922 26953 solver.cpp:244]     Train net output #0: loss = 1.9743 (* 1 = 1.9743 loss)
I0812 04:00:02.623888 26953 sgd_solver.cpp:106] Iteration 21590, lr = 0.01
I0812 04:00:20.398728 26953 solver.cpp:337] Iteration 21600, Testing net (#0)
I0812 04:00:20.992559 26953 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0812 04:00:20.992619 26953 solver.cpp:404]     Test net output #1: loss = 2.24673 (* 1 = 2.24673 loss)
I0812 04:00:21.565934 26953 solver.cpp:228] Iteration 21600, loss = 1.98571
I0812 04:00:21.566030 26953 solver.cpp:244]     Train net output #0: loss = 1.98571 (* 1 = 1.98571 loss)
I0812 04:00:22.946008 26953 sgd_solver.cpp:106] Iteration 21600, lr = 0.01
I0812 04:00:41.348770 26953 solver.cpp:228] Iteration 21610, loss = 2.11858
I0812 04:00:41.348913 26953 solver.cpp:244]     Train net output #0: loss = 2.11858 (* 1 = 2.11858 loss)
I0812 04:00:42.746300 26953 sgd_solver.cpp:106] Iteration 21610, lr = 0.01
I0812 04:01:01.101279 26953 solver.cpp:228] Iteration 21620, loss = 2.00876
I0812 04:01:01.101346 26953 solver.cpp:244]     Train net output #0: loss = 2.00876 (* 1 = 2.00876 loss)
I0812 04:01:02.488553 26953 sgd_solver.cpp:106] Iteration 21620, lr = 0.01
I0812 04:01:20.859823 26953 solver.cpp:228] Iteration 21630, loss = 2.1387
I0812 04:01:20.859958 26953 solver.cpp:244]     Train net output #0: loss = 2.1387 (* 1 = 2.1387 loss)
I0812 04:01:22.257668 26953 sgd_solver.cpp:106] Iteration 21630, lr = 0.01
I0812 04:01:40.612658 26953 solver.cpp:228] Iteration 21640, loss = 2.02057
I0812 04:01:40.612725 26953 solver.cpp:244]     Train net output #0: loss = 2.02057 (* 1 = 2.02057 loss)
I0812 04:01:42.006009 26953 sgd_solver.cpp:106] Iteration 21640, lr = 0.01
I0812 04:02:00.350756 26953 solver.cpp:228] Iteration 21650, loss = 2.27722
I0812 04:02:00.350955 26953 solver.cpp:244]     Train net output #0: loss = 2.27722 (* 1 = 2.27722 loss)
I0812 04:02:01.760046 26953 sgd_solver.cpp:106] Iteration 21650, lr = 0.01
I0812 04:02:20.190498 26953 solver.cpp:228] Iteration 21660, loss = 2.06711
I0812 04:02:20.190558 26953 solver.cpp:244]     Train net output #0: loss = 2.06711 (* 1 = 2.06711 loss)
I0812 04:02:21.576673 26953 sgd_solver.cpp:106] Iteration 21660, lr = 0.01
I0812 04:02:39.964015 26953 solver.cpp:228] Iteration 21670, loss = 2.05397
I0812 04:02:39.964277 26953 solver.cpp:244]     Train net output #0: loss = 2.05397 (* 1 = 2.05397 loss)
I0812 04:02:41.382367 26953 sgd_solver.cpp:106] Iteration 21670, lr = 0.01
I0812 04:02:59.766446 26953 solver.cpp:228] Iteration 21680, loss = 2.27169
I0812 04:02:59.766549 26953 solver.cpp:244]     Train net output #0: loss = 2.27169 (* 1 = 2.27169 loss)
I0812 04:03:01.153615 26953 sgd_solver.cpp:106] Iteration 21680, lr = 0.01
I0812 04:03:19.549072 26953 solver.cpp:228] Iteration 21690, loss = 1.98348
I0812 04:03:19.549406 26953 solver.cpp:244]     Train net output #0: loss = 1.98348 (* 1 = 1.98348 loss)
I0812 04:03:20.947280 26953 sgd_solver.cpp:106] Iteration 21690, lr = 0.01
I0812 04:03:38.743072 26953 solver.cpp:337] Iteration 21700, Testing net (#0)
I0812 04:03:39.340034 26953 solver.cpp:404]     Test net output #0: accuracy = 0.492
I0812 04:03:39.340101 26953 solver.cpp:404]     Test net output #1: loss = 2.30139 (* 1 = 2.30139 loss)
I0812 04:03:39.907090 26953 solver.cpp:228] Iteration 21700, loss = 2.14025
I0812 04:03:39.907201 26953 solver.cpp:244]     Train net output #0: loss = 2.14025 (* 1 = 2.14025 loss)
I0812 04:03:41.286837 26953 sgd_solver.cpp:106] Iteration 21700, lr = 0.01
I0812 04:03:59.678592 26953 solver.cpp:228] Iteration 21710, loss = 1.99673
I0812 04:03:59.678925 26953 solver.cpp:244]     Train net output #0: loss = 1.99673 (* 1 = 1.99673 loss)
I0812 04:04:01.071842 26953 sgd_solver.cpp:106] Iteration 21710, lr = 0.01
I0812 04:04:19.446096 26953 solver.cpp:228] Iteration 21720, loss = 2.20476
I0812 04:04:19.446168 26953 solver.cpp:244]     Train net output #0: loss = 2.20476 (* 1 = 2.20476 loss)
I0812 04:04:20.846627 26953 sgd_solver.cpp:106] Iteration 21720, lr = 0.01
I0812 04:04:39.192534 26953 solver.cpp:228] Iteration 21730, loss = 1.92155
I0812 04:04:39.192746 26953 solver.cpp:244]     Train net output #0: loss = 1.92155 (* 1 = 1.92155 loss)
I0812 04:04:40.602061 26953 sgd_solver.cpp:106] Iteration 21730, lr = 0.01
I0812 04:04:58.958945 26953 solver.cpp:228] Iteration 21740, loss = 2.0944
I0812 04:04:58.959022 26953 solver.cpp:244]     Train net output #0: loss = 2.0944 (* 1 = 2.0944 loss)
I0812 04:05:00.349882 26953 sgd_solver.cpp:106] Iteration 21740, lr = 0.01
I0812 04:05:18.793606 26953 solver.cpp:228] Iteration 21750, loss = 1.91086
I0812 04:05:18.793807 26953 solver.cpp:244]     Train net output #0: loss = 1.91086 (* 1 = 1.91086 loss)
I0812 04:05:20.196127 26953 sgd_solver.cpp:106] Iteration 21750, lr = 0.01
I0812 04:05:38.568688 26953 solver.cpp:228] Iteration 21760, loss = 2.06098
I0812 04:05:38.568763 26953 solver.cpp:244]     Train net output #0: loss = 2.06098 (* 1 = 2.06098 loss)
I0812 04:05:39.967655 26953 sgd_solver.cpp:106] Iteration 21760, lr = 0.01
I0812 04:05:58.331928 26953 solver.cpp:228] Iteration 21770, loss = 2.1342
I0812 04:05:58.332099 26953 solver.cpp:244]     Train net output #0: loss = 2.1342 (* 1 = 2.1342 loss)
I0812 04:05:59.749940 26953 sgd_solver.cpp:106] Iteration 21770, lr = 0.01
I0812 04:06:18.144081 26953 solver.cpp:228] Iteration 21780, loss = 2.07793
I0812 04:06:18.144155 26953 solver.cpp:244]     Train net output #0: loss = 2.07793 (* 1 = 2.07793 loss)
I0812 04:06:19.541251 26953 sgd_solver.cpp:106] Iteration 21780, lr = 0.01
I0812 04:06:37.891839 26953 solver.cpp:228] Iteration 21790, loss = 2.05031
I0812 04:06:37.892099 26953 solver.cpp:244]     Train net output #0: loss = 2.05031 (* 1 = 2.05031 loss)
I0812 04:06:39.285984 26953 sgd_solver.cpp:106] Iteration 21790, lr = 0.01
I0812 04:06:57.120663 26953 solver.cpp:337] Iteration 21800, Testing net (#0)
I0812 04:06:57.708235 26953 solver.cpp:404]     Test net output #0: accuracy = 0.472
I0812 04:06:57.708303 26953 solver.cpp:404]     Test net output #1: loss = 2.29057 (* 1 = 2.29057 loss)
I0812 04:06:58.275815 26953 solver.cpp:228] Iteration 21800, loss = 2.02835
I0812 04:06:58.275889 26953 solver.cpp:244]     Train net output #0: loss = 2.02835 (* 1 = 2.02835 loss)
I0812 04:06:59.650709 26953 sgd_solver.cpp:106] Iteration 21800, lr = 0.01
I0812 04:07:18.036471 26953 solver.cpp:228] Iteration 21810, loss = 2.155
I0812 04:07:18.036710 26953 solver.cpp:244]     Train net output #0: loss = 2.155 (* 1 = 2.155 loss)
I0812 04:07:19.437780 26953 sgd_solver.cpp:106] Iteration 21810, lr = 0.01
I0812 04:07:37.839866 26953 solver.cpp:228] Iteration 21820, loss = 2.06291
I0812 04:07:37.839961 26953 solver.cpp:244]     Train net output #0: loss = 2.06291 (* 1 = 2.06291 loss)
I0812 04:07:39.259465 26953 sgd_solver.cpp:106] Iteration 21820, lr = 0.01
I0812 04:07:57.622715 26953 solver.cpp:228] Iteration 21830, loss = 2.06712
I0812 04:07:57.622964 26953 solver.cpp:244]     Train net output #0: loss = 2.06712 (* 1 = 2.06712 loss)
I0812 04:07:59.013788 26953 sgd_solver.cpp:106] Iteration 21830, lr = 0.01
I0812 04:08:17.415554 26953 solver.cpp:228] Iteration 21840, loss = 2.08435
I0812 04:08:17.415616 26953 solver.cpp:244]     Train net output #0: loss = 2.08435 (* 1 = 2.08435 loss)
I0812 04:08:18.799834 26953 sgd_solver.cpp:106] Iteration 21840, lr = 0.01
I0812 04:08:37.153704 26953 solver.cpp:228] Iteration 21850, loss = 2.21569
I0812 04:08:37.153916 26953 solver.cpp:244]     Train net output #0: loss = 2.21569 (* 1 = 2.21569 loss)
I0812 04:08:38.548764 26953 sgd_solver.cpp:106] Iteration 21850, lr = 0.01
I0812 04:08:56.924728 26953 solver.cpp:228] Iteration 21860, loss = 2.13484
I0812 04:08:56.924798 26953 solver.cpp:244]     Train net output #0: loss = 2.13484 (* 1 = 2.13484 loss)
I0812 04:08:58.321296 26953 sgd_solver.cpp:106] Iteration 21860, lr = 0.01
I0812 04:09:16.676367 26953 solver.cpp:228] Iteration 21870, loss = 2.27952
I0812 04:09:16.676524 26953 solver.cpp:244]     Train net output #0: loss = 2.27952 (* 1 = 2.27952 loss)
I0812 04:09:18.076369 26953 sgd_solver.cpp:106] Iteration 21870, lr = 0.01
I0812 04:09:36.486438 26953 solver.cpp:228] Iteration 21880, loss = 2.06615
I0812 04:09:36.486517 26953 solver.cpp:244]     Train net output #0: loss = 2.06615 (* 1 = 2.06615 loss)
I0812 04:09:37.874292 26953 sgd_solver.cpp:106] Iteration 21880, lr = 0.01
I0812 04:09:56.261651 26953 solver.cpp:228] Iteration 21890, loss = 1.96774
I0812 04:09:56.261903 26953 solver.cpp:244]     Train net output #0: loss = 1.96774 (* 1 = 1.96774 loss)
I0812 04:09:57.662570 26953 sgd_solver.cpp:106] Iteration 21890, lr = 0.01
I0812 04:10:15.484313 26953 solver.cpp:337] Iteration 21900, Testing net (#0)
I0812 04:10:16.073402 26953 solver.cpp:404]     Test net output #0: accuracy = 0.48
I0812 04:10:16.073472 26953 solver.cpp:404]     Test net output #1: loss = 2.32232 (* 1 = 2.32232 loss)
I0812 04:10:16.633096 26953 solver.cpp:228] Iteration 21900, loss = 1.96984
I0812 04:10:16.633183 26953 solver.cpp:244]     Train net output #0: loss = 1.96984 (* 1 = 1.96984 loss)
I0812 04:10:18.024492 26953 sgd_solver.cpp:106] Iteration 21900, lr = 0.01
I0812 04:10:36.429589 26953 solver.cpp:228] Iteration 21910, loss = 2.00846
I0812 04:10:36.429838 26953 solver.cpp:244]     Train net output #0: loss = 2.00846 (* 1 = 2.00846 loss)
I0812 04:10:37.823582 26953 sgd_solver.cpp:106] Iteration 21910, lr = 0.01
I0812 04:10:56.208020 26953 solver.cpp:228] Iteration 21920, loss = 2.07725
I0812 04:10:56.208092 26953 solver.cpp:244]     Train net output #0: loss = 2.07725 (* 1 = 2.07725 loss)
I0812 04:10:57.602391 26953 sgd_solver.cpp:106] Iteration 21920, lr = 0.01
I0812 04:11:15.945121 26953 solver.cpp:228] Iteration 21930, loss = 2.03239
I0812 04:11:15.945288 26953 solver.cpp:244]     Train net output #0: loss = 2.03239 (* 1 = 2.03239 loss)
I0812 04:11:17.349431 26953 sgd_solver.cpp:106] Iteration 21930, lr = 0.01
I0812 04:11:35.715648 26953 solver.cpp:228] Iteration 21940, loss = 2.06927
I0812 04:11:35.715713 26953 solver.cpp:244]     Train net output #0: loss = 2.06927 (* 1 = 2.06927 loss)
I0812 04:11:37.105864 26953 sgd_solver.cpp:106] Iteration 21940, lr = 0.01
I0812 04:11:55.526659 26953 solver.cpp:228] Iteration 21950, loss = 2.09374
I0812 04:11:55.526901 26953 solver.cpp:244]     Train net output #0: loss = 2.09374 (* 1 = 2.09374 loss)
I0812 04:11:56.917346 26953 sgd_solver.cpp:106] Iteration 21950, lr = 0.01
I0812 04:12:15.274153 26953 solver.cpp:228] Iteration 21960, loss = 2.04829
I0812 04:12:15.274230 26953 solver.cpp:244]     Train net output #0: loss = 2.04829 (* 1 = 2.04829 loss)
I0812 04:12:16.688693 26953 sgd_solver.cpp:106] Iteration 21960, lr = 0.01
I0812 04:12:35.039983 26953 solver.cpp:228] Iteration 21970, loss = 2.18095
I0812 04:12:35.040184 26953 solver.cpp:244]     Train net output #0: loss = 2.18095 (* 1 = 2.18095 loss)
I0812 04:12:36.465209 26953 sgd_solver.cpp:106] Iteration 21970, lr = 0.01
I0812 04:12:54.829346 26953 solver.cpp:228] Iteration 21980, loss = 2.13861
I0812 04:12:54.829432 26953 solver.cpp:244]     Train net output #0: loss = 2.13861 (* 1 = 2.13861 loss)
I0812 04:12:56.241011 26953 sgd_solver.cpp:106] Iteration 21980, lr = 0.01
I0812 04:13:14.628576 26953 solver.cpp:228] Iteration 21990, loss = 2.11211
I0812 04:13:14.628808 26953 solver.cpp:244]     Train net output #0: loss = 2.11211 (* 1 = 2.11211 loss)
I0812 04:13:16.047216 26953 sgd_solver.cpp:106] Iteration 21990, lr = 0.01
I0812 04:13:33.827401 26953 solver.cpp:337] Iteration 22000, Testing net (#0)
I0812 04:13:34.413960 26953 solver.cpp:404]     Test net output #0: accuracy = 0.472
I0812 04:13:34.414018 26953 solver.cpp:404]     Test net output #1: loss = 2.22642 (* 1 = 2.22642 loss)
I0812 04:13:34.975535 26953 solver.cpp:228] Iteration 22000, loss = 2.12514
I0812 04:13:34.975627 26953 solver.cpp:244]     Train net output #0: loss = 2.12514 (* 1 = 2.12514 loss)
I0812 04:13:36.352918 26953 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I0812 04:13:54.775723 26953 solver.cpp:228] Iteration 22010, loss = 2.03201
I0812 04:13:54.775952 26953 solver.cpp:244]     Train net output #0: loss = 2.03201 (* 1 = 2.03201 loss)
I0812 04:13:56.180953 26953 sgd_solver.cpp:106] Iteration 22010, lr = 0.01
I0812 04:14:14.524742 26953 solver.cpp:228] Iteration 22020, loss = 2.0684
I0812 04:14:14.524812 26953 solver.cpp:244]     Train net output #0: loss = 2.0684 (* 1 = 2.0684 loss)
I0812 04:14:15.929954 26953 sgd_solver.cpp:106] Iteration 22020, lr = 0.01
I0812 04:14:34.310467 26953 solver.cpp:228] Iteration 22030, loss = 2.15415
I0812 04:14:34.310698 26953 solver.cpp:244]     Train net output #0: loss = 2.15415 (* 1 = 2.15415 loss)
I0812 04:14:35.718107 26953 sgd_solver.cpp:106] Iteration 22030, lr = 0.01
I0812 04:14:54.059830 26953 solver.cpp:228] Iteration 22040, loss = 2.10299
I0812 04:14:54.059922 26953 solver.cpp:244]     Train net output #0: loss = 2.10299 (* 1 = 2.10299 loss)
I0812 04:14:55.447216 26953 sgd_solver.cpp:106] Iteration 22040, lr = 0.01
I0812 04:15:13.915099 26953 solver.cpp:228] Iteration 22050, loss = 1.89311
I0812 04:15:13.915262 26953 solver.cpp:244]     Train net output #0: loss = 1.89311 (* 1 = 1.89311 loss)
I0812 04:15:15.319687 26953 sgd_solver.cpp:106] Iteration 22050, lr = 0.01
I0812 04:15:33.676280 26953 solver.cpp:228] Iteration 22060, loss = 1.93049
I0812 04:15:33.676373 26953 solver.cpp:244]     Train net output #0: loss = 1.93049 (* 1 = 1.93049 loss)
I0812 04:15:35.086403 26953 sgd_solver.cpp:106] Iteration 22060, lr = 0.01
I0812 04:15:53.454816 26953 solver.cpp:228] Iteration 22070, loss = 2.22988
I0812 04:15:53.455050 26953 solver.cpp:244]     Train net output #0: loss = 2.22988 (* 1 = 2.22988 loss)
I0812 04:15:54.856755 26953 sgd_solver.cpp:106] Iteration 22070, lr = 0.01
I0812 04:16:13.299154 26953 solver.cpp:228] Iteration 22080, loss = 1.99695
I0812 04:16:13.299222 26953 solver.cpp:244]     Train net output #0: loss = 1.99695 (* 1 = 1.99695 loss)
I0812 04:16:14.706732 26953 sgd_solver.cpp:106] Iteration 22080, lr = 0.01
I0812 04:16:33.059368 26953 solver.cpp:228] Iteration 22090, loss = 2.30297
I0812 04:16:33.059626 26953 solver.cpp:244]     Train net output #0: loss = 2.30297 (* 1 = 2.30297 loss)
I0812 04:16:34.481557 26953 sgd_solver.cpp:106] Iteration 22090, lr = 0.01
I0812 04:16:52.248837 26953 solver.cpp:337] Iteration 22100, Testing net (#0)
I0812 04:16:52.840533 26953 solver.cpp:404]     Test net output #0: accuracy = 0.488
I0812 04:16:52.840600 26953 solver.cpp:404]     Test net output #1: loss = 2.29033 (* 1 = 2.29033 loss)
I0812 04:16:53.426687 26953 solver.cpp:228] Iteration 22100, loss = 1.94227
I0812 04:16:53.426776 26953 solver.cpp:244]     Train net output #0: loss = 1.94227 (* 1 = 1.94227 loss)
I0812 04:16:54.782315 26953 sgd_solver.cpp:106] Iteration 22100, lr = 0.01
I0812 04:17:13.189471 26953 solver.cpp:228] Iteration 22110, loss = 2.03814
I0812 04:17:13.189662 26953 solver.cpp:244]     Train net output #0: loss = 2.03814 (* 1 = 2.03814 loss)
I0812 04:17:14.610572 26953 sgd_solver.cpp:106] Iteration 22110, lr = 0.01
I0812 04:17:32.979472 26953 solver.cpp:228] Iteration 22120, loss = 2.09117
I0812 04:17:32.979553 26953 solver.cpp:244]     Train net output #0: loss = 2.09117 (* 1 = 2.09117 loss)
I0812 04:17:34.368876 26953 sgd_solver.cpp:106] Iteration 22120, lr = 0.01
I0812 04:17:52.788545 26953 solver.cpp:228] Iteration 22130, loss = 2.15629
I0812 04:17:52.788777 26953 solver.cpp:244]     Train net output #0: loss = 2.15629 (* 1 = 2.15629 loss)
I0812 04:17:54.186163 26953 sgd_solver.cpp:106] Iteration 22130, lr = 0.01
I0812 04:18:12.534812 26953 solver.cpp:228] Iteration 22140, loss = 2.10368
I0812 04:18:12.534886 26953 solver.cpp:244]     Train net output #0: loss = 2.10368 (* 1 = 2.10368 loss)
I0812 04:18:13.948398 26953 sgd_solver.cpp:106] Iteration 22140, lr = 0.01
I0812 04:18:32.309294 26953 solver.cpp:228] Iteration 22150, loss = 2.02683
I0812 04:18:32.309471 26953 solver.cpp:244]     Train net output #0: loss = 2.02683 (* 1 = 2.02683 loss)
I0812 04:18:33.705257 26953 sgd_solver.cpp:106] Iteration 22150, lr = 0.01
I0812 04:18:52.073954 26953 solver.cpp:228] Iteration 22160, loss = 1.99751
I0812 04:18:52.074031 26953 solver.cpp:244]     Train net output #0: loss = 1.99751 (* 1 = 1.99751 loss)
I0812 04:18:53.465139 26953 sgd_solver.cpp:106] Iteration 22160, lr = 0.01
I0812 04:19:11.810945 26953 solver.cpp:228] Iteration 22170, loss = 2.07282
I0812 04:19:11.811094 26953 solver.cpp:244]     Train net output #0: loss = 2.07282 (* 1 = 2.07282 loss)
I0812 04:19:13.197545 26953 sgd_solver.cpp:106] Iteration 22170, lr = 0.01
I0812 04:19:31.655050 26953 solver.cpp:228] Iteration 22180, loss = 2.11742
I0812 04:19:31.655140 26953 solver.cpp:244]     Train net output #0: loss = 2.11742 (* 1 = 2.11742 loss)
I0812 04:19:33.049892 26953 sgd_solver.cpp:106] Iteration 22180, lr = 0.01
I0812 04:19:51.409787 26953 solver.cpp:228] Iteration 22190, loss = 2.09691
I0812 04:19:51.409982 26953 solver.cpp:244]     Train net output #0: loss = 2.09691 (* 1 = 2.09691 loss)
I0812 04:19:52.818145 26953 sgd_solver.cpp:106] Iteration 22190, lr = 0.01
I0812 04:20:10.663156 26953 solver.cpp:337] Iteration 22200, Testing net (#0)
I0812 04:20:11.252710 26953 solver.cpp:404]     Test net output #0: accuracy = 0.478
I0812 04:20:11.252774 26953 solver.cpp:404]     Test net output #1: loss = 2.13117 (* 1 = 2.13117 loss)
I0812 04:20:11.836227 26953 solver.cpp:228] Iteration 22200, loss = 2.06179
I0812 04:20:11.836307 26953 solver.cpp:244]     Train net output #0: loss = 2.06179 (* 1 = 2.06179 loss)
I0812 04:20:13.196712 26953 sgd_solver.cpp:106] Iteration 22200, lr = 0.01
I0812 04:20:31.563765 26953 solver.cpp:228] Iteration 22210, loss = 2.0149
I0812 04:20:31.564033 26953 solver.cpp:244]     Train net output #0: loss = 2.0149 (* 1 = 2.0149 loss)
I0812 04:20:32.992578 26953 sgd_solver.cpp:106] Iteration 22210, lr = 0.01
I0812 04:20:51.342605 26953 solver.cpp:228] Iteration 22220, loss = 2.18475
I0812 04:20:51.342676 26953 solver.cpp:244]     Train net output #0: loss = 2.18475 (* 1 = 2.18475 loss)
I0812 04:20:52.735121 26953 sgd_solver.cpp:106] Iteration 22220, lr = 0.01
I0812 04:21:11.166702 26953 solver.cpp:228] Iteration 22230, loss = 2.12561
I0812 04:21:11.166915 26953 solver.cpp:244]     Train net output #0: loss = 2.12561 (* 1 = 2.12561 loss)
I0812 04:21:12.563910 26953 sgd_solver.cpp:106] Iteration 22230, lr = 0.01
I0812 04:21:30.930418 26953 solver.cpp:228] Iteration 22240, loss = 2.05209
I0812 04:21:30.930482 26953 solver.cpp:244]     Train net output #0: loss = 2.05209 (* 1 = 2.05209 loss)
I0812 04:21:32.317071 26953 sgd_solver.cpp:106] Iteration 22240, lr = 0.01
I0812 04:21:50.651633 26953 solver.cpp:228] Iteration 22250, loss = 1.97781
I0812 04:21:50.651862 26953 solver.cpp:244]     Train net output #0: loss = 1.97781 (* 1 = 1.97781 loss)
I0812 04:21:52.069569 26953 sgd_solver.cpp:106] Iteration 22250, lr = 0.01
I0812 04:22:10.471537 26953 solver.cpp:228] Iteration 22260, loss = 2.21706
I0812 04:22:10.471601 26953 solver.cpp:244]     Train net output #0: loss = 2.21706 (* 1 = 2.21706 loss)
I0812 04:22:11.860319 26953 sgd_solver.cpp:106] Iteration 22260, lr = 0.01
I0812 04:22:30.254060 26953 solver.cpp:228] Iteration 22270, loss = 2.07583
I0812 04:22:30.254360 26953 solver.cpp:244]     Train net output #0: loss = 2.07583 (* 1 = 2.07583 loss)
I0812 04:22:31.665984 26953 sgd_solver.cpp:106] Iteration 22270, lr = 0.01
I0812 04:22:50.062588 26953 solver.cpp:228] Iteration 22280, loss = 2.22181
I0812 04:22:50.062647 26953 solver.cpp:244]     Train net output #0: loss = 2.22181 (* 1 = 2.22181 loss)
I0812 04:22:51.461758 26953 sgd_solver.cpp:106] Iteration 22280, lr = 0.01
I0812 04:23:09.919440 26953 solver.cpp:228] Iteration 22290, loss = 2.14664
I0812 04:23:09.919661 26953 solver.cpp:244]     Train net output #0: loss = 2.14664 (* 1 = 2.14664 loss)
I0812 04:23:11.315791 26953 sgd_solver.cpp:106] Iteration 22290, lr = 0.01
I0812 04:23:29.084120 26953 solver.cpp:337] Iteration 22300, Testing net (#0)
I0812 04:23:29.672552 26953 solver.cpp:404]     Test net output #0: accuracy = 0.492
I0812 04:23:29.672618 26953 solver.cpp:404]     Test net output #1: loss = 2.26258 (* 1 = 2.26258 loss)
I0812 04:23:30.243386 26953 solver.cpp:228] Iteration 22300, loss = 2.0472
I0812 04:23:30.243480 26953 solver.cpp:244]     Train net output #0: loss = 2.0472 (* 1 = 2.0472 loss)
I0812 04:23:31.625923 26953 sgd_solver.cpp:106] Iteration 22300, lr = 0.01
I0812 04:23:49.997172 26953 solver.cpp:228] Iteration 22310, loss = 2.04946
I0812 04:23:49.997411 26953 solver.cpp:244]     Train net output #0: loss = 2.04946 (* 1 = 2.04946 loss)
I0812 04:23:51.388617 26953 sgd_solver.cpp:106] Iteration 22310, lr = 0.01
I0812 04:24:09.836665 26953 solver.cpp:228] Iteration 22320, loss = 2.12372
I0812 04:24:09.836760 26953 solver.cpp:244]     Train net output #0: loss = 2.12372 (* 1 = 2.12372 loss)
I0812 04:24:11.244670 26953 sgd_solver.cpp:106] Iteration 22320, lr = 0.01
I0812 04:24:29.596211 26953 solver.cpp:228] Iteration 22330, loss = 2.19275
I0812 04:24:29.596451 26953 solver.cpp:244]     Train net output #0: loss = 2.19275 (* 1 = 2.19275 loss)
I0812 04:24:31.003682 26953 sgd_solver.cpp:106] Iteration 22330, lr = 0.01
I0812 04:24:49.374892 26953 solver.cpp:228] Iteration 22340, loss = 2.11402
I0812 04:24:49.374961 26953 solver.cpp:244]     Train net output #0: loss = 2.11402 (* 1 = 2.11402 loss)
I0812 04:24:50.770829 26953 sgd_solver.cpp:106] Iteration 22340, lr = 0.01
I0812 04:25:09.125035 26953 solver.cpp:228] Iteration 22350, loss = 2.2795
I0812 04:25:09.125277 26953 solver.cpp:244]     Train net output #0: loss = 2.2795 (* 1 = 2.2795 loss)
I0812 04:25:10.530144 26953 sgd_solver.cpp:106] Iteration 22350, lr = 0.01
I0812 04:25:28.945333 26953 solver.cpp:228] Iteration 22360, loss = 2.2367
I0812 04:25:28.945417 26953 solver.cpp:244]     Train net output #0: loss = 2.2367 (* 1 = 2.2367 loss)
I0812 04:25:30.357101 26953 sgd_solver.cpp:106] Iteration 22360, lr = 0.01
I0812 04:25:48.691573 26953 solver.cpp:228] Iteration 22370, loss = 2.19656
I0812 04:25:48.691823 26953 solver.cpp:244]     Train net output #0: loss = 2.19656 (* 1 = 2.19656 loss)
I0812 04:25:50.097139 26953 sgd_solver.cpp:106] Iteration 22370, lr = 0.01
I0812 04:26:08.497433 26953 solver.cpp:228] Iteration 22380, loss = 2.21876
I0812 04:26:08.497534 26953 solver.cpp:244]     Train net output #0: loss = 2.21876 (* 1 = 2.21876 loss)
I0812 04:26:09.900316 26953 sgd_solver.cpp:106] Iteration 22380, lr = 0.01
I0812 04:26:28.309873 26953 solver.cpp:228] Iteration 22390, loss = 2.22422
I0812 04:26:28.310119 26953 solver.cpp:244]     Train net output #0: loss = 2.22422 (* 1 = 2.22422 loss)
I0812 04:26:29.726058 26953 sgd_solver.cpp:106] Iteration 22390, lr = 0.01
I0812 04:26:47.535207 26953 solver.cpp:337] Iteration 22400, Testing net (#0)
I0812 04:26:48.128871 26953 solver.cpp:404]     Test net output #0: accuracy = 0.492
I0812 04:26:48.128938 26953 solver.cpp:404]     Test net output #1: loss = 2.19744 (* 1 = 2.19744 loss)
I0812 04:26:48.722569 26953 solver.cpp:228] Iteration 22400, loss = 2.04618
I0812 04:26:48.722651 26953 solver.cpp:244]     Train net output #0: loss = 2.04618 (* 1 = 2.04618 loss)
I0812 04:26:50.059923 26953 sgd_solver.cpp:106] Iteration 22400, lr = 0.01
I0812 04:27:08.409190 26953 solver.cpp:228] Iteration 22410, loss = 2.16578
I0812 04:27:08.410858 26953 solver.cpp:244]     Train net output #0: loss = 2.16578 (* 1 = 2.16578 loss)
I0812 04:27:09.804162 26953 sgd_solver.cpp:106] Iteration 22410, lr = 0.01
I0812 04:27:28.181705 26953 solver.cpp:228] Iteration 22420, loss = 2.19321
I0812 04:27:28.181780 26953 solver.cpp:244]     Train net output #0: loss = 2.19321 (* 1 = 2.19321 loss)
I0812 04:27:29.581761 26953 sgd_solver.cpp:106] Iteration 22420, lr = 0.01
I0812 04:27:47.939631 26953 solver.cpp:228] Iteration 22430, loss = 2.01817
I0812 04:27:47.939872 26953 solver.cpp:244]     Train net output #0: loss = 2.01817 (* 1 = 2.01817 loss)
I0812 04:27:49.353956 26953 sgd_solver.cpp:106] Iteration 22430, lr = 0.01
I0812 04:28:07.723590 26953 solver.cpp:228] Iteration 22440, loss = 2.13514
I0812 04:28:07.723695 26953 solver.cpp:244]     Train net output #0: loss = 2.13514 (* 1 = 2.13514 loss)
I0812 04:28:09.133535 26953 sgd_solver.cpp:106] Iteration 22440, lr = 0.01
I0812 04:28:27.550472 26953 solver.cpp:228] Iteration 22450, loss = 2.08063
I0812 04:28:27.550700 26953 solver.cpp:244]     Train net output #0: loss = 2.08063 (* 1 = 2.08063 loss)
I0812 04:28:28.950626 26953 sgd_solver.cpp:106] Iteration 22450, lr = 0.01
I0812 04:28:47.342236 26953 solver.cpp:228] Iteration 22460, loss = 1.80246
I0812 04:28:47.342324 26953 solver.cpp:244]     Train net output #0: loss = 1.80246 (* 1 = 1.80246 loss)
I0812 04:28:48.741909 26953 sgd_solver.cpp:106] Iteration 22460, lr = 0.01
I0812 04:29:07.116189 26953 solver.cpp:228] Iteration 22470, loss = 2.10529
I0812 04:29:07.116348 26953 solver.cpp:244]     Train net output #0: loss = 2.10529 (* 1 = 2.10529 loss)
I0812 04:29:08.513907 26953 sgd_solver.cpp:106] Iteration 22470, lr = 0.01
I0812 04:29:26.964088 26953 solver.cpp:228] Iteration 22480, loss = 2.05053
I0812 04:29:26.964156 26953 solver.cpp:244]     Train net output #0: loss = 2.05053 (* 1 = 2.05053 loss)
I0812 04:29:28.377035 26953 sgd_solver.cpp:106] Iteration 22480, lr = 0.01
I0812 04:29:46.720201 26953 solver.cpp:228] Iteration 22490, loss = 2.31956
I0812 04:29:46.720366 26953 solver.cpp:244]     Train net output #0: loss = 2.31956 (* 1 = 2.31956 loss)
I0812 04:29:48.126744 26953 sgd_solver.cpp:106] Iteration 22490, lr = 0.01
I0812 04:30:05.940382 26953 solver.cpp:337] Iteration 22500, Testing net (#0)
I0812 04:30:06.535612 26953 solver.cpp:404]     Test net output #0: accuracy = 0.484
I0812 04:30:06.535688 26953 solver.cpp:404]     Test net output #1: loss = 2.2791 (* 1 = 2.2791 loss)
I0812 04:30:07.094715 26953 solver.cpp:228] Iteration 22500, loss = 2.26665
I0812 04:30:07.094791 26953 solver.cpp:244]     Train net output #0: loss = 2.26665 (* 1 = 2.26665 loss)
I0812 04:30:08.478718 26953 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I0812 04:30:26.864564 26953 solver.cpp:228] Iteration 22510, loss = 2.04492
I0812 04:30:26.864708 26953 solver.cpp:244]     Train net output #0: loss = 2.04492 (* 1 = 2.04492 loss)
I0812 04:30:28.275450 26953 sgd_solver.cpp:106] Iteration 22510, lr = 0.01
I0812 04:30:46.667588 26953 solver.cpp:228] Iteration 22520, loss = 2.00145
I0812 04:30:46.667661 26953 solver.cpp:244]     Train net output #0: loss = 2.00145 (* 1 = 2.00145 loss)
I0812 04:30:48.068512 26953 sgd_solver.cpp:106] Iteration 22520, lr = 0.01
I0812 04:31:06.460475 26953 solver.cpp:228] Iteration 22530, loss = 2.16976
I0812 04:31:06.460626 26953 solver.cpp:244]     Train net output #0: loss = 2.16976 (* 1 = 2.16976 loss)
I0812 04:31:07.865752 26953 sgd_solver.cpp:106] Iteration 22530, lr = 0.01
I0812 04:31:26.238713 26953 solver.cpp:228] Iteration 22540, loss = 2.11266
I0812 04:31:26.238808 26953 solver.cpp:244]     Train net output #0: loss = 2.11266 (* 1 = 2.11266 loss)
I0812 04:31:27.635896 26953 sgd_solver.cpp:106] Iteration 22540, lr = 0.01
I0812 04:31:45.988083 26953 solver.cpp:228] Iteration 22550, loss = 2.15287
I0812 04:31:45.988270 26953 solver.cpp:244]     Train net output #0: loss = 2.15287 (* 1 = 2.15287 loss)
I0812 04:31:47.397464 26953 sgd_solver.cpp:106] Iteration 22550, lr = 0.01
I0812 04:32:05.769105 26953 solver.cpp:228] Iteration 22560, loss = 2.13052
I0812 04:32:05.769165 26953 solver.cpp:244]     Train net output #0: loss = 2.13052 (* 1 = 2.13052 loss)
I0812 04:32:07.169356 26953 sgd_solver.cpp:106] Iteration 22560, lr = 0.01
I0812 04:32:25.569092 26953 solver.cpp:228] Iteration 22570, loss = 2.12248
I0812 04:32:25.569286 26953 solver.cpp:244]     Train net output #0: loss = 2.12248 (* 1 = 2.12248 loss)
I0812 04:32:26.956571 26953 sgd_solver.cpp:106] Iteration 22570, lr = 0.01
I0812 04:32:45.368748 26953 solver.cpp:228] Iteration 22580, loss = 2.08347
I0812 04:32:45.368808 26953 solver.cpp:244]     Train net output #0: loss = 2.08347 (* 1 = 2.08347 loss)
I0812 04:32:46.775992 26953 sgd_solver.cpp:106] Iteration 22580, lr = 0.01
I0812 04:33:05.112524 26953 solver.cpp:228] Iteration 22590, loss = 2.05382
I0812 04:33:05.112720 26953 solver.cpp:244]     Train net output #0: loss = 2.05382 (* 1 = 2.05382 loss)
I0812 04:33:06.520419 26953 sgd_solver.cpp:106] Iteration 22590, lr = 0.01
I0812 04:33:24.305361 26953 solver.cpp:337] Iteration 22600, Testing net (#0)
I0812 04:33:24.903477 26953 solver.cpp:404]     Test net output #0: accuracy = 0.546
I0812 04:33:24.903545 26953 solver.cpp:404]     Test net output #1: loss = 2.1626 (* 1 = 2.1626 loss)
I0812 04:33:25.476974 26953 solver.cpp:228] Iteration 22600, loss = 2.02218
I0812 04:33:25.477072 26953 solver.cpp:244]     Train net output #0: loss = 2.02218 (* 1 = 2.02218 loss)
I0812 04:33:26.845144 26953 sgd_solver.cpp:106] Iteration 22600, lr = 0.01
I0812 04:33:45.230466 26953 solver.cpp:228] Iteration 22610, loss = 2.08427
I0812 04:33:45.230728 26953 solver.cpp:244]     Train net output #0: loss = 2.08427 (* 1 = 2.08427 loss)
I0812 04:33:46.636613 26953 sgd_solver.cpp:106] Iteration 22610, lr = 0.01
I0812 04:34:04.981196 26953 solver.cpp:228] Iteration 22620, loss = 2.10855
I0812 04:34:04.981279 26953 solver.cpp:244]     Train net output #0: loss = 2.10855 (* 1 = 2.10855 loss)
I0812 04:34:06.390995 26953 sgd_solver.cpp:106] Iteration 22620, lr = 0.01
I0812 04:34:24.797412 26953 solver.cpp:228] Iteration 22630, loss = 2.08111
I0812 04:34:24.797634 26953 solver.cpp:244]     Train net output #0: loss = 2.08111 (* 1 = 2.08111 loss)
I0812 04:34:26.189124 26953 sgd_solver.cpp:106] Iteration 22630, lr = 0.01
I0812 04:34:44.583534 26953 solver.cpp:228] Iteration 22640, loss = 2.17061
I0812 04:34:44.583617 26953 solver.cpp:244]     Train net output #0: loss = 2.17061 (* 1 = 2.17061 loss)
I0812 04:34:45.998982 26953 sgd_solver.cpp:106] Iteration 22640, lr = 0.01
I0812 04:35:04.371564 26953 solver.cpp:228] Iteration 22650, loss = 2.08823
I0812 04:35:04.371817 26953 solver.cpp:244]     Train net output #0: loss = 2.08823 (* 1 = 2.08823 loss)
I0812 04:35:05.764255 26953 sgd_solver.cpp:106] Iteration 22650, lr = 0.01
I0812 04:35:24.143610 26953 solver.cpp:228] Iteration 22660, loss = 2.20996
I0812 04:35:24.143699 26953 solver.cpp:244]     Train net output #0: loss = 2.20996 (* 1 = 2.20996 loss)
I0812 04:35:25.559000 26953 sgd_solver.cpp:106] Iteration 22660, lr = 0.01
I0812 04:35:43.942277 26953 solver.cpp:228] Iteration 22670, loss = 2.20272
I0812 04:35:43.942492 26953 solver.cpp:244]     Train net output #0: loss = 2.20272 (* 1 = 2.20272 loss)
I0812 04:35:45.344632 26953 sgd_solver.cpp:106] Iteration 22670, lr = 0.01
I0812 04:36:03.722177 26953 solver.cpp:228] Iteration 22680, loss = 2.03978
I0812 04:36:03.722244 26953 solver.cpp:244]     Train net output #0: loss = 2.03978 (* 1 = 2.03978 loss)
I0812 04:36:05.130870 26953 sgd_solver.cpp:106] Iteration 22680, lr = 0.01
I0812 04:36:23.526528 26953 solver.cpp:228] Iteration 22690, loss = 2.03398
I0812 04:36:23.526777 26953 solver.cpp:244]     Train net output #0: loss = 2.03398 (* 1 = 2.03398 loss)
I0812 04:36:24.928258 26953 sgd_solver.cpp:106] Iteration 22690, lr = 0.01
I0812 04:36:42.712529 26953 solver.cpp:337] Iteration 22700, Testing net (#0)
I0812 04:36:43.302242 26953 solver.cpp:404]     Test net output #0: accuracy = 0.53
I0812 04:36:43.302337 26953 solver.cpp:404]     Test net output #1: loss = 2.26316 (* 1 = 2.26316 loss)
I0812 04:36:43.880875 26953 solver.cpp:228] Iteration 22700, loss = 2.01221
I0812 04:36:43.880973 26953 solver.cpp:244]     Train net output #0: loss = 2.01221 (* 1 = 2.01221 loss)
I0812 04:36:45.249435 26953 sgd_solver.cpp:106] Iteration 22700, lr = 0.01
I0812 04:37:03.617624 26953 solver.cpp:228] Iteration 22710, loss = 2.18197
I0812 04:37:03.617791 26953 solver.cpp:244]     Train net output #0: loss = 2.18197 (* 1 = 2.18197 loss)
I0812 04:37:05.032774 26953 sgd_solver.cpp:106] Iteration 22710, lr = 0.01
I0812 04:37:23.418655 26953 solver.cpp:228] Iteration 22720, loss = 1.89761
I0812 04:37:23.418742 26953 solver.cpp:244]     Train net output #0: loss = 1.89761 (* 1 = 1.89761 loss)
I0812 04:37:24.819178 26953 sgd_solver.cpp:106] Iteration 22720, lr = 0.01
I0812 04:37:43.233763 26953 solver.cpp:228] Iteration 22730, loss = 2.00395
I0812 04:37:43.233935 26953 solver.cpp:244]     Train net output #0: loss = 2.00395 (* 1 = 2.00395 loss)
I0812 04:37:44.633371 26953 sgd_solver.cpp:106] Iteration 22730, lr = 0.01
I0812 04:38:02.984208 26953 solver.cpp:228] Iteration 22740, loss = 2.02501
I0812 04:38:02.984278 26953 solver.cpp:244]     Train net output #0: loss = 2.02501 (* 1 = 2.02501 loss)
I0812 04:38:04.396631 26953 sgd_solver.cpp:106] Iteration 22740, lr = 0.01
I0812 04:38:22.771248 26953 solver.cpp:228] Iteration 22750, loss = 2.11335
I0812 04:38:22.771464 26953 solver.cpp:244]     Train net output #0: loss = 2.11335 (* 1 = 2.11335 loss)
I0812 04:38:24.173846 26953 sgd_solver.cpp:106] Iteration 22750, lr = 0.01
I0812 04:38:42.583012 26953 solver.cpp:228] Iteration 22760, loss = 2.14242
I0812 04:38:42.583102 26953 solver.cpp:244]     Train net output #0: loss = 2.14242 (* 1 = 2.14242 loss)
I0812 04:38:43.990391 26953 sgd_solver.cpp:106] Iteration 22760, lr = 0.01
I0812 04:39:02.353601 26953 solver.cpp:228] Iteration 22770, loss = 1.95661
I0812 04:39:02.353806 26953 solver.cpp:244]     Train net output #0: loss = 1.95661 (* 1 = 1.95661 loss)
I0812 04:39:03.766043 26953 sgd_solver.cpp:106] Iteration 22770, lr = 0.01
I0812 04:39:22.150189 26953 solver.cpp:228] Iteration 22780, loss = 1.99093
I0812 04:39:22.150271 26953 solver.cpp:244]     Train net output #0: loss = 1.99093 (* 1 = 1.99093 loss)
I0812 04:39:23.542124 26953 sgd_solver.cpp:106] Iteration 22780, lr = 0.01
I0812 04:39:41.934110 26953 solver.cpp:228] Iteration 22790, loss = 2.01478
I0812 04:39:41.934321 26953 solver.cpp:244]     Train net output #0: loss = 2.01478 (* 1 = 2.01478 loss)
I0812 04:39:43.327894 26953 sgd_solver.cpp:106] Iteration 22790, lr = 0.01
I0812 04:40:01.146713 26953 solver.cpp:337] Iteration 22800, Testing net (#0)
I0812 04:40:01.743926 26953 solver.cpp:404]     Test net output #0: accuracy = 0.48
I0812 04:40:01.743980 26953 solver.cpp:404]     Test net output #1: loss = 2.32296 (* 1 = 2.32296 loss)
I0812 04:40:02.319078 26953 solver.cpp:228] Iteration 22800, loss = 2.08448
I0812 04:40:02.319154 26953 solver.cpp:244]     Train net output #0: loss = 2.08448 (* 1 = 2.08448 loss)
I0812 04:40:03.697602 26953 sgd_solver.cpp:106] Iteration 22800, lr = 0.01
I0812 04:40:22.026208 26953 solver.cpp:228] Iteration 22810, loss = 2.06694
I0812 04:40:22.026356 26953 solver.cpp:244]     Train net output #0: loss = 2.06694 (* 1 = 2.06694 loss)
I0812 04:40:23.445513 26953 sgd_solver.cpp:106] Iteration 22810, lr = 0.01
I0812 04:40:41.786716 26953 solver.cpp:228] Iteration 22820, loss = 2.05969
I0812 04:40:41.786778 26953 solver.cpp:244]     Train net output #0: loss = 2.05969 (* 1 = 2.05969 loss)
I0812 04:40:43.182363 26953 sgd_solver.cpp:106] Iteration 22820, lr = 0.01
I0812 04:41:01.540439 26953 solver.cpp:228] Iteration 22830, loss = 2.09178
I0812 04:41:01.540621 26953 solver.cpp:244]     Train net output #0: loss = 2.09178 (* 1 = 2.09178 loss)
I0812 04:41:02.940203 26953 sgd_solver.cpp:106] Iteration 22830, lr = 0.01
I0812 04:41:21.324188 26953 solver.cpp:228] Iteration 22840, loss = 2.07966
I0812 04:41:21.324257 26953 solver.cpp:244]     Train net output #0: loss = 2.07966 (* 1 = 2.07966 loss)
I0812 04:41:22.722225 26953 sgd_solver.cpp:106] Iteration 22840, lr = 0.01
I0812 04:41:41.076851 26953 solver.cpp:228] Iteration 22850, loss = 2.08966
I0812 04:41:41.077302 26953 solver.cpp:244]     Train net output #0: loss = 2.08966 (* 1 = 2.08966 loss)
I0812 04:41:42.489022 26953 sgd_solver.cpp:106] Iteration 22850, lr = 0.01
I0812 04:42:00.886507 26953 solver.cpp:228] Iteration 22860, loss = 1.96078
I0812 04:42:00.886606 26953 solver.cpp:244]     Train net output #0: loss = 1.96078 (* 1 = 1.96078 loss)
I0812 04:42:02.295686 26953 sgd_solver.cpp:106] Iteration 22860, lr = 0.01
I0812 04:42:20.694006 26953 solver.cpp:228] Iteration 22870, loss = 2.10963
I0812 04:42:20.694196 26953 solver.cpp:244]     Train net output #0: loss = 2.10963 (* 1 = 2.10963 loss)
I0812 04:42:22.102927 26953 sgd_solver.cpp:106] Iteration 22870, lr = 0.01
I0812 04:42:40.456040 26953 solver.cpp:228] Iteration 22880, loss = 2.0217
I0812 04:42:40.456100 26953 solver.cpp:244]     Train net output #0: loss = 2.0217 (* 1 = 2.0217 loss)
I0812 04:42:41.865157 26953 sgd_solver.cpp:106] Iteration 22880, lr = 0.01
I0812 04:43:00.230574 26953 solver.cpp:228] Iteration 22890, loss = 1.94555
I0812 04:43:00.230737 26953 solver.cpp:244]     Train net output #0: loss = 1.94555 (* 1 = 1.94555 loss)
I0812 04:43:01.622829 26953 sgd_solver.cpp:106] Iteration 22890, lr = 0.01
I0812 04:43:19.475210 26953 solver.cpp:337] Iteration 22900, Testing net (#0)
I0812 04:43:20.065589 26953 solver.cpp:404]     Test net output #0: accuracy = 0.488
I0812 04:43:20.065654 26953 solver.cpp:404]     Test net output #1: loss = 2.27415 (* 1 = 2.27415 loss)
I0812 04:43:20.635979 26953 solver.cpp:228] Iteration 22900, loss = 2.09064
I0812 04:43:20.636036 26953 solver.cpp:244]     Train net output #0: loss = 2.09064 (* 1 = 2.09064 loss)
I0812 04:43:22.016744 26953 sgd_solver.cpp:106] Iteration 22900, lr = 0.01
I0812 04:43:40.413359 26953 solver.cpp:228] Iteration 22910, loss = 2.22498
I0812 04:43:40.413532 26953 solver.cpp:244]     Train net output #0: loss = 2.22498 (* 1 = 2.22498 loss)
I0812 04:43:41.817364 26953 sgd_solver.cpp:106] Iteration 22910, lr = 0.01
I0812 04:44:00.203758 26953 solver.cpp:228] Iteration 22920, loss = 1.96765
I0812 04:44:00.203815 26953 solver.cpp:244]     Train net output #0: loss = 1.96765 (* 1 = 1.96765 loss)
I0812 04:44:01.601155 26953 sgd_solver.cpp:106] Iteration 22920, lr = 0.01
I0812 04:44:19.962201 26953 solver.cpp:228] Iteration 22930, loss = 2.11984
I0812 04:44:19.962368 26953 solver.cpp:244]     Train net output #0: loss = 2.11984 (* 1 = 2.11984 loss)
I0812 04:44:21.362390 26953 sgd_solver.cpp:106] Iteration 22930, lr = 0.01
I0812 04:44:39.762167 26953 solver.cpp:228] Iteration 22940, loss = 2.0336
I0812 04:44:39.762238 26953 solver.cpp:244]     Train net output #0: loss = 2.0336 (* 1 = 2.0336 loss)
I0812 04:44:41.152506 26953 sgd_solver.cpp:106] Iteration 22940, lr = 0.01
I0812 04:44:59.611735 26953 solver.cpp:228] Iteration 22950, loss = 2.01549
I0812 04:44:59.611956 26953 solver.cpp:244]     Train net output #0: loss = 2.01549 (* 1 = 2.01549 loss)
I0812 04:45:01.011806 26953 sgd_solver.cpp:106] Iteration 22950, lr = 0.01
I0812 04:45:19.381394 26953 solver.cpp:228] Iteration 22960, loss = 2.00676
I0812 04:45:19.381476 26953 solver.cpp:244]     Train net output #0: loss = 2.00676 (* 1 = 2.00676 loss)
I0812 04:45:20.796531 26953 sgd_solver.cpp:106] Iteration 22960, lr = 0.01
I0812 04:45:39.179443 26953 solver.cpp:228] Iteration 22970, loss = 1.99138
I0812 04:45:39.179653 26953 solver.cpp:244]     Train net output #0: loss = 1.99138 (* 1 = 1.99138 loss)
I0812 04:45:40.576903 26953 sgd_solver.cpp:106] Iteration 22970, lr = 0.01
I0812 04:45:58.983989 26953 solver.cpp:228] Iteration 22980, loss = 1.94159
I0812 04:45:58.984058 26953 solver.cpp:244]     Train net output #0: loss = 1.94159 (* 1 = 1.94159 loss)
I0812 04:46:00.385056 26953 sgd_solver.cpp:106] Iteration 22980, lr = 0.01
I0812 04:46:18.749723 26953 solver.cpp:228] Iteration 22990, loss = 1.99428
I0812 04:46:18.749981 26953 solver.cpp:244]     Train net output #0: loss = 1.99428 (* 1 = 1.99428 loss)
I0812 04:46:20.170752 26953 sgd_solver.cpp:106] Iteration 22990, lr = 0.01
I0812 04:46:37.963795 26953 solver.cpp:337] Iteration 23000, Testing net (#0)
I0812 04:46:38.560083 26953 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0812 04:46:38.560153 26953 solver.cpp:404]     Test net output #1: loss = 2.13139 (* 1 = 2.13139 loss)
I0812 04:46:39.139655 26953 solver.cpp:228] Iteration 23000, loss = 2.17534
I0812 04:46:39.139744 26953 solver.cpp:244]     Train net output #0: loss = 2.17534 (* 1 = 2.17534 loss)
I0812 04:46:40.501566 26953 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I0812 04:46:58.889881 26953 solver.cpp:228] Iteration 23010, loss = 2.13247
I0812 04:46:58.891036 26953 solver.cpp:244]     Train net output #0: loss = 2.13247 (* 1 = 2.13247 loss)
I0812 04:47:00.293649 26953 sgd_solver.cpp:106] Iteration 23010, lr = 0.01
I0812 04:47:18.678371 26953 solver.cpp:228] Iteration 23020, loss = 2.08942
I0812 04:47:18.678437 26953 solver.cpp:244]     Train net output #0: loss = 2.08942 (* 1 = 2.08942 loss)
I0812 04:47:20.088487 26953 sgd_solver.cpp:106] Iteration 23020, lr = 0.01
I0812 04:47:38.503494 26953 solver.cpp:228] Iteration 23030, loss = 2.0142
I0812 04:47:38.503729 26953 solver.cpp:244]     Train net output #0: loss = 2.0142 (* 1 = 2.0142 loss)
I0812 04:47:39.915168 26953 sgd_solver.cpp:106] Iteration 23030, lr = 0.01
I0812 04:47:58.283255 26953 solver.cpp:228] Iteration 23040, loss = 2.16108
I0812 04:47:58.283339 26953 solver.cpp:244]     Train net output #0: loss = 2.16108 (* 1 = 2.16108 loss)
I0812 04:47:59.689122 26953 sgd_solver.cpp:106] Iteration 23040, lr = 0.01
I0812 04:48:18.078419 26953 solver.cpp:228] Iteration 23050, loss = 2.00993
I0812 04:48:18.078681 26953 solver.cpp:244]     Train net output #0: loss = 2.00993 (* 1 = 2.00993 loss)
I0812 04:48:19.482758 26953 sgd_solver.cpp:106] Iteration 23050, lr = 0.01
I0812 04:48:37.940742 26953 solver.cpp:228] Iteration 23060, loss = 2.01093
I0812 04:48:37.940815 26953 solver.cpp:244]     Train net output #0: loss = 2.01093 (* 1 = 2.01093 loss)
I0812 04:48:39.345490 26953 sgd_solver.cpp:106] Iteration 23060, lr = 0.01
I0812 04:48:57.708618 26953 solver.cpp:228] Iteration 23070, loss = 2.01483
I0812 04:48:57.708816 26953 solver.cpp:244]     Train net output #0: loss = 2.01483 (* 1 = 2.01483 loss)
I0812 04:48:59.104929 26953 sgd_solver.cpp:106] Iteration 23070, lr = 0.01
I0812 04:49:17.424283 26953 solver.cpp:228] Iteration 23080, loss = 2.21261
I0812 04:49:17.424382 26953 solver.cpp:244]     Train net output #0: loss = 2.21261 (* 1 = 2.21261 loss)
I0812 04:49:18.827157 26953 sgd_solver.cpp:106] Iteration 23080, lr = 0.01
I0812 04:49:37.243140 26953 solver.cpp:228] Iteration 23090, loss = 2.10826
I0812 04:49:37.243332 26953 solver.cpp:244]     Train net output #0: loss = 2.10826 (* 1 = 2.10826 loss)
I0812 04:49:38.649544 26953 sgd_solver.cpp:106] Iteration 23090, lr = 0.01
I0812 04:49:56.459995 26953 solver.cpp:337] Iteration 23100, Testing net (#0)
I0812 04:49:57.050174 26953 solver.cpp:404]     Test net output #0: accuracy = 0.542
I0812 04:49:57.050230 26953 solver.cpp:404]     Test net output #1: loss = 2.02944 (* 1 = 2.02944 loss)
I0812 04:49:57.620941 26953 solver.cpp:228] Iteration 23100, loss = 2.17036
I0812 04:49:57.621028 26953 solver.cpp:244]     Train net output #0: loss = 2.17036 (* 1 = 2.17036 loss)
I0812 04:49:58.998488 26953 sgd_solver.cpp:106] Iteration 23100, lr = 0.01
I0812 04:50:17.415935 26953 solver.cpp:228] Iteration 23110, loss = 2.00233
I0812 04:50:17.416115 26953 solver.cpp:244]     Train net output #0: loss = 2.00233 (* 1 = 2.00233 loss)
I0812 04:50:18.813201 26953 sgd_solver.cpp:106] Iteration 23110, lr = 0.01
I0812 04:50:37.197149 26953 solver.cpp:228] Iteration 23120, loss = 2.06851
I0812 04:50:37.197219 26953 solver.cpp:244]     Train net output #0: loss = 2.06851 (* 1 = 2.06851 loss)
I0812 04:50:38.605268 26953 sgd_solver.cpp:106] Iteration 23120, lr = 0.01
I0812 04:50:56.969626 26953 solver.cpp:228] Iteration 23130, loss = 1.94964
I0812 04:50:56.969808 26953 solver.cpp:244]     Train net output #0: loss = 1.94964 (* 1 = 1.94964 loss)
I0812 04:50:58.364919 26953 sgd_solver.cpp:106] Iteration 23130, lr = 0.01
I0812 04:51:16.785887 26953 solver.cpp:228] Iteration 23140, loss = 2.11509
I0812 04:51:16.785964 26953 solver.cpp:244]     Train net output #0: loss = 2.11509 (* 1 = 2.11509 loss)
I0812 04:51:18.182555 26953 sgd_solver.cpp:106] Iteration 23140, lr = 0.01
I0812 04:51:36.581420 26953 solver.cpp:228] Iteration 23150, loss = 2.02166
I0812 04:51:36.581692 26953 solver.cpp:244]     Train net output #0: loss = 2.02166 (* 1 = 2.02166 loss)
I0812 04:51:37.977557 26953 sgd_solver.cpp:106] Iteration 23150, lr = 0.01
I0812 04:51:56.320113 26953 solver.cpp:228] Iteration 23160, loss = 2.19607
I0812 04:51:56.320183 26953 solver.cpp:244]     Train net output #0: loss = 2.19607 (* 1 = 2.19607 loss)
I0812 04:51:57.728404 26953 sgd_solver.cpp:106] Iteration 23160, lr = 0.01
I0812 04:52:16.155021 26953 solver.cpp:228] Iteration 23170, loss = 2.06759
I0812 04:52:16.155259 26953 solver.cpp:244]     Train net output #0: loss = 2.06759 (* 1 = 2.06759 loss)
I0812 04:52:17.540484 26953 sgd_solver.cpp:106] Iteration 23170, lr = 0.01
I0812 04:52:35.925063 26953 solver.cpp:228] Iteration 23180, loss = 1.98219
I0812 04:52:35.925132 26953 solver.cpp:244]     Train net output #0: loss = 1.98219 (* 1 = 1.98219 loss)
I0812 04:52:37.322417 26953 sgd_solver.cpp:106] Iteration 23180, lr = 0.01
I0812 04:52:55.707597 26953 solver.cpp:228] Iteration 23190, loss = 2.05867
I0812 04:52:55.707795 26953 solver.cpp:244]     Train net output #0: loss = 2.05867 (* 1 = 2.05867 loss)
I0812 04:52:57.116751 26953 sgd_solver.cpp:106] Iteration 23190, lr = 0.01
I0812 04:53:14.899117 26953 solver.cpp:337] Iteration 23200, Testing net (#0)
I0812 04:53:15.489490 26953 solver.cpp:404]     Test net output #0: accuracy = 0.522
I0812 04:53:15.489548 26953 solver.cpp:404]     Test net output #1: loss = 2.18493 (* 1 = 2.18493 loss)
I0812 04:53:16.068387 26953 solver.cpp:228] Iteration 23200, loss = 2.07736
I0812 04:53:16.068464 26953 solver.cpp:244]     Train net output #0: loss = 2.07736 (* 1 = 2.07736 loss)
I0812 04:53:17.440212 26953 sgd_solver.cpp:106] Iteration 23200, lr = 0.01
I0812 04:53:35.837324 26953 solver.cpp:228] Iteration 23210, loss = 2.06804
I0812 04:53:35.837565 26953 solver.cpp:244]     Train net output #0: loss = 2.06804 (* 1 = 2.06804 loss)
I0812 04:53:37.254555 26953 sgd_solver.cpp:106] Iteration 23210, lr = 0.01
I0812 04:53:55.633041 26953 solver.cpp:228] Iteration 23220, loss = 2.05242
I0812 04:53:55.633113 26953 solver.cpp:244]     Train net output #0: loss = 2.05242 (* 1 = 2.05242 loss)
I0812 04:53:57.041472 26953 sgd_solver.cpp:106] Iteration 23220, lr = 0.01
I0812 04:54:15.419710 26953 solver.cpp:228] Iteration 23230, loss = 1.95491
I0812 04:54:15.419940 26953 solver.cpp:244]     Train net output #0: loss = 1.95491 (* 1 = 1.95491 loss)
I0812 04:54:16.814272 26953 sgd_solver.cpp:106] Iteration 23230, lr = 0.01
I0812 04:54:35.218003 26953 solver.cpp:228] Iteration 23240, loss = 2.05136
I0812 04:54:35.218071 26953 solver.cpp:244]     Train net output #0: loss = 2.05136 (* 1 = 2.05136 loss)
I0812 04:54:36.629545 26953 sgd_solver.cpp:106] Iteration 23240, lr = 0.01
I0812 04:54:54.960961 26953 solver.cpp:228] Iteration 23250, loss = 2.07992
I0812 04:54:54.961218 26953 solver.cpp:244]     Train net output #0: loss = 2.07992 (* 1 = 2.07992 loss)
I0812 04:54:56.364794 26953 sgd_solver.cpp:106] Iteration 23250, lr = 0.01
I0812 04:55:14.721736 26953 solver.cpp:228] Iteration 23260, loss = 2.0895
I0812 04:55:14.721823 26953 solver.cpp:244]     Train net output #0: loss = 2.0895 (* 1 = 2.0895 loss)
I0812 04:55:16.116951 26953 sgd_solver.cpp:106] Iteration 23260, lr = 0.01
I0812 04:55:34.537261 26953 solver.cpp:228] Iteration 23270, loss = 2.13476
I0812 04:55:34.537542 26953 solver.cpp:244]     Train net output #0: loss = 2.13476 (* 1 = 2.13476 loss)
I0812 04:55:35.938010 26953 sgd_solver.cpp:106] Iteration 23270, lr = 0.01
I0812 04:55:54.319154 26953 solver.cpp:228] Iteration 23280, loss = 2.04683
I0812 04:55:54.319231 26953 solver.cpp:244]     Train net output #0: loss = 2.04683 (* 1 = 2.04683 loss)
I0812 04:55:55.722875 26953 sgd_solver.cpp:106] Iteration 23280, lr = 0.01
I0812 04:56:14.099405 26953 solver.cpp:228] Iteration 23290, loss = 1.98495
I0812 04:56:14.099648 26953 solver.cpp:244]     Train net output #0: loss = 1.98495 (* 1 = 1.98495 loss)
I0812 04:56:15.513522 26953 sgd_solver.cpp:106] Iteration 23290, lr = 0.01
I0812 04:56:33.409879 26953 solver.cpp:337] Iteration 23300, Testing net (#0)
I0812 04:56:34.012841 26953 solver.cpp:404]     Test net output #0: accuracy = 0.522
I0812 04:56:34.012917 26953 solver.cpp:404]     Test net output #1: loss = 2.16067 (* 1 = 2.16067 loss)
I0812 04:56:34.604863 26953 solver.cpp:228] Iteration 23300, loss = 1.94709
I0812 04:56:34.604939 26953 solver.cpp:244]     Train net output #0: loss = 1.94709 (* 1 = 1.94709 loss)
I0812 04:56:35.958443 26953 sgd_solver.cpp:106] Iteration 23300, lr = 0.01
I0812 04:56:54.299590 26953 solver.cpp:228] Iteration 23310, loss = 1.98612
I0812 04:56:54.299753 26953 solver.cpp:244]     Train net output #0: loss = 1.98612 (* 1 = 1.98612 loss)
I0812 04:56:55.708219 26953 sgd_solver.cpp:106] Iteration 23310, lr = 0.01
I0812 04:57:14.147416 26953 solver.cpp:228] Iteration 23320, loss = 2.27833
I0812 04:57:14.147480 26953 solver.cpp:244]     Train net output #0: loss = 2.27833 (* 1 = 2.27833 loss)
I0812 04:57:15.565083 26953 sgd_solver.cpp:106] Iteration 23320, lr = 0.01
I0812 04:57:33.907363 26953 solver.cpp:228] Iteration 23330, loss = 2.09666
I0812 04:57:33.907613 26953 solver.cpp:244]     Train net output #0: loss = 2.09666 (* 1 = 2.09666 loss)
I0812 04:57:35.317441 26953 sgd_solver.cpp:106] Iteration 23330, lr = 0.01
I0812 04:57:53.722297 26953 solver.cpp:228] Iteration 23340, loss = 2.0503
I0812 04:57:53.722368 26953 solver.cpp:244]     Train net output #0: loss = 2.0503 (* 1 = 2.0503 loss)
I0812 04:57:55.129750 26953 sgd_solver.cpp:106] Iteration 23340, lr = 0.01
I0812 04:58:13.499830 26953 solver.cpp:228] Iteration 23350, loss = 1.97985
I0812 04:58:13.500048 26953 solver.cpp:244]     Train net output #0: loss = 1.97985 (* 1 = 1.97985 loss)
I0812 04:58:14.910354 26953 sgd_solver.cpp:106] Iteration 23350, lr = 0.01
I0812 04:58:33.298991 26953 solver.cpp:228] Iteration 23360, loss = 2.12235
I0812 04:58:33.299055 26953 solver.cpp:244]     Train net output #0: loss = 2.12235 (* 1 = 2.12235 loss)
I0812 04:58:34.697929 26953 sgd_solver.cpp:106] Iteration 23360, lr = 0.01
I0812 04:58:53.096930 26953 solver.cpp:228] Iteration 23370, loss = 2.05643
I0812 04:58:53.097079 26953 solver.cpp:244]     Train net output #0: loss = 2.05643 (* 1 = 2.05643 loss)
I0812 04:58:54.493654 26953 sgd_solver.cpp:106] Iteration 23370, lr = 0.01
I0812 04:59:12.909677 26953 solver.cpp:228] Iteration 23380, loss = 2.24641
I0812 04:59:12.909745 26953 solver.cpp:244]     Train net output #0: loss = 2.24641 (* 1 = 2.24641 loss)
I0812 04:59:14.306150 26953 sgd_solver.cpp:106] Iteration 23380, lr = 0.01
I0812 04:59:32.678190 26953 solver.cpp:228] Iteration 23390, loss = 2.07867
I0812 04:59:32.678395 26953 solver.cpp:244]     Train net output #0: loss = 2.07867 (* 1 = 2.07867 loss)
I0812 04:59:34.078310 26953 sgd_solver.cpp:106] Iteration 23390, lr = 0.01
I0812 04:59:51.873375 26953 solver.cpp:337] Iteration 23400, Testing net (#0)
I0812 04:59:52.466014 26953 solver.cpp:404]     Test net output #0: accuracy = 0.536
I0812 04:59:52.466089 26953 solver.cpp:404]     Test net output #1: loss = 2.0624 (* 1 = 2.0624 loss)
I0812 04:59:53.032692 26953 solver.cpp:228] Iteration 23400, loss = 2.00946
I0812 04:59:53.032793 26953 solver.cpp:244]     Train net output #0: loss = 2.00946 (* 1 = 2.00946 loss)
I0812 04:59:54.419004 26953 sgd_solver.cpp:106] Iteration 23400, lr = 0.01
I0812 05:00:12.821830 26953 solver.cpp:228] Iteration 23410, loss = 2.06839
I0812 05:00:12.822103 26953 solver.cpp:244]     Train net output #0: loss = 2.06839 (* 1 = 2.06839 loss)
I0812 05:00:14.245632 26953 sgd_solver.cpp:106] Iteration 23410, lr = 0.01
I0812 05:00:32.621068 26953 solver.cpp:228] Iteration 23420, loss = 2.03396
I0812 05:00:32.621134 26953 solver.cpp:244]     Train net output #0: loss = 2.03396 (* 1 = 2.03396 loss)
I0812 05:00:34.022357 26953 sgd_solver.cpp:106] Iteration 23420, lr = 0.01
I0812 05:00:52.425603 26953 solver.cpp:228] Iteration 23430, loss = 1.99249
I0812 05:00:52.425838 26953 solver.cpp:244]     Train net output #0: loss = 1.99249 (* 1 = 1.99249 loss)
I0812 05:00:53.833375 26953 sgd_solver.cpp:106] Iteration 23430, lr = 0.01
I0812 05:01:12.195201 26953 solver.cpp:228] Iteration 23440, loss = 2.06162
I0812 05:01:12.195267 26953 solver.cpp:244]     Train net output #0: loss = 2.06162 (* 1 = 2.06162 loss)
I0812 05:01:13.597100 26953 sgd_solver.cpp:106] Iteration 23440, lr = 0.01
I0812 05:01:31.935457 26953 solver.cpp:228] Iteration 23450, loss = 2.19482
I0812 05:01:31.935693 26953 solver.cpp:244]     Train net output #0: loss = 2.19482 (* 1 = 2.19482 loss)
I0812 05:01:33.337061 26953 sgd_solver.cpp:106] Iteration 23450, lr = 0.01
I0812 05:01:51.761960 26953 solver.cpp:228] Iteration 23460, loss = 2.14481
I0812 05:01:51.762032 26953 solver.cpp:244]     Train net output #0: loss = 2.14481 (* 1 = 2.14481 loss)
I0812 05:01:53.166427 26953 sgd_solver.cpp:106] Iteration 23460, lr = 0.01
I0812 05:02:11.532594 26953 solver.cpp:228] Iteration 23470, loss = 1.97626
I0812 05:02:11.532804 26953 solver.cpp:244]     Train net output #0: loss = 1.97626 (* 1 = 1.97626 loss)
I0812 05:02:12.939864 26953 sgd_solver.cpp:106] Iteration 23470, lr = 0.01
I0812 05:02:31.310580 26953 solver.cpp:228] Iteration 23480, loss = 2.0071
I0812 05:02:31.310645 26953 solver.cpp:244]     Train net output #0: loss = 2.0071 (* 1 = 2.0071 loss)
I0812 05:02:32.701248 26953 sgd_solver.cpp:106] Iteration 23480, lr = 0.01
I0812 05:02:51.090842 26953 solver.cpp:228] Iteration 23490, loss = 2.10522
I0812 05:02:51.091038 26953 solver.cpp:244]     Train net output #0: loss = 2.10522 (* 1 = 2.10522 loss)
I0812 05:02:52.479476 26953 sgd_solver.cpp:106] Iteration 23490, lr = 0.01
I0812 05:03:10.357033 26953 solver.cpp:337] Iteration 23500, Testing net (#0)
I0812 05:03:10.948632 26953 solver.cpp:404]     Test net output #0: accuracy = 0.512
I0812 05:03:10.948685 26953 solver.cpp:404]     Test net output #1: loss = 2.16931 (* 1 = 2.16931 loss)
I0812 05:03:11.515627 26953 solver.cpp:228] Iteration 23500, loss = 1.95488
I0812 05:03:11.515693 26953 solver.cpp:244]     Train net output #0: loss = 1.95488 (* 1 = 1.95488 loss)
I0812 05:03:12.899734 26953 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I0812 05:03:31.286501 26953 solver.cpp:228] Iteration 23510, loss = 2.18255
I0812 05:03:31.286761 26953 solver.cpp:244]     Train net output #0: loss = 2.18255 (* 1 = 2.18255 loss)
I0812 05:03:32.680932 26953 sgd_solver.cpp:106] Iteration 23510, lr = 0.01
I0812 05:03:51.064142 26953 solver.cpp:228] Iteration 23520, loss = 1.95829
I0812 05:03:51.064214 26953 solver.cpp:244]     Train net output #0: loss = 1.95829 (* 1 = 1.95829 loss)
I0812 05:03:52.470497 26953 sgd_solver.cpp:106] Iteration 23520, lr = 0.01
I0812 05:04:10.859699 26953 solver.cpp:228] Iteration 23530, loss = 2.04674
I0812 05:04:10.859944 26953 solver.cpp:244]     Train net output #0: loss = 2.04674 (* 1 = 2.04674 loss)
I0812 05:04:12.279500 26953 sgd_solver.cpp:106] Iteration 23530, lr = 0.01
I0812 05:04:30.661954 26953 solver.cpp:228] Iteration 23540, loss = 2.00062
I0812 05:04:30.662034 26953 solver.cpp:244]     Train net output #0: loss = 2.00062 (* 1 = 2.00062 loss)
I0812 05:04:32.053794 26953 sgd_solver.cpp:106] Iteration 23540, lr = 0.01
I0812 05:04:50.479315 26953 solver.cpp:228] Iteration 23550, loss = 2.04809
I0812 05:04:50.479472 26953 solver.cpp:244]     Train net output #0: loss = 2.04809 (* 1 = 2.04809 loss)
I0812 05:04:51.882892 26953 sgd_solver.cpp:106] Iteration 23550, lr = 0.01
I0812 05:05:10.239681 26953 solver.cpp:228] Iteration 23560, loss = 2.0827
I0812 05:05:10.239753 26953 solver.cpp:244]     Train net output #0: loss = 2.0827 (* 1 = 2.0827 loss)
I0812 05:05:11.644078 26953 sgd_solver.cpp:106] Iteration 23560, lr = 0.01
I0812 05:05:29.983711 26953 solver.cpp:228] Iteration 23570, loss = 2.13456
I0812 05:05:29.983947 26953 solver.cpp:244]     Train net output #0: loss = 2.13456 (* 1 = 2.13456 loss)
I0812 05:05:31.385888 26953 sgd_solver.cpp:106] Iteration 23570, lr = 0.01
I0812 05:05:49.755514 26953 solver.cpp:228] Iteration 23580, loss = 2.08172
I0812 05:05:49.755584 26953 solver.cpp:244]     Train net output #0: loss = 2.08172 (* 1 = 2.08172 loss)
I0812 05:05:51.158562 26953 sgd_solver.cpp:106] Iteration 23580, lr = 0.01
I0812 05:06:09.537282 26953 solver.cpp:228] Iteration 23590, loss = 2.06624
I0812 05:06:09.537545 26953 solver.cpp:244]     Train net output #0: loss = 2.06624 (* 1 = 2.06624 loss)
I0812 05:06:10.930609 26953 sgd_solver.cpp:106] Iteration 23590, lr = 0.01
I0812 05:06:28.741899 26953 solver.cpp:337] Iteration 23600, Testing net (#0)
I0812 05:06:29.330035 26953 solver.cpp:404]     Test net output #0: accuracy = 0.518
I0812 05:06:29.330122 26953 solver.cpp:404]     Test net output #1: loss = 2.18106 (* 1 = 2.18106 loss)
I0812 05:06:29.895119 26953 solver.cpp:228] Iteration 23600, loss = 2.11624
I0812 05:06:29.895213 26953 solver.cpp:244]     Train net output #0: loss = 2.11624 (* 1 = 2.11624 loss)
I0812 05:06:31.271775 26953 sgd_solver.cpp:106] Iteration 23600, lr = 0.01
I0812 05:06:49.676769 26953 solver.cpp:228] Iteration 23610, loss = 2.19284
I0812 05:06:49.677008 26953 solver.cpp:244]     Train net output #0: loss = 2.19284 (* 1 = 2.19284 loss)
I0812 05:06:51.072633 26953 sgd_solver.cpp:106] Iteration 23610, lr = 0.01
I0812 05:07:09.438246 26953 solver.cpp:228] Iteration 23620, loss = 2.07354
I0812 05:07:09.438318 26953 solver.cpp:244]     Train net output #0: loss = 2.07354 (* 1 = 2.07354 loss)
I0812 05:07:10.832273 26953 sgd_solver.cpp:106] Iteration 23620, lr = 0.01
I0812 05:07:29.209033 26953 solver.cpp:228] Iteration 23630, loss = 2.00702
I0812 05:07:29.209283 26953 solver.cpp:244]     Train net output #0: loss = 2.00702 (* 1 = 2.00702 loss)
I0812 05:07:30.612093 26953 sgd_solver.cpp:106] Iteration 23630, lr = 0.01
I0812 05:07:49.034200 26953 solver.cpp:228] Iteration 23640, loss = 2.00415
I0812 05:07:49.034299 26953 solver.cpp:244]     Train net output #0: loss = 2.00415 (* 1 = 2.00415 loss)
I0812 05:07:50.433799 26953 sgd_solver.cpp:106] Iteration 23640, lr = 0.01
I0812 05:08:08.859136 26953 solver.cpp:228] Iteration 23650, loss = 2.11433
I0812 05:08:08.859350 26953 solver.cpp:244]     Train net output #0: loss = 2.11433 (* 1 = 2.11433 loss)
I0812 05:08:10.261345 26953 sgd_solver.cpp:106] Iteration 23650, lr = 0.01
I0812 05:08:28.619493 26953 solver.cpp:228] Iteration 23660, loss = 2.2735
I0812 05:08:28.619585 26953 solver.cpp:244]     Train net output #0: loss = 2.2735 (* 1 = 2.2735 loss)
I0812 05:08:30.014430 26953 sgd_solver.cpp:106] Iteration 23660, lr = 0.01
I0812 05:08:48.413424 26953 solver.cpp:228] Iteration 23670, loss = 1.99294
I0812 05:08:48.413650 26953 solver.cpp:244]     Train net output #0: loss = 1.99294 (* 1 = 1.99294 loss)
I0812 05:08:49.817255 26953 sgd_solver.cpp:106] Iteration 23670, lr = 0.01
I0812 05:09:08.209782 26953 solver.cpp:228] Iteration 23680, loss = 2.09642
I0812 05:09:08.209853 26953 solver.cpp:244]     Train net output #0: loss = 2.09642 (* 1 = 2.09642 loss)
I0812 05:09:09.604660 26953 sgd_solver.cpp:106] Iteration 23680, lr = 0.01
I0812 05:09:27.950804 26953 solver.cpp:228] Iteration 23690, loss = 2.11678
I0812 05:09:27.951014 26953 solver.cpp:244]     Train net output #0: loss = 2.11678 (* 1 = 2.11678 loss)
I0812 05:09:29.367820 26953 sgd_solver.cpp:106] Iteration 23690, lr = 0.01
I0812 05:09:47.152590 26953 solver.cpp:337] Iteration 23700, Testing net (#0)
I0812 05:09:47.745734 26953 solver.cpp:404]     Test net output #0: accuracy = 0.512
I0812 05:09:47.745821 26953 solver.cpp:404]     Test net output #1: loss = 2.19814 (* 1 = 2.19814 loss)
I0812 05:09:48.310247 26953 solver.cpp:228] Iteration 23700, loss = 2.06628
I0812 05:09:48.310351 26953 solver.cpp:244]     Train net output #0: loss = 2.06628 (* 1 = 2.06628 loss)
I0812 05:09:49.693161 26953 sgd_solver.cpp:106] Iteration 23700, lr = 0.01
I0812 05:10:08.072227 26953 solver.cpp:228] Iteration 23710, loss = 2.07494
I0812 05:10:08.072432 26953 solver.cpp:244]     Train net output #0: loss = 2.07494 (* 1 = 2.07494 loss)
I0812 05:10:09.467669 26953 sgd_solver.cpp:106] Iteration 23710, lr = 0.01
I0812 05:10:27.804107 26953 solver.cpp:228] Iteration 23720, loss = 2.1908
I0812 05:10:27.804184 26953 solver.cpp:244]     Train net output #0: loss = 2.1908 (* 1 = 2.1908 loss)
I0812 05:10:29.204744 26953 sgd_solver.cpp:106] Iteration 23720, lr = 0.01
I0812 05:10:47.542531 26953 solver.cpp:228] Iteration 23730, loss = 1.98669
I0812 05:10:47.542773 26953 solver.cpp:244]     Train net output #0: loss = 1.98669 (* 1 = 1.98669 loss)
I0812 05:10:48.961143 26953 sgd_solver.cpp:106] Iteration 23730, lr = 0.01
I0812 05:11:07.353252 26953 solver.cpp:228] Iteration 23740, loss = 2.09111
I0812 05:11:07.353323 26953 solver.cpp:244]     Train net output #0: loss = 2.09111 (* 1 = 2.09111 loss)
I0812 05:11:08.748075 26953 sgd_solver.cpp:106] Iteration 23740, lr = 0.01
I0812 05:11:27.157469 26953 solver.cpp:228] Iteration 23750, loss = 2.15755
I0812 05:11:27.157718 26953 solver.cpp:244]     Train net output #0: loss = 2.15755 (* 1 = 2.15755 loss)
I0812 05:11:28.554672 26953 sgd_solver.cpp:106] Iteration 23750, lr = 0.01
I0812 05:11:46.934533 26953 solver.cpp:228] Iteration 23760, loss = 2.14909
I0812 05:11:46.934593 26953 solver.cpp:244]     Train net output #0: loss = 2.14909 (* 1 = 2.14909 loss)
I0812 05:11:48.337348 26953 sgd_solver.cpp:106] Iteration 23760, lr = 0.01
I0812 05:12:06.731807 26953 solver.cpp:228] Iteration 23770, loss = 2.08476
I0812 05:12:06.732064 26953 solver.cpp:244]     Train net output #0: loss = 2.08476 (* 1 = 2.08476 loss)
I0812 05:12:08.135851 26953 sgd_solver.cpp:106] Iteration 23770, lr = 0.01
I0812 05:12:26.534029 26953 solver.cpp:228] Iteration 23780, loss = 2.29769
I0812 05:12:26.534102 26953 solver.cpp:244]     Train net output #0: loss = 2.29769 (* 1 = 2.29769 loss)
I0812 05:12:27.937050 26953 sgd_solver.cpp:106] Iteration 23780, lr = 0.01
I0812 05:12:46.317890 26953 solver.cpp:228] Iteration 23790, loss = 1.95841
I0812 05:12:46.318115 26953 solver.cpp:244]     Train net output #0: loss = 1.95841 (* 1 = 1.95841 loss)
I0812 05:12:47.716073 26953 sgd_solver.cpp:106] Iteration 23790, lr = 0.01
I0812 05:13:05.489753 26953 solver.cpp:337] Iteration 23800, Testing net (#0)
I0812 05:13:06.076804 26953 solver.cpp:404]     Test net output #0: accuracy = 0.554
I0812 05:13:06.076881 26953 solver.cpp:404]     Test net output #1: loss = 2.15252 (* 1 = 2.15252 loss)
I0812 05:13:06.651948 26953 solver.cpp:228] Iteration 23800, loss = 2.14096
I0812 05:13:06.652012 26953 solver.cpp:244]     Train net output #0: loss = 2.14096 (* 1 = 2.14096 loss)
I0812 05:13:08.024061 26953 sgd_solver.cpp:106] Iteration 23800, lr = 0.01
I0812 05:13:26.460693 26953 solver.cpp:228] Iteration 23810, loss = 2.13785
I0812 05:13:26.460839 26953 solver.cpp:244]     Train net output #0: loss = 2.13785 (* 1 = 2.13785 loss)
I0812 05:13:27.868983 26953 sgd_solver.cpp:106] Iteration 23810, lr = 0.01
I0812 05:13:46.228090 26953 solver.cpp:228] Iteration 23820, loss = 1.96362
I0812 05:13:46.228162 26953 solver.cpp:244]     Train net output #0: loss = 1.96362 (* 1 = 1.96362 loss)
I0812 05:13:47.643106 26953 sgd_solver.cpp:106] Iteration 23820, lr = 0.01
I0812 05:14:06.026345 26953 solver.cpp:228] Iteration 23830, loss = 2.0256
I0812 05:14:06.026505 26953 solver.cpp:244]     Train net output #0: loss = 2.0256 (* 1 = 2.0256 loss)
I0812 05:14:07.423589 26953 sgd_solver.cpp:106] Iteration 23830, lr = 0.01
I0812 05:14:25.841954 26953 solver.cpp:228] Iteration 23840, loss = 1.98581
I0812 05:14:25.842031 26953 solver.cpp:244]     Train net output #0: loss = 1.98581 (* 1 = 1.98581 loss)
I0812 05:14:27.252931 26953 sgd_solver.cpp:106] Iteration 23840, lr = 0.01
I0812 05:14:45.627768 26953 solver.cpp:228] Iteration 23850, loss = 1.89997
I0812 05:14:45.628006 26953 solver.cpp:244]     Train net output #0: loss = 1.89997 (* 1 = 1.89997 loss)
I0812 05:14:47.020155 26953 sgd_solver.cpp:106] Iteration 23850, lr = 0.01
I0812 05:15:05.429630 26953 solver.cpp:228] Iteration 23860, loss = 1.99624
I0812 05:15:05.429710 26953 solver.cpp:244]     Train net output #0: loss = 1.99624 (* 1 = 1.99624 loss)
I0812 05:15:06.815815 26953 sgd_solver.cpp:106] Iteration 23860, lr = 0.01
I0812 05:15:25.175904 26953 solver.cpp:228] Iteration 23870, loss = 2.14697
I0812 05:15:25.176216 26953 solver.cpp:244]     Train net output #0: loss = 2.14697 (* 1 = 2.14697 loss)
I0812 05:15:26.570683 26953 sgd_solver.cpp:106] Iteration 23870, lr = 0.01
I0812 05:15:44.925648 26953 solver.cpp:228] Iteration 23880, loss = 2.16678
I0812 05:15:44.925711 26953 solver.cpp:244]     Train net output #0: loss = 2.16678 (* 1 = 2.16678 loss)
I0812 05:15:46.338898 26953 sgd_solver.cpp:106] Iteration 23880, lr = 0.01
I0812 05:16:04.739007 26953 solver.cpp:228] Iteration 23890, loss = 2.20054
I0812 05:16:04.739171 26953 solver.cpp:244]     Train net output #0: loss = 2.20054 (* 1 = 2.20054 loss)
I0812 05:16:06.150296 26953 sgd_solver.cpp:106] Iteration 23890, lr = 0.01
I0812 05:16:23.955631 26953 solver.cpp:337] Iteration 23900, Testing net (#0)
I0812 05:16:24.550309 26953 solver.cpp:404]     Test net output #0: accuracy = 0.524
I0812 05:16:24.550393 26953 solver.cpp:404]     Test net output #1: loss = 2.14656 (* 1 = 2.14656 loss)
I0812 05:16:25.116430 26953 solver.cpp:228] Iteration 23900, loss = 2.13726
I0812 05:16:25.116516 26953 solver.cpp:244]     Train net output #0: loss = 2.13726 (* 1 = 2.13726 loss)
I0812 05:16:26.497586 26953 sgd_solver.cpp:106] Iteration 23900, lr = 0.01
I0812 05:16:44.859724 26953 solver.cpp:228] Iteration 23910, loss = 1.98989
I0812 05:16:44.859951 26953 solver.cpp:244]     Train net output #0: loss = 1.98989 (* 1 = 1.98989 loss)
I0812 05:16:46.267376 26953 sgd_solver.cpp:106] Iteration 23910, lr = 0.01
I0812 05:17:04.602653 26953 solver.cpp:228] Iteration 23920, loss = 2.1486
I0812 05:17:04.602726 26953 solver.cpp:244]     Train net output #0: loss = 2.1486 (* 1 = 2.1486 loss)
I0812 05:17:06.007871 26953 sgd_solver.cpp:106] Iteration 23920, lr = 0.01
I0812 05:17:24.389475 26953 solver.cpp:228] Iteration 23930, loss = 1.94544
I0812 05:17:24.389623 26953 solver.cpp:244]     Train net output #0: loss = 1.94544 (* 1 = 1.94544 loss)
I0812 05:17:25.796537 26953 sgd_solver.cpp:106] Iteration 23930, lr = 0.01
I0812 05:17:44.187090 26953 solver.cpp:228] Iteration 23940, loss = 2.05091
I0812 05:17:44.187160 26953 solver.cpp:244]     Train net output #0: loss = 2.05091 (* 1 = 2.05091 loss)
I0812 05:17:45.590517 26953 sgd_solver.cpp:106] Iteration 23940, lr = 0.01
I0812 05:18:03.937971 26953 solver.cpp:228] Iteration 23950, loss = 2.01252
I0812 05:18:03.938127 26953 solver.cpp:244]     Train net output #0: loss = 2.01252 (* 1 = 2.01252 loss)
I0812 05:18:05.370182 26953 sgd_solver.cpp:106] Iteration 23950, lr = 0.01
I0812 05:18:23.700494 26953 solver.cpp:228] Iteration 23960, loss = 1.98789
I0812 05:18:23.700567 26953 solver.cpp:244]     Train net output #0: loss = 1.98789 (* 1 = 1.98789 loss)
I0812 05:18:25.104285 26953 sgd_solver.cpp:106] Iteration 23960, lr = 0.01
I0812 05:18:43.506032 26953 solver.cpp:228] Iteration 23970, loss = 2.02651
I0812 05:18:43.506249 26953 solver.cpp:244]     Train net output #0: loss = 2.02651 (* 1 = 2.02651 loss)
I0812 05:18:44.906831 26953 sgd_solver.cpp:106] Iteration 23970, lr = 0.01
I0812 05:19:03.285706 26953 solver.cpp:228] Iteration 23980, loss = 2.11463
I0812 05:19:03.285776 26953 solver.cpp:244]     Train net output #0: loss = 2.11463 (* 1 = 2.11463 loss)
I0812 05:19:04.695030 26953 sgd_solver.cpp:106] Iteration 23980, lr = 0.01
I0812 05:19:23.052979 26953 solver.cpp:228] Iteration 23990, loss = 2.0253
I0812 05:19:23.053211 26953 solver.cpp:244]     Train net output #0: loss = 2.0253 (* 1 = 2.0253 loss)
I0812 05:19:24.455791 26953 sgd_solver.cpp:106] Iteration 23990, lr = 0.01
I0812 05:19:42.293879 26953 solver.cpp:337] Iteration 24000, Testing net (#0)
I0812 05:19:42.884362 26953 solver.cpp:404]     Test net output #0: accuracy = 0.46
I0812 05:19:42.884443 26953 solver.cpp:404]     Test net output #1: loss = 2.39426 (* 1 = 2.39426 loss)
I0812 05:19:43.469931 26953 solver.cpp:228] Iteration 24000, loss = 1.9048
I0812 05:19:43.470010 26953 solver.cpp:244]     Train net output #0: loss = 1.9048 (* 1 = 1.9048 loss)
I0812 05:19:44.854651 26953 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I0812 05:20:03.241212 26953 solver.cpp:228] Iteration 24010, loss = 1.91572
I0812 05:20:03.241458 26953 solver.cpp:244]     Train net output #0: loss = 1.91572 (* 1 = 1.91572 loss)
I0812 05:20:04.641530 26953 sgd_solver.cpp:106] Iteration 24010, lr = 0.01
I0812 05:20:23.054167 26953 solver.cpp:228] Iteration 24020, loss = 2.02923
I0812 05:20:23.054224 26953 solver.cpp:244]     Train net output #0: loss = 2.02923 (* 1 = 2.02923 loss)
I0812 05:20:24.454596 26953 sgd_solver.cpp:106] Iteration 24020, lr = 0.01
I0812 05:20:42.857267 26953 solver.cpp:228] Iteration 24030, loss = 2.07441
I0812 05:20:42.857537 26953 solver.cpp:244]     Train net output #0: loss = 2.07441 (* 1 = 2.07441 loss)
I0812 05:20:44.257561 26953 sgd_solver.cpp:106] Iteration 24030, lr = 0.01
I0812 05:21:02.616621 26953 solver.cpp:228] Iteration 24040, loss = 2.05796
I0812 05:21:02.616689 26953 solver.cpp:244]     Train net output #0: loss = 2.05796 (* 1 = 2.05796 loss)
I0812 05:21:04.023504 26953 sgd_solver.cpp:106] Iteration 24040, lr = 0.01
I0812 05:21:22.412111 26953 solver.cpp:228] Iteration 24050, loss = 2.18514
I0812 05:21:22.412310 26953 solver.cpp:244]     Train net output #0: loss = 2.18514 (* 1 = 2.18514 loss)
I0812 05:21:23.810546 26953 sgd_solver.cpp:106] Iteration 24050, lr = 0.01
I0812 05:21:42.215983 26953 solver.cpp:228] Iteration 24060, loss = 2.14535
I0812 05:21:42.216054 26953 solver.cpp:244]     Train net output #0: loss = 2.14535 (* 1 = 2.14535 loss)
I0812 05:21:43.628000 26953 sgd_solver.cpp:106] Iteration 24060, lr = 0.01
I0812 05:22:01.983255 26953 solver.cpp:228] Iteration 24070, loss = 1.95207
I0812 05:22:01.983412 26953 solver.cpp:244]     Train net output #0: loss = 1.95207 (* 1 = 1.95207 loss)
I0812 05:22:03.396893 26953 sgd_solver.cpp:106] Iteration 24070, lr = 0.01
I0812 05:22:21.754182 26953 solver.cpp:228] Iteration 24080, loss = 2.01777
I0812 05:22:21.754257 26953 solver.cpp:244]     Train net output #0: loss = 2.01777 (* 1 = 2.01777 loss)
I0812 05:22:23.145840 26953 sgd_solver.cpp:106] Iteration 24080, lr = 0.01
I0812 05:22:41.599758 26953 solver.cpp:228] Iteration 24090, loss = 2.0271
I0812 05:22:41.600026 26953 solver.cpp:244]     Train net output #0: loss = 2.0271 (* 1 = 2.0271 loss)
I0812 05:22:43.012392 26953 sgd_solver.cpp:106] Iteration 24090, lr = 0.01
I0812 05:23:00.804800 26953 solver.cpp:337] Iteration 24100, Testing net (#0)
I0812 05:23:01.392391 26953 solver.cpp:404]     Test net output #0: accuracy = 0.512
I0812 05:23:01.392447 26953 solver.cpp:404]     Test net output #1: loss = 2.24637 (* 1 = 2.24637 loss)
I0812 05:23:01.967620 26953 solver.cpp:228] Iteration 24100, loss = 1.93542
I0812 05:23:01.967713 26953 solver.cpp:244]     Train net output #0: loss = 1.93542 (* 1 = 1.93542 loss)
I0812 05:23:03.329730 26953 sgd_solver.cpp:106] Iteration 24100, lr = 0.01
I0812 05:23:21.717759 26953 solver.cpp:228] Iteration 24110, loss = 1.99425
I0812 05:23:21.717900 26953 solver.cpp:244]     Train net output #0: loss = 1.99425 (* 1 = 1.99425 loss)
I0812 05:23:23.122002 26953 sgd_solver.cpp:106] Iteration 24110, lr = 0.01
I0812 05:23:41.517771 26953 solver.cpp:228] Iteration 24120, loss = 1.91099
I0812 05:23:41.517839 26953 solver.cpp:244]     Train net output #0: loss = 1.91099 (* 1 = 1.91099 loss)
I0812 05:23:42.938586 26953 sgd_solver.cpp:106] Iteration 24120, lr = 0.01
I0812 05:24:01.425339 26953 solver.cpp:228] Iteration 24130, loss = 2.22212
I0812 05:24:01.425503 26953 solver.cpp:244]     Train net output #0: loss = 2.22212 (* 1 = 2.22212 loss)
I0812 05:24:02.829967 26953 sgd_solver.cpp:106] Iteration 24130, lr = 0.01
I0812 05:24:21.210088 26953 solver.cpp:228] Iteration 24140, loss = 2.05075
I0812 05:24:21.210165 26953 solver.cpp:244]     Train net output #0: loss = 2.05075 (* 1 = 2.05075 loss)
I0812 05:24:22.596740 26953 sgd_solver.cpp:106] Iteration 24140, lr = 0.01
I0812 05:24:40.927230 26953 solver.cpp:228] Iteration 24150, loss = 2.00221
I0812 05:24:40.927484 26953 solver.cpp:244]     Train net output #0: loss = 2.00221 (* 1 = 2.00221 loss)
I0812 05:24:42.328352 26953 sgd_solver.cpp:106] Iteration 24150, lr = 0.01
I0812 05:25:00.698151 26953 solver.cpp:228] Iteration 24160, loss = 1.95729
I0812 05:25:00.698211 26953 solver.cpp:244]     Train net output #0: loss = 1.95729 (* 1 = 1.95729 loss)
I0812 05:25:02.091555 26953 sgd_solver.cpp:106] Iteration 24160, lr = 0.01
I0812 05:25:20.540992 26953 solver.cpp:228] Iteration 24170, loss = 2.01795
I0812 05:25:20.541249 26953 solver.cpp:244]     Train net output #0: loss = 2.01795 (* 1 = 2.01795 loss)
I0812 05:25:21.944691 26953 sgd_solver.cpp:106] Iteration 24170, lr = 0.01
I0812 05:25:40.288698 26953 solver.cpp:228] Iteration 24180, loss = 2.10134
I0812 05:25:40.288770 26953 solver.cpp:244]     Train net output #0: loss = 2.10134 (* 1 = 2.10134 loss)
I0812 05:25:41.706555 26953 sgd_solver.cpp:106] Iteration 24180, lr = 0.01
I0812 05:26:00.094882 26953 solver.cpp:228] Iteration 24190, loss = 2.06596
I0812 05:26:00.095110 26953 solver.cpp:244]     Train net output #0: loss = 2.06596 (* 1 = 2.06596 loss)
I0812 05:26:01.495254 26953 sgd_solver.cpp:106] Iteration 24190, lr = 0.01
I0812 05:26:19.317649 26953 solver.cpp:337] Iteration 24200, Testing net (#0)
I0812 05:26:19.916280 26953 solver.cpp:404]     Test net output #0: accuracy = 0.542
I0812 05:26:19.916365 26953 solver.cpp:404]     Test net output #1: loss = 2.09559 (* 1 = 2.09559 loss)
I0812 05:26:20.502213 26953 solver.cpp:228] Iteration 24200, loss = 1.89453
I0812 05:26:20.502290 26953 solver.cpp:244]     Train net output #0: loss = 1.89453 (* 1 = 1.89453 loss)
I0812 05:26:21.867885 26953 sgd_solver.cpp:106] Iteration 24200, lr = 0.01
I0812 05:26:40.264102 26953 solver.cpp:228] Iteration 24210, loss = 2.21932
I0812 05:26:40.264343 26953 solver.cpp:244]     Train net output #0: loss = 2.21932 (* 1 = 2.21932 loss)
I0812 05:26:41.657559 26953 sgd_solver.cpp:106] Iteration 24210, lr = 0.01
I0812 05:27:00.039553 26953 solver.cpp:228] Iteration 24220, loss = 1.92856
I0812 05:27:00.039629 26953 solver.cpp:244]     Train net output #0: loss = 1.92856 (* 1 = 1.92856 loss)
I0812 05:27:01.442167 26953 sgd_solver.cpp:106] Iteration 24220, lr = 0.01
I0812 05:27:19.796859 26953 solver.cpp:228] Iteration 24230, loss = 2.25002
I0812 05:27:19.797003 26953 solver.cpp:244]     Train net output #0: loss = 2.25002 (* 1 = 2.25002 loss)
I0812 05:27:21.194373 26953 sgd_solver.cpp:106] Iteration 24230, lr = 0.01
I0812 05:27:39.589568 26953 solver.cpp:228] Iteration 24240, loss = 2.03582
I0812 05:27:39.589668 26953 solver.cpp:244]     Train net output #0: loss = 2.03582 (* 1 = 2.03582 loss)
I0812 05:27:41.001919 26953 sgd_solver.cpp:106] Iteration 24240, lr = 0.01
I0812 05:27:59.437947 26953 solver.cpp:228] Iteration 24250, loss = 1.88903
I0812 05:27:59.438097 26953 solver.cpp:244]     Train net output #0: loss = 1.88903 (* 1 = 1.88903 loss)
I0812 05:28:00.840097 26953 sgd_solver.cpp:106] Iteration 24250, lr = 0.01
I0812 05:28:19.228914 26953 solver.cpp:228] Iteration 24260, loss = 2.17216
I0812 05:28:19.228987 26953 solver.cpp:244]     Train net output #0: loss = 2.17216 (* 1 = 2.17216 loss)
I0812 05:28:20.626284 26953 sgd_solver.cpp:106] Iteration 24260, lr = 0.01
I0812 05:28:38.970285 26953 solver.cpp:228] Iteration 24270, loss = 2.09391
I0812 05:28:38.970530 26953 solver.cpp:244]     Train net output #0: loss = 2.09391 (* 1 = 2.09391 loss)
I0812 05:28:40.371654 26953 sgd_solver.cpp:106] Iteration 24270, lr = 0.01
I0812 05:28:58.763924 26953 solver.cpp:228] Iteration 24280, loss = 2.03454
I0812 05:28:58.763998 26953 solver.cpp:244]     Train net output #0: loss = 2.03454 (* 1 = 2.03454 loss)
I0812 05:29:00.164466 26953 sgd_solver.cpp:106] Iteration 24280, lr = 0.01
I0812 05:29:18.578754 26953 solver.cpp:228] Iteration 24290, loss = 1.81438
I0812 05:29:18.578971 26953 solver.cpp:244]     Train net output #0: loss = 1.81438 (* 1 = 1.81438 loss)
I0812 05:29:19.991569 26953 sgd_solver.cpp:106] Iteration 24290, lr = 0.01
I0812 05:29:37.805418 26953 solver.cpp:337] Iteration 24300, Testing net (#0)
I0812 05:29:38.399826 26953 solver.cpp:404]     Test net output #0: accuracy = 0.504
I0812 05:29:38.399893 26953 solver.cpp:404]     Test net output #1: loss = 2.16903 (* 1 = 2.16903 loss)
I0812 05:29:38.970741 26953 solver.cpp:228] Iteration 24300, loss = 2.07831
I0812 05:29:38.970810 26953 solver.cpp:244]     Train net output #0: loss = 2.07831 (* 1 = 2.07831 loss)
I0812 05:29:40.337548 26953 sgd_solver.cpp:106] Iteration 24300, lr = 0.01
I0812 05:29:58.717089 26953 solver.cpp:228] Iteration 24310, loss = 2.11622
I0812 05:29:58.717252 26953 solver.cpp:244]     Train net output #0: loss = 2.11622 (* 1 = 2.11622 loss)
I0812 05:30:00.137454 26953 sgd_solver.cpp:106] Iteration 24310, lr = 0.01
I0812 05:30:18.509210 26953 solver.cpp:228] Iteration 24320, loss = 2.13217
I0812 05:30:18.509284 26953 solver.cpp:244]     Train net output #0: loss = 2.13217 (* 1 = 2.13217 loss)
I0812 05:30:19.905994 26953 sgd_solver.cpp:106] Iteration 24320, lr = 0.01
I0812 05:30:38.319732 26953 solver.cpp:228] Iteration 24330, loss = 2.16032
I0812 05:30:38.319960 26953 solver.cpp:244]     Train net output #0: loss = 2.16032 (* 1 = 2.16032 loss)
I0812 05:30:39.714254 26953 sgd_solver.cpp:106] Iteration 24330, lr = 0.01
I0812 05:30:58.113914 26953 solver.cpp:228] Iteration 24340, loss = 2.14794
I0812 05:30:58.114006 26953 solver.cpp:244]     Train net output #0: loss = 2.14794 (* 1 = 2.14794 loss)
I0812 05:30:59.512089 26953 sgd_solver.cpp:106] Iteration 24340, lr = 0.01
I0812 05:31:17.858954 26953 solver.cpp:228] Iteration 24350, loss = 2.03618
I0812 05:31:17.859172 26953 solver.cpp:244]     Train net output #0: loss = 2.03618 (* 1 = 2.03618 loss)
I0812 05:31:19.258486 26953 sgd_solver.cpp:106] Iteration 24350, lr = 0.01
I0812 05:31:37.640002 26953 solver.cpp:228] Iteration 24360, loss = 2.07387
I0812 05:31:37.640060 26953 solver.cpp:244]     Train net output #0: loss = 2.07387 (* 1 = 2.07387 loss)
I0812 05:31:39.050787 26953 sgd_solver.cpp:106] Iteration 24360, lr = 0.01
I0812 05:31:57.437058 26953 solver.cpp:228] Iteration 24370, loss = 2.1156
I0812 05:31:57.437304 26953 solver.cpp:244]     Train net output #0: loss = 2.1156 (* 1 = 2.1156 loss)
I0812 05:31:58.838306 26953 sgd_solver.cpp:106] Iteration 24370, lr = 0.01
I0812 05:32:17.221022 26953 solver.cpp:228] Iteration 24380, loss = 1.88737
I0812 05:32:17.221097 26953 solver.cpp:244]     Train net output #0: loss = 1.88737 (* 1 = 1.88737 loss)
I0812 05:32:18.640198 26953 sgd_solver.cpp:106] Iteration 24380, lr = 0.01
I0812 05:32:36.987910 26953 solver.cpp:228] Iteration 24390, loss = 2.03223
I0812 05:32:36.988163 26953 solver.cpp:244]     Train net output #0: loss = 2.03223 (* 1 = 2.03223 loss)
I0812 05:32:38.394208 26953 sgd_solver.cpp:106] Iteration 24390, lr = 0.01
I0812 05:32:56.272730 26953 solver.cpp:337] Iteration 24400, Testing net (#0)
I0812 05:32:56.865376 26953 solver.cpp:404]     Test net output #0: accuracy = 0.514
I0812 05:32:56.865453 26953 solver.cpp:404]     Test net output #1: loss = 2.23233 (* 1 = 2.23233 loss)
I0812 05:32:58.813513 26953 solver.cpp:228] Iteration 24400, loss = 2.18417
I0812 05:32:58.813580 26953 solver.cpp:244]     Train net output #0: loss = 2.18417 (* 1 = 2.18417 loss)
I0812 05:32:58.813617 26953 sgd_solver.cpp:106] Iteration 24400, lr = 0.01
I0812 05:33:18.444532 26953 solver.cpp:228] Iteration 24410, loss = 2.10074
I0812 05:33:18.444798 26953 solver.cpp:244]     Train net output #0: loss = 2.10074 (* 1 = 2.10074 loss)
I0812 05:33:19.842730 26953 sgd_solver.cpp:106] Iteration 24410, lr = 0.01
I0812 05:33:38.250314 26953 solver.cpp:228] Iteration 24420, loss = 1.87823
I0812 05:33:38.250387 26953 solver.cpp:244]     Train net output #0: loss = 1.87823 (* 1 = 1.87823 loss)
I0812 05:33:39.644500 26953 sgd_solver.cpp:106] Iteration 24420, lr = 0.01
I0812 05:33:58.044314 26953 solver.cpp:228] Iteration 24430, loss = 1.86389
I0812 05:33:58.044701 26953 solver.cpp:244]     Train net output #0: loss = 1.86389 (* 1 = 1.86389 loss)
I0812 05:33:59.454916 26953 sgd_solver.cpp:106] Iteration 24430, lr = 0.01
I0812 05:34:17.822258 26953 solver.cpp:228] Iteration 24440, loss = 2.16592
I0812 05:34:17.822337 26953 solver.cpp:244]     Train net output #0: loss = 2.16592 (* 1 = 2.16592 loss)
I0812 05:34:19.228627 26953 sgd_solver.cpp:106] Iteration 24440, lr = 0.01
I0812 05:34:37.632549 26953 solver.cpp:228] Iteration 24450, loss = 2.10501
I0812 05:34:37.632784 26953 solver.cpp:244]     Train net output #0: loss = 2.10501 (* 1 = 2.10501 loss)
I0812 05:34:39.024956 26953 sgd_solver.cpp:106] Iteration 24450, lr = 0.01
I0812 05:34:57.408803 26953 solver.cpp:228] Iteration 24460, loss = 2.05452
I0812 05:34:57.408895 26953 solver.cpp:244]     Train net output #0: loss = 2.05452 (* 1 = 2.05452 loss)
I0812 05:34:58.818907 26953 sgd_solver.cpp:106] Iteration 24460, lr = 0.01
I0812 05:35:17.210037 26953 solver.cpp:228] Iteration 24470, loss = 1.95368
I0812 05:35:17.210238 26953 solver.cpp:244]     Train net output #0: loss = 1.95368 (* 1 = 1.95368 loss)
I0812 05:35:18.594936 26953 sgd_solver.cpp:106] Iteration 24470, lr = 0.01
I0812 05:35:36.990094 26953 solver.cpp:228] Iteration 24480, loss = 2.10187
I0812 05:35:36.990186 26953 solver.cpp:244]     Train net output #0: loss = 2.10187 (* 1 = 2.10187 loss)
I0812 05:35:38.378732 26953 sgd_solver.cpp:106] Iteration 24480, lr = 0.01
I0812 05:35:56.742239 26953 solver.cpp:228] Iteration 24490, loss = 2.20555
I0812 05:35:56.742389 26953 solver.cpp:244]     Train net output #0: loss = 2.20555 (* 1 = 2.20555 loss)
I0812 05:35:58.150475 26953 sgd_solver.cpp:106] Iteration 24490, lr = 0.01
I0812 05:36:15.948696 26953 solver.cpp:337] Iteration 24500, Testing net (#0)
I0812 05:36:16.544157 26953 solver.cpp:404]     Test net output #0: accuracy = 0.526
I0812 05:36:16.544245 26953 solver.cpp:404]     Test net output #1: loss = 2.20174 (* 1 = 2.20174 loss)
I0812 05:36:17.116191 26953 solver.cpp:228] Iteration 24500, loss = 2.27875
I0812 05:36:17.116277 26953 solver.cpp:244]     Train net output #0: loss = 2.27875 (* 1 = 2.27875 loss)
I0812 05:36:18.477637 26953 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I0812 05:36:36.909879 26953 solver.cpp:228] Iteration 24510, loss = 2.04697
I0812 05:36:36.910112 26953 solver.cpp:244]     Train net output #0: loss = 2.04697 (* 1 = 2.04697 loss)
I0812 05:36:38.309897 26953 sgd_solver.cpp:106] Iteration 24510, lr = 0.01
I0812 05:36:56.680359 26953 solver.cpp:228] Iteration 24520, loss = 1.99642
I0812 05:36:56.680450 26953 solver.cpp:244]     Train net output #0: loss = 1.99642 (* 1 = 1.99642 loss)
I0812 05:36:58.082355 26953 sgd_solver.cpp:106] Iteration 24520, lr = 0.01
I0812 05:37:16.455086 26953 solver.cpp:228] Iteration 24530, loss = 1.79367
I0812 05:37:16.455343 26953 solver.cpp:244]     Train net output #0: loss = 1.79367 (* 1 = 1.79367 loss)
I0812 05:37:17.863351 26953 sgd_solver.cpp:106] Iteration 24530, lr = 0.01
I0812 05:37:36.276098 26953 solver.cpp:228] Iteration 24540, loss = 2.16322
I0812 05:37:36.276175 26953 solver.cpp:244]     Train net output #0: loss = 2.16322 (* 1 = 2.16322 loss)
I0812 05:37:37.674113 26953 sgd_solver.cpp:106] Iteration 24540, lr = 0.01
I0812 05:37:56.035282 26953 solver.cpp:228] Iteration 24550, loss = 2.21436
I0812 05:37:56.035503 26953 solver.cpp:244]     Train net output #0: loss = 2.21436 (* 1 = 2.21436 loss)
I0812 05:37:57.425389 26953 sgd_solver.cpp:106] Iteration 24550, lr = 0.01
I0812 05:38:15.793540 26953 solver.cpp:228] Iteration 24560, loss = 1.95627
I0812 05:38:15.793613 26953 solver.cpp:244]     Train net output #0: loss = 1.95627 (* 1 = 1.95627 loss)
I0812 05:38:17.194651 26953 sgd_solver.cpp:106] Iteration 24560, lr = 0.01
I0812 05:38:35.578647 26953 solver.cpp:228] Iteration 24570, loss = 2.00269
I0812 05:38:35.578866 26953 solver.cpp:244]     Train net output #0: loss = 2.00269 (* 1 = 2.00269 loss)
I0812 05:38:36.973948 26953 sgd_solver.cpp:106] Iteration 24570, lr = 0.01
I0812 05:38:55.419488 26953 solver.cpp:228] Iteration 24580, loss = 2.03886
I0812 05:38:55.419579 26953 solver.cpp:244]     Train net output #0: loss = 2.03886 (* 1 = 2.03886 loss)
I0812 05:38:56.834341 26953 sgd_solver.cpp:106] Iteration 24580, lr = 0.01
I0812 05:39:15.165156 26953 solver.cpp:228] Iteration 24590, loss = 2.07064
I0812 05:39:15.165370 26953 solver.cpp:244]     Train net output #0: loss = 2.07064 (* 1 = 2.07064 loss)
I0812 05:39:16.578974 26953 sgd_solver.cpp:106] Iteration 24590, lr = 0.01
I0812 05:39:34.423871 26953 solver.cpp:337] Iteration 24600, Testing net (#0)
I0812 05:39:35.012749 26953 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0812 05:39:35.012820 26953 solver.cpp:404]     Test net output #1: loss = 2.13429 (* 1 = 2.13429 loss)
I0812 05:39:35.602052 26953 solver.cpp:228] Iteration 24600, loss = 2.00274
I0812 05:39:35.602154 26953 solver.cpp:244]     Train net output #0: loss = 2.00274 (* 1 = 2.00274 loss)
I0812 05:39:36.981684 26953 sgd_solver.cpp:106] Iteration 24600, lr = 0.01
I0812 05:39:55.372112 26953 solver.cpp:228] Iteration 24610, loss = 2.14927
I0812 05:39:55.372282 26953 solver.cpp:244]     Train net output #0: loss = 2.14927 (* 1 = 2.14927 loss)
I0812 05:39:56.780736 26953 sgd_solver.cpp:106] Iteration 24610, lr = 0.01
I0812 05:40:15.176956 26953 solver.cpp:228] Iteration 24620, loss = 2.0994
I0812 05:40:15.177027 26953 solver.cpp:244]     Train net output #0: loss = 2.0994 (* 1 = 2.0994 loss)
I0812 05:40:16.563134 26953 sgd_solver.cpp:106] Iteration 24620, lr = 0.01
I0812 05:40:34.943034 26953 solver.cpp:228] Iteration 24630, loss = 2.03542
I0812 05:40:34.943256 26953 solver.cpp:244]     Train net output #0: loss = 2.03542 (* 1 = 2.03542 loss)
I0812 05:40:36.351641 26953 sgd_solver.cpp:106] Iteration 24630, lr = 0.01
I0812 05:40:54.709533 26953 solver.cpp:228] Iteration 24640, loss = 2.08853
I0812 05:40:54.709595 26953 solver.cpp:244]     Train net output #0: loss = 2.08853 (* 1 = 2.08853 loss)
I0812 05:40:56.115101 26953 sgd_solver.cpp:106] Iteration 24640, lr = 0.01
I0812 05:41:14.466307 26953 solver.cpp:228] Iteration 24650, loss = 2.10963
I0812 05:41:14.466564 26953 solver.cpp:244]     Train net output #0: loss = 2.10963 (* 1 = 2.10963 loss)
I0812 05:41:15.879441 26953 sgd_solver.cpp:106] Iteration 24650, lr = 0.01
I0812 05:41:34.360996 26953 solver.cpp:228] Iteration 24660, loss = 2.07508
I0812 05:41:34.361052 26953 solver.cpp:244]     Train net output #0: loss = 2.07508 (* 1 = 2.07508 loss)
I0812 05:41:35.791893 26953 sgd_solver.cpp:106] Iteration 24660, lr = 0.01
I0812 05:41:54.129060 26953 solver.cpp:228] Iteration 24670, loss = 2.15335
I0812 05:41:54.129252 26953 solver.cpp:244]     Train net output #0: loss = 2.15335 (* 1 = 2.15335 loss)
I0812 05:41:55.533257 26953 sgd_solver.cpp:106] Iteration 24670, lr = 0.01
I0812 05:42:13.938941 26953 solver.cpp:228] Iteration 24680, loss = 2.09642
I0812 05:42:13.939030 26953 solver.cpp:244]     Train net output #0: loss = 2.09642 (* 1 = 2.09642 loss)
I0812 05:42:15.324168 26953 sgd_solver.cpp:106] Iteration 24680, lr = 0.01
I0812 05:42:33.719959 26953 solver.cpp:228] Iteration 24690, loss = 2.14347
I0812 05:42:33.720177 26953 solver.cpp:244]     Train net output #0: loss = 2.14347 (* 1 = 2.14347 loss)
I0812 05:42:35.139591 26953 sgd_solver.cpp:106] Iteration 24690, lr = 0.01
I0812 05:42:52.893980 26953 solver.cpp:337] Iteration 24700, Testing net (#0)
I0812 05:42:53.487195 26953 solver.cpp:404]     Test net output #0: accuracy = 0.486
I0812 05:42:53.487292 26953 solver.cpp:404]     Test net output #1: loss = 2.33479 (* 1 = 2.33479 loss)
I0812 05:42:54.054137 26953 solver.cpp:228] Iteration 24700, loss = 2.04943
I0812 05:42:54.054227 26953 solver.cpp:244]     Train net output #0: loss = 2.04943 (* 1 = 2.04943 loss)
I0812 05:42:55.435525 26953 sgd_solver.cpp:106] Iteration 24700, lr = 0.01
I0812 05:43:13.837349 26953 solver.cpp:228] Iteration 24710, loss = 1.93866
I0812 05:43:13.837570 26953 solver.cpp:244]     Train net output #0: loss = 1.93866 (* 1 = 1.93866 loss)
I0812 05:43:15.222471 26953 sgd_solver.cpp:106] Iteration 24710, lr = 0.01
I0812 05:43:33.608686 26953 solver.cpp:228] Iteration 24720, loss = 1.9936
I0812 05:43:33.608765 26953 solver.cpp:244]     Train net output #0: loss = 1.9936 (* 1 = 1.9936 loss)
I0812 05:43:35.021991 26953 sgd_solver.cpp:106] Iteration 24720, lr = 0.01
I0812 05:43:53.382594 26953 solver.cpp:228] Iteration 24730, loss = 2.024
I0812 05:43:53.382786 26953 solver.cpp:244]     Train net output #0: loss = 2.024 (* 1 = 2.024 loss)
I0812 05:43:54.783788 26953 sgd_solver.cpp:106] Iteration 24730, lr = 0.01
I0812 05:44:13.185766 26953 solver.cpp:228] Iteration 24740, loss = 1.96796
I0812 05:44:13.185847 26953 solver.cpp:244]     Train net output #0: loss = 1.96796 (* 1 = 1.96796 loss)
I0812 05:44:14.578650 26953 sgd_solver.cpp:106] Iteration 24740, lr = 0.01
I0812 05:44:32.977999 26953 solver.cpp:228] Iteration 24750, loss = 2.19392
I0812 05:44:32.978243 26953 solver.cpp:244]     Train net output #0: loss = 2.19392 (* 1 = 2.19392 loss)
I0812 05:44:34.383510 26953 sgd_solver.cpp:106] Iteration 24750, lr = 0.01
I0812 05:44:52.751830 26953 solver.cpp:228] Iteration 24760, loss = 2.14189
I0812 05:44:52.751899 26953 solver.cpp:244]     Train net output #0: loss = 2.14189 (* 1 = 2.14189 loss)
I0812 05:44:54.155556 26953 sgd_solver.cpp:106] Iteration 24760, lr = 0.01
I0812 05:45:12.518169 26953 solver.cpp:228] Iteration 24770, loss = 1.8347
I0812 05:45:12.518378 26953 solver.cpp:244]     Train net output #0: loss = 1.8347 (* 1 = 1.8347 loss)
I0812 05:45:13.922718 26953 sgd_solver.cpp:106] Iteration 24770, lr = 0.01
I0812 05:45:32.329053 26953 solver.cpp:228] Iteration 24780, loss = 2.02793
I0812 05:45:32.329116 26953 solver.cpp:244]     Train net output #0: loss = 2.02793 (* 1 = 2.02793 loss)
I0812 05:45:33.727161 26953 sgd_solver.cpp:106] Iteration 24780, lr = 0.01
I0812 05:45:52.129220 26953 solver.cpp:228] Iteration 24790, loss = 2.07515
I0812 05:45:52.129454 26953 solver.cpp:244]     Train net output #0: loss = 2.07515 (* 1 = 2.07515 loss)
I0812 05:45:53.524392 26953 sgd_solver.cpp:106] Iteration 24790, lr = 0.01
I0812 05:46:11.307634 26953 solver.cpp:337] Iteration 24800, Testing net (#0)
I0812 05:46:11.903149 26953 solver.cpp:404]     Test net output #0: accuracy = 0.502
I0812 05:46:11.903218 26953 solver.cpp:404]     Test net output #1: loss = 2.20846 (* 1 = 2.20846 loss)
I0812 05:46:12.479598 26953 solver.cpp:228] Iteration 24800, loss = 2.16027
I0812 05:46:12.479686 26953 solver.cpp:244]     Train net output #0: loss = 2.16027 (* 1 = 2.16027 loss)
I0812 05:46:13.851969 26953 sgd_solver.cpp:106] Iteration 24800, lr = 0.01
I0812 05:46:32.269675 26953 solver.cpp:228] Iteration 24810, loss = 1.9688
I0812 05:46:32.269871 26953 solver.cpp:244]     Train net output #0: loss = 1.9688 (* 1 = 1.9688 loss)
I0812 05:46:33.683744 26953 sgd_solver.cpp:106] Iteration 24810, lr = 0.01
I0812 05:46:52.099632 26953 solver.cpp:228] Iteration 24820, loss = 1.97203
I0812 05:46:52.099701 26953 solver.cpp:244]     Train net output #0: loss = 1.97203 (* 1 = 1.97203 loss)
I0812 05:46:53.496449 26953 sgd_solver.cpp:106] Iteration 24820, lr = 0.01
I0812 05:47:11.898208 26953 solver.cpp:228] Iteration 24830, loss = 1.97852
I0812 05:47:11.898494 26953 solver.cpp:244]     Train net output #0: loss = 1.97852 (* 1 = 1.97852 loss)
I0812 05:47:13.299720 26953 sgd_solver.cpp:106] Iteration 24830, lr = 0.01
I0812 05:47:31.691356 26953 solver.cpp:228] Iteration 24840, loss = 2.05555
I0812 05:47:31.691422 26953 solver.cpp:244]     Train net output #0: loss = 2.05555 (* 1 = 2.05555 loss)
I0812 05:47:33.110332 26953 sgd_solver.cpp:106] Iteration 24840, lr = 0.01
I0812 05:47:51.514689 26953 solver.cpp:228] Iteration 24850, loss = 1.96072
I0812 05:47:51.514895 26953 solver.cpp:244]     Train net output #0: loss = 1.96072 (* 1 = 1.96072 loss)
I0812 05:47:52.918634 26953 sgd_solver.cpp:106] Iteration 24850, lr = 0.01
I0812 05:48:11.295059 26953 solver.cpp:228] Iteration 24860, loss = 1.97521
I0812 05:48:11.295125 26953 solver.cpp:244]     Train net output #0: loss = 1.97521 (* 1 = 1.97521 loss)
I0812 05:48:12.681536 26953 sgd_solver.cpp:106] Iteration 24860, lr = 0.01
I0812 05:48:31.032963 26953 solver.cpp:228] Iteration 24870, loss = 2.03827
I0812 05:48:31.033241 26953 solver.cpp:244]     Train net output #0: loss = 2.03827 (* 1 = 2.03827 loss)
I0812 05:48:32.426306 26953 sgd_solver.cpp:106] Iteration 24870, lr = 0.01
I0812 05:48:50.777075 26953 solver.cpp:228] Iteration 24880, loss = 2.07102
I0812 05:48:50.777142 26953 solver.cpp:244]     Train net output #0: loss = 2.07102 (* 1 = 2.07102 loss)
I0812 05:48:52.175386 26953 sgd_solver.cpp:106] Iteration 24880, lr = 0.01
I0812 05:49:10.580564 26953 solver.cpp:228] Iteration 24890, loss = 2.11982
I0812 05:49:10.580904 26953 solver.cpp:244]     Train net output #0: loss = 2.11982 (* 1 = 2.11982 loss)
I0812 05:49:11.972653 26953 sgd_solver.cpp:106] Iteration 24890, lr = 0.01
I0812 05:49:29.824997 26953 solver.cpp:337] Iteration 24900, Testing net (#0)
I0812 05:49:30.417095 26953 solver.cpp:404]     Test net output #0: accuracy = 0.5
I0812 05:49:30.417183 26953 solver.cpp:404]     Test net output #1: loss = 2.54642 (* 1 = 2.54642 loss)
I0812 05:49:31.005082 26953 solver.cpp:228] Iteration 24900, loss = 2.07541
I0812 05:49:31.005159 26953 solver.cpp:244]     Train net output #0: loss = 2.07541 (* 1 = 2.07541 loss)
I0812 05:49:32.378064 26953 sgd_solver.cpp:106] Iteration 24900, lr = 0.01
I0812 05:49:50.760860 26953 solver.cpp:228] Iteration 24910, loss = 2.1016
I0812 05:49:50.761106 26953 solver.cpp:244]     Train net output #0: loss = 2.1016 (* 1 = 2.1016 loss)
I0812 05:49:52.159391 26953 sgd_solver.cpp:106] Iteration 24910, lr = 0.01
I0812 05:50:10.563583 26953 solver.cpp:228] Iteration 24920, loss = 2.07783
I0812 05:50:10.563647 26953 solver.cpp:244]     Train net output #0: loss = 2.07783 (* 1 = 2.07783 loss)
I0812 05:50:11.979504 26953 sgd_solver.cpp:106] Iteration 24920, lr = 0.01
I0812 05:50:30.343087 26953 solver.cpp:228] Iteration 24930, loss = 2.12776
I0812 05:50:30.343278 26953 solver.cpp:244]     Train net output #0: loss = 2.12776 (* 1 = 2.12776 loss)
I0812 05:50:31.741026 26953 sgd_solver.cpp:106] Iteration 24930, lr = 0.01
I0812 05:50:50.126184 26953 solver.cpp:228] Iteration 24940, loss = 2.07727
I0812 05:50:50.126246 26953 solver.cpp:244]     Train net output #0: loss = 2.07727 (* 1 = 2.07727 loss)
I0812 05:50:51.523043 26953 sgd_solver.cpp:106] Iteration 24940, lr = 0.01
I0812 05:51:09.914185 26953 solver.cpp:228] Iteration 24950, loss = 2.10902
I0812 05:51:09.914427 26953 solver.cpp:244]     Train net output #0: loss = 2.10902 (* 1 = 2.10902 loss)
I0812 05:51:11.313053 26953 sgd_solver.cpp:106] Iteration 24950, lr = 0.01
I0812 05:51:29.646893 26953 solver.cpp:228] Iteration 24960, loss = 2.04118
I0812 05:51:29.646965 26953 solver.cpp:244]     Train net output #0: loss = 2.04118 (* 1 = 2.04118 loss)
I0812 05:51:31.056121 26953 sgd_solver.cpp:106] Iteration 24960, lr = 0.01
I0812 05:51:49.411057 26953 solver.cpp:228] Iteration 24970, loss = 2.23794
I0812 05:51:49.411223 26953 solver.cpp:244]     Train net output #0: loss = 2.23794 (* 1 = 2.23794 loss)
I0812 05:51:50.798533 26953 sgd_solver.cpp:106] Iteration 24970, lr = 0.01
I0812 05:52:09.178289 26953 solver.cpp:228] Iteration 24980, loss = 1.98798
I0812 05:52:09.178383 26953 solver.cpp:244]     Train net output #0: loss = 1.98798 (* 1 = 1.98798 loss)
I0812 05:52:10.569715 26953 sgd_solver.cpp:106] Iteration 24980, lr = 0.01
I0812 05:52:28.984436 26953 solver.cpp:228] Iteration 24990, loss = 1.96173
I0812 05:52:28.984575 26953 solver.cpp:244]     Train net output #0: loss = 1.96173 (* 1 = 1.96173 loss)
I0812 05:52:30.392123 26953 sgd_solver.cpp:106] Iteration 24990, lr = 0.01
I0812 05:52:48.165313 26953 solver.cpp:337] Iteration 25000, Testing net (#0)
I0812 05:52:48.751077 26953 solver.cpp:404]     Test net output #0: accuracy = 0.504
I0812 05:52:48.751147 26953 solver.cpp:404]     Test net output #1: loss = 2.10285 (* 1 = 2.10285 loss)
I0812 05:52:49.327066 26953 solver.cpp:228] Iteration 25000, loss = 2.04162
I0812 05:52:49.327165 26953 solver.cpp:244]     Train net output #0: loss = 2.04162 (* 1 = 2.04162 loss)
I0812 05:52:50.702339 26953 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I0812 05:53:09.075011 26953 solver.cpp:228] Iteration 25010, loss = 1.92803
I0812 05:53:09.075194 26953 solver.cpp:244]     Train net output #0: loss = 1.92803 (* 1 = 1.92803 loss)
I0812 05:53:10.478411 26953 sgd_solver.cpp:106] Iteration 25010, lr = 0.01
I0812 05:53:28.873644 26953 solver.cpp:228] Iteration 25020, loss = 2.16503
I0812 05:53:28.873713 26953 solver.cpp:244]     Train net output #0: loss = 2.16503 (* 1 = 2.16503 loss)
I0812 05:53:30.263175 26953 sgd_solver.cpp:106] Iteration 25020, lr = 0.01
I0812 05:53:48.656430 26953 solver.cpp:228] Iteration 25030, loss = 2.17637
I0812 05:53:48.656671 26953 solver.cpp:244]     Train net output #0: loss = 2.17637 (* 1 = 2.17637 loss)
I0812 05:53:50.081970 26953 sgd_solver.cpp:106] Iteration 25030, lr = 0.01
I0812 05:54:08.447782 26953 solver.cpp:228] Iteration 25040, loss = 2.00666
I0812 05:54:08.447851 26953 solver.cpp:244]     Train net output #0: loss = 2.00666 (* 1 = 2.00666 loss)
I0812 05:54:09.837388 26953 sgd_solver.cpp:106] Iteration 25040, lr = 0.01
I0812 05:54:28.272114 26953 solver.cpp:228] Iteration 25050, loss = 2.09433
I0812 05:54:28.272326 26953 solver.cpp:244]     Train net output #0: loss = 2.09433 (* 1 = 2.09433 loss)
I0812 05:54:29.667352 26953 sgd_solver.cpp:106] Iteration 25050, lr = 0.01
I0812 05:54:48.011821 26953 solver.cpp:228] Iteration 25060, loss = 2.06847
I0812 05:54:48.011900 26953 solver.cpp:244]     Train net output #0: loss = 2.06847 (* 1 = 2.06847 loss)
I0812 05:54:49.434274 26953 sgd_solver.cpp:106] Iteration 25060, lr = 0.01
I0812 05:55:07.787487 26953 solver.cpp:228] Iteration 25070, loss = 2.02557
I0812 05:55:07.787649 26953 solver.cpp:244]     Train net output #0: loss = 2.02557 (* 1 = 2.02557 loss)
I0812 05:55:09.194602 26953 sgd_solver.cpp:106] Iteration 25070, lr = 0.01
I0812 05:55:27.597448 26953 solver.cpp:228] Iteration 25080, loss = 1.99618
I0812 05:55:27.597537 26953 solver.cpp:244]     Train net output #0: loss = 1.99618 (* 1 = 1.99618 loss)
I0812 05:55:28.998528 26953 sgd_solver.cpp:106] Iteration 25080, lr = 0.01
I0812 05:55:47.381970 26953 solver.cpp:228] Iteration 25090, loss = 2.01776
I0812 05:55:47.382184 26953 solver.cpp:244]     Train net output #0: loss = 2.01776 (* 1 = 2.01776 loss)
I0812 05:55:48.789449 26953 sgd_solver.cpp:106] Iteration 25090, lr = 0.01
I0812 05:56:06.585546 26953 solver.cpp:337] Iteration 25100, Testing net (#0)
I0812 05:56:07.182474 26953 solver.cpp:404]     Test net output #0: accuracy = 0.538
I0812 05:56:07.182574 26953 solver.cpp:404]     Test net output #1: loss = 2.11315 (* 1 = 2.11315 loss)
I0812 05:56:07.760968 26953 solver.cpp:228] Iteration 25100, loss = 2.04413
I0812 05:56:07.761075 26953 solver.cpp:244]     Train net output #0: loss = 2.04413 (* 1 = 2.04413 loss)
I0812 05:56:09.122378 26953 sgd_solver.cpp:106] Iteration 25100, lr = 0.01
I0812 05:56:27.529026 26953 solver.cpp:228] Iteration 25110, loss = 1.95136
I0812 05:56:27.529309 26953 solver.cpp:244]     Train net output #0: loss = 1.95136 (* 1 = 1.95136 loss)
I0812 05:56:28.924065 26953 sgd_solver.cpp:106] Iteration 25110, lr = 0.01
I0812 05:56:47.270732 26953 solver.cpp:228] Iteration 25120, loss = 2.01795
I0812 05:56:47.270869 26953 solver.cpp:244]     Train net output #0: loss = 2.01795 (* 1 = 2.01795 loss)
I0812 05:56:48.687546 26953 sgd_solver.cpp:106] Iteration 25120, lr = 0.01
I0812 05:57:07.031951 26953 solver.cpp:228] Iteration 25130, loss = 2.14504
I0812 05:57:07.032173 26953 solver.cpp:244]     Train net output #0: loss = 2.14504 (* 1 = 2.14504 loss)
I0812 05:57:08.445444 26953 sgd_solver.cpp:106] Iteration 25130, lr = 0.01
I0812 05:57:26.833940 26953 solver.cpp:228] Iteration 25140, loss = 2.00468
I0812 05:57:26.834027 26953 solver.cpp:244]     Train net output #0: loss = 2.00468 (* 1 = 2.00468 loss)
I0812 05:57:28.237011 26953 sgd_solver.cpp:106] Iteration 25140, lr = 0.01
I0812 05:57:46.683957 26953 solver.cpp:228] Iteration 25150, loss = 2.01457
I0812 05:57:46.684226 26953 solver.cpp:244]     Train net output #0: loss = 2.01457 (* 1 = 2.01457 loss)
I0812 05:57:48.087968 26953 sgd_solver.cpp:106] Iteration 25150, lr = 0.01
I0812 05:58:06.431493 26953 solver.cpp:228] Iteration 25160, loss = 2.00866
I0812 05:58:06.431565 26953 solver.cpp:244]     Train net output #0: loss = 2.00866 (* 1 = 2.00866 loss)
I0812 05:58:07.829505 26953 sgd_solver.cpp:106] Iteration 25160, lr = 0.01
I0812 05:58:26.201884 26953 solver.cpp:228] Iteration 25170, loss = 2.11123
I0812 05:58:26.202188 26953 solver.cpp:244]     Train net output #0: loss = 2.11123 (* 1 = 2.11123 loss)
I0812 05:58:27.601949 26953 sgd_solver.cpp:106] Iteration 25170, lr = 0.01
I0812 05:58:46.037065 26953 solver.cpp:228] Iteration 25180, loss = 2.07105
I0812 05:58:46.037143 26953 solver.cpp:244]     Train net output #0: loss = 2.07105 (* 1 = 2.07105 loss)
I0812 05:58:47.456259 26953 sgd_solver.cpp:106] Iteration 25180, lr = 0.01
I0812 05:59:05.800460 26953 solver.cpp:228] Iteration 25190, loss = 1.95788
I0812 05:59:05.800690 26953 solver.cpp:244]     Train net output #0: loss = 1.95788 (* 1 = 1.95788 loss)
I0812 05:59:07.208914 26953 sgd_solver.cpp:106] Iteration 25190, lr = 0.01
I0812 05:59:25.042405 26953 solver.cpp:337] Iteration 25200, Testing net (#0)
I0812 05:59:25.637182 26953 solver.cpp:404]     Test net output #0: accuracy = 0.502
I0812 05:59:25.637284 26953 solver.cpp:404]     Test net output #1: loss = 2.24247 (* 1 = 2.24247 loss)
I0812 05:59:26.202632 26953 solver.cpp:228] Iteration 25200, loss = 2.00735
I0812 05:59:26.202731 26953 solver.cpp:244]     Train net output #0: loss = 2.00735 (* 1 = 2.00735 loss)
I0812 05:59:27.603013 26953 sgd_solver.cpp:106] Iteration 25200, lr = 0.01
I0812 05:59:45.972692 26953 solver.cpp:228] Iteration 25210, loss = 2.02401
I0812 05:59:45.972908 26953 solver.cpp:244]     Train net output #0: loss = 2.02401 (* 1 = 2.02401 loss)
I0812 05:59:47.375102 26953 sgd_solver.cpp:106] Iteration 25210, lr = 0.01
I0812 06:00:05.745070 26953 solver.cpp:228] Iteration 25220, loss = 1.99316
I0812 06:00:05.745164 26953 solver.cpp:244]     Train net output #0: loss = 1.99316 (* 1 = 1.99316 loss)
I0812 06:00:07.141827 26953 sgd_solver.cpp:106] Iteration 25220, lr = 0.01
I0812 06:00:25.555644 26953 solver.cpp:228] Iteration 25230, loss = 2.03061
I0812 06:00:25.555807 26953 solver.cpp:244]     Train net output #0: loss = 2.03061 (* 1 = 2.03061 loss)
I0812 06:00:26.963796 26953 sgd_solver.cpp:106] Iteration 25230, lr = 0.01
I0812 06:00:45.317349 26953 solver.cpp:228] Iteration 25240, loss = 1.94914
I0812 06:00:45.317435 26953 solver.cpp:244]     Train net output #0: loss = 1.94914 (* 1 = 1.94914 loss)
I0812 06:00:46.716333 26953 sgd_solver.cpp:106] Iteration 25240, lr = 0.01
I0812 06:01:05.103178 26953 solver.cpp:228] Iteration 25250, loss = 2.19771
I0812 06:01:05.103413 26953 solver.cpp:244]     Train net output #0: loss = 2.19771 (* 1 = 2.19771 loss)
I0812 06:01:06.513351 26953 sgd_solver.cpp:106] Iteration 25250, lr = 0.01
I0812 06:01:24.893316 26953 solver.cpp:228] Iteration 25260, loss = 1.8884
I0812 06:01:24.893379 26953 solver.cpp:244]     Train net output #0: loss = 1.8884 (* 1 = 1.8884 loss)
I0812 06:01:26.291129 26953 sgd_solver.cpp:106] Iteration 25260, lr = 0.01
I0812 06:01:44.702435 26953 solver.cpp:228] Iteration 25270, loss = 2.03751
I0812 06:01:44.702591 26953 solver.cpp:244]     Train net output #0: loss = 2.03751 (* 1 = 2.03751 loss)
I0812 06:01:46.106497 26953 sgd_solver.cpp:106] Iteration 25270, lr = 0.01
I0812 06:02:04.467370 26953 solver.cpp:228] Iteration 25280, loss = 2.13688
I0812 06:02:04.467439 26953 solver.cpp:244]     Train net output #0: loss = 2.13688 (* 1 = 2.13688 loss)
I0812 06:02:05.861977 26953 sgd_solver.cpp:106] Iteration 25280, lr = 0.01
I0812 06:02:24.259127 26953 solver.cpp:228] Iteration 25290, loss = 2.08853
I0812 06:02:24.259318 26953 solver.cpp:244]     Train net output #0: loss = 2.08853 (* 1 = 2.08853 loss)
I0812 06:02:25.668390 26953 sgd_solver.cpp:106] Iteration 25290, lr = 0.01
I0812 06:02:43.493921 26953 solver.cpp:337] Iteration 25300, Testing net (#0)
I0812 06:02:44.090735 26953 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0812 06:02:44.090801 26953 solver.cpp:404]     Test net output #1: loss = 2.20812 (* 1 = 2.20812 loss)
I0812 06:02:44.657269 26953 solver.cpp:228] Iteration 25300, loss = 2.06734
I0812 06:02:44.657347 26953 solver.cpp:244]     Train net output #0: loss = 2.06734 (* 1 = 2.06734 loss)
I0812 06:02:46.039608 26953 sgd_solver.cpp:106] Iteration 25300, lr = 0.01
I0812 06:03:04.459734 26953 solver.cpp:228] Iteration 25310, loss = 1.85018
I0812 06:03:04.460036 26953 solver.cpp:244]     Train net output #0: loss = 1.85018 (* 1 = 1.85018 loss)
I0812 06:03:05.844202 26953 sgd_solver.cpp:106] Iteration 25310, lr = 0.01
I0812 06:03:24.237346 26953 solver.cpp:228] Iteration 25320, loss = 1.95521
I0812 06:03:24.237419 26953 solver.cpp:244]     Train net output #0: loss = 1.95521 (* 1 = 1.95521 loss)
I0812 06:03:25.641718 26953 sgd_solver.cpp:106] Iteration 25320, lr = 0.01
I0812 06:03:43.996639 26953 solver.cpp:228] Iteration 25330, loss = 2.1305
I0812 06:03:43.996912 26953 solver.cpp:244]     Train net output #0: loss = 2.1305 (* 1 = 2.1305 loss)
I0812 06:03:45.395243 26953 sgd_solver.cpp:106] Iteration 25330, lr = 0.01
I0812 06:04:03.736941 26953 solver.cpp:228] Iteration 25340, loss = 2.19372
I0812 06:04:03.737030 26953 solver.cpp:244]     Train net output #0: loss = 2.19372 (* 1 = 2.19372 loss)
I0812 06:04:05.136200 26953 sgd_solver.cpp:106] Iteration 25340, lr = 0.01
I0812 06:04:23.561277 26953 solver.cpp:228] Iteration 25350, loss = 1.98258
I0812 06:04:23.561471 26953 solver.cpp:244]     Train net output #0: loss = 1.98258 (* 1 = 1.98258 loss)
I0812 06:04:24.964527 26953 sgd_solver.cpp:106] Iteration 25350, lr = 0.01
I0812 06:04:43.357033 26953 solver.cpp:228] Iteration 25360, loss = 2.00136
I0812 06:04:43.357108 26953 solver.cpp:244]     Train net output #0: loss = 2.00136 (* 1 = 2.00136 loss)
I0812 06:04:44.755846 26953 sgd_solver.cpp:106] Iteration 25360, lr = 0.01
I0812 06:05:03.112747 26953 solver.cpp:228] Iteration 25370, loss = 1.9842
I0812 06:05:03.113003 26953 solver.cpp:244]     Train net output #0: loss = 1.9842 (* 1 = 1.9842 loss)
I0812 06:05:04.517354 26953 sgd_solver.cpp:106] Iteration 25370, lr = 0.01
I0812 06:05:22.894327 26953 solver.cpp:228] Iteration 25380, loss = 1.79812
I0812 06:05:22.894397 26953 solver.cpp:244]     Train net output #0: loss = 1.79812 (* 1 = 1.79812 loss)
I0812 06:05:24.298199 26953 sgd_solver.cpp:106] Iteration 25380, lr = 0.01
I0812 06:05:42.689805 26953 solver.cpp:228] Iteration 25390, loss = 1.92643
I0812 06:05:42.690034 26953 solver.cpp:244]     Train net output #0: loss = 1.92643 (* 1 = 1.92643 loss)
I0812 06:05:44.088172 26953 sgd_solver.cpp:106] Iteration 25390, lr = 0.01
I0812 06:06:01.887259 26953 solver.cpp:337] Iteration 25400, Testing net (#0)
I0812 06:06:02.478340 26953 solver.cpp:404]     Test net output #0: accuracy = 0.468
I0812 06:06:02.478412 26953 solver.cpp:404]     Test net output #1: loss = 2.46011 (* 1 = 2.46011 loss)
I0812 06:06:03.045203 26953 solver.cpp:228] Iteration 25400, loss = 1.8988
I0812 06:06:03.045305 26953 solver.cpp:244]     Train net output #0: loss = 1.8988 (* 1 = 1.8988 loss)
I0812 06:06:04.421941 26953 sgd_solver.cpp:106] Iteration 25400, lr = 0.01
I0812 06:06:22.860570 26953 solver.cpp:228] Iteration 25410, loss = 2.02403
I0812 06:06:22.860790 26953 solver.cpp:244]     Train net output #0: loss = 2.02403 (* 1 = 2.02403 loss)
I0812 06:06:24.270956 26953 sgd_solver.cpp:106] Iteration 25410, lr = 0.01
I0812 06:06:42.616890 26953 solver.cpp:228] Iteration 25420, loss = 1.95565
I0812 06:06:42.616963 26953 solver.cpp:244]     Train net output #0: loss = 1.95565 (* 1 = 1.95565 loss)
I0812 06:06:44.016976 26953 sgd_solver.cpp:106] Iteration 25420, lr = 0.01
I0812 06:07:02.377451 26953 solver.cpp:228] Iteration 25430, loss = 1.86634
I0812 06:07:02.377611 26953 solver.cpp:244]     Train net output #0: loss = 1.86634 (* 1 = 1.86634 loss)
I0812 06:07:03.785261 26953 sgd_solver.cpp:106] Iteration 25430, lr = 0.01
I0812 06:07:22.182368 26953 solver.cpp:228] Iteration 25440, loss = 1.92982
I0812 06:07:22.182456 26953 solver.cpp:244]     Train net output #0: loss = 1.92982 (* 1 = 1.92982 loss)
I0812 06:07:23.578361 26953 sgd_solver.cpp:106] Iteration 25440, lr = 0.01
I0812 06:07:41.996280 26953 solver.cpp:228] Iteration 25450, loss = 1.89051
I0812 06:07:41.996543 26953 solver.cpp:244]     Train net output #0: loss = 1.89051 (* 1 = 1.89051 loss)
I0812 06:07:43.396914 26953 sgd_solver.cpp:106] Iteration 25450, lr = 0.01
I0812 06:08:01.798414 26953 solver.cpp:228] Iteration 25460, loss = 2.04256
I0812 06:08:01.798478 26953 solver.cpp:244]     Train net output #0: loss = 2.04256 (* 1 = 2.04256 loss)
I0812 06:08:03.180070 26953 sgd_solver.cpp:106] Iteration 25460, lr = 0.01
I0812 06:08:21.596568 26953 solver.cpp:228] Iteration 25470, loss = 2.00639
I0812 06:08:21.596822 26953 solver.cpp:244]     Train net output #0: loss = 2.00639 (* 1 = 2.00639 loss)
I0812 06:08:22.997303 26953 sgd_solver.cpp:106] Iteration 25470, lr = 0.01
I0812 06:08:41.392917 26953 solver.cpp:228] Iteration 25480, loss = 1.96156
I0812 06:08:41.393007 26953 solver.cpp:244]     Train net output #0: loss = 1.96156 (* 1 = 1.96156 loss)
I0812 06:08:42.800979 26953 sgd_solver.cpp:106] Iteration 25480, lr = 0.01
I0812 06:09:01.175535 26953 solver.cpp:228] Iteration 25490, loss = 2.16646
I0812 06:09:01.175689 26953 solver.cpp:244]     Train net output #0: loss = 2.16646 (* 1 = 2.16646 loss)
I0812 06:09:02.577322 26953 sgd_solver.cpp:106] Iteration 25490, lr = 0.01
I0812 06:09:20.433135 26953 solver.cpp:337] Iteration 25500, Testing net (#0)
I0812 06:09:21.031482 26953 solver.cpp:404]     Test net output #0: accuracy = 0.538
I0812 06:09:21.031548 26953 solver.cpp:404]     Test net output #1: loss = 2.1337 (* 1 = 2.1337 loss)
I0812 06:09:21.625612 26953 solver.cpp:228] Iteration 25500, loss = 2.0973
I0812 06:09:21.625684 26953 solver.cpp:244]     Train net output #0: loss = 2.0973 (* 1 = 2.0973 loss)
I0812 06:09:22.994829 26953 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I0812 06:09:41.389845 26953 solver.cpp:228] Iteration 25510, loss = 2.16312
I0812 06:09:41.390085 26953 solver.cpp:244]     Train net output #0: loss = 2.16312 (* 1 = 2.16312 loss)
I0812 06:09:42.779455 26953 sgd_solver.cpp:106] Iteration 25510, lr = 0.01
I0812 06:10:01.214468 26953 solver.cpp:228] Iteration 25520, loss = 1.73114
I0812 06:10:01.214543 26953 solver.cpp:244]     Train net output #0: loss = 1.73114 (* 1 = 1.73114 loss)
I0812 06:10:02.618717 26953 sgd_solver.cpp:106] Iteration 25520, lr = 0.01
I0812 06:10:21.043758 26953 solver.cpp:228] Iteration 25530, loss = 1.87656
I0812 06:10:21.044000 26953 solver.cpp:244]     Train net output #0: loss = 1.87656 (* 1 = 1.87656 loss)
I0812 06:10:22.443533 26953 sgd_solver.cpp:106] Iteration 25530, lr = 0.01
I0812 06:10:40.854579 26953 solver.cpp:228] Iteration 25540, loss = 2.02842
I0812 06:10:40.854647 26953 solver.cpp:244]     Train net output #0: loss = 2.02842 (* 1 = 2.02842 loss)
I0812 06:10:42.257150 26953 sgd_solver.cpp:106] Iteration 25540, lr = 0.01
I0812 06:11:00.651365 26953 solver.cpp:228] Iteration 25550, loss = 2.01339
I0812 06:11:00.651513 26953 solver.cpp:244]     Train net output #0: loss = 2.01339 (* 1 = 2.01339 loss)
I0812 06:11:02.052532 26953 sgd_solver.cpp:106] Iteration 25550, lr = 0.01
I0812 06:11:20.469233 26953 solver.cpp:228] Iteration 25560, loss = 2.12444
I0812 06:11:20.469303 26953 solver.cpp:244]     Train net output #0: loss = 2.12444 (* 1 = 2.12444 loss)
I0812 06:11:21.870182 26953 sgd_solver.cpp:106] Iteration 25560, lr = 0.01
I0812 06:11:40.282187 26953 solver.cpp:228] Iteration 25570, loss = 2.0245
I0812 06:11:40.282327 26953 solver.cpp:244]     Train net output #0: loss = 2.0245 (* 1 = 2.0245 loss)
I0812 06:11:41.682247 26953 sgd_solver.cpp:106] Iteration 25570, lr = 0.01
I0812 06:12:00.068397 26953 solver.cpp:228] Iteration 25580, loss = 2.05929
I0812 06:12:00.068457 26953 solver.cpp:244]     Train net output #0: loss = 2.05929 (* 1 = 2.05929 loss)
I0812 06:12:01.462002 26953 sgd_solver.cpp:106] Iteration 25580, lr = 0.01
I0812 06:12:19.905282 26953 solver.cpp:228] Iteration 25590, loss = 1.90661
I0812 06:12:19.905504 26953 solver.cpp:244]     Train net output #0: loss = 1.90661 (* 1 = 1.90661 loss)
I0812 06:12:21.318377 26953 sgd_solver.cpp:106] Iteration 25590, lr = 0.01
I0812 06:12:39.079215 26953 solver.cpp:337] Iteration 25600, Testing net (#0)
I0812 06:12:39.670970 26953 solver.cpp:404]     Test net output #0: accuracy = 0.488
I0812 06:12:39.671051 26953 solver.cpp:404]     Test net output #1: loss = 2.2082 (* 1 = 2.2082 loss)
I0812 06:12:40.240427 26953 solver.cpp:228] Iteration 25600, loss = 2.00839
I0812 06:12:40.240499 26953 solver.cpp:244]     Train net output #0: loss = 2.00839 (* 1 = 2.00839 loss)
I0812 06:12:41.622160 26953 sgd_solver.cpp:106] Iteration 25600, lr = 0.01
I0812 06:13:00.027122 26953 solver.cpp:228] Iteration 25610, loss = 1.90436
I0812 06:13:00.027379 26953 solver.cpp:244]     Train net output #0: loss = 1.90436 (* 1 = 1.90436 loss)
I0812 06:13:01.425526 26953 sgd_solver.cpp:106] Iteration 25610, lr = 0.01
I0812 06:13:19.825695 26953 solver.cpp:228] Iteration 25620, loss = 2.09805
I0812 06:13:19.825780 26953 solver.cpp:244]     Train net output #0: loss = 2.09805 (* 1 = 2.09805 loss)
I0812 06:13:21.224498 26953 sgd_solver.cpp:106] Iteration 25620, lr = 0.01
I0812 06:13:39.586729 26953 solver.cpp:228] Iteration 25630, loss = 2.13844
I0812 06:13:39.586925 26953 solver.cpp:244]     Train net output #0: loss = 2.13844 (* 1 = 2.13844 loss)
I0812 06:13:40.976069 26953 sgd_solver.cpp:106] Iteration 25630, lr = 0.01
I0812 06:13:59.354245 26953 solver.cpp:228] Iteration 25640, loss = 2.17811
I0812 06:13:59.354326 26953 solver.cpp:244]     Train net output #0: loss = 2.17811 (* 1 = 2.17811 loss)
I0812 06:14:00.744011 26953 sgd_solver.cpp:106] Iteration 25640, lr = 0.01
I0812 06:14:19.155171 26953 solver.cpp:228] Iteration 25650, loss = 1.96061
I0812 06:14:19.155380 26953 solver.cpp:244]     Train net output #0: loss = 1.96061 (* 1 = 1.96061 loss)
I0812 06:14:20.559734 26953 sgd_solver.cpp:106] Iteration 25650, lr = 0.01
I0812 06:14:38.946982 26953 solver.cpp:228] Iteration 25660, loss = 2.11664
I0812 06:14:38.947054 26953 solver.cpp:244]     Train net output #0: loss = 2.11664 (* 1 = 2.11664 loss)
I0812 06:14:40.367228 26953 sgd_solver.cpp:106] Iteration 25660, lr = 0.01
I0812 06:14:58.822145 26953 solver.cpp:228] Iteration 25670, loss = 2.14217
I0812 06:14:58.822307 26953 solver.cpp:244]     Train net output #0: loss = 2.14217 (* 1 = 2.14217 loss)
I0812 06:15:00.217545 26953 sgd_solver.cpp:106] Iteration 25670, lr = 0.01
I0812 06:15:18.579804 26953 solver.cpp:228] Iteration 25680, loss = 1.95127
I0812 06:15:18.579888 26953 solver.cpp:244]     Train net output #0: loss = 1.95127 (* 1 = 1.95127 loss)
I0812 06:15:20.009217 26953 sgd_solver.cpp:106] Iteration 25680, lr = 0.01
I0812 06:15:38.385541 26953 solver.cpp:228] Iteration 25690, loss = 2.09133
I0812 06:15:38.385808 26953 solver.cpp:244]     Train net output #0: loss = 2.09133 (* 1 = 2.09133 loss)
I0812 06:15:39.769762 26953 sgd_solver.cpp:106] Iteration 25690, lr = 0.01
I0812 06:15:57.628474 26953 solver.cpp:337] Iteration 25700, Testing net (#0)
I0812 06:15:58.223376 26953 solver.cpp:404]     Test net output #0: accuracy = 0.504
I0812 06:15:58.223428 26953 solver.cpp:404]     Test net output #1: loss = 2.1612 (* 1 = 2.1612 loss)
I0812 06:15:58.797564 26953 solver.cpp:228] Iteration 25700, loss = 1.96104
I0812 06:15:58.797653 26953 solver.cpp:244]     Train net output #0: loss = 1.96104 (* 1 = 1.96104 loss)
I0812 06:16:00.172291 26953 sgd_solver.cpp:106] Iteration 25700, lr = 0.01
I0812 06:16:18.527838 26953 solver.cpp:228] Iteration 25710, loss = 1.85991
I0812 06:16:18.528093 26953 solver.cpp:244]     Train net output #0: loss = 1.85991 (* 1 = 1.85991 loss)
I0812 06:16:19.935237 26953 sgd_solver.cpp:106] Iteration 25710, lr = 0.01
I0812 06:16:38.338860 26953 solver.cpp:228] Iteration 25720, loss = 2.03672
I0812 06:16:38.338933 26953 solver.cpp:244]     Train net output #0: loss = 2.03672 (* 1 = 2.03672 loss)
I0812 06:16:39.743674 26953 sgd_solver.cpp:106] Iteration 25720, lr = 0.01
I0812 06:16:58.142326 26953 solver.cpp:228] Iteration 25730, loss = 2.20544
I0812 06:16:58.142536 26953 solver.cpp:244]     Train net output #0: loss = 2.20544 (* 1 = 2.20544 loss)
I0812 06:16:59.543323 26953 sgd_solver.cpp:106] Iteration 25730, lr = 0.01
I0812 06:17:17.963042 26953 solver.cpp:228] Iteration 25740, loss = 1.86883
I0812 06:17:17.963112 26953 solver.cpp:244]     Train net output #0: loss = 1.86883 (* 1 = 1.86883 loss)
I0812 06:17:19.354763 26953 sgd_solver.cpp:106] Iteration 25740, lr = 0.01
I0812 06:17:37.780057 26953 solver.cpp:228] Iteration 25750, loss = 1.90798
I0812 06:17:37.780292 26953 solver.cpp:244]     Train net output #0: loss = 1.90798 (* 1 = 1.90798 loss)
I0812 06:17:39.180117 26953 sgd_solver.cpp:106] Iteration 25750, lr = 0.01
I0812 06:17:57.535840 26953 solver.cpp:228] Iteration 25760, loss = 1.98173
I0812 06:17:57.535924 26953 solver.cpp:244]     Train net output #0: loss = 1.98173 (* 1 = 1.98173 loss)
I0812 06:17:58.955811 26953 sgd_solver.cpp:106] Iteration 25760, lr = 0.01
I0812 06:18:17.422688 26953 solver.cpp:228] Iteration 25770, loss = 2.05029
I0812 06:18:17.422888 26953 solver.cpp:244]     Train net output #0: loss = 2.05029 (* 1 = 2.05029 loss)
I0812 06:18:18.828908 26953 sgd_solver.cpp:106] Iteration 25770, lr = 0.01
I0812 06:18:37.182605 26953 solver.cpp:228] Iteration 25780, loss = 2.21653
I0812 06:18:37.182670 26953 solver.cpp:244]     Train net output #0: loss = 2.21653 (* 1 = 2.21653 loss)
I0812 06:18:38.589409 26953 sgd_solver.cpp:106] Iteration 25780, lr = 0.01
I0812 06:18:56.971750 26953 solver.cpp:228] Iteration 25790, loss = 2.09159
I0812 06:18:56.971997 26953 solver.cpp:244]     Train net output #0: loss = 2.09159 (* 1 = 2.09159 loss)
I0812 06:18:58.374743 26953 sgd_solver.cpp:106] Iteration 25790, lr = 0.01
I0812 06:19:16.241492 26953 solver.cpp:337] Iteration 25800, Testing net (#0)
I0812 06:19:16.835788 26953 solver.cpp:404]     Test net output #0: accuracy = 0.504
I0812 06:19:16.835883 26953 solver.cpp:404]     Test net output #1: loss = 2.21309 (* 1 = 2.21309 loss)
I0812 06:19:17.401769 26953 solver.cpp:228] Iteration 25800, loss = 1.7225
I0812 06:19:17.401890 26953 solver.cpp:244]     Train net output #0: loss = 1.7225 (* 1 = 1.7225 loss)
I0812 06:19:18.781101 26953 sgd_solver.cpp:106] Iteration 25800, lr = 0.01
I0812 06:19:37.148907 26953 solver.cpp:228] Iteration 25810, loss = 2.01315
I0812 06:19:37.149142 26953 solver.cpp:244]     Train net output #0: loss = 2.01315 (* 1 = 2.01315 loss)
I0812 06:19:38.531455 26953 sgd_solver.cpp:106] Iteration 25810, lr = 0.01
I0812 06:19:56.989037 26953 solver.cpp:228] Iteration 25820, loss = 2.26177
I0812 06:19:56.989117 26953 solver.cpp:244]     Train net output #0: loss = 2.26177 (* 1 = 2.26177 loss)
I0812 06:19:58.388213 26953 sgd_solver.cpp:106] Iteration 25820, lr = 0.01
I0812 06:20:16.744403 26953 solver.cpp:228] Iteration 25830, loss = 2.11627
I0812 06:20:16.744621 26953 solver.cpp:244]     Train net output #0: loss = 2.11627 (* 1 = 2.11627 loss)
I0812 06:20:18.159448 26953 sgd_solver.cpp:106] Iteration 25830, lr = 0.01
I0812 06:20:36.545624 26953 solver.cpp:228] Iteration 25840, loss = 2.14503
I0812 06:20:36.545738 26953 solver.cpp:244]     Train net output #0: loss = 2.14503 (* 1 = 2.14503 loss)
I0812 06:20:37.942688 26953 sgd_solver.cpp:106] Iteration 25840, lr = 0.01
I0812 06:20:56.335065 26953 solver.cpp:228] Iteration 25850, loss = 1.94971
I0812 06:20:56.335280 26953 solver.cpp:244]     Train net output #0: loss = 1.94971 (* 1 = 1.94971 loss)
I0812 06:20:57.725555 26953 sgd_solver.cpp:106] Iteration 25850, lr = 0.01
I0812 06:21:16.096149 26953 solver.cpp:228] Iteration 25860, loss = 1.87753
I0812 06:21:16.096225 26953 solver.cpp:244]     Train net output #0: loss = 1.87753 (* 1 = 1.87753 loss)
I0812 06:21:17.506309 26953 sgd_solver.cpp:106] Iteration 25860, lr = 0.01
I0812 06:21:35.860029 26953 solver.cpp:228] Iteration 25870, loss = 1.90757
I0812 06:21:35.860231 26953 solver.cpp:244]     Train net output #0: loss = 1.90757 (* 1 = 1.90757 loss)
I0812 06:21:37.260713 26953 sgd_solver.cpp:106] Iteration 25870, lr = 0.01
I0812 06:21:55.664834 26953 solver.cpp:228] Iteration 25880, loss = 2.06594
I0812 06:21:55.664912 26953 solver.cpp:244]     Train net output #0: loss = 2.06594 (* 1 = 2.06594 loss)
I0812 06:21:57.056809 26953 sgd_solver.cpp:106] Iteration 25880, lr = 0.01
I0812 06:22:15.469125 26953 solver.cpp:228] Iteration 25890, loss = 2.09939
I0812 06:22:15.469393 26953 solver.cpp:244]     Train net output #0: loss = 2.09939 (* 1 = 2.09939 loss)
I0812 06:22:16.865734 26953 sgd_solver.cpp:106] Iteration 25890, lr = 0.01
I0812 06:22:34.644122 26953 solver.cpp:337] Iteration 25900, Testing net (#0)
I0812 06:22:35.238950 26953 solver.cpp:404]     Test net output #0: accuracy = 0.548
I0812 06:22:35.239007 26953 solver.cpp:404]     Test net output #1: loss = 2.0701 (* 1 = 2.0701 loss)
I0812 06:22:35.813030 26953 solver.cpp:228] Iteration 25900, loss = 2.0508
I0812 06:22:35.813143 26953 solver.cpp:244]     Train net output #0: loss = 2.0508 (* 1 = 2.0508 loss)
I0812 06:22:37.184044 26953 sgd_solver.cpp:106] Iteration 25900, lr = 0.01
I0812 06:22:55.569757 26953 solver.cpp:228] Iteration 25910, loss = 2.0982
I0812 06:22:55.569967 26953 solver.cpp:244]     Train net output #0: loss = 2.0982 (* 1 = 2.0982 loss)
I0812 06:22:56.974460 26953 sgd_solver.cpp:106] Iteration 25910, lr = 0.01
I0812 06:23:15.407222 26953 solver.cpp:228] Iteration 25920, loss = 2.10944
I0812 06:23:15.407291 26953 solver.cpp:244]     Train net output #0: loss = 2.10944 (* 1 = 2.10944 loss)
I0812 06:23:16.813431 26953 sgd_solver.cpp:106] Iteration 25920, lr = 0.01
I0812 06:23:35.176694 26953 solver.cpp:228] Iteration 25930, loss = 2.07451
I0812 06:23:35.176928 26953 solver.cpp:244]     Train net output #0: loss = 2.07451 (* 1 = 2.07451 loss)
I0812 06:23:36.577503 26953 sgd_solver.cpp:106] Iteration 25930, lr = 0.01
I0812 06:23:54.978936 26953 solver.cpp:228] Iteration 25940, loss = 2.13555
I0812 06:23:54.979012 26953 solver.cpp:244]     Train net output #0: loss = 2.13555 (* 1 = 2.13555 loss)
I0812 06:23:56.370611 26953 sgd_solver.cpp:106] Iteration 25940, lr = 0.01
I0812 06:24:14.749804 26953 solver.cpp:228] Iteration 25950, loss = 2.13293
I0812 06:24:14.750053 26953 solver.cpp:244]     Train net output #0: loss = 2.13293 (* 1 = 2.13293 loss)
I0812 06:24:16.164386 26953 sgd_solver.cpp:106] Iteration 25950, lr = 0.01
I0812 06:24:34.553992 26953 solver.cpp:228] Iteration 25960, loss = 1.93446
I0812 06:24:34.554078 26953 solver.cpp:244]     Train net output #0: loss = 1.93446 (* 1 = 1.93446 loss)
I0812 06:24:35.926161 26953 sgd_solver.cpp:106] Iteration 25960, lr = 0.01
I0812 06:24:54.318205 26953 solver.cpp:228] Iteration 25970, loss = 2.07277
I0812 06:24:54.318433 26953 solver.cpp:244]     Train net output #0: loss = 2.07277 (* 1 = 2.07277 loss)
I0812 06:24:55.711454 26953 sgd_solver.cpp:106] Iteration 25970, lr = 0.01
I0812 06:25:14.108568 26953 solver.cpp:228] Iteration 25980, loss = 2.14409
I0812 06:25:14.108625 26953 solver.cpp:244]     Train net output #0: loss = 2.14409 (* 1 = 2.14409 loss)
I0812 06:25:15.507871 26953 sgd_solver.cpp:106] Iteration 25980, lr = 0.01
I0812 06:25:33.871116 26953 solver.cpp:228] Iteration 25990, loss = 2.0881
I0812 06:25:33.871356 26953 solver.cpp:244]     Train net output #0: loss = 2.0881 (* 1 = 2.0881 loss)
I0812 06:25:35.283705 26953 sgd_solver.cpp:106] Iteration 25990, lr = 0.01
I0812 06:25:53.110776 26953 solver.cpp:337] Iteration 26000, Testing net (#0)
I0812 06:25:53.707332 26953 solver.cpp:404]     Test net output #0: accuracy = 0.52
I0812 06:25:53.707392 26953 solver.cpp:404]     Test net output #1: loss = 2.21358 (* 1 = 2.21358 loss)
I0812 06:25:54.274873 26953 solver.cpp:228] Iteration 26000, loss = 1.94274
I0812 06:25:54.274973 26953 solver.cpp:244]     Train net output #0: loss = 1.94274 (* 1 = 1.94274 loss)
I0812 06:25:55.671440 26953 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I0812 06:26:14.027649 26953 solver.cpp:228] Iteration 26010, loss = 1.92705
I0812 06:26:14.027806 26953 solver.cpp:244]     Train net output #0: loss = 1.92705 (* 1 = 1.92705 loss)
I0812 06:26:15.436918 26953 sgd_solver.cpp:106] Iteration 26010, lr = 0.01
I0812 06:26:33.888625 26953 solver.cpp:228] Iteration 26020, loss = 1.969
I0812 06:26:33.888695 26953 solver.cpp:244]     Train net output #0: loss = 1.969 (* 1 = 1.969 loss)
I0812 06:26:35.289777 26953 sgd_solver.cpp:106] Iteration 26020, lr = 0.01
I0812 06:26:53.679816 26953 solver.cpp:228] Iteration 26030, loss = 1.9281
I0812 06:26:53.680049 26953 solver.cpp:244]     Train net output #0: loss = 1.9281 (* 1 = 1.9281 loss)
I0812 06:26:55.081195 26953 sgd_solver.cpp:106] Iteration 26030, lr = 0.01
I0812 06:27:13.465642 26953 solver.cpp:228] Iteration 26040, loss = 1.93378
I0812 06:27:13.465730 26953 solver.cpp:244]     Train net output #0: loss = 1.93378 (* 1 = 1.93378 loss)
I0812 06:27:14.863553 26953 sgd_solver.cpp:106] Iteration 26040, lr = 0.01
I0812 06:27:33.285898 26953 solver.cpp:228] Iteration 26050, loss = 1.90608
I0812 06:27:33.286126 26953 solver.cpp:244]     Train net output #0: loss = 1.90608 (* 1 = 1.90608 loss)
I0812 06:27:34.684463 26953 sgd_solver.cpp:106] Iteration 26050, lr = 0.01
I0812 06:27:53.080183 26953 solver.cpp:228] Iteration 26060, loss = 2.0347
I0812 06:27:53.080253 26953 solver.cpp:244]     Train net output #0: loss = 2.0347 (* 1 = 2.0347 loss)
I0812 06:27:54.486577 26953 sgd_solver.cpp:106] Iteration 26060, lr = 0.01
I0812 06:28:12.857393 26953 solver.cpp:228] Iteration 26070, loss = 2.04753
I0812 06:28:12.857542 26953 solver.cpp:244]     Train net output #0: loss = 2.04753 (* 1 = 2.04753 loss)
I0812 06:28:14.245009 26953 sgd_solver.cpp:106] Iteration 26070, lr = 0.01
I0812 06:28:32.643456 26953 solver.cpp:228] Iteration 26080, loss = 2.14549
I0812 06:28:32.643522 26953 solver.cpp:244]     Train net output #0: loss = 2.14549 (* 1 = 2.14549 loss)
I0812 06:28:34.040757 26953 sgd_solver.cpp:106] Iteration 26080, lr = 0.01
I0812 06:28:52.426790 26953 solver.cpp:228] Iteration 26090, loss = 1.83031
I0812 06:28:52.427014 26953 solver.cpp:244]     Train net output #0: loss = 1.83031 (* 1 = 1.83031 loss)
I0812 06:28:53.843530 26953 sgd_solver.cpp:106] Iteration 26090, lr = 0.01
I0812 06:29:11.671334 26953 solver.cpp:337] Iteration 26100, Testing net (#0)
I0812 06:29:12.263026 26953 solver.cpp:404]     Test net output #0: accuracy = 0.54
I0812 06:29:12.263100 26953 solver.cpp:404]     Test net output #1: loss = 2.12673 (* 1 = 2.12673 loss)
I0812 06:29:12.829859 26953 solver.cpp:228] Iteration 26100, loss = 2.10411
I0812 06:29:12.829934 26953 solver.cpp:244]     Train net output #0: loss = 2.10411 (* 1 = 2.10411 loss)
I0812 06:29:14.214957 26953 sgd_solver.cpp:106] Iteration 26100, lr = 0.01
I0812 06:29:32.599251 26953 solver.cpp:228] Iteration 26110, loss = 2.08901
I0812 06:29:32.599469 26953 solver.cpp:244]     Train net output #0: loss = 2.08901 (* 1 = 2.08901 loss)
I0812 06:29:34.005476 26953 sgd_solver.cpp:106] Iteration 26110, lr = 0.01
I0812 06:29:52.390195 26953 solver.cpp:228] Iteration 26120, loss = 1.98157
I0812 06:29:52.390266 26953 solver.cpp:244]     Train net output #0: loss = 1.98157 (* 1 = 1.98157 loss)
I0812 06:29:53.782965 26953 sgd_solver.cpp:106] Iteration 26120, lr = 0.01
I0812 06:30:12.197563 26953 solver.cpp:228] Iteration 26130, loss = 2.10949
I0812 06:30:12.197782 26953 solver.cpp:244]     Train net output #0: loss = 2.10949 (* 1 = 2.10949 loss)
I0812 06:30:13.612648 26953 sgd_solver.cpp:106] Iteration 26130, lr = 0.01
I0812 06:30:31.996084 26953 solver.cpp:228] Iteration 26140, loss = 1.99857
I0812 06:30:31.996155 26953 solver.cpp:244]     Train net output #0: loss = 1.99857 (* 1 = 1.99857 loss)
I0812 06:30:33.393673 26953 sgd_solver.cpp:106] Iteration 26140, lr = 0.01
I0812 06:30:51.818276 26953 solver.cpp:228] Iteration 26150, loss = 2.05019
I0812 06:30:51.818428 26953 solver.cpp:244]     Train net output #0: loss = 2.05019 (* 1 = 2.05019 loss)
I0812 06:30:53.213516 26953 sgd_solver.cpp:106] Iteration 26150, lr = 0.01
I0812 06:31:11.606842 26953 solver.cpp:228] Iteration 26160, loss = 2.04616
I0812 06:31:11.606906 26953 solver.cpp:244]     Train net output #0: loss = 2.04616 (* 1 = 2.04616 loss)
I0812 06:31:13.004601 26953 sgd_solver.cpp:106] Iteration 26160, lr = 0.01
I0812 06:31:31.379302 26953 solver.cpp:228] Iteration 26170, loss = 2.068
I0812 06:31:31.379482 26953 solver.cpp:244]     Train net output #0: loss = 2.068 (* 1 = 2.068 loss)
I0812 06:31:32.782002 26953 sgd_solver.cpp:106] Iteration 26170, lr = 0.01
I0812 06:31:51.155283 26953 solver.cpp:228] Iteration 26180, loss = 1.98331
I0812 06:31:51.155367 26953 solver.cpp:244]     Train net output #0: loss = 1.98331 (* 1 = 1.98331 loss)
I0812 06:31:52.540736 26953 sgd_solver.cpp:106] Iteration 26180, lr = 0.01
I0812 06:32:10.956655 26953 solver.cpp:228] Iteration 26190, loss = 1.86168
I0812 06:32:10.956894 26953 solver.cpp:244]     Train net output #0: loss = 1.86168 (* 1 = 1.86168 loss)
I0812 06:32:12.347581 26953 sgd_solver.cpp:106] Iteration 26190, lr = 0.01
I0812 06:32:30.169626 26953 solver.cpp:337] Iteration 26200, Testing net (#0)
I0812 06:32:30.763269 26953 solver.cpp:404]     Test net output #0: accuracy = 0.512
I0812 06:32:30.763330 26953 solver.cpp:404]     Test net output #1: loss = 2.18261 (* 1 = 2.18261 loss)
I0812 06:32:31.331182 26953 solver.cpp:228] Iteration 26200, loss = 2.07072
I0812 06:32:31.331280 26953 solver.cpp:244]     Train net output #0: loss = 2.07072 (* 1 = 2.07072 loss)
I0812 06:32:32.711293 26953 sgd_solver.cpp:106] Iteration 26200, lr = 0.01
I0812 06:32:51.105741 26953 solver.cpp:228] Iteration 26210, loss = 1.85563
I0812 06:32:51.105896 26953 solver.cpp:244]     Train net output #0: loss = 1.85563 (* 1 = 1.85563 loss)
I0812 06:32:52.505964 26953 sgd_solver.cpp:106] Iteration 26210, lr = 0.01
I0812 06:33:10.912905 26953 solver.cpp:228] Iteration 26220, loss = 2.06151
I0812 06:33:10.912969 26953 solver.cpp:244]     Train net output #0: loss = 2.06151 (* 1 = 2.06151 loss)
I0812 06:33:12.311702 26953 sgd_solver.cpp:106] Iteration 26220, lr = 0.01
I0812 06:33:30.679077 26953 solver.cpp:228] Iteration 26230, loss = 1.96668
I0812 06:33:30.679343 26953 solver.cpp:244]     Train net output #0: loss = 1.96668 (* 1 = 1.96668 loss)
I0812 06:33:32.083606 26953 sgd_solver.cpp:106] Iteration 26230, lr = 0.01
I0812 06:33:50.460872 26953 solver.cpp:228] Iteration 26240, loss = 2.02511
I0812 06:33:50.460944 26953 solver.cpp:244]     Train net output #0: loss = 2.02511 (* 1 = 2.02511 loss)
I0812 06:33:51.838439 26953 sgd_solver.cpp:106] Iteration 26240, lr = 0.01
I0812 06:34:10.249155 26953 solver.cpp:228] Iteration 26250, loss = 1.99542
I0812 06:34:10.249372 26953 solver.cpp:244]     Train net output #0: loss = 1.99542 (* 1 = 1.99542 loss)
I0812 06:34:11.656761 26953 sgd_solver.cpp:106] Iteration 26250, lr = 0.01
I0812 06:34:30.068102 26953 solver.cpp:228] Iteration 26260, loss = 2.08695
I0812 06:34:30.068236 26953 solver.cpp:244]     Train net output #0: loss = 2.08695 (* 1 = 2.08695 loss)
I0812 06:34:31.475060 26953 sgd_solver.cpp:106] Iteration 26260, lr = 0.01
I0812 06:34:49.908756 26953 solver.cpp:228] Iteration 26270, loss = 2.13731
I0812 06:34:49.909013 26953 solver.cpp:244]     Train net output #0: loss = 2.13731 (* 1 = 2.13731 loss)
I0812 06:34:51.298408 26953 sgd_solver.cpp:106] Iteration 26270, lr = 0.01
I0812 06:35:09.703951 26953 solver.cpp:228] Iteration 26280, loss = 2.05826
I0812 06:35:09.704033 26953 solver.cpp:244]     Train net output #0: loss = 2.05826 (* 1 = 2.05826 loss)
I0812 06:35:11.122301 26953 sgd_solver.cpp:106] Iteration 26280, lr = 0.01
I0812 06:35:29.502055 26953 solver.cpp:228] Iteration 26290, loss = 2.17787
I0812 06:35:29.502297 26953 solver.cpp:244]     Train net output #0: loss = 2.17787 (* 1 = 2.17787 loss)
I0812 06:35:30.899588 26953 sgd_solver.cpp:106] Iteration 26290, lr = 0.01
I0812 06:35:48.743041 26953 solver.cpp:337] Iteration 26300, Testing net (#0)
I0812 06:35:49.329059 26953 solver.cpp:404]     Test net output #0: accuracy = 0.514
I0812 06:35:49.329141 26953 solver.cpp:404]     Test net output #1: loss = 2.12261 (* 1 = 2.12261 loss)
I0812 06:35:49.921890 26953 solver.cpp:228] Iteration 26300, loss = 2.07994
I0812 06:35:49.921983 26953 solver.cpp:244]     Train net output #0: loss = 2.07994 (* 1 = 2.07994 loss)
I0812 06:35:51.284346 26953 sgd_solver.cpp:106] Iteration 26300, lr = 0.01
I0812 06:36:09.718423 26953 solver.cpp:228] Iteration 26310, loss = 1.96915
I0812 06:36:09.718672 26953 solver.cpp:244]     Train net output #0: loss = 1.96915 (* 1 = 1.96915 loss)
I0812 06:36:11.109727 26953 sgd_solver.cpp:106] Iteration 26310, lr = 0.01
I0812 06:36:29.498211 26953 solver.cpp:228] Iteration 26320, loss = 2.08357
I0812 06:36:29.498287 26953 solver.cpp:244]     Train net output #0: loss = 2.08357 (* 1 = 2.08357 loss)
I0812 06:36:30.895556 26953 sgd_solver.cpp:106] Iteration 26320, lr = 0.01
I0812 06:36:49.271656 26953 solver.cpp:228] Iteration 26330, loss = 2.00323
I0812 06:36:49.271841 26953 solver.cpp:244]     Train net output #0: loss = 2.00323 (* 1 = 2.00323 loss)
I0812 06:36:50.685048 26953 sgd_solver.cpp:106] Iteration 26330, lr = 0.01
I0812 06:37:09.096969 26953 solver.cpp:228] Iteration 26340, loss = 2.04226
I0812 06:37:09.097051 26953 solver.cpp:244]     Train net output #0: loss = 2.04226 (* 1 = 2.04226 loss)
I0812 06:37:10.496202 26953 sgd_solver.cpp:106] Iteration 26340, lr = 0.01
I0812 06:37:28.901260 26953 solver.cpp:228] Iteration 26350, loss = 2.05922
I0812 06:37:28.901494 26953 solver.cpp:244]     Train net output #0: loss = 2.05922 (* 1 = 2.05922 loss)
I0812 06:37:30.298384 26953 sgd_solver.cpp:106] Iteration 26350, lr = 0.01
I0812 06:37:48.672768 26953 solver.cpp:228] Iteration 26360, loss = 2.07196
I0812 06:37:48.672848 26953 solver.cpp:244]     Train net output #0: loss = 2.07196 (* 1 = 2.07196 loss)
I0812 06:37:50.070525 26953 sgd_solver.cpp:106] Iteration 26360, lr = 0.01
I0812 06:38:08.472517 26953 solver.cpp:228] Iteration 26370, loss = 1.89906
I0812 06:38:08.472728 26953 solver.cpp:244]     Train net output #0: loss = 1.89906 (* 1 = 1.89906 loss)
I0812 06:38:09.869678 26953 sgd_solver.cpp:106] Iteration 26370, lr = 0.01
I0812 06:38:28.268226 26953 solver.cpp:228] Iteration 26380, loss = 2.07412
I0812 06:38:28.268303 26953 solver.cpp:244]     Train net output #0: loss = 2.07412 (* 1 = 2.07412 loss)
I0812 06:38:29.674578 26953 sgd_solver.cpp:106] Iteration 26380, lr = 0.01
I0812 06:38:48.037422 26953 solver.cpp:228] Iteration 26390, loss = 2.07265
I0812 06:38:48.037680 26953 solver.cpp:244]     Train net output #0: loss = 2.07265 (* 1 = 2.07265 loss)
I0812 06:38:49.449425 26953 sgd_solver.cpp:106] Iteration 26390, lr = 0.01
I0812 06:39:07.258009 26953 solver.cpp:337] Iteration 26400, Testing net (#0)
I0812 06:39:07.851653 26953 solver.cpp:404]     Test net output #0: accuracy = 0.548
I0812 06:39:07.851748 26953 solver.cpp:404]     Test net output #1: loss = 1.95915 (* 1 = 1.95915 loss)
I0812 06:39:08.423173 26953 solver.cpp:228] Iteration 26400, loss = 1.96429
I0812 06:39:08.423259 26953 solver.cpp:244]     Train net output #0: loss = 1.96429 (* 1 = 1.96429 loss)
I0812 06:39:09.805950 26953 sgd_solver.cpp:106] Iteration 26400, lr = 0.01
I0812 06:39:28.181864 26953 solver.cpp:228] Iteration 26410, loss = 2.05292
I0812 06:39:28.182078 26953 solver.cpp:244]     Train net output #0: loss = 2.05292 (* 1 = 2.05292 loss)
I0812 06:39:29.585152 26953 sgd_solver.cpp:106] Iteration 26410, lr = 0.01
I0812 06:39:47.970474 26953 solver.cpp:228] Iteration 26420, loss = 2.05171
I0812 06:39:47.970554 26953 solver.cpp:244]     Train net output #0: loss = 2.05171 (* 1 = 2.05171 loss)
I0812 06:39:49.365988 26953 sgd_solver.cpp:106] Iteration 26420, lr = 0.01
I0812 06:40:07.793895 26953 solver.cpp:228] Iteration 26430, loss = 2.0112
I0812 06:40:07.794129 26953 solver.cpp:244]     Train net output #0: loss = 2.0112 (* 1 = 2.0112 loss)
I0812 06:40:09.206090 26953 sgd_solver.cpp:106] Iteration 26430, lr = 0.01
I0812 06:40:27.571667 26953 solver.cpp:228] Iteration 26440, loss = 2.05903
I0812 06:40:27.571746 26953 solver.cpp:244]     Train net output #0: loss = 2.05903 (* 1 = 2.05903 loss)
I0812 06:40:28.979344 26953 sgd_solver.cpp:106] Iteration 26440, lr = 0.01
I0812 06:40:47.389600 26953 solver.cpp:228] Iteration 26450, loss = 1.885
I0812 06:40:47.389832 26953 solver.cpp:244]     Train net output #0: loss = 1.885 (* 1 = 1.885 loss)
I0812 06:40:48.789903 26953 sgd_solver.cpp:106] Iteration 26450, lr = 0.01
I0812 06:41:07.205798 26953 solver.cpp:228] Iteration 26460, loss = 2.15102
I0812 06:41:07.205858 26953 solver.cpp:244]     Train net output #0: loss = 2.15102 (* 1 = 2.15102 loss)
I0812 06:41:08.598510 26953 sgd_solver.cpp:106] Iteration 26460, lr = 0.01
I0812 06:41:26.960669 26953 solver.cpp:228] Iteration 26470, loss = 2.1578
I0812 06:41:26.960953 26953 solver.cpp:244]     Train net output #0: loss = 2.1578 (* 1 = 2.1578 loss)
I0812 06:41:28.374828 26953 sgd_solver.cpp:106] Iteration 26470, lr = 0.01
I0812 06:41:46.760682 26953 solver.cpp:228] Iteration 26480, loss = 1.9481
I0812 06:41:46.760754 26953 solver.cpp:244]     Train net output #0: loss = 1.9481 (* 1 = 1.9481 loss)
I0812 06:41:48.161208 26953 sgd_solver.cpp:106] Iteration 26480, lr = 0.01
I0812 06:42:06.561604 26953 solver.cpp:228] Iteration 26490, loss = 2.01619
I0812 06:42:06.561826 26953 solver.cpp:244]     Train net output #0: loss = 2.01619 (* 1 = 2.01619 loss)
I0812 06:42:07.961899 26953 sgd_solver.cpp:106] Iteration 26490, lr = 0.01
I0812 06:42:25.741396 26953 solver.cpp:337] Iteration 26500, Testing net (#0)
I0812 06:42:26.339668 26953 solver.cpp:404]     Test net output #0: accuracy = 0.516
I0812 06:42:26.339766 26953 solver.cpp:404]     Test net output #1: loss = 2.10067 (* 1 = 2.10067 loss)
I0812 06:42:26.907347 26953 solver.cpp:228] Iteration 26500, loss = 2.10708
I0812 06:42:26.907444 26953 solver.cpp:244]     Train net output #0: loss = 2.10708 (* 1 = 2.10708 loss)
I0812 06:42:28.294513 26953 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I0812 06:42:46.701026 26953 solver.cpp:228] Iteration 26510, loss = 1.99608
I0812 06:42:46.701253 26953 solver.cpp:244]     Train net output #0: loss = 1.99608 (* 1 = 1.99608 loss)
I0812 06:42:48.101415 26953 sgd_solver.cpp:106] Iteration 26510, lr = 0.01
I0812 06:43:06.493932 26953 solver.cpp:228] Iteration 26520, loss = 1.97086
I0812 06:43:06.494004 26953 solver.cpp:244]     Train net output #0: loss = 1.97086 (* 1 = 1.97086 loss)
I0812 06:43:07.893100 26953 sgd_solver.cpp:106] Iteration 26520, lr = 0.01
I0812 06:43:26.353014 26953 solver.cpp:228] Iteration 26530, loss = 2.04794
I0812 06:43:26.353276 26953 solver.cpp:244]     Train net output #0: loss = 2.04794 (* 1 = 2.04794 loss)
I0812 06:43:27.760053 26953 sgd_solver.cpp:106] Iteration 26530, lr = 0.01
I0812 06:43:46.149503 26953 solver.cpp:228] Iteration 26540, loss = 1.90343
I0812 06:43:46.149601 26953 solver.cpp:244]     Train net output #0: loss = 1.90343 (* 1 = 1.90343 loss)
I0812 06:43:47.549252 26953 sgd_solver.cpp:106] Iteration 26540, lr = 0.01
I0812 06:44:05.929203 26953 solver.cpp:228] Iteration 26550, loss = 2.08396
I0812 06:44:05.929450 26953 solver.cpp:244]     Train net output #0: loss = 2.08396 (* 1 = 2.08396 loss)
I0812 06:44:07.325101 26953 sgd_solver.cpp:106] Iteration 26550, lr = 0.01
I0812 06:44:25.788717 26953 solver.cpp:228] Iteration 26560, loss = 2.31744
I0812 06:44:25.788797 26953 solver.cpp:244]     Train net output #0: loss = 2.31744 (* 1 = 2.31744 loss)
I0812 06:44:27.183722 26953 sgd_solver.cpp:106] Iteration 26560, lr = 0.01
I0812 06:44:45.555770 26953 solver.cpp:228] Iteration 26570, loss = 2.09771
I0812 06:44:45.555939 26953 solver.cpp:244]     Train net output #0: loss = 2.09771 (* 1 = 2.09771 loss)
I0812 06:44:46.971850 26953 sgd_solver.cpp:106] Iteration 26570, lr = 0.01
I0812 06:45:05.377606 26953 solver.cpp:228] Iteration 26580, loss = 1.94812
I0812 06:45:05.377686 26953 solver.cpp:244]     Train net output #0: loss = 1.94812 (* 1 = 1.94812 loss)
I0812 06:45:06.779659 26953 sgd_solver.cpp:106] Iteration 26580, lr = 0.01
I0812 06:45:25.183542 26953 solver.cpp:228] Iteration 26590, loss = 1.96855
I0812 06:45:25.183723 26953 solver.cpp:244]     Train net output #0: loss = 1.96855 (* 1 = 1.96855 loss)
I0812 06:45:26.592149 26953 sgd_solver.cpp:106] Iteration 26590, lr = 0.01
I0812 06:45:44.380358 26953 solver.cpp:337] Iteration 26600, Testing net (#0)
I0812 06:45:44.971261 26953 solver.cpp:404]     Test net output #0: accuracy = 0.562
I0812 06:45:44.971338 26953 solver.cpp:404]     Test net output #1: loss = 1.94641 (* 1 = 1.94641 loss)
I0812 06:45:45.546224 26953 solver.cpp:228] Iteration 26600, loss = 2.02017
I0812 06:45:45.546294 26953 solver.cpp:244]     Train net output #0: loss = 2.02017 (* 1 = 2.02017 loss)
I0812 06:45:46.914789 26953 sgd_solver.cpp:106] Iteration 26600, lr = 0.01
I0812 06:46:05.314288 26953 solver.cpp:228] Iteration 26610, loss = 1.90945
I0812 06:46:05.314589 26953 solver.cpp:244]     Train net output #0: loss = 1.90945 (* 1 = 1.90945 loss)
I0812 06:46:06.723202 26953 sgd_solver.cpp:106] Iteration 26610, lr = 0.01
I0812 06:46:25.083747 26953 solver.cpp:228] Iteration 26620, loss = 2.0286
I0812 06:46:25.083839 26953 solver.cpp:244]     Train net output #0: loss = 2.0286 (* 1 = 2.0286 loss)
I0812 06:46:26.482893 26953 sgd_solver.cpp:106] Iteration 26620, lr = 0.01
I0812 06:46:44.869259 26953 solver.cpp:228] Iteration 26630, loss = 1.99204
I0812 06:46:44.869511 26953 solver.cpp:244]     Train net output #0: loss = 1.99204 (* 1 = 1.99204 loss)
I0812 06:46:46.276756 26953 sgd_solver.cpp:106] Iteration 26630, lr = 0.01
I0812 06:47:04.740846 26953 solver.cpp:228] Iteration 26640, loss = 1.79359
I0812 06:47:04.740921 26953 solver.cpp:244]     Train net output #0: loss = 1.79359 (* 1 = 1.79359 loss)
I0812 06:47:06.148080 26953 sgd_solver.cpp:106] Iteration 26640, lr = 0.01
I0812 06:47:24.508853 26953 solver.cpp:228] Iteration 26650, loss = 2.02858
I0812 06:47:24.509066 26953 solver.cpp:244]     Train net output #0: loss = 2.02858 (* 1 = 2.02858 loss)
I0812 06:47:25.910781 26953 sgd_solver.cpp:106] Iteration 26650, lr = 0.01
I0812 06:47:44.310591 26953 solver.cpp:228] Iteration 26660, loss = 1.94224
I0812 06:47:44.310662 26953 solver.cpp:244]     Train net output #0: loss = 1.94224 (* 1 = 1.94224 loss)
I0812 06:47:45.709859 26953 sgd_solver.cpp:106] Iteration 26660, lr = 0.01
I0812 06:48:04.126335 26953 solver.cpp:228] Iteration 26670, loss = 1.91708
I0812 06:48:04.126571 26953 solver.cpp:244]     Train net output #0: loss = 1.91708 (* 1 = 1.91708 loss)
I0812 06:48:05.540696 26953 sgd_solver.cpp:106] Iteration 26670, lr = 0.01
I0812 06:48:23.950815 26953 solver.cpp:228] Iteration 26680, loss = 1.97215
I0812 06:48:23.950896 26953 solver.cpp:244]     Train net output #0: loss = 1.97215 (* 1 = 1.97215 loss)
I0812 06:48:25.349009 26953 sgd_solver.cpp:106] Iteration 26680, lr = 0.01
I0812 06:48:43.737689 26953 solver.cpp:228] Iteration 26690, loss = 1.89765
I0812 06:48:43.737839 26953 solver.cpp:244]     Train net output #0: loss = 1.89765 (* 1 = 1.89765 loss)
I0812 06:48:45.139636 26953 sgd_solver.cpp:106] Iteration 26690, lr = 0.01
I0812 06:49:02.918700 26953 solver.cpp:337] Iteration 26700, Testing net (#0)
I0812 06:49:03.513026 26953 solver.cpp:404]     Test net output #0: accuracy = 0.546
I0812 06:49:03.513095 26953 solver.cpp:404]     Test net output #1: loss = 1.99299 (* 1 = 1.99299 loss)
I0812 06:49:04.075790 26953 solver.cpp:228] Iteration 26700, loss = 2.07126
I0812 06:49:04.075883 26953 solver.cpp:244]     Train net output #0: loss = 2.07126 (* 1 = 2.07126 loss)
I0812 06:49:05.464246 26953 sgd_solver.cpp:106] Iteration 26700, lr = 0.01
I0812 06:49:23.883229 26953 solver.cpp:228] Iteration 26710, loss = 1.99947
I0812 06:49:23.883479 26953 solver.cpp:244]     Train net output #0: loss = 1.99947 (* 1 = 1.99947 loss)
I0812 06:49:25.277555 26953 sgd_solver.cpp:106] Iteration 26710, lr = 0.01
I0812 06:49:43.645656 26953 solver.cpp:228] Iteration 26720, loss = 1.93864
I0812 06:49:43.645726 26953 solver.cpp:244]     Train net output #0: loss = 1.93864 (* 1 = 1.93864 loss)
I0812 06:49:45.047549 26953 sgd_solver.cpp:106] Iteration 26720, lr = 0.01
I0812 06:50:03.405401 26953 solver.cpp:228] Iteration 26730, loss = 1.9283
I0812 06:50:03.405650 26953 solver.cpp:244]     Train net output #0: loss = 1.9283 (* 1 = 1.9283 loss)
I0812 06:50:04.804822 26953 sgd_solver.cpp:106] Iteration 26730, lr = 0.01
I0812 06:50:23.168257 26953 solver.cpp:228] Iteration 26740, loss = 2.06767
I0812 06:50:23.168325 26953 solver.cpp:244]     Train net output #0: loss = 2.06767 (* 1 = 2.06767 loss)
I0812 06:50:24.563626 26953 sgd_solver.cpp:106] Iteration 26740, lr = 0.01
I0812 06:50:42.967042 26953 solver.cpp:228] Iteration 26750, loss = 1.88402
I0812 06:50:42.967324 26953 solver.cpp:244]     Train net output #0: loss = 1.88402 (* 1 = 1.88402 loss)
I0812 06:50:44.371348 26953 sgd_solver.cpp:106] Iteration 26750, lr = 0.01
I0812 06:51:02.783695 26953 solver.cpp:228] Iteration 26760, loss = 2.01162
I0812 06:51:02.783753 26953 solver.cpp:244]     Train net output #0: loss = 2.01162 (* 1 = 2.01162 loss)
I0812 06:51:04.188990 26953 sgd_solver.cpp:106] Iteration 26760, lr = 0.01
I0812 06:51:22.548166 26953 solver.cpp:228] Iteration 26770, loss = 2.103
I0812 06:51:22.548391 26953 solver.cpp:244]     Train net output #0: loss = 2.103 (* 1 = 2.103 loss)
I0812 06:51:23.949652 26953 sgd_solver.cpp:106] Iteration 26770, lr = 0.01
I0812 06:51:42.402053 26953 solver.cpp:228] Iteration 26780, loss = 1.90957
I0812 06:51:42.402137 26953 solver.cpp:244]     Train net output #0: loss = 1.90957 (* 1 = 1.90957 loss)
I0812 06:51:43.806239 26953 sgd_solver.cpp:106] Iteration 26780, lr = 0.01
I0812 06:52:02.161720 26953 solver.cpp:228] Iteration 26790, loss = 1.95194
I0812 06:52:02.161967 26953 solver.cpp:244]     Train net output #0: loss = 1.95194 (* 1 = 1.95194 loss)
I0812 06:52:03.580881 26953 sgd_solver.cpp:106] Iteration 26790, lr = 0.01
I0812 06:52:21.416107 26953 solver.cpp:337] Iteration 26800, Testing net (#0)
I0812 06:52:22.010745 26953 solver.cpp:404]     Test net output #0: accuracy = 0.552
I0812 06:52:22.010809 26953 solver.cpp:404]     Test net output #1: loss = 2.01929 (* 1 = 2.01929 loss)
I0812 06:52:22.604290 26953 solver.cpp:228] Iteration 26800, loss = 1.86586
I0812 06:52:22.604387 26953 solver.cpp:244]     Train net output #0: loss = 1.86586 (* 1 = 1.86586 loss)
I0812 06:52:23.968744 26953 sgd_solver.cpp:106] Iteration 26800, lr = 0.01
I0812 06:52:42.345047 26953 solver.cpp:228] Iteration 26810, loss = 1.96853
I0812 06:52:42.345299 26953 solver.cpp:244]     Train net output #0: loss = 1.96853 (* 1 = 1.96853 loss)
I0812 06:52:43.746366 26953 sgd_solver.cpp:106] Iteration 26810, lr = 0.01
I0812 06:53:02.176076 26953 solver.cpp:228] Iteration 26820, loss = 1.93744
I0812 06:53:02.176139 26953 solver.cpp:244]     Train net output #0: loss = 1.93744 (* 1 = 1.93744 loss)
I0812 06:53:03.566555 26953 sgd_solver.cpp:106] Iteration 26820, lr = 0.01
I0812 06:53:21.995370 26953 solver.cpp:228] Iteration 26830, loss = 1.93826
I0812 06:53:21.995543 26953 solver.cpp:244]     Train net output #0: loss = 1.93826 (* 1 = 1.93826 loss)
I0812 06:53:23.393136 26953 sgd_solver.cpp:106] Iteration 26830, lr = 0.01
I0812 06:53:41.762359 26953 solver.cpp:228] Iteration 26840, loss = 2.05895
I0812 06:53:41.762423 26953 solver.cpp:244]     Train net output #0: loss = 2.05895 (* 1 = 2.05895 loss)
I0812 06:53:43.164731 26953 sgd_solver.cpp:106] Iteration 26840, lr = 0.01
I0812 06:54:01.550194 26953 solver.cpp:228] Iteration 26850, loss = 2.03337
I0812 06:54:01.550420 26953 solver.cpp:244]     Train net output #0: loss = 2.03337 (* 1 = 2.03337 loss)
I0812 06:54:02.950626 26953 sgd_solver.cpp:106] Iteration 26850, lr = 0.01
I0812 06:54:21.358088 26953 solver.cpp:228] Iteration 26860, loss = 1.82682
I0812 06:54:21.358160 26953 solver.cpp:244]     Train net output #0: loss = 1.82682 (* 1 = 1.82682 loss)
I0812 06:54:22.776718 26953 sgd_solver.cpp:106] Iteration 26860, lr = 0.01
I0812 06:54:41.139163 26953 solver.cpp:228] Iteration 26870, loss = 2.00882
I0812 06:54:41.139320 26953 solver.cpp:244]     Train net output #0: loss = 2.00882 (* 1 = 2.00882 loss)
I0812 06:54:42.542575 26953 sgd_solver.cpp:106] Iteration 26870, lr = 0.01
I0812 06:55:00.942505 26953 solver.cpp:228] Iteration 26880, loss = 2.16523
I0812 06:55:00.942575 26953 solver.cpp:244]     Train net output #0: loss = 2.16523 (* 1 = 2.16523 loss)
I0812 06:55:02.338161 26953 sgd_solver.cpp:106] Iteration 26880, lr = 0.01
I0812 06:55:20.780298 26953 solver.cpp:228] Iteration 26890, loss = 2.09
I0812 06:55:20.780509 26953 solver.cpp:244]     Train net output #0: loss = 2.09 (* 1 = 2.09 loss)
I0812 06:55:22.181890 26953 sgd_solver.cpp:106] Iteration 26890, lr = 0.01
I0812 06:55:39.990620 26953 solver.cpp:337] Iteration 26900, Testing net (#0)
I0812 06:55:40.582659 26953 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0812 06:55:40.582721 26953 solver.cpp:404]     Test net output #1: loss = 2.20925 (* 1 = 2.20925 loss)
I0812 06:55:41.147445 26953 solver.cpp:228] Iteration 26900, loss = 2.0235
I0812 06:55:41.147514 26953 solver.cpp:244]     Train net output #0: loss = 2.0235 (* 1 = 2.0235 loss)
I0812 06:55:42.541956 26953 sgd_solver.cpp:106] Iteration 26900, lr = 0.01
I0812 06:56:00.923529 26953 solver.cpp:228] Iteration 26910, loss = 2.16839
I0812 06:56:00.923789 26953 solver.cpp:244]     Train net output #0: loss = 2.16839 (* 1 = 2.16839 loss)
I0812 06:56:02.317886 26953 sgd_solver.cpp:106] Iteration 26910, lr = 0.01
I0812 06:56:20.698814 26953 solver.cpp:228] Iteration 26920, loss = 2.05089
I0812 06:56:20.698884 26953 solver.cpp:244]     Train net output #0: loss = 2.05089 (* 1 = 2.05089 loss)
I0812 06:56:22.101348 26953 sgd_solver.cpp:106] Iteration 26920, lr = 0.01
I0812 06:56:40.546411 26953 solver.cpp:228] Iteration 26930, loss = 1.96197
I0812 06:56:40.546686 26953 solver.cpp:244]     Train net output #0: loss = 1.96197 (* 1 = 1.96197 loss)
I0812 06:56:41.941812 26953 sgd_solver.cpp:106] Iteration 26930, lr = 0.01
I0812 06:57:00.239661 26953 solver.cpp:228] Iteration 26940, loss = 1.77431
I0812 06:57:00.239729 26953 solver.cpp:244]     Train net output #0: loss = 1.77431 (* 1 = 1.77431 loss)
I0812 06:57:01.636096 26953 sgd_solver.cpp:106] Iteration 26940, lr = 0.01
I0812 06:57:20.030270 26953 solver.cpp:228] Iteration 26950, loss = 2.11076
I0812 06:57:20.030436 26953 solver.cpp:244]     Train net output #0: loss = 2.11076 (* 1 = 2.11076 loss)
I0812 06:57:21.446820 26953 sgd_solver.cpp:106] Iteration 26950, lr = 0.01
I0812 06:57:39.795783 26953 solver.cpp:228] Iteration 26960, loss = 2.00906
I0812 06:57:39.795864 26953 solver.cpp:244]     Train net output #0: loss = 2.00906 (* 1 = 2.00906 loss)
I0812 06:57:41.198065 26953 sgd_solver.cpp:106] Iteration 26960, lr = 0.01
I0812 06:57:59.597385 26953 solver.cpp:228] Iteration 26970, loss = 2.06471
I0812 06:57:59.597622 26953 solver.cpp:244]     Train net output #0: loss = 2.06471 (* 1 = 2.06471 loss)
I0812 06:58:01.001021 26953 sgd_solver.cpp:106] Iteration 26970, lr = 0.01
I0812 06:58:19.403806 26953 solver.cpp:228] Iteration 26980, loss = 1.90104
I0812 06:58:19.403887 26953 solver.cpp:244]     Train net output #0: loss = 1.90104 (* 1 = 1.90104 loss)
I0812 06:58:20.819583 26953 sgd_solver.cpp:106] Iteration 26980, lr = 0.01
I0812 06:58:39.228771 26953 solver.cpp:228] Iteration 26990, loss = 2.04074
I0812 06:58:39.228927 26953 solver.cpp:244]     Train net output #0: loss = 2.04074 (* 1 = 2.04074 loss)
I0812 06:58:40.639228 26953 sgd_solver.cpp:106] Iteration 26990, lr = 0.01
I0812 06:58:58.480916 26953 solver.cpp:337] Iteration 27000, Testing net (#0)
I0812 06:58:59.067631 26953 solver.cpp:404]     Test net output #0: accuracy = 0.508
I0812 06:58:59.067700 26953 solver.cpp:404]     Test net output #1: loss = 2.20541 (* 1 = 2.20541 loss)
I0812 06:58:59.651834 26953 solver.cpp:228] Iteration 27000, loss = 2.16584
I0812 06:58:59.651935 26953 solver.cpp:244]     Train net output #0: loss = 2.16584 (* 1 = 2.16584 loss)
I0812 06:59:01.029448 26953 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I0812 06:59:19.406486 26953 solver.cpp:228] Iteration 27010, loss = 2.11263
I0812 06:59:19.406698 26953 solver.cpp:244]     Train net output #0: loss = 2.11263 (* 1 = 2.11263 loss)
I0812 06:59:20.808022 26953 sgd_solver.cpp:106] Iteration 27010, lr = 0.01
I0812 06:59:39.172101 26953 solver.cpp:228] Iteration 27020, loss = 2.03756
I0812 06:59:39.172173 26953 solver.cpp:244]     Train net output #0: loss = 2.03756 (* 1 = 2.03756 loss)
I0812 06:59:40.566020 26953 sgd_solver.cpp:106] Iteration 27020, lr = 0.01
I0812 06:59:58.947968 26953 solver.cpp:228] Iteration 27030, loss = 1.81102
I0812 06:59:58.948115 26953 solver.cpp:244]     Train net output #0: loss = 1.81102 (* 1 = 1.81102 loss)
I0812 07:00:00.348111 26953 sgd_solver.cpp:106] Iteration 27030, lr = 0.01
I0812 07:00:18.726274 26953 solver.cpp:228] Iteration 27040, loss = 1.95084
I0812 07:00:18.726361 26953 solver.cpp:244]     Train net output #0: loss = 1.95084 (* 1 = 1.95084 loss)
I0812 07:00:20.123430 26953 sgd_solver.cpp:106] Iteration 27040, lr = 0.01
I0812 07:00:38.543095 26953 solver.cpp:228] Iteration 27050, loss = 2.16818
I0812 07:00:38.543351 26953 solver.cpp:244]     Train net output #0: loss = 2.16818 (* 1 = 2.16818 loss)
I0812 07:00:39.952148 26953 sgd_solver.cpp:106] Iteration 27050, lr = 0.01
I0812 07:00:58.343883 26953 solver.cpp:228] Iteration 27060, loss = 2.06407
I0812 07:00:58.343955 26953 solver.cpp:244]     Train net output #0: loss = 2.06407 (* 1 = 2.06407 loss)
I0812 07:00:59.745386 26953 sgd_solver.cpp:106] Iteration 27060, lr = 0.01
I0812 07:01:18.147622 26953 solver.cpp:228] Iteration 27070, loss = 2.04892
I0812 07:01:18.147860 26953 solver.cpp:244]     Train net output #0: loss = 2.04892 (* 1 = 2.04892 loss)
I0812 07:01:19.541066 26953 sgd_solver.cpp:106] Iteration 27070, lr = 0.01
I0812 07:01:37.986039 26953 solver.cpp:228] Iteration 27080, loss = 1.87315
I0812 07:01:37.986119 26953 solver.cpp:244]     Train net output #0: loss = 1.87315 (* 1 = 1.87315 loss)
I0812 07:01:39.400193 26953 sgd_solver.cpp:106] Iteration 27080, lr = 0.01
I0812 07:01:57.765034 26953 solver.cpp:228] Iteration 27090, loss = 1.82931
I0812 07:01:57.765266 26953 solver.cpp:244]     Train net output #0: loss = 1.82931 (* 1 = 1.82931 loss)
I0812 07:01:59.168180 26953 sgd_solver.cpp:106] Iteration 27090, lr = 0.01
I0812 07:02:16.969532 26953 solver.cpp:337] Iteration 27100, Testing net (#0)
I0812 07:02:17.559942 26953 solver.cpp:404]     Test net output #0: accuracy = 0.532
I0812 07:02:17.560000 26953 solver.cpp:404]     Test net output #1: loss = 2.0382 (* 1 = 2.0382 loss)
I0812 07:02:18.133800 26953 solver.cpp:228] Iteration 27100, loss = 2.05561
I0812 07:02:18.133890 26953 solver.cpp:244]     Train net output #0: loss = 2.05561 (* 1 = 2.05561 loss)
I0812 07:02:19.493960 26953 sgd_solver.cpp:106] Iteration 27100, lr = 0.01
I0812 07:02:37.901693 26953 solver.cpp:228] Iteration 27110, loss = 1.95357
I0812 07:02:37.901923 26953 solver.cpp:244]     Train net output #0: loss = 1.95357 (* 1 = 1.95357 loss)
I0812 07:02:39.303933 26953 sgd_solver.cpp:106] Iteration 27110, lr = 0.01
I0812 07:02:57.644556 26953 solver.cpp:228] Iteration 27120, loss = 1.90709
I0812 07:02:57.644639 26953 solver.cpp:244]     Train net output #0: loss = 1.90709 (* 1 = 1.90709 loss)
I0812 07:02:59.040154 26953 sgd_solver.cpp:106] Iteration 27120, lr = 0.01
I0812 07:03:17.449362 26953 solver.cpp:228] Iteration 27130, loss = 2.12244
I0812 07:03:17.449589 26953 solver.cpp:244]     Train net output #0: loss = 2.12244 (* 1 = 2.12244 loss)
I0812 07:03:18.829071 26953 sgd_solver.cpp:106] Iteration 27130, lr = 0.01
I0812 07:03:37.268215 26953 solver.cpp:228] Iteration 27140, loss = 2.05739
I0812 07:03:37.268287 26953 solver.cpp:244]     Train net output #0: loss = 2.05739 (* 1 = 2.05739 loss)
I0812 07:03:38.661291 26953 sgd_solver.cpp:106] Iteration 27140, lr = 0.01
I0812 07:03:57.037513 26953 solver.cpp:228] Iteration 27150, loss = 1.95901
I0812 07:03:57.037670 26953 solver.cpp:244]     Train net output #0: loss = 1.95901 (* 1 = 1.95901 loss)
I0812 07:03:58.452399 26953 sgd_solver.cpp:106] Iteration 27150, lr = 0.01
I0812 07:04:16.905786 26953 solver.cpp:228] Iteration 27160, loss = 2.15959
I0812 07:04:16.905859 26953 solver.cpp:244]     Train net output #0: loss = 2.15959 (* 1 = 2.15959 loss)
I0812 07:04:18.297149 26953 sgd_solver.cpp:106] Iteration 27160, lr = 0.01
I0812 07:04:36.676542 26953 solver.cpp:228] Iteration 27170, loss = 2.09918
I0812 07:04:36.676748 26953 solver.cpp:244]     Train net output #0: loss = 2.09918 (* 1 = 2.09918 loss)
I0812 07:04:38.099196 26953 sgd_solver.cpp:106] Iteration 27170, lr = 0.01
I0812 07:04:56.459327 26953 solver.cpp:228] Iteration 27180, loss = 1.99484
I0812 07:04:56.459401 26953 solver.cpp:244]     Train net output #0: loss = 1.99484 (* 1 = 1.99484 loss)
I0812 07:04:57.878420 26953 sgd_solver.cpp:106] Iteration 27180, lr = 0.01
I0812 07:05:16.309932 26953 solver.cpp:228] Iteration 27190, loss = 2.07909
I0812 07:05:16.310128 26953 solver.cpp:244]     Train net output #0: loss = 2.07909 (* 1 = 2.07909 loss)
I0812 07:05:17.715330 26953 sgd_solver.cpp:106] Iteration 27190, lr = 0.01
I0812 07:05:35.494012 26953 solver.cpp:337] Iteration 27200, Testing net (#0)
I0812 07:05:36.090387 26953 solver.cpp:404]     Test net output #0: accuracy = 0.538
I0812 07:05:36.090456 26953 solver.cpp:404]     Test net output #1: loss = 2.08951 (* 1 = 2.08951 loss)
I0812 07:05:36.665159 26953 solver.cpp:228] Iteration 27200, loss = 2.22754
I0812 07:05:36.665235 26953 solver.cpp:244]     Train net output #0: loss = 2.22754 (* 1 = 2.22754 loss)
I0812 07:05:38.030091 26953 sgd_solver.cpp:106] Iteration 27200, lr = 0.01
I0812 07:05:56.458679 26953 solver.cpp:228] Iteration 27210, loss = 2.1469
I0812 07:05:56.458920 26953 solver.cpp:244]     Train net output #0: loss = 2.1469 (* 1 = 2.1469 loss)
I0812 07:05:57.855553 26953 sgd_solver.cpp:106] Iteration 27210, lr = 0.01
I0812 07:06:16.243710 26953 solver.cpp:228] Iteration 27220, loss = 2.01732
I0812 07:06:16.243789 26953 solver.cpp:244]     Train net output #0: loss = 2.01732 (* 1 = 2.01732 loss)
I0812 07:06:17.659862 26953 sgd_solver.cpp:106] Iteration 27220, lr = 0.01
I0812 07:06:36.120857 26953 solver.cpp:228] Iteration 27230, loss = 2.00371
I0812 07:06:36.121068 26953 solver.cpp:244]     Train net output #0: loss = 2.00371 (* 1 = 2.00371 loss)
I0812 07:06:37.514008 26953 sgd_solver.cpp:106] Iteration 27230, lr = 0.01
I0812 07:06:55.919478 26953 solver.cpp:228] Iteration 27240, loss = 2.30266
I0812 07:06:55.919549 26953 solver.cpp:244]     Train net output #0: loss = 2.30266 (* 1 = 2.30266 loss)
I0812 07:06:57.322904 26953 sgd_solver.cpp:106] Iteration 27240, lr = 0.01
I0812 07:07:15.679350 26953 solver.cpp:228] Iteration 27250, loss = 1.94391
I0812 07:07:15.679581 26953 solver.cpp:244]     Train net output #0: loss = 1.94391 (* 1 = 1.94391 loss)
I0812 07:07:17.077219 26953 sgd_solver.cpp:106] Iteration 27250, lr = 0.01
I0812 07:07:35.515292 26953 solver.cpp:228] Iteration 27260, loss = 1.91776
I0812 07:07:35.515360 26953 solver.cpp:244]     Train net output #0: loss = 1.91776 (* 1 = 1.91776 loss)
I0812 07:07:36.921913 26953 sgd_solver.cpp:106] Iteration 27260, lr = 0.01
I0812 07:07:55.264418 26953 solver.cpp:228] Iteration 27270, loss = 2.05924
I0812 07:07:55.264618 26953 solver.cpp:244]     Train net output #0: loss = 2.05924 (* 1 = 2.05924 loss)
I0812 07:07:56.672349 26953 sgd_solver.cpp:106] Iteration 27270, lr = 0.01
I0812 07:08:15.025882 26953 solver.cpp:228] Iteration 27280, loss = 1.98733
I0812 07:08:15.025954 26953 solver.cpp:244]     Train net output #0: loss = 1.98733 (* 1 = 1.98733 loss)
I0812 07:08:16.426575 26953 sgd_solver.cpp:106] Iteration 27280, lr = 0.01
I0812 07:08:34.846894 26953 solver.cpp:228] Iteration 27290, loss = 2.15826
I0812 07:08:34.847121 26953 solver.cpp:244]     Train net output #0: loss = 2.15826 (* 1 = 2.15826 loss)
I0812 07:08:36.249064 26953 sgd_solver.cpp:106] Iteration 27290, lr = 0.01
I0812 07:08:54.069902 26953 solver.cpp:337] Iteration 27300, Testing net (#0)
I0812 07:08:54.663916 26953 solver.cpp:404]     Test net output #0: accuracy = 0.48
I0812 07:08:54.664006 26953 solver.cpp:404]     Test net output #1: loss = 2.32918 (* 1 = 2.32918 loss)
I0812 07:08:55.223016 26953 solver.cpp:228] Iteration 27300, loss = 2.03554
I0812 07:08:55.223088 26953 solver.cpp:244]     Train net output #0: loss = 2.03554 (* 1 = 2.03554 loss)
I0812 07:08:56.604943 26953 sgd_solver.cpp:106] Iteration 27300, lr = 0.01
I0812 07:09:14.941339 26953 solver.cpp:228] Iteration 27310, loss = 2.06319
I0812 07:09:14.943006 26953 solver.cpp:244]     Train net output #0: loss = 2.06319 (* 1 = 2.06319 loss)
I0812 07:09:16.330281 26953 sgd_solver.cpp:106] Iteration 27310, lr = 0.01
I0812 07:09:34.753650 26953 solver.cpp:228] Iteration 27320, loss = 1.91069
I0812 07:09:34.753726 26953 solver.cpp:244]     Train net output #0: loss = 1.91069 (* 1 = 1.91069 loss)
I0812 07:09:36.151695 26953 sgd_solver.cpp:106] Iteration 27320, lr = 0.01
I0812 07:09:54.547323 26953 solver.cpp:228] Iteration 27330, loss = 2.19222
I0812 07:09:54.547523 26953 solver.cpp:244]     Train net output #0: loss = 2.19222 (* 1 = 2.19222 loss)
I0812 07:09:55.950218 26953 sgd_solver.cpp:106] Iteration 27330, lr = 0.01
I0812 07:10:14.357365 26953 solver.cpp:228] Iteration 27340, loss = 2.15508
I0812 07:10:14.357435 26953 solver.cpp:244]     Train net output #0: loss = 2.15508 (* 1 = 2.15508 loss)
I0812 07:10:15.755506 26953 sgd_solver.cpp:106] Iteration 27340, lr = 0.01
I0812 07:10:34.197857 26953 solver.cpp:228] Iteration 27350, loss = 1.81528
I0812 07:10:34.198081 26953 solver.cpp:244]     Train net output #0: loss = 1.81528 (* 1 = 1.81528 loss)
I0812 07:10:35.622035 26953 sgd_solver.cpp:106] Iteration 27350, lr = 0.01
I0812 07:10:54.008641 26953 solver.cpp:228] Iteration 27360, loss = 2.1656
I0812 07:10:54.008715 26953 solver.cpp:244]     Train net output #0: loss = 2.1656 (* 1 = 2.1656 loss)
I0812 07:10:55.403951 26953 sgd_solver.cpp:106] Iteration 27360, lr = 0.01
I0812 07:11:13.837697 26953 solver.cpp:228] Iteration 27370, loss = 2.01398
I0812 07:11:13.837925 26953 solver.cpp:244]     Train net output #0: loss = 2.01398 (* 1 = 2.01398 loss)
I0812 07:11:15.248633 26953 sgd_solver.cpp:106] Iteration 27370, lr = 0.01
I0812 07:11:33.577831 26953 solver.cpp:228] Iteration 27380, loss = 1.98575
I0812 07:11:33.577910 26953 solver.cpp:244]     Train net output #0: loss = 1.98575 (* 1 = 1.98575 loss)
I0812 07:11:35.006191 26953 sgd_solver.cpp:106] Iteration 27380, lr = 0.01
I0812 07:11:53.408841 26953 solver.cpp:228] Iteration 27390, loss = 2.05097
I0812 07:11:53.409008 26953 solver.cpp:244]     Train net output #0: loss = 2.05097 (* 1 = 2.05097 loss)
I0812 07:11:54.813045 26953 sgd_solver.cpp:106] Iteration 27390, lr = 0.01
I0812 07:12:12.641468 26953 solver.cpp:337] Iteration 27400, Testing net (#0)
I0812 07:12:13.231581 26953 solver.cpp:404]     Test net output #0: accuracy = 0.536
I0812 07:12:13.231649 26953 solver.cpp:404]     Test net output #1: loss = 2.09604 (* 1 = 2.09604 loss)
I0812 07:12:13.789216 26953 solver.cpp:228] Iteration 27400, loss = 2.00712
I0812 07:12:13.789294 26953 solver.cpp:244]     Train net output #0: loss = 2.00712 (* 1 = 2.00712 loss)
I0812 07:12:15.195569 26953 sgd_solver.cpp:106] Iteration 27400, lr = 0.01
I0812 07:12:33.614619 26953 solver.cpp:228] Iteration 27410, loss = 2.03336
I0812 07:12:33.614856 26953 solver.cpp:244]     Train net output #0: loss = 2.03336 (* 1 = 2.03336 loss)
I0812 07:12:35.017263 26953 sgd_solver.cpp:106] Iteration 27410, lr = 0.01
I0812 07:12:53.416057 26953 solver.cpp:228] Iteration 27420, loss = 1.74481
I0812 07:12:53.416128 26953 solver.cpp:244]     Train net output #0: loss = 1.74481 (* 1 = 1.74481 loss)
I0812 07:12:54.815006 26953 sgd_solver.cpp:106] Iteration 27420, lr = 0.01
I0812 07:13:13.190860 26953 solver.cpp:228] Iteration 27430, loss = 1.93481
I0812 07:13:13.191071 26953 solver.cpp:244]     Train net output #0: loss = 1.93481 (* 1 = 1.93481 loss)
I0812 07:13:14.589604 26953 sgd_solver.cpp:106] Iteration 27430, lr = 0.01
I0812 07:13:32.972499 26953 solver.cpp:228] Iteration 27440, loss = 2.0411
I0812 07:13:32.972573 26953 solver.cpp:244]     Train net output #0: loss = 2.0411 (* 1 = 2.0411 loss)
I0812 07:13:34.382220 26953 sgd_solver.cpp:106] Iteration 27440, lr = 0.01
I0812 07:13:52.790560 26953 solver.cpp:228] Iteration 27450, loss = 2.0385
I0812 07:13:52.790793 26953 solver.cpp:244]     Train net output #0: loss = 2.0385 (* 1 = 2.0385 loss)
I0812 07:13:54.207186 26953 sgd_solver.cpp:106] Iteration 27450, lr = 0.01
I0812 07:14:12.574041 26953 solver.cpp:228] Iteration 27460, loss = 1.98192
I0812 07:14:12.574136 26953 solver.cpp:244]     Train net output #0: loss = 1.98192 (* 1 = 1.98192 loss)
I0812 07:14:13.971618 26953 sgd_solver.cpp:106] Iteration 27460, lr = 0.01
I0812 07:14:32.343139 26953 solver.cpp:228] Iteration 27470, loss = 2.05528
I0812 07:14:32.343333 26953 solver.cpp:244]     Train net output #0: loss = 2.05528 (* 1 = 2.05528 loss)
I0812 07:14:33.738548 26953 sgd_solver.cpp:106] Iteration 27470, lr = 0.01
I0812 07:14:52.176893 26953 solver.cpp:228] Iteration 27480, loss = 2.03511
I0812 07:14:52.176967 26953 solver.cpp:244]     Train net output #0: loss = 2.03511 (* 1 = 2.03511 loss)
I0812 07:14:53.592073 26953 sgd_solver.cpp:106] Iteration 27480, lr = 0.01
I0812 07:15:11.943109 26953 solver.cpp:228] Iteration 27490, loss = 2.00828
I0812 07:15:11.943331 26953 solver.cpp:244]     Train net output #0: loss = 2.00828 (* 1 = 2.00828 loss)
I0812 07:15:13.344350 26953 sgd_solver.cpp:106] Iteration 27490, lr = 0.01
I0812 07:15:31.143585 26953 solver.cpp:337] Iteration 27500, Testing net (#0)
I0812 07:15:31.735280 26953 solver.cpp:404]     Test net output #0: accuracy = 0.542
I0812 07:15:31.735353 26953 solver.cpp:404]     Test net output #1: loss = 2.03853 (* 1 = 2.03853 loss)
I0812 07:15:32.318531 26953 solver.cpp:228] Iteration 27500, loss = 2.03324
I0812 07:15:32.318624 26953 solver.cpp:244]     Train net output #0: loss = 2.03324 (* 1 = 2.03324 loss)
I0812 07:15:33.692975 26953 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I0812 07:15:52.080349 26953 solver.cpp:228] Iteration 27510, loss = 1.81493
I0812 07:15:52.080577 26953 solver.cpp:244]     Train net output #0: loss = 1.81493 (* 1 = 1.81493 loss)
I0812 07:15:53.483587 26953 sgd_solver.cpp:106] Iteration 27510, lr = 0.01
I0812 07:16:11.866279 26953 solver.cpp:228] Iteration 27520, loss = 2.23132
I0812 07:16:11.866350 26953 solver.cpp:244]     Train net output #0: loss = 2.23132 (* 1 = 2.23132 loss)
I0812 07:16:13.264704 26953 sgd_solver.cpp:106] Iteration 27520, lr = 0.01
I0812 07:16:31.646785 26953 solver.cpp:228] Iteration 27530, loss = 1.99844
I0812 07:16:31.647011 26953 solver.cpp:244]     Train net output #0: loss = 1.99844 (* 1 = 1.99844 loss)
I0812 07:16:33.046957 26953 sgd_solver.cpp:106] Iteration 27530, lr = 0.01
I0812 07:16:51.433117 26953 solver.cpp:228] Iteration 27540, loss = 1.81831
I0812 07:16:51.433182 26953 solver.cpp:244]     Train net output #0: loss = 1.81831 (* 1 = 1.81831 loss)
I0812 07:16:52.827321 26953 sgd_solver.cpp:106] Iteration 27540, lr = 0.01
I0812 07:17:11.209434 26953 solver.cpp:228] Iteration 27550, loss = 1.88364
I0812 07:17:11.209681 26953 solver.cpp:244]     Train net output #0: loss = 1.88364 (* 1 = 1.88364 loss)
I0812 07:17:12.595521 26953 sgd_solver.cpp:106] Iteration 27550, lr = 0.01
I0812 07:17:30.971107 26953 solver.cpp:228] Iteration 27560, loss = 2.02633
I0812 07:17:30.971169 26953 solver.cpp:244]     Train net output #0: loss = 2.02633 (* 1 = 2.02633 loss)
I0812 07:17:32.361670 26953 sgd_solver.cpp:106] Iteration 27560, lr = 0.01
I0812 07:17:50.833065 26953 solver.cpp:228] Iteration 27570, loss = 1.93316
I0812 07:17:50.833320 26953 solver.cpp:244]     Train net output #0: loss = 1.93316 (* 1 = 1.93316 loss)
I0812 07:17:52.246997 26953 sgd_solver.cpp:106] Iteration 27570, lr = 0.01
I0812 07:18:10.627723 26953 solver.cpp:228] Iteration 27580, loss = 1.91134
I0812 07:18:10.627794 26953 solver.cpp:244]     Train net output #0: loss = 1.91134 (* 1 = 1.91134 loss)
I0812 07:18:12.032313 26953 sgd_solver.cpp:106] Iteration 27580, lr = 0.01
I0812 07:18:30.407281 26953 solver.cpp:228] Iteration 27590, loss = 1.88605
I0812 07:18:30.407426 26953 solver.cpp:244]     Train net output #0: loss = 1.88605 (* 1 = 1.88605 loss)
I0812 07:18:31.803073 26953 sgd_solver.cpp:106] Iteration 27590, lr = 0.01
I0812 07:18:49.604501 26953 solver.cpp:337] Iteration 27600, Testing net (#0)
I0812 07:18:50.196187 26953 solver.cpp:404]     Test net output #0: accuracy = 0.508
I0812 07:18:50.196247 26953 solver.cpp:404]     Test net output #1: loss = 2.11447 (* 1 = 2.11447 loss)
I0812 07:18:50.758916 26953 solver.cpp:228] Iteration 27600, loss = 1.91931
I0812 07:18:50.759011 26953 solver.cpp:244]     Train net output #0: loss = 1.91931 (* 1 = 1.91931 loss)
I0812 07:18:52.144194 26953 sgd_solver.cpp:106] Iteration 27600, lr = 0.01
I0812 07:19:10.518494 26953 solver.cpp:228] Iteration 27610, loss = 2.02842
I0812 07:19:10.518692 26953 solver.cpp:244]     Train net output #0: loss = 2.02842 (* 1 = 2.02842 loss)
I0812 07:19:11.896859 26953 sgd_solver.cpp:106] Iteration 27610, lr = 0.01
I0812 07:19:30.334105 26953 solver.cpp:228] Iteration 27620, loss = 1.98336
I0812 07:19:30.334167 26953 solver.cpp:244]     Train net output #0: loss = 1.98336 (* 1 = 1.98336 loss)
I0812 07:19:31.727701 26953 sgd_solver.cpp:106] Iteration 27620, lr = 0.01
I0812 07:19:50.129714 26953 solver.cpp:228] Iteration 27630, loss = 1.88341
I0812 07:19:50.129943 26953 solver.cpp:244]     Train net output #0: loss = 1.88341 (* 1 = 1.88341 loss)
I0812 07:19:51.543503 26953 sgd_solver.cpp:106] Iteration 27630, lr = 0.01
I0812 07:20:09.932559 26953 solver.cpp:228] Iteration 27640, loss = 2.01755
I0812 07:20:09.932626 26953 solver.cpp:244]     Train net output #0: loss = 2.01755 (* 1 = 2.01755 loss)
I0812 07:20:11.327540 26953 sgd_solver.cpp:106] Iteration 27640, lr = 0.01
I0812 07:20:29.771492 26953 solver.cpp:228] Iteration 27650, loss = 2.18862
I0812 07:20:29.771708 26953 solver.cpp:244]     Train net output #0: loss = 2.18862 (* 1 = 2.18862 loss)
I0812 07:20:31.180304 26953 sgd_solver.cpp:106] Iteration 27650, lr = 0.01
I0812 07:20:49.554409 26953 solver.cpp:228] Iteration 27660, loss = 1.94117
I0812 07:20:49.554481 26953 solver.cpp:244]     Train net output #0: loss = 1.94117 (* 1 = 1.94117 loss)
I0812 07:20:50.946105 26953 sgd_solver.cpp:106] Iteration 27660, lr = 0.01
I0812 07:21:09.392441 26953 solver.cpp:228] Iteration 27670, loss = 1.82619
I0812 07:21:09.392596 26953 solver.cpp:244]     Train net output #0: loss = 1.82619 (* 1 = 1.82619 loss)
I0812 07:21:10.793834 26953 sgd_solver.cpp:106] Iteration 27670, lr = 0.01
I0812 07:21:29.164453 26953 solver.cpp:228] Iteration 27680, loss = 1.79881
I0812 07:21:29.164537 26953 solver.cpp:244]     Train net output #0: loss = 1.79881 (* 1 = 1.79881 loss)
I0812 07:21:30.567530 26953 sgd_solver.cpp:106] Iteration 27680, lr = 0.01
I0812 07:21:49.005044 26953 solver.cpp:228] Iteration 27690, loss = 1.98403
I0812 07:21:49.005259 26953 solver.cpp:244]     Train net output #0: loss = 1.98403 (* 1 = 1.98403 loss)
I0812 07:21:50.397117 26953 sgd_solver.cpp:106] Iteration 27690, lr = 0.01
I0812 07:22:08.243319 26953 solver.cpp:337] Iteration 27700, Testing net (#0)
I0812 07:22:08.831734 26953 solver.cpp:404]     Test net output #0: accuracy = 0.52
I0812 07:22:08.831799 26953 solver.cpp:404]     Test net output #1: loss = 2.21892 (* 1 = 2.21892 loss)
I0812 07:22:09.408504 26953 solver.cpp:228] Iteration 27700, loss = 2.09302
I0812 07:22:09.408578 26953 solver.cpp:244]     Train net output #0: loss = 2.09302 (* 1 = 2.09302 loss)
I0812 07:22:10.783790 26953 sgd_solver.cpp:106] Iteration 27700, lr = 0.01
I0812 07:22:29.167762 26953 solver.cpp:228] Iteration 27710, loss = 1.84574
I0812 07:22:29.168005 26953 solver.cpp:244]     Train net output #0: loss = 1.84574 (* 1 = 1.84574 loss)
I0812 07:22:30.567700 26953 sgd_solver.cpp:106] Iteration 27710, lr = 0.01
I0812 07:22:48.982744 26953 solver.cpp:228] Iteration 27720, loss = 2.08638
I0812 07:22:48.982833 26953 solver.cpp:244]     Train net output #0: loss = 2.08638 (* 1 = 2.08638 loss)
I0812 07:22:50.373188 26953 sgd_solver.cpp:106] Iteration 27720, lr = 0.01
I0812 07:23:08.739683 26953 solver.cpp:228] Iteration 27730, loss = 1.99935
I0812 07:23:08.739912 26953 solver.cpp:244]     Train net output #0: loss = 1.99935 (* 1 = 1.99935 loss)
I0812 07:23:10.147639 26953 sgd_solver.cpp:106] Iteration 27730, lr = 0.01
I0812 07:23:28.542570 26953 solver.cpp:228] Iteration 27740, loss = 2.08253
I0812 07:23:28.542665 26953 solver.cpp:244]     Train net output #0: loss = 2.08253 (* 1 = 2.08253 loss)
I0812 07:23:29.951025 26953 sgd_solver.cpp:106] Iteration 27740, lr = 0.01
I0812 07:23:48.353829 26953 solver.cpp:228] Iteration 27750, loss = 2.07809
I0812 07:23:48.354063 26953 solver.cpp:244]     Train net output #0: loss = 2.07809 (* 1 = 2.07809 loss)
I0812 07:23:49.758726 26953 sgd_solver.cpp:106] Iteration 27750, lr = 0.01
I0812 07:24:08.095039 26953 solver.cpp:228] Iteration 27760, loss = 1.99947
I0812 07:24:08.095130 26953 solver.cpp:244]     Train net output #0: loss = 1.99947 (* 1 = 1.99947 loss)
I0812 07:24:09.506875 26953 sgd_solver.cpp:106] Iteration 27760, lr = 0.01
I0812 07:24:27.910567 26953 solver.cpp:228] Iteration 27770, loss = 2.15653
I0812 07:24:27.910854 26953 solver.cpp:244]     Train net output #0: loss = 2.15653 (* 1 = 2.15653 loss)
I0812 07:24:29.303742 26953 sgd_solver.cpp:106] Iteration 27770, lr = 0.01
I0812 07:24:47.707195 26953 solver.cpp:228] Iteration 27780, loss = 2.09708
I0812 07:24:47.707265 26953 solver.cpp:244]     Train net output #0: loss = 2.09708 (* 1 = 2.09708 loss)
I0812 07:24:49.115528 26953 sgd_solver.cpp:106] Iteration 27780, lr = 0.01
I0812 07:25:07.493764 26953 solver.cpp:228] Iteration 27790, loss = 1.96754
I0812 07:25:07.494006 26953 solver.cpp:244]     Train net output #0: loss = 1.96754 (* 1 = 1.96754 loss)
I0812 07:25:08.892108 26953 sgd_solver.cpp:106] Iteration 27790, lr = 0.01
I0812 07:25:26.757783 26953 solver.cpp:337] Iteration 27800, Testing net (#0)
I0812 07:25:27.341857 26953 solver.cpp:404]     Test net output #0: accuracy = 0.514
I0812 07:25:27.341920 26953 solver.cpp:404]     Test net output #1: loss = 2.2432 (* 1 = 2.2432 loss)
I0812 07:25:27.917510 26953 solver.cpp:228] Iteration 27800, loss = 2.03786
I0812 07:25:27.917593 26953 solver.cpp:244]     Train net output #0: loss = 2.03786 (* 1 = 2.03786 loss)
I0812 07:25:29.295809 26953 sgd_solver.cpp:106] Iteration 27800, lr = 0.01
I0812 07:25:47.674124 26953 solver.cpp:228] Iteration 27810, loss = 1.96861
I0812 07:25:47.674278 26953 solver.cpp:244]     Train net output #0: loss = 1.96861 (* 1 = 1.96861 loss)
I0812 07:25:49.079872 26953 sgd_solver.cpp:106] Iteration 27810, lr = 0.01
I0812 07:26:07.475637 26953 solver.cpp:228] Iteration 27820, loss = 2.01241
I0812 07:26:07.475713 26953 solver.cpp:244]     Train net output #0: loss = 2.01241 (* 1 = 2.01241 loss)
I0812 07:26:08.867017 26953 sgd_solver.cpp:106] Iteration 27820, lr = 0.01
I0812 07:26:27.270368 26953 solver.cpp:228] Iteration 27830, loss = 2.08561
I0812 07:26:27.270622 26953 solver.cpp:244]     Train net output #0: loss = 2.08561 (* 1 = 2.08561 loss)
I0812 07:26:28.662468 26953 sgd_solver.cpp:106] Iteration 27830, lr = 0.01
I0812 07:26:47.045336 26953 solver.cpp:228] Iteration 27840, loss = 1.9575
I0812 07:26:47.045404 26953 solver.cpp:244]     Train net output #0: loss = 1.9575 (* 1 = 1.9575 loss)
I0812 07:26:48.456248 26953 sgd_solver.cpp:106] Iteration 27840, lr = 0.01
I0812 07:27:06.810955 26953 solver.cpp:228] Iteration 27850, loss = 1.87429
I0812 07:27:06.811203 26953 solver.cpp:244]     Train net output #0: loss = 1.87429 (* 1 = 1.87429 loss)
I0812 07:27:08.205396 26953 sgd_solver.cpp:106] Iteration 27850, lr = 0.01
I0812 07:27:26.662688 26953 solver.cpp:228] Iteration 27860, loss = 1.98979
I0812 07:27:26.662778 26953 solver.cpp:244]     Train net output #0: loss = 1.98979 (* 1 = 1.98979 loss)
I0812 07:27:28.072232 26953 sgd_solver.cpp:106] Iteration 27860, lr = 0.01
I0812 07:27:46.422435 26953 solver.cpp:228] Iteration 27870, loss = 2.03511
I0812 07:27:46.422701 26953 solver.cpp:244]     Train net output #0: loss = 2.03511 (* 1 = 2.03511 loss)
I0812 07:27:47.838799 26953 sgd_solver.cpp:106] Iteration 27870, lr = 0.01
I0812 07:28:06.261610 26953 solver.cpp:228] Iteration 27880, loss = 2.01436
I0812 07:28:06.261683 26953 solver.cpp:244]     Train net output #0: loss = 2.01436 (* 1 = 2.01436 loss)
I0812 07:28:07.647378 26953 sgd_solver.cpp:106] Iteration 27880, lr = 0.01
I0812 07:28:26.041296 26953 solver.cpp:228] Iteration 27890, loss = 1.97412
I0812 07:28:26.041494 26953 solver.cpp:244]     Train net output #0: loss = 1.97412 (* 1 = 1.97412 loss)
I0812 07:28:27.450403 26953 sgd_solver.cpp:106] Iteration 27890, lr = 0.01
I0812 07:28:45.235556 26953 solver.cpp:337] Iteration 27900, Testing net (#0)
I0812 07:28:45.830387 26953 solver.cpp:404]     Test net output #0: accuracy = 0.532
I0812 07:28:45.830443 26953 solver.cpp:404]     Test net output #1: loss = 2.07996 (* 1 = 2.07996 loss)
I0812 07:28:46.422032 26953 solver.cpp:228] Iteration 27900, loss = 2.02091
I0812 07:28:46.422124 26953 solver.cpp:244]     Train net output #0: loss = 2.02091 (* 1 = 2.02091 loss)
I0812 07:28:47.773290 26953 sgd_solver.cpp:106] Iteration 27900, lr = 0.01
I0812 07:29:06.218915 26953 solver.cpp:228] Iteration 27910, loss = 2.07404
I0812 07:29:06.219151 26953 solver.cpp:244]     Train net output #0: loss = 2.07404 (* 1 = 2.07404 loss)
I0812 07:29:07.622941 26953 sgd_solver.cpp:106] Iteration 27910, lr = 0.01
I0812 07:29:25.983156 26953 solver.cpp:228] Iteration 27920, loss = 2.06572
I0812 07:29:25.983230 26953 solver.cpp:244]     Train net output #0: loss = 2.06572 (* 1 = 2.06572 loss)
I0812 07:29:27.390290 26953 sgd_solver.cpp:106] Iteration 27920, lr = 0.01
I0812 07:29:45.801134 26953 solver.cpp:228] Iteration 27930, loss = 1.99104
I0812 07:29:45.801375 26953 solver.cpp:244]     Train net output #0: loss = 1.99104 (* 1 = 1.99104 loss)
I0812 07:29:47.194643 26953 sgd_solver.cpp:106] Iteration 27930, lr = 0.01
I0812 07:30:05.609091 26953 solver.cpp:228] Iteration 27940, loss = 2.03969
I0812 07:30:05.609161 26953 solver.cpp:244]     Train net output #0: loss = 2.03969 (* 1 = 2.03969 loss)
I0812 07:30:07.012821 26953 sgd_solver.cpp:106] Iteration 27940, lr = 0.01
I0812 07:30:25.364549 26953 solver.cpp:228] Iteration 27950, loss = 1.86442
I0812 07:30:25.364722 26953 solver.cpp:244]     Train net output #0: loss = 1.86442 (* 1 = 1.86442 loss)
I0812 07:30:26.771482 26953 sgd_solver.cpp:106] Iteration 27950, lr = 0.01
I0812 07:30:45.173030 26953 solver.cpp:228] Iteration 27960, loss = 2.01272
I0812 07:30:45.173108 26953 solver.cpp:244]     Train net output #0: loss = 2.01272 (* 1 = 2.01272 loss)
I0812 07:30:46.566761 26953 sgd_solver.cpp:106] Iteration 27960, lr = 0.01
I0812 07:31:04.959477 26953 solver.cpp:228] Iteration 27970, loss = 2.21915
I0812 07:31:04.959632 26953 solver.cpp:244]     Train net output #0: loss = 2.21915 (* 1 = 2.21915 loss)
I0812 07:31:06.370045 26953 sgd_solver.cpp:106] Iteration 27970, lr = 0.01
I0812 07:31:24.713732 26953 solver.cpp:228] Iteration 27980, loss = 1.96313
I0812 07:31:24.713796 26953 solver.cpp:244]     Train net output #0: loss = 1.96313 (* 1 = 1.96313 loss)
I0812 07:31:26.114392 26953 sgd_solver.cpp:106] Iteration 27980, lr = 0.01
I0812 07:31:44.489217 26953 solver.cpp:228] Iteration 27990, loss = 2.0399
I0812 07:31:44.489470 26953 solver.cpp:244]     Train net output #0: loss = 2.0399 (* 1 = 2.0399 loss)
I0812 07:31:45.887240 26953 sgd_solver.cpp:106] Iteration 27990, lr = 0.01
I0812 07:32:03.727041 26953 solver.cpp:337] Iteration 28000, Testing net (#0)
I0812 07:32:04.316171 26953 solver.cpp:404]     Test net output #0: accuracy = 0.474
I0812 07:32:04.316242 26953 solver.cpp:404]     Test net output #1: loss = 2.37176 (* 1 = 2.37176 loss)
I0812 07:32:04.888283 26953 solver.cpp:228] Iteration 28000, loss = 2.05122
I0812 07:32:04.888360 26953 solver.cpp:244]     Train net output #0: loss = 2.05122 (* 1 = 2.05122 loss)
I0812 07:32:06.278189 26953 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I0812 07:32:24.675920 26953 solver.cpp:228] Iteration 28010, loss = 1.89953
I0812 07:32:24.676127 26953 solver.cpp:244]     Train net output #0: loss = 1.89953 (* 1 = 1.89953 loss)
I0812 07:32:26.070158 26953 sgd_solver.cpp:106] Iteration 28010, lr = 0.01
I0812 07:32:44.491492 26953 solver.cpp:228] Iteration 28020, loss = 1.92018
I0812 07:32:44.491580 26953 solver.cpp:244]     Train net output #0: loss = 1.92018 (* 1 = 1.92018 loss)
I0812 07:32:45.894103 26953 sgd_solver.cpp:106] Iteration 28020, lr = 0.01
I0812 07:33:04.261641 26953 solver.cpp:228] Iteration 28030, loss = 1.83639
I0812 07:33:04.262960 26953 solver.cpp:244]     Train net output #0: loss = 1.83639 (* 1 = 1.83639 loss)
I0812 07:33:05.658890 26953 sgd_solver.cpp:106] Iteration 28030, lr = 0.01
I0812 07:33:24.010536 26953 solver.cpp:228] Iteration 28040, loss = 1.96632
I0812 07:33:24.010610 26953 solver.cpp:244]     Train net output #0: loss = 1.96632 (* 1 = 1.96632 loss)
I0812 07:33:25.415583 26953 sgd_solver.cpp:106] Iteration 28040, lr = 0.01
I0812 07:33:43.809375 26953 solver.cpp:228] Iteration 28050, loss = 2.01003
I0812 07:33:43.809569 26953 solver.cpp:244]     Train net output #0: loss = 2.01003 (* 1 = 2.01003 loss)
I0812 07:33:45.196041 26953 sgd_solver.cpp:106] Iteration 28050, lr = 0.01
I0812 07:34:03.623919 26953 solver.cpp:228] Iteration 28060, loss = 1.90307
I0812 07:34:03.624001 26953 solver.cpp:244]     Train net output #0: loss = 1.90307 (* 1 = 1.90307 loss)
I0812 07:34:05.016897 26953 sgd_solver.cpp:106] Iteration 28060, lr = 0.01
I0812 07:34:23.386893 26953 solver.cpp:228] Iteration 28070, loss = 1.99489
I0812 07:34:23.387186 26953 solver.cpp:244]     Train net output #0: loss = 1.99489 (* 1 = 1.99489 loss)
I0812 07:34:24.804016 26953 sgd_solver.cpp:106] Iteration 28070, lr = 0.01
I0812 07:34:43.161299 26953 solver.cpp:228] Iteration 28080, loss = 2.04241
I0812 07:34:43.161370 26953 solver.cpp:244]     Train net output #0: loss = 2.04241 (* 1 = 2.04241 loss)
I0812 07:34:44.560555 26953 sgd_solver.cpp:106] Iteration 28080, lr = 0.01
I0812 07:35:02.974433 26953 solver.cpp:228] Iteration 28090, loss = 1.94784
I0812 07:35:02.974648 26953 solver.cpp:244]     Train net output #0: loss = 1.94784 (* 1 = 1.94784 loss)
I0812 07:35:04.363095 26953 sgd_solver.cpp:106] Iteration 28090, lr = 0.01
I0812 07:35:22.145386 26953 solver.cpp:337] Iteration 28100, Testing net (#0)
I0812 07:35:22.733963 26953 solver.cpp:404]     Test net output #0: accuracy = 0.538
I0812 07:35:22.734035 26953 solver.cpp:404]     Test net output #1: loss = 2.09917 (* 1 = 2.09917 loss)
I0812 07:35:23.306064 26953 solver.cpp:228] Iteration 28100, loss = 1.80351
I0812 07:35:23.306152 26953 solver.cpp:244]     Train net output #0: loss = 1.80351 (* 1 = 1.80351 loss)
I0812 07:35:24.675097 26953 sgd_solver.cpp:106] Iteration 28100, lr = 0.01
I0812 07:35:43.095780 26953 solver.cpp:228] Iteration 28110, loss = 2.09245
I0812 07:35:43.095929 26953 solver.cpp:244]     Train net output #0: loss = 2.09245 (* 1 = 2.09245 loss)
I0812 07:35:44.489663 26953 sgd_solver.cpp:106] Iteration 28110, lr = 0.01
I0812 07:36:02.883680 26953 solver.cpp:228] Iteration 28120, loss = 1.82995
I0812 07:36:02.883754 26953 solver.cpp:244]     Train net output #0: loss = 1.82995 (* 1 = 1.82995 loss)
I0812 07:36:04.300297 26953 sgd_solver.cpp:106] Iteration 28120, lr = 0.01
I0812 07:36:22.672915 26953 solver.cpp:228] Iteration 28130, loss = 1.9885
I0812 07:36:22.673131 26953 solver.cpp:244]     Train net output #0: loss = 1.9885 (* 1 = 1.9885 loss)
I0812 07:36:24.067400 26953 sgd_solver.cpp:106] Iteration 28130, lr = 0.01
I0812 07:36:42.478238 26953 solver.cpp:228] Iteration 28140, loss = 2.10074
I0812 07:36:42.478313 26953 solver.cpp:244]     Train net output #0: loss = 2.10074 (* 1 = 2.10074 loss)
I0812 07:36:43.889039 26953 sgd_solver.cpp:106] Iteration 28140, lr = 0.01
I0812 07:37:02.282168 26953 solver.cpp:228] Iteration 28150, loss = 2.02594
I0812 07:37:02.282313 26953 solver.cpp:244]     Train net output #0: loss = 2.02594 (* 1 = 2.02594 loss)
I0812 07:37:03.679029 26953 sgd_solver.cpp:106] Iteration 28150, lr = 0.01
I0812 07:37:22.048620 26953 solver.cpp:228] Iteration 28160, loss = 1.89399
I0812 07:37:22.048681 26953 solver.cpp:244]     Train net output #0: loss = 1.89399 (* 1 = 1.89399 loss)
I0812 07:37:23.453060 26953 sgd_solver.cpp:106] Iteration 28160, lr = 0.01
I0812 07:37:41.919549 26953 solver.cpp:228] Iteration 28170, loss = 1.97574
I0812 07:37:41.919701 26953 solver.cpp:244]     Train net output #0: loss = 1.97574 (* 1 = 1.97574 loss)
I0812 07:37:43.316591 26953 sgd_solver.cpp:106] Iteration 28170, lr = 0.01
I0812 07:38:01.703377 26953 solver.cpp:228] Iteration 28180, loss = 2.05183
I0812 07:38:01.703434 26953 solver.cpp:244]     Train net output #0: loss = 2.05183 (* 1 = 2.05183 loss)
I0812 07:38:03.120177 26953 sgd_solver.cpp:106] Iteration 28180, lr = 0.01
I0812 07:38:21.499721 26953 solver.cpp:228] Iteration 28190, loss = 2.04753
I0812 07:38:21.499864 26953 solver.cpp:244]     Train net output #0: loss = 2.04753 (* 1 = 2.04753 loss)
I0812 07:38:22.902449 26953 sgd_solver.cpp:106] Iteration 28190, lr = 0.01
I0812 07:38:40.721556 26953 solver.cpp:337] Iteration 28200, Testing net (#0)
I0812 07:38:41.315016 26953 solver.cpp:404]     Test net output #0: accuracy = 0.53
I0812 07:38:41.315084 26953 solver.cpp:404]     Test net output #1: loss = 2.23548 (* 1 = 2.23548 loss)
I0812 07:38:41.880128 26953 solver.cpp:228] Iteration 28200, loss = 2.01414
I0812 07:38:41.880224 26953 solver.cpp:244]     Train net output #0: loss = 2.01414 (* 1 = 2.01414 loss)
I0812 07:38:43.261059 26953 sgd_solver.cpp:106] Iteration 28200, lr = 0.01
I0812 07:39:01.666658 26953 solver.cpp:228] Iteration 28210, loss = 2.05188
I0812 07:39:01.666826 26953 solver.cpp:244]     Train net output #0: loss = 2.05188 (* 1 = 2.05188 loss)
I0812 07:39:03.054132 26953 sgd_solver.cpp:106] Iteration 28210, lr = 0.01
I0812 07:39:21.452042 26953 solver.cpp:228] Iteration 28220, loss = 1.99784
I0812 07:39:21.452103 26953 solver.cpp:244]     Train net output #0: loss = 1.99784 (* 1 = 1.99784 loss)
I0812 07:39:22.854157 26953 sgd_solver.cpp:106] Iteration 28220, lr = 0.01
I0812 07:39:41.246301 26953 solver.cpp:228] Iteration 28230, loss = 1.9466
I0812 07:39:41.246493 26953 solver.cpp:244]     Train net output #0: loss = 1.9466 (* 1 = 1.9466 loss)
I0812 07:39:42.665781 26953 sgd_solver.cpp:106] Iteration 28230, lr = 0.01
I0812 07:40:01.087425 26953 solver.cpp:228] Iteration 28240, loss = 1.92414
I0812 07:40:01.087492 26953 solver.cpp:244]     Train net output #0: loss = 1.92414 (* 1 = 1.92414 loss)
I0812 07:40:02.491574 26953 sgd_solver.cpp:106] Iteration 28240, lr = 0.01
I0812 07:40:20.892689 26953 solver.cpp:228] Iteration 28250, loss = 2.05986
I0812 07:40:20.892938 26953 solver.cpp:244]     Train net output #0: loss = 2.05986 (* 1 = 2.05986 loss)
I0812 07:40:22.305308 26953 sgd_solver.cpp:106] Iteration 28250, lr = 0.01
I0812 07:40:40.658761 26953 solver.cpp:228] Iteration 28260, loss = 1.76781
I0812 07:40:40.658820 26953 solver.cpp:244]     Train net output #0: loss = 1.76781 (* 1 = 1.76781 loss)
I0812 07:40:42.066942 26953 sgd_solver.cpp:106] Iteration 28260, lr = 0.01
I0812 07:41:00.487166 26953 solver.cpp:228] Iteration 28270, loss = 1.95478
I0812 07:41:00.487372 26953 solver.cpp:244]     Train net output #0: loss = 1.95478 (* 1 = 1.95478 loss)
I0812 07:41:01.883323 26953 sgd_solver.cpp:106] Iteration 28270, lr = 0.01
I0812 07:41:20.271942 26953 solver.cpp:228] Iteration 28280, loss = 2.06217
I0812 07:41:20.271999 26953 solver.cpp:244]     Train net output #0: loss = 2.06217 (* 1 = 2.06217 loss)
I0812 07:41:21.678313 26953 sgd_solver.cpp:106] Iteration 28280, lr = 0.01
I0812 07:41:40.059808 26953 solver.cpp:228] Iteration 28290, loss = 1.97578
I0812 07:41:40.060053 26953 solver.cpp:244]     Train net output #0: loss = 1.97578 (* 1 = 1.97578 loss)
I0812 07:41:41.470479 26953 sgd_solver.cpp:106] Iteration 28290, lr = 0.01
I0812 07:41:59.262814 26953 solver.cpp:337] Iteration 28300, Testing net (#0)
I0812 07:41:59.851785 26953 solver.cpp:404]     Test net output #0: accuracy = 0.528
I0812 07:41:59.851840 26953 solver.cpp:404]     Test net output #1: loss = 2.13116 (* 1 = 2.13116 loss)
I0812 07:42:00.435878 26953 solver.cpp:228] Iteration 28300, loss = 1.9764
I0812 07:42:00.435961 26953 solver.cpp:244]     Train net output #0: loss = 1.9764 (* 1 = 1.9764 loss)
I0812 07:42:01.821277 26953 sgd_solver.cpp:106] Iteration 28300, lr = 0.01
I0812 07:42:20.224843 26953 solver.cpp:228] Iteration 28310, loss = 2.01383
I0812 07:42:20.225051 26953 solver.cpp:244]     Train net output #0: loss = 2.01383 (* 1 = 2.01383 loss)
I0812 07:42:21.619395 26953 sgd_solver.cpp:106] Iteration 28310, lr = 0.01
I0812 07:42:40.000298 26953 solver.cpp:228] Iteration 28320, loss = 1.99257
I0812 07:42:40.000357 26953 solver.cpp:244]     Train net output #0: loss = 1.99257 (* 1 = 1.99257 loss)
I0812 07:42:41.388649 26953 sgd_solver.cpp:106] Iteration 28320, lr = 0.01
I0812 07:42:59.813336 26953 solver.cpp:228] Iteration 28330, loss = 2.03229
I0812 07:42:59.813575 26953 solver.cpp:244]     Train net output #0: loss = 2.03229 (* 1 = 2.03229 loss)
I0812 07:43:01.217666 26953 sgd_solver.cpp:106] Iteration 28330, lr = 0.01
I0812 07:43:19.593711 26953 solver.cpp:228] Iteration 28340, loss = 1.77167
I0812 07:43:19.593793 26953 solver.cpp:244]     Train net output #0: loss = 1.77167 (* 1 = 1.77167 loss)
I0812 07:43:21.006434 26953 sgd_solver.cpp:106] Iteration 28340, lr = 0.01
I0812 07:43:39.447162 26953 solver.cpp:228] Iteration 28350, loss = 1.90795
I0812 07:43:39.447445 26953 solver.cpp:244]     Train net output #0: loss = 1.90795 (* 1 = 1.90795 loss)
I0812 07:43:40.835011 26953 sgd_solver.cpp:106] Iteration 28350, lr = 0.01
I0812 07:43:59.196944 26953 solver.cpp:228] Iteration 28360, loss = 1.97194
I0812 07:43:59.197016 26953 solver.cpp:244]     Train net output #0: loss = 1.97194 (* 1 = 1.97194 loss)
I0812 07:44:00.606171 26953 sgd_solver.cpp:106] Iteration 28360, lr = 0.01
I0812 07:44:18.970331 26953 solver.cpp:228] Iteration 28370, loss = 1.98184
I0812 07:44:18.970593 26953 solver.cpp:244]     Train net output #0: loss = 1.98184 (* 1 = 1.98184 loss)
I0812 07:44:20.383855 26953 sgd_solver.cpp:106] Iteration 28370, lr = 0.01
I0812 07:44:38.830332 26953 solver.cpp:228] Iteration 28380, loss = 1.90005
I0812 07:44:38.830404 26953 solver.cpp:244]     Train net output #0: loss = 1.90005 (* 1 = 1.90005 loss)
I0812 07:44:40.246310 26953 sgd_solver.cpp:106] Iteration 28380, lr = 0.01
I0812 07:44:58.618391 26953 solver.cpp:228] Iteration 28390, loss = 1.92473
I0812 07:44:58.618621 26953 solver.cpp:244]     Train net output #0: loss = 1.92473 (* 1 = 1.92473 loss)
I0812 07:45:00.016037 26953 sgd_solver.cpp:106] Iteration 28390, lr = 0.01
I0812 07:45:17.817863 26953 solver.cpp:337] Iteration 28400, Testing net (#0)
I0812 07:45:18.410928 26953 solver.cpp:404]     Test net output #0: accuracy = 0.536
I0812 07:45:18.410997 26953 solver.cpp:404]     Test net output #1: loss = 2.05494 (* 1 = 2.05494 loss)
I0812 07:45:18.984609 26953 solver.cpp:228] Iteration 28400, loss = 2.01703
I0812 07:45:18.984699 26953 solver.cpp:244]     Train net output #0: loss = 2.01703 (* 1 = 2.01703 loss)
I0812 07:45:20.347376 26953 sgd_solver.cpp:106] Iteration 28400, lr = 0.01
I0812 07:45:38.773150 26953 solver.cpp:228] Iteration 28410, loss = 1.87034
I0812 07:45:38.773416 26953 solver.cpp:244]     Train net output #0: loss = 1.87034 (* 1 = 1.87034 loss)
I0812 07:45:40.157798 26953 sgd_solver.cpp:106] Iteration 28410, lr = 0.01
I0812 07:45:58.577924 26953 solver.cpp:228] Iteration 28420, loss = 1.94425
I0812 07:45:58.578019 26953 solver.cpp:244]     Train net output #0: loss = 1.94425 (* 1 = 1.94425 loss)
I0812 07:45:59.981638 26953 sgd_solver.cpp:106] Iteration 28420, lr = 0.01
I0812 07:46:18.365310 26953 solver.cpp:228] Iteration 28430, loss = 1.98974
I0812 07:46:18.365546 26953 solver.cpp:244]     Train net output #0: loss = 1.98974 (* 1 = 1.98974 loss)
I0812 07:46:19.761921 26953 sgd_solver.cpp:106] Iteration 28430, lr = 0.01
I0812 07:46:38.152168 26953 solver.cpp:228] Iteration 28440, loss = 1.92737
I0812 07:46:38.152247 26953 solver.cpp:244]     Train net output #0: loss = 1.92737 (* 1 = 1.92737 loss)
I0812 07:46:39.562427 26953 sgd_solver.cpp:106] Iteration 28440, lr = 0.01
I0812 07:46:57.921568 26953 solver.cpp:228] Iteration 28450, loss = 1.90296
I0812 07:46:57.921723 26953 solver.cpp:244]     Train net output #0: loss = 1.90296 (* 1 = 1.90296 loss)
I0812 07:46:59.325356 26953 sgd_solver.cpp:106] Iteration 28450, lr = 0.01
I0812 07:47:17.758868 26953 solver.cpp:228] Iteration 28460, loss = 2.0273
I0812 07:47:17.758949 26953 solver.cpp:244]     Train net output #0: loss = 2.0273 (* 1 = 2.0273 loss)
I0812 07:47:19.151720 26953 sgd_solver.cpp:106] Iteration 28460, lr = 0.01
I0812 07:47:37.517953 26953 solver.cpp:228] Iteration 28470, loss = 2.12778
I0812 07:47:37.518143 26953 solver.cpp:244]     Train net output #0: loss = 2.12778 (* 1 = 2.12778 loss)
I0812 07:47:38.931802 26953 sgd_solver.cpp:106] Iteration 28470, lr = 0.01
I0812 07:47:57.300544 26953 solver.cpp:228] Iteration 28480, loss = 1.87177
I0812 07:47:57.300619 26953 solver.cpp:244]     Train net output #0: loss = 1.87177 (* 1 = 1.87177 loss)
I0812 07:47:58.702893 26953 sgd_solver.cpp:106] Iteration 28480, lr = 0.01
I0812 07:48:17.104506 26953 solver.cpp:228] Iteration 28490, loss = 1.86641
I0812 07:48:17.104672 26953 solver.cpp:244]     Train net output #0: loss = 1.86641 (* 1 = 1.86641 loss)
I0812 07:48:18.497619 26953 sgd_solver.cpp:106] Iteration 28490, lr = 0.01
I0812 07:48:36.305605 26953 solver.cpp:337] Iteration 28500, Testing net (#0)
I0812 07:48:36.898241 26953 solver.cpp:404]     Test net output #0: accuracy = 0.494
I0812 07:48:36.898319 26953 solver.cpp:404]     Test net output #1: loss = 2.15318 (* 1 = 2.15318 loss)
I0812 07:48:37.466466 26953 solver.cpp:228] Iteration 28500, loss = 1.95093
I0812 07:48:37.466557 26953 solver.cpp:244]     Train net output #0: loss = 1.95093 (* 1 = 1.95093 loss)
I0812 07:48:38.852123 26953 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I0812 07:48:57.241952 26953 solver.cpp:228] Iteration 28510, loss = 2.05699
I0812 07:48:57.242266 26953 solver.cpp:244]     Train net output #0: loss = 2.05699 (* 1 = 2.05699 loss)
I0812 07:48:58.633539 26953 sgd_solver.cpp:106] Iteration 28510, lr = 0.01
I0812 07:49:17.012220 26953 solver.cpp:228] Iteration 28520, loss = 2.03979
I0812 07:49:17.012305 26953 solver.cpp:244]     Train net output #0: loss = 2.03979 (* 1 = 2.03979 loss)
I0812 07:49:18.414263 26953 sgd_solver.cpp:106] Iteration 28520, lr = 0.01
I0812 07:49:36.781544 26953 solver.cpp:228] Iteration 28530, loss = 1.89337
I0812 07:49:36.781775 26953 solver.cpp:244]     Train net output #0: loss = 1.89337 (* 1 = 1.89337 loss)
I0812 07:49:38.171340 26953 sgd_solver.cpp:106] Iteration 28530, lr = 0.01
I0812 07:49:56.565596 26953 solver.cpp:228] Iteration 28540, loss = 1.98579
I0812 07:49:56.565662 26953 solver.cpp:244]     Train net output #0: loss = 1.98579 (* 1 = 1.98579 loss)
I0812 07:49:57.970434 26953 sgd_solver.cpp:106] Iteration 28540, lr = 0.01
I0812 07:50:16.399327 26953 solver.cpp:228] Iteration 28550, loss = 1.80326
I0812 07:50:16.399507 26953 solver.cpp:244]     Train net output #0: loss = 1.80326 (* 1 = 1.80326 loss)
I0812 07:50:17.792642 26953 sgd_solver.cpp:106] Iteration 28550, lr = 0.01
I0812 07:50:36.192306 26953 solver.cpp:228] Iteration 28560, loss = 1.95229
I0812 07:50:36.192378 26953 solver.cpp:244]     Train net output #0: loss = 1.95229 (* 1 = 1.95229 loss)
I0812 07:50:37.611359 26953 sgd_solver.cpp:106] Iteration 28560, lr = 0.01
I0812 07:50:55.983758 26953 solver.cpp:228] Iteration 28570, loss = 2.0454
I0812 07:50:55.983986 26953 solver.cpp:244]     Train net output #0: loss = 2.0454 (* 1 = 2.0454 loss)
I0812 07:50:57.394481 26953 sgd_solver.cpp:106] Iteration 28570, lr = 0.01
I0812 07:51:15.840510 26953 solver.cpp:228] Iteration 28580, loss = 1.87329
I0812 07:51:15.840587 26953 solver.cpp:244]     Train net output #0: loss = 1.87329 (* 1 = 1.87329 loss)
I0812 07:51:17.243420 26953 sgd_solver.cpp:106] Iteration 28580, lr = 0.01
I0812 07:51:35.626776 26953 solver.cpp:228] Iteration 28590, loss = 2.10075
I0812 07:51:35.627084 26953 solver.cpp:244]     Train net output #0: loss = 2.10075 (* 1 = 2.10075 loss)
I0812 07:51:37.027330 26953 sgd_solver.cpp:106] Iteration 28590, lr = 0.01
I0812 07:51:54.871780 26953 solver.cpp:337] Iteration 28600, Testing net (#0)
I0812 07:51:55.469017 26953 solver.cpp:404]     Test net output #0: accuracy = 0.5
I0812 07:51:55.469104 26953 solver.cpp:404]     Test net output #1: loss = 2.21771 (* 1 = 2.21771 loss)
I0812 07:51:56.043813 26953 solver.cpp:228] Iteration 28600, loss = 2.07119
I0812 07:51:56.043887 26953 solver.cpp:244]     Train net output #0: loss = 2.07119 (* 1 = 2.07119 loss)
I0812 07:51:57.428966 26953 sgd_solver.cpp:106] Iteration 28600, lr = 0.01
I0812 07:52:15.805683 26953 solver.cpp:228] Iteration 28610, loss = 1.91988
I0812 07:52:15.805877 26953 solver.cpp:244]     Train net output #0: loss = 1.91988 (* 1 = 1.91988 loss)
I0812 07:52:17.192627 26953 sgd_solver.cpp:106] Iteration 28610, lr = 0.01
I0812 07:52:35.677232 26953 solver.cpp:228] Iteration 28620, loss = 2.06553
I0812 07:52:35.677309 26953 solver.cpp:244]     Train net output #0: loss = 2.06553 (* 1 = 2.06553 loss)
I0812 07:52:37.077334 26953 sgd_solver.cpp:106] Iteration 28620, lr = 0.01
I0812 07:52:55.426761 26953 solver.cpp:228] Iteration 28630, loss = 1.83211
I0812 07:52:55.426988 26953 solver.cpp:244]     Train net output #0: loss = 1.83211 (* 1 = 1.83211 loss)
I0812 07:52:56.831737 26953 sgd_solver.cpp:106] Iteration 28630, lr = 0.01
I0812 07:53:15.214988 26953 solver.cpp:228] Iteration 28640, loss = 1.84219
I0812 07:53:15.215062 26953 solver.cpp:244]     Train net output #0: loss = 1.84219 (* 1 = 1.84219 loss)
I0812 07:53:16.593102 26953 sgd_solver.cpp:106] Iteration 28640, lr = 0.01
I0812 07:53:35.013479 26953 solver.cpp:228] Iteration 28650, loss = 1.98529
I0812 07:53:35.014755 26953 solver.cpp:244]     Train net output #0: loss = 1.98529 (* 1 = 1.98529 loss)
I0812 07:53:36.406783 26953 sgd_solver.cpp:106] Iteration 28650, lr = 0.01
I0812 07:53:54.771605 26953 solver.cpp:228] Iteration 28660, loss = 1.82709
I0812 07:53:54.771663 26953 solver.cpp:244]     Train net output #0: loss = 1.82709 (* 1 = 1.82709 loss)
I0812 07:53:56.194983 26953 sgd_solver.cpp:106] Iteration 28660, lr = 0.01
I0812 07:54:14.597378 26953 solver.cpp:228] Iteration 28670, loss = 2.17325
I0812 07:54:14.597604 26953 solver.cpp:244]     Train net output #0: loss = 2.17325 (* 1 = 2.17325 loss)
I0812 07:54:16.004982 26953 sgd_solver.cpp:106] Iteration 28670, lr = 0.01
I0812 07:54:34.416355 26953 solver.cpp:228] Iteration 28680, loss = 1.88069
I0812 07:54:34.416651 26953 solver.cpp:244]     Train net output #0: loss = 1.88069 (* 1 = 1.88069 loss)
I0812 07:54:35.834530 26953 sgd_solver.cpp:106] Iteration 28680, lr = 0.01
I0812 07:54:54.180999 26953 solver.cpp:228] Iteration 28690, loss = 1.96666
I0812 07:54:54.181253 26953 solver.cpp:244]     Train net output #0: loss = 1.96666 (* 1 = 1.96666 loss)
I0812 07:54:55.578846 26953 sgd_solver.cpp:106] Iteration 28690, lr = 0.01
I0812 07:55:13.428616 26953 solver.cpp:337] Iteration 28700, Testing net (#0)
I0812 07:55:14.015888 26953 solver.cpp:404]     Test net output #0: accuracy = 0.51
I0812 07:55:14.015952 26953 solver.cpp:404]     Test net output #1: loss = 2.16315 (* 1 = 2.16315 loss)
I0812 07:55:14.579536 26953 solver.cpp:228] Iteration 28700, loss = 1.85662
I0812 07:55:14.579607 26953 solver.cpp:244]     Train net output #0: loss = 1.85662 (* 1 = 1.85662 loss)
I0812 07:55:15.967926 26953 sgd_solver.cpp:106] Iteration 28700, lr = 0.01
I0812 07:55:34.343477 26953 solver.cpp:228] Iteration 28710, loss = 2.02658
I0812 07:55:34.343703 26953 solver.cpp:244]     Train net output #0: loss = 2.02658 (* 1 = 2.02658 loss)
I0812 07:55:35.742507 26953 sgd_solver.cpp:106] Iteration 28710, lr = 0.01
I0812 07:55:54.221292 26953 solver.cpp:228] Iteration 28720, loss = 1.89327
I0812 07:55:54.221356 26953 solver.cpp:244]     Train net output #0: loss = 1.89327 (* 1 = 1.89327 loss)
I0812 07:55:55.625098 26953 sgd_solver.cpp:106] Iteration 28720, lr = 0.01
I0812 07:56:14.008263 26953 solver.cpp:228] Iteration 28730, loss = 1.93479
I0812 07:56:14.008528 26953 solver.cpp:244]     Train net output #0: loss = 1.93479 (* 1 = 1.93479 loss)
I0812 07:56:15.415010 26953 sgd_solver.cpp:106] Iteration 28730, lr = 0.01
I0812 07:56:33.777062 26953 solver.cpp:228] Iteration 28740, loss = 1.79235
I0812 07:56:33.777148 26953 solver.cpp:244]     Train net output #0: loss = 1.79235 (* 1 = 1.79235 loss)
I0812 07:56:35.175541 26953 sgd_solver.cpp:106] Iteration 28740, lr = 0.01
I0812 07:56:53.550657 26953 solver.cpp:228] Iteration 28750, loss = 2.1293
I0812 07:56:53.550884 26953 solver.cpp:244]     Train net output #0: loss = 2.1293 (* 1 = 2.1293 loss)
I0812 07:56:54.955461 26953 sgd_solver.cpp:106] Iteration 28750, lr = 0.01
I0812 07:57:13.340191 26953 solver.cpp:228] Iteration 28760, loss = 2.05359
I0812 07:57:13.340260 26953 solver.cpp:244]     Train net output #0: loss = 2.05359 (* 1 = 2.05359 loss)
I0812 07:57:14.755403 26953 sgd_solver.cpp:106] Iteration 28760, lr = 0.01
I0812 07:57:33.096431 26953 solver.cpp:228] Iteration 28770, loss = 1.96556
I0812 07:57:33.096660 26953 solver.cpp:244]     Train net output #0: loss = 1.96556 (* 1 = 1.96556 loss)
I0812 07:57:34.501266 26953 sgd_solver.cpp:106] Iteration 28770, lr = 0.01
I0812 07:57:52.916172 26953 solver.cpp:228] Iteration 28780, loss = 1.8573
I0812 07:57:52.916245 26953 solver.cpp:244]     Train net output #0: loss = 1.8573 (* 1 = 1.8573 loss)
I0812 07:57:54.320816 26953 sgd_solver.cpp:106] Iteration 28780, lr = 0.01
I0812 07:58:12.744416 26953 solver.cpp:228] Iteration 28790, loss = 2.00167
I0812 07:58:12.744665 26953 solver.cpp:244]     Train net output #0: loss = 2.00167 (* 1 = 2.00167 loss)
I0812 07:58:14.146173 26953 sgd_solver.cpp:106] Iteration 28790, lr = 0.01
I0812 07:58:32.029623 26953 solver.cpp:337] Iteration 28800, Testing net (#0)
I0812 07:58:32.625083 26953 solver.cpp:404]     Test net output #0: accuracy = 0.552
I0812 07:58:32.625165 26953 solver.cpp:404]     Test net output #1: loss = 2.08553 (* 1 = 2.08553 loss)
I0812 07:58:33.189944 26953 solver.cpp:228] Iteration 28800, loss = 1.93684
I0812 07:58:33.190022 26953 solver.cpp:244]     Train net output #0: loss = 1.93684 (* 1 = 1.93684 loss)
I0812 07:58:34.580615 26953 sgd_solver.cpp:106] Iteration 28800, lr = 0.01
I0812 07:58:52.958839 26953 solver.cpp:228] Iteration 28810, loss = 1.97531
I0812 07:58:52.959018 26953 solver.cpp:244]     Train net output #0: loss = 1.97531 (* 1 = 1.97531 loss)
I0812 07:58:54.357154 26953 sgd_solver.cpp:106] Iteration 28810, lr = 0.01
I0812 07:59:12.797889 26953 solver.cpp:228] Iteration 28820, loss = 1.9999
I0812 07:59:12.797956 26953 solver.cpp:244]     Train net output #0: loss = 1.9999 (* 1 = 1.9999 loss)
I0812 07:59:14.185214 26953 sgd_solver.cpp:106] Iteration 28820, lr = 0.01
I0812 07:59:32.570771 26953 solver.cpp:228] Iteration 28830, loss = 2.02671
I0812 07:59:32.571038 26953 solver.cpp:244]     Train net output #0: loss = 2.02671 (* 1 = 2.02671 loss)
I0812 07:59:33.980885 26953 sgd_solver.cpp:106] Iteration 28830, lr = 0.01
I0812 07:59:52.328305 26953 solver.cpp:228] Iteration 28840, loss = 2.12582
I0812 07:59:52.328379 26953 solver.cpp:244]     Train net output #0: loss = 2.12582 (* 1 = 2.12582 loss)
I0812 07:59:53.748965 26953 sgd_solver.cpp:106] Iteration 28840, lr = 0.01
I0812 08:00:12.126467 26953 solver.cpp:228] Iteration 28850, loss = 1.96344
I0812 08:00:12.126713 26953 solver.cpp:244]     Train net output #0: loss = 1.96344 (* 1 = 1.96344 loss)
I0812 08:00:13.518230 26953 sgd_solver.cpp:106] Iteration 28850, lr = 0.01
I0812 08:00:31.947536 26953 solver.cpp:228] Iteration 28860, loss = 1.83406
I0812 08:00:31.947594 26953 solver.cpp:244]     Train net output #0: loss = 1.83406 (* 1 = 1.83406 loss)
I0812 08:00:33.358188 26953 sgd_solver.cpp:106] Iteration 28860, lr = 0.01
I0812 08:00:51.727226 26953 solver.cpp:228] Iteration 28870, loss = 1.91069
I0812 08:00:51.727474 26953 solver.cpp:244]     Train net output #0: loss = 1.91069 (* 1 = 1.91069 loss)
I0812 08:00:53.126466 26953 sgd_solver.cpp:106] Iteration 28870, lr = 0.01
I0812 08:01:11.590992 26953 solver.cpp:228] Iteration 28880, loss = 2.08089
I0812 08:01:11.591053 26953 solver.cpp:244]     Train net output #0: loss = 2.08089 (* 1 = 2.08089 loss)
I0812 08:01:12.988734 26953 sgd_solver.cpp:106] Iteration 28880, lr = 0.01
I0812 08:01:31.368966 26953 solver.cpp:228] Iteration 28890, loss = 1.95387
I0812 08:01:31.369202 26953 solver.cpp:244]     Train net output #0: loss = 1.95387 (* 1 = 1.95387 loss)
I0812 08:01:32.789917 26953 sgd_solver.cpp:106] Iteration 28890, lr = 0.01
I0812 08:01:50.615226 26953 solver.cpp:337] Iteration 28900, Testing net (#0)
I0812 08:01:51.202249 26953 solver.cpp:404]     Test net output #0: accuracy = 0.544
I0812 08:01:51.202301 26953 solver.cpp:404]     Test net output #1: loss = 2.09436 (* 1 = 2.09436 loss)
I0812 08:01:51.769100 26953 solver.cpp:228] Iteration 28900, loss = 1.96397
I0812 08:01:51.769208 26953 solver.cpp:244]     Train net output #0: loss = 1.96397 (* 1 = 1.96397 loss)
I0812 08:01:53.143980 26953 sgd_solver.cpp:106] Iteration 28900, lr = 0.01
I0812 08:02:11.547843 26953 solver.cpp:228] Iteration 28910, loss = 1.778
I0812 08:02:11.548084 26953 solver.cpp:244]     Train net output #0: loss = 1.778 (* 1 = 1.778 loss)
I0812 08:02:12.944367 26953 sgd_solver.cpp:106] Iteration 28910, lr = 0.01
I0812 08:02:31.303431 26953 solver.cpp:228] Iteration 28920, loss = 1.98193
I0812 08:02:31.303532 26953 solver.cpp:244]     Train net output #0: loss = 1.98193 (* 1 = 1.98193 loss)
I0812 08:02:32.712991 26953 sgd_solver.cpp:106] Iteration 28920, lr = 0.01
I0812 08:02:51.085702 26953 solver.cpp:228] Iteration 28930, loss = 2.21042
I0812 08:02:51.085968 26953 solver.cpp:244]     Train net output #0: loss = 2.21042 (* 1 = 2.21042 loss)
I0812 08:02:52.473254 26953 sgd_solver.cpp:106] Iteration 28930, lr = 0.01
I0812 08:03:10.886152 26953 solver.cpp:228] Iteration 28940, loss = 1.98002
I0812 08:03:10.886219 26953 solver.cpp:244]     Train net output #0: loss = 1.98002 (* 1 = 1.98002 loss)
I0812 08:03:12.291676 26953 sgd_solver.cpp:106] Iteration 28940, lr = 0.01
I0812 08:03:30.646697 26953 solver.cpp:228] Iteration 28950, loss = 2.00809
I0812 08:03:30.646967 26953 solver.cpp:244]     Train net output #0: loss = 2.00809 (* 1 = 2.00809 loss)
I0812 08:03:32.069152 26953 sgd_solver.cpp:106] Iteration 28950, lr = 0.01
I0812 08:03:50.483379 26953 solver.cpp:228] Iteration 28960, loss = 1.83021
I0812 08:03:50.483438 26953 solver.cpp:244]     Train net output #0: loss = 1.83021 (* 1 = 1.83021 loss)
I0812 08:03:51.879215 26953 sgd_solver.cpp:106] Iteration 28960, lr = 0.01
I0812 08:04:10.326061 26953 solver.cpp:228] Iteration 28970, loss = 2.25258
I0812 08:04:10.326305 26953 solver.cpp:244]     Train net output #0: loss = 2.25258 (* 1 = 2.25258 loss)
I0812 08:04:11.719040 26953 sgd_solver.cpp:106] Iteration 28970, lr = 0.01
I0812 08:04:30.108237 26953 solver.cpp:228] Iteration 28980, loss = 2.04931
I0812 08:04:30.108296 26953 solver.cpp:244]     Train net output #0: loss = 2.04931 (* 1 = 2.04931 loss)
I0812 08:04:31.501854 26953 sgd_solver.cpp:106] Iteration 28980, lr = 0.01
I0812 08:04:49.971968 26953 solver.cpp:228] Iteration 28990, loss = 2.05129
I0812 08:04:49.972208 26953 solver.cpp:244]     Train net output #0: loss = 2.05129 (* 1 = 2.05129 loss)
I0812 08:04:51.368624 26953 sgd_solver.cpp:106] Iteration 28990, lr = 0.01
I0812 08:05:09.162945 26953 solver.cpp:337] Iteration 29000, Testing net (#0)
I0812 08:05:09.759395 26953 solver.cpp:404]     Test net output #0: accuracy = 0.568
I0812 08:05:09.759462 26953 solver.cpp:404]     Test net output #1: loss = 2.00481 (* 1 = 2.00481 loss)
I0812 08:05:10.330302 26953 solver.cpp:228] Iteration 29000, loss = 2.03507
I0812 08:05:10.330371 26953 solver.cpp:244]     Train net output #0: loss = 2.03507 (* 1 = 2.03507 loss)
I0812 08:05:11.707119 26953 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I0812 08:05:30.123756 26953 solver.cpp:228] Iteration 29010, loss = 1.88839
I0812 08:05:30.123950 26953 solver.cpp:244]     Train net output #0: loss = 1.88839 (* 1 = 1.88839 loss)
I0812 08:05:31.549068 26953 sgd_solver.cpp:106] Iteration 29010, lr = 0.01
I0812 08:05:49.939760 26953 solver.cpp:228] Iteration 29020, loss = 1.73311
I0812 08:05:49.939832 26953 solver.cpp:244]     Train net output #0: loss = 1.73311 (* 1 = 1.73311 loss)
I0812 08:05:51.340042 26953 sgd_solver.cpp:106] Iteration 29020, lr = 0.01
I0812 08:06:09.769389 26953 solver.cpp:228] Iteration 29030, loss = 1.96547
I0812 08:06:09.769650 26953 solver.cpp:244]     Train net output #0: loss = 1.96547 (* 1 = 1.96547 loss)
I0812 08:06:11.179183 26953 sgd_solver.cpp:106] Iteration 29030, lr = 0.01
I0812 08:06:29.558704 26953 solver.cpp:228] Iteration 29040, loss = 2.01801
I0812 08:06:29.558774 26953 solver.cpp:244]     Train net output #0: loss = 2.01801 (* 1 = 2.01801 loss)
I0812 08:06:30.961660 26953 sgd_solver.cpp:106] Iteration 29040, lr = 0.01
I0812 08:06:49.312782 26953 solver.cpp:228] Iteration 29050, loss = 1.92492
I0812 08:06:49.313056 26953 solver.cpp:244]     Train net output #0: loss = 1.92492 (* 1 = 1.92492 loss)
I0812 08:06:50.712039 26953 sgd_solver.cpp:106] Iteration 29050, lr = 0.01
I0812 08:07:09.103751 26953 solver.cpp:228] Iteration 29060, loss = 2.06294
I0812 08:07:09.103824 26953 solver.cpp:244]     Train net output #0: loss = 2.06294 (* 1 = 2.06294 loss)
I0812 08:07:10.504289 26953 sgd_solver.cpp:106] Iteration 29060, lr = 0.01
I0812 08:07:28.894274 26953 solver.cpp:228] Iteration 29070, loss = 1.91999
I0812 08:07:28.894410 26953 solver.cpp:244]     Train net output #0: loss = 1.91999 (* 1 = 1.91999 loss)
I0812 08:07:30.293992 26953 sgd_solver.cpp:106] Iteration 29070, lr = 0.01
I0812 08:07:48.731823 26953 solver.cpp:228] Iteration 29080, loss = 1.90712
I0812 08:07:48.731899 26953 solver.cpp:244]     Train net output #0: loss = 1.90712 (* 1 = 1.90712 loss)
I0812 08:07:50.118603 26953 sgd_solver.cpp:106] Iteration 29080, lr = 0.01
I0812 08:08:08.574512 26953 solver.cpp:228] Iteration 29090, loss = 2.03412
I0812 08:08:08.574793 26953 solver.cpp:244]     Train net output #0: loss = 2.03412 (* 1 = 2.03412 loss)
I0812 08:08:09.986781 26953 sgd_solver.cpp:106] Iteration 29090, lr = 0.01
I0812 08:08:27.804968 26953 solver.cpp:337] Iteration 29100, Testing net (#0)
I0812 08:08:28.403849 26953 solver.cpp:404]     Test net output #0: accuracy = 0.524
I0812 08:08:28.403939 26953 solver.cpp:404]     Test net output #1: loss = 2.06897 (* 1 = 2.06897 loss)
I0812 08:08:28.985555 26953 solver.cpp:228] Iteration 29100, loss = 2.034
I0812 08:08:28.985620 26953 solver.cpp:244]     Train net output #0: loss = 2.034 (* 1 = 2.034 loss)
I0812 08:08:30.339839 26953 sgd_solver.cpp:106] Iteration 29100, lr = 0.01
I0812 08:08:48.740933 26953 solver.cpp:228] Iteration 29110, loss = 2.03125
I0812 08:08:48.741137 26953 solver.cpp:244]     Train net output #0: loss = 2.03125 (* 1 = 2.03125 loss)
I0812 08:08:50.153139 26953 sgd_solver.cpp:106] Iteration 29110, lr = 0.01
I0812 08:09:08.529664 26953 solver.cpp:228] Iteration 29120, loss = 1.88767
I0812 08:09:08.529742 26953 solver.cpp:244]     Train net output #0: loss = 1.88767 (* 1 = 1.88767 loss)
I0812 08:09:09.927073 26953 sgd_solver.cpp:106] Iteration 29120, lr = 0.01
I0812 08:09:28.324435 26953 solver.cpp:228] Iteration 29130, loss = 1.89318
I0812 08:09:28.324671 26953 solver.cpp:244]     Train net output #0: loss = 1.89318 (* 1 = 1.89318 loss)
I0812 08:09:29.725433 26953 sgd_solver.cpp:106] Iteration 29130, lr = 0.01
I0812 08:09:48.098407 26953 solver.cpp:228] Iteration 29140, loss = 1.93485
I0812 08:09:48.098497 26953 solver.cpp:244]     Train net output #0: loss = 1.93485 (* 1 = 1.93485 loss)
I0812 08:09:49.509742 26953 sgd_solver.cpp:106] Iteration 29140, lr = 0.01
I0812 08:10:07.983182 26953 solver.cpp:228] Iteration 29150, loss = 1.98352
I0812 08:10:07.983414 26953 solver.cpp:244]     Train net output #0: loss = 1.98352 (* 1 = 1.98352 loss)
I0812 08:10:09.384706 26953 sgd_solver.cpp:106] Iteration 29150, lr = 0.01
I0812 08:10:27.787173 26953 solver.cpp:228] Iteration 29160, loss = 2.17808
I0812 08:10:27.787255 26953 solver.cpp:244]     Train net output #0: loss = 2.17808 (* 1 = 2.17808 loss)
I0812 08:10:29.204360 26953 sgd_solver.cpp:106] Iteration 29160, lr = 0.01
I0812 08:10:47.606899 26953 solver.cpp:228] Iteration 29170, loss = 1.92611
I0812 08:10:47.607130 26953 solver.cpp:244]     Train net output #0: loss = 1.92611 (* 1 = 1.92611 loss)
I0812 08:10:49.011606 26953 sgd_solver.cpp:106] Iteration 29170, lr = 0.01
I0812 08:11:07.437847 26953 solver.cpp:228] Iteration 29180, loss = 2.05541
I0812 08:11:07.437933 26953 solver.cpp:244]     Train net output #0: loss = 2.05541 (* 1 = 2.05541 loss)
I0812 08:11:08.852414 26953 sgd_solver.cpp:106] Iteration 29180, lr = 0.01
I0812 08:11:27.211408 26953 solver.cpp:228] Iteration 29190, loss = 2.03515
I0812 08:11:27.211640 26953 solver.cpp:244]     Train net output #0: loss = 2.03515 (* 1 = 2.03515 loss)
I0812 08:11:28.615058 26953 sgd_solver.cpp:106] Iteration 29190, lr = 0.01
I0812 08:11:46.411783 26953 solver.cpp:337] Iteration 29200, Testing net (#0)
I0812 08:11:47.001564 26953 solver.cpp:404]     Test net output #0: accuracy = 0.526
I0812 08:11:47.001618 26953 solver.cpp:404]     Test net output #1: loss = 2.07906 (* 1 = 2.07906 loss)
I0812 08:11:47.581589 26953 solver.cpp:228] Iteration 29200, loss = 2.07938
I0812 08:11:47.581684 26953 solver.cpp:244]     Train net output #0: loss = 2.07938 (* 1 = 2.07938 loss)
I0812 08:11:48.954005 26953 sgd_solver.cpp:106] Iteration 29200, lr = 0.01
I0812 08:12:07.347384 26953 solver.cpp:228] Iteration 29210, loss = 1.91095
I0812 08:12:07.347653 26953 solver.cpp:244]     Train net output #0: loss = 1.91095 (* 1 = 1.91095 loss)
I0812 08:12:08.747211 26953 sgd_solver.cpp:106] Iteration 29210, lr = 0.01
I0812 08:12:27.109103 26953 solver.cpp:228] Iteration 29220, loss = 1.91583
I0812 08:12:27.109182 26953 solver.cpp:244]     Train net output #0: loss = 1.91583 (* 1 = 1.91583 loss)
I0812 08:12:28.512251 26953 sgd_solver.cpp:106] Iteration 29220, lr = 0.01
I0812 08:12:46.982566 26953 solver.cpp:228] Iteration 29230, loss = 1.9195
I0812 08:12:46.982774 26953 solver.cpp:244]     Train net output #0: loss = 1.9195 (* 1 = 1.9195 loss)
I0812 08:12:48.372082 26953 sgd_solver.cpp:106] Iteration 29230, lr = 0.01
I0812 08:13:06.746943 26953 solver.cpp:228] Iteration 29240, loss = 2.01268
I0812 08:13:06.747011 26953 solver.cpp:244]     Train net output #0: loss = 2.01268 (* 1 = 2.01268 loss)
I0812 08:13:08.152498 26953 sgd_solver.cpp:106] Iteration 29240, lr = 0.01
I0812 08:13:26.580631 26953 solver.cpp:228] Iteration 29250, loss = 1.77507
I0812 08:13:26.580864 26953 solver.cpp:244]     Train net output #0: loss = 1.77507 (* 1 = 1.77507 loss)
I0812 08:13:27.991899 26953 sgd_solver.cpp:106] Iteration 29250, lr = 0.01
I0812 08:13:46.390043 26953 solver.cpp:228] Iteration 29260, loss = 1.97861
I0812 08:13:46.390116 26953 solver.cpp:244]     Train net output #0: loss = 1.97861 (* 1 = 1.97861 loss)
I0812 08:13:47.799955 26953 sgd_solver.cpp:106] Iteration 29260, lr = 0.01
I0812 08:14:06.201483 26953 solver.cpp:228] Iteration 29270, loss = 2.04373
I0812 08:14:06.201725 26953 solver.cpp:244]     Train net output #0: loss = 2.04373 (* 1 = 2.04373 loss)
I0812 08:14:07.598346 26953 sgd_solver.cpp:106] Iteration 29270, lr = 0.01
I0812 08:14:26.027900 26953 solver.cpp:228] Iteration 29280, loss = 1.84679
I0812 08:14:26.027973 26953 solver.cpp:244]     Train net output #0: loss = 1.84679 (* 1 = 1.84679 loss)
I0812 08:14:27.444622 26953 sgd_solver.cpp:106] Iteration 29280, lr = 0.01
I0812 08:14:45.853891 26953 solver.cpp:228] Iteration 29290, loss = 2.17514
I0812 08:14:45.854112 26953 solver.cpp:244]     Train net output #0: loss = 2.17514 (* 1 = 2.17514 loss)
I0812 08:14:47.247777 26953 sgd_solver.cpp:106] Iteration 29290, lr = 0.01
I0812 08:15:05.072098 26953 solver.cpp:337] Iteration 29300, Testing net (#0)
I0812 08:15:05.661141 26953 solver.cpp:404]     Test net output #0: accuracy = 0.492
I0812 08:15:05.661252 26953 solver.cpp:404]     Test net output #1: loss = 2.20182 (* 1 = 2.20182 loss)
I0812 08:15:06.233958 26953 solver.cpp:228] Iteration 29300, loss = 1.85978
I0812 08:15:06.234058 26953 solver.cpp:244]     Train net output #0: loss = 1.85978 (* 1 = 1.85978 loss)
I0812 08:15:07.608521 26953 sgd_solver.cpp:106] Iteration 29300, lr = 0.01
I0812 08:15:26.018743 26953 solver.cpp:228] Iteration 29310, loss = 1.88866
I0812 08:15:26.019021 26953 solver.cpp:244]     Train net output #0: loss = 1.88866 (* 1 = 1.88866 loss)
I0812 08:15:27.432062 26953 sgd_solver.cpp:106] Iteration 29310, lr = 0.01
I0812 08:15:45.856361 26953 solver.cpp:228] Iteration 29320, loss = 2.09047
I0812 08:15:45.856431 26953 solver.cpp:244]     Train net output #0: loss = 2.09047 (* 1 = 2.09047 loss)
I0812 08:15:47.253296 26953 sgd_solver.cpp:106] Iteration 29320, lr = 0.01
I0812 08:16:05.622406 26953 solver.cpp:228] Iteration 29330, loss = 1.97634
I0812 08:16:05.622580 26953 solver.cpp:244]     Train net output #0: loss = 1.97634 (* 1 = 1.97634 loss)
I0812 08:16:07.025957 26953 sgd_solver.cpp:106] Iteration 29330, lr = 0.01
I0812 08:16:25.379848 26953 solver.cpp:228] Iteration 29340, loss = 1.85645
I0812 08:16:25.379920 26953 solver.cpp:244]     Train net output #0: loss = 1.85645 (* 1 = 1.85645 loss)
I0812 08:16:26.783514 26953 sgd_solver.cpp:106] Iteration 29340, lr = 0.01
I0812 08:16:45.258769 26953 solver.cpp:228] Iteration 29350, loss = 1.9364
I0812 08:16:45.258955 26953 solver.cpp:244]     Train net output #0: loss = 1.9364 (* 1 = 1.9364 loss)
I0812 08:16:46.675756 26953 sgd_solver.cpp:106] Iteration 29350, lr = 0.01
I0812 08:17:05.019232 26953 solver.cpp:228] Iteration 29360, loss = 1.90516
I0812 08:17:05.019304 26953 solver.cpp:244]     Train net output #0: loss = 1.90516 (* 1 = 1.90516 loss)
I0812 08:17:06.422113 26953 sgd_solver.cpp:106] Iteration 29360, lr = 0.01
I0812 08:17:24.852988 26953 solver.cpp:228] Iteration 29370, loss = 1.98208
I0812 08:17:24.853201 26953 solver.cpp:244]     Train net output #0: loss = 1.98208 (* 1 = 1.98208 loss)
I0812 08:17:26.247269 26953 sgd_solver.cpp:106] Iteration 29370, lr = 0.01
I0812 08:17:44.630691 26953 solver.cpp:228] Iteration 29380, loss = 1.94184
I0812 08:17:44.630765 26953 solver.cpp:244]     Train net output #0: loss = 1.94184 (* 1 = 1.94184 loss)
I0812 08:17:46.044427 26953 sgd_solver.cpp:106] Iteration 29380, lr = 0.01
I0812 08:18:04.417129 26953 solver.cpp:228] Iteration 29390, loss = 1.9288
I0812 08:18:04.417397 26953 solver.cpp:244]     Train net output #0: loss = 1.9288 (* 1 = 1.9288 loss)
I0812 08:18:05.819109 26953 sgd_solver.cpp:106] Iteration 29390, lr = 0.01
I0812 08:18:23.650323 26953 solver.cpp:337] Iteration 29400, Testing net (#0)
I0812 08:18:24.239398 26953 solver.cpp:404]     Test net output #0: accuracy = 0.498
I0812 08:18:24.239470 26953 solver.cpp:404]     Test net output #1: loss = 2.19343 (* 1 = 2.19343 loss)
I0812 08:18:24.818351 26953 solver.cpp:228] Iteration 29400, loss = 2.00447
I0812 08:18:24.818428 26953 solver.cpp:244]     Train net output #0: loss = 2.00447 (* 1 = 2.00447 loss)
I0812 08:18:26.196710 26953 sgd_solver.cpp:106] Iteration 29400, lr = 0.01
I0812 08:18:44.570508 26953 solver.cpp:228] Iteration 29410, loss = 2.07334
I0812 08:18:44.570761 26953 solver.cpp:244]     Train net output #0: loss = 2.07334 (* 1 = 2.07334 loss)
I0812 08:18:45.980196 26953 sgd_solver.cpp:106] Iteration 29410, lr = 0.01
I0812 08:19:04.364945 26953 solver.cpp:228] Iteration 29420, loss = 1.82999
I0812 08:19:04.365020 26953 solver.cpp:244]     Train net output #0: loss = 1.82999 (* 1 = 1.82999 loss)
I0812 08:19:05.760296 26953 sgd_solver.cpp:106] Iteration 29420, lr = 0.01
I0812 08:19:24.151046 26953 solver.cpp:228] Iteration 29430, loss = 2.06188
I0812 08:19:24.151329 26953 solver.cpp:244]     Train net output #0: loss = 2.06188 (* 1 = 2.06188 loss)
I0812 08:19:25.545802 26953 sgd_solver.cpp:106] Iteration 29430, lr = 0.01
I0812 08:19:43.945983 26953 solver.cpp:228] Iteration 29440, loss = 2.016
I0812 08:19:43.946041 26953 solver.cpp:244]     Train net output #0: loss = 2.016 (* 1 = 2.016 loss)
I0812 08:19:45.337867 26953 sgd_solver.cpp:106] Iteration 29440, lr = 0.01
I0812 08:20:03.691332 26953 solver.cpp:228] Iteration 29450, loss = 1.84451
I0812 08:20:03.691548 26953 solver.cpp:244]     Train net output #0: loss = 1.84451 (* 1 = 1.84451 loss)
I0812 08:20:05.089833 26953 sgd_solver.cpp:106] Iteration 29450, lr = 0.01
I0812 08:20:23.530678 26953 solver.cpp:228] Iteration 29460, loss = 1.96012
I0812 08:20:23.530741 26953 solver.cpp:244]     Train net output #0: loss = 1.96012 (* 1 = 1.96012 loss)
I0812 08:20:24.924811 26953 sgd_solver.cpp:106] Iteration 29460, lr = 0.01
I0812 08:20:43.285071 26953 solver.cpp:228] Iteration 29470, loss = 1.89324
I0812 08:20:43.285336 26953 solver.cpp:244]     Train net output #0: loss = 1.89324 (* 1 = 1.89324 loss)
I0812 08:20:44.706940 26953 sgd_solver.cpp:106] Iteration 29470, lr = 0.01
I0812 08:21:03.151901 26953 solver.cpp:228] Iteration 29480, loss = 2.05349
I0812 08:21:03.151957 26953 solver.cpp:244]     Train net output #0: loss = 2.05349 (* 1 = 2.05349 loss)
I0812 08:21:04.540464 26953 sgd_solver.cpp:106] Iteration 29480, lr = 0.01
I0812 08:21:22.940016 26953 solver.cpp:228] Iteration 29490, loss = 1.98233
I0812 08:21:22.940223 26953 solver.cpp:244]     Train net output #0: loss = 1.98233 (* 1 = 1.98233 loss)
I0812 08:21:24.353201 26953 sgd_solver.cpp:106] Iteration 29490, lr = 0.01
I0812 08:21:42.169452 26953 solver.cpp:337] Iteration 29500, Testing net (#0)
I0812 08:21:42.760577 26953 solver.cpp:404]     Test net output #0: accuracy = 0.528
I0812 08:21:42.760675 26953 solver.cpp:404]     Test net output #1: loss = 2.16679 (* 1 = 2.16679 loss)
I0812 08:21:43.351027 26953 solver.cpp:228] Iteration 29500, loss = 2.14271
I0812 08:21:43.351096 26953 solver.cpp:244]     Train net output #0: loss = 2.14271 (* 1 = 2.14271 loss)
I0812 08:21:44.693013 26953 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I0812 08:22:03.118993 26953 solver.cpp:228] Iteration 29510, loss = 2.05949
I0812 08:22:03.119256 26953 solver.cpp:244]     Train net output #0: loss = 2.05949 (* 1 = 2.05949 loss)
I0812 08:22:04.508920 26953 sgd_solver.cpp:106] Iteration 29510, lr = 0.01
I0812 08:22:22.870810 26953 solver.cpp:228] Iteration 29520, loss = 2.0645
I0812 08:22:22.870892 26953 solver.cpp:244]     Train net output #0: loss = 2.0645 (* 1 = 2.0645 loss)
I0812 08:22:24.279139 26953 sgd_solver.cpp:106] Iteration 29520, lr = 0.01
I0812 08:22:42.613653 26953 solver.cpp:228] Iteration 29530, loss = 2.24978
I0812 08:22:42.614821 26953 solver.cpp:244]     Train net output #0: loss = 2.24978 (* 1 = 2.24978 loss)
I0812 08:22:44.019443 26953 sgd_solver.cpp:106] Iteration 29530, lr = 0.01
I0812 08:23:02.389758 26953 solver.cpp:228] Iteration 29540, loss = 1.9431
I0812 08:23:02.389837 26953 solver.cpp:244]     Train net output #0: loss = 1.9431 (* 1 = 1.9431 loss)
I0812 08:23:03.784274 26953 sgd_solver.cpp:106] Iteration 29540, lr = 0.01
I0812 08:23:22.199450 26953 solver.cpp:228] Iteration 29550, loss = 2.17329
I0812 08:23:22.199707 26953 solver.cpp:244]     Train net output #0: loss = 2.17329 (* 1 = 2.17329 loss)
I0812 08:23:23.602398 26953 sgd_solver.cpp:106] Iteration 29550, lr = 0.01
I0812 08:23:41.988052 26953 solver.cpp:228] Iteration 29560, loss = 2.01361
I0812 08:23:41.988117 26953 solver.cpp:244]     Train net output #0: loss = 2.01361 (* 1 = 2.01361 loss)
I0812 08:23:43.387562 26953 sgd_solver.cpp:106] Iteration 29560, lr = 0.01
I0812 08:24:01.727643 26953 solver.cpp:228] Iteration 29570, loss = 1.93031
I0812 08:24:01.727854 26953 solver.cpp:244]     Train net output #0: loss = 1.93031 (* 1 = 1.93031 loss)
I0812 08:24:03.120623 26953 sgd_solver.cpp:106] Iteration 29570, lr = 0.01
I0812 08:24:21.519675 26953 solver.cpp:228] Iteration 29580, loss = 1.91457
I0812 08:24:21.519765 26953 solver.cpp:244]     Train net output #0: loss = 1.91457 (* 1 = 1.91457 loss)
I0812 08:24:22.906308 26953 sgd_solver.cpp:106] Iteration 29580, lr = 0.01
I0812 08:24:41.334326 26953 solver.cpp:228] Iteration 29590, loss = 1.85884
I0812 08:24:41.334532 26953 solver.cpp:244]     Train net output #0: loss = 1.85884 (* 1 = 1.85884 loss)
I0812 08:24:42.736791 26953 sgd_solver.cpp:106] Iteration 29590, lr = 0.01
I0812 08:25:00.494259 26953 solver.cpp:337] Iteration 29600, Testing net (#0)
I0812 08:25:01.093343 26953 solver.cpp:404]     Test net output #0: accuracy = 0.522
I0812 08:25:01.093413 26953 solver.cpp:404]     Test net output #1: loss = 2.23187 (* 1 = 2.23187 loss)
I0812 08:25:01.665189 26953 solver.cpp:228] Iteration 29600, loss = 1.75483
I0812 08:25:01.665285 26953 solver.cpp:244]     Train net output #0: loss = 1.75483 (* 1 = 1.75483 loss)
I0812 08:25:03.041769 26953 sgd_solver.cpp:106] Iteration 29600, lr = 0.01
I0812 08:25:21.485729 26953 solver.cpp:228] Iteration 29610, loss = 1.88498
I0812 08:25:21.485960 26953 solver.cpp:244]     Train net output #0: loss = 1.88498 (* 1 = 1.88498 loss)
I0812 08:25:22.891446 26953 sgd_solver.cpp:106] Iteration 29610, lr = 0.01
I0812 08:25:41.304322 26953 solver.cpp:228] Iteration 29620, loss = 2.02494
I0812 08:25:41.304409 26953 solver.cpp:244]     Train net output #0: loss = 2.02494 (* 1 = 2.02494 loss)
I0812 08:25:42.701463 26953 sgd_solver.cpp:106] Iteration 29620, lr = 0.01
I0812 08:26:01.067533 26953 solver.cpp:228] Iteration 29630, loss = 1.96705
I0812 08:26:01.067752 26953 solver.cpp:244]     Train net output #0: loss = 1.96705 (* 1 = 1.96705 loss)
I0812 08:26:02.460834 26953 sgd_solver.cpp:106] Iteration 29630, lr = 0.01
I0812 08:26:20.873903 26953 solver.cpp:228] Iteration 29640, loss = 1.96248
I0812 08:26:20.873968 26953 solver.cpp:244]     Train net output #0: loss = 1.96248 (* 1 = 1.96248 loss)
I0812 08:26:22.280982 26953 sgd_solver.cpp:106] Iteration 29640, lr = 0.01
I0812 08:26:40.643527 26953 solver.cpp:228] Iteration 29650, loss = 1.82144
I0812 08:26:40.643692 26953 solver.cpp:244]     Train net output #0: loss = 1.82144 (* 1 = 1.82144 loss)
I0812 08:26:42.038635 26953 sgd_solver.cpp:106] Iteration 29650, lr = 0.01
I0812 08:27:00.470176 26953 solver.cpp:228] Iteration 29660, loss = 1.81553
I0812 08:27:00.470240 26953 solver.cpp:244]     Train net output #0: loss = 1.81553 (* 1 = 1.81553 loss)
I0812 08:27:01.866189 26953 sgd_solver.cpp:106] Iteration 29660, lr = 0.01
I0812 08:27:20.270776 26953 solver.cpp:228] Iteration 29670, loss = 1.93492
I0812 08:27:20.270970 26953 solver.cpp:244]     Train net output #0: loss = 1.93492 (* 1 = 1.93492 loss)
I0812 08:27:21.689546 26953 sgd_solver.cpp:106] Iteration 29670, lr = 0.01
I0812 08:27:40.075788 26953 solver.cpp:228] Iteration 29680, loss = 1.92469
I0812 08:27:40.075853 26953 solver.cpp:244]     Train net output #0: loss = 1.92469 (* 1 = 1.92469 loss)
I0812 08:27:41.476822 26953 sgd_solver.cpp:106] Iteration 29680, lr = 0.01
I0812 08:27:59.888139 26953 solver.cpp:228] Iteration 29690, loss = 2.04392
I0812 08:27:59.888335 26953 solver.cpp:244]     Train net output #0: loss = 2.04392 (* 1 = 2.04392 loss)
I0812 08:28:01.304723 26953 sgd_solver.cpp:106] Iteration 29690, lr = 0.01
I0812 08:28:19.078300 26953 solver.cpp:337] Iteration 29700, Testing net (#0)
I0812 08:28:19.673272 26953 solver.cpp:404]     Test net output #0: accuracy = 0.536
I0812 08:28:19.673336 26953 solver.cpp:404]     Test net output #1: loss = 2.16367 (* 1 = 2.16367 loss)
I0812 08:28:20.245882 26953 solver.cpp:228] Iteration 29700, loss = 2.04682
I0812 08:28:20.245975 26953 solver.cpp:244]     Train net output #0: loss = 2.04682 (* 1 = 2.04682 loss)
I0812 08:28:21.622170 26953 sgd_solver.cpp:106] Iteration 29700, lr = 0.01
I0812 08:28:40.046924 26953 solver.cpp:228] Iteration 29710, loss = 1.92305
I0812 08:28:40.047152 26953 solver.cpp:244]     Train net output #0: loss = 1.92305 (* 1 = 1.92305 loss)
I0812 08:28:41.446815 26953 sgd_solver.cpp:106] Iteration 29710, lr = 0.01
I0812 08:28:59.823052 26953 solver.cpp:228] Iteration 29720, loss = 1.99208
I0812 08:28:59.823132 26953 solver.cpp:244]     Train net output #0: loss = 1.99208 (* 1 = 1.99208 loss)
I0812 08:29:01.222143 26953 sgd_solver.cpp:106] Iteration 29720, lr = 0.01
I0812 08:29:19.659553 26953 solver.cpp:228] Iteration 29730, loss = 2.05982
I0812 08:29:19.659795 26953 solver.cpp:244]     Train net output #0: loss = 2.05982 (* 1 = 2.05982 loss)
I0812 08:29:21.048857 26953 sgd_solver.cpp:106] Iteration 29730, lr = 0.01
I0812 08:29:39.470296 26953 solver.cpp:228] Iteration 29740, loss = 2.08448
I0812 08:29:39.470382 26953 solver.cpp:244]     Train net output #0: loss = 2.08448 (* 1 = 2.08448 loss)
I0812 08:29:40.869132 26953 sgd_solver.cpp:106] Iteration 29740, lr = 0.01
I0812 08:29:59.233994 26953 solver.cpp:228] Iteration 29750, loss = 1.98162
I0812 08:29:59.234176 26953 solver.cpp:244]     Train net output #0: loss = 1.98162 (* 1 = 1.98162 loss)
I0812 08:30:00.636669 26953 sgd_solver.cpp:106] Iteration 29750, lr = 0.01
I0812 08:30:19.084950 26953 solver.cpp:228] Iteration 29760, loss = 2.12496
I0812 08:30:19.085047 26953 solver.cpp:244]     Train net output #0: loss = 2.12496 (* 1 = 2.12496 loss)
I0812 08:30:20.486737 26953 sgd_solver.cpp:106] Iteration 29760, lr = 0.01
I0812 08:30:38.865459 26953 solver.cpp:228] Iteration 29770, loss = 1.82696
I0812 08:30:38.865697 26953 solver.cpp:244]     Train net output #0: loss = 1.82696 (* 1 = 1.82696 loss)
I0812 08:30:40.269083 26953 sgd_solver.cpp:106] Iteration 29770, lr = 0.01
I0812 08:30:58.736397 26953 solver.cpp:228] Iteration 29780, loss = 1.90246
I0812 08:30:58.736469 26953 solver.cpp:244]     Train net output #0: loss = 1.90246 (* 1 = 1.90246 loss)
I0812 08:31:00.130590 26953 sgd_solver.cpp:106] Iteration 29780, lr = 0.01
I0812 08:31:18.489087 26953 solver.cpp:228] Iteration 29790, loss = 2.02199
I0812 08:31:18.489246 26953 solver.cpp:244]     Train net output #0: loss = 2.02199 (* 1 = 2.02199 loss)
I0812 08:31:19.904280 26953 sgd_solver.cpp:106] Iteration 29790, lr = 0.01
I0812 08:31:37.735951 26953 solver.cpp:337] Iteration 29800, Testing net (#0)
I0812 08:31:38.324681 26953 solver.cpp:404]     Test net output #0: accuracy = 0.548
I0812 08:31:38.324746 26953 solver.cpp:404]     Test net output #1: loss = 1.87467 (* 1 = 1.87467 loss)
I0812 08:31:38.894704 26953 solver.cpp:228] Iteration 29800, loss = 1.84699
I0812 08:31:38.894793 26953 solver.cpp:244]     Train net output #0: loss = 1.84699 (* 1 = 1.84699 loss)
I0812 08:31:40.258635 26953 sgd_solver.cpp:106] Iteration 29800, lr = 0.01
I0812 08:31:58.670800 26953 solver.cpp:228] Iteration 29810, loss = 1.86571
I0812 08:31:58.671001 26953 solver.cpp:244]     Train net output #0: loss = 1.86571 (* 1 = 1.86571 loss)
I0812 08:32:00.070844 26953 sgd_solver.cpp:106] Iteration 29810, lr = 0.01
I0812 08:32:18.450204 26953 solver.cpp:228] Iteration 29820, loss = 1.99549
I0812 08:32:18.450284 26953 solver.cpp:244]     Train net output #0: loss = 1.99549 (* 1 = 1.99549 loss)
I0812 08:32:19.866824 26953 sgd_solver.cpp:106] Iteration 29820, lr = 0.01
I0812 08:32:38.294792 26953 solver.cpp:228] Iteration 29830, loss = 1.99211
I0812 08:32:38.294988 26953 solver.cpp:244]     Train net output #0: loss = 1.99211 (* 1 = 1.99211 loss)
I0812 08:32:39.685889 26953 sgd_solver.cpp:106] Iteration 29830, lr = 0.01
I0812 08:32:58.073993 26953 solver.cpp:228] Iteration 29840, loss = 1.93236
I0812 08:32:58.074074 26953 solver.cpp:244]     Train net output #0: loss = 1.93236 (* 1 = 1.93236 loss)
I0812 08:32:59.484423 26953 sgd_solver.cpp:106] Iteration 29840, lr = 0.01
I0812 08:33:17.844524 26953 solver.cpp:228] Iteration 29850, loss = 1.92499
I0812 08:33:17.844748 26953 solver.cpp:244]     Train net output #0: loss = 1.92499 (* 1 = 1.92499 loss)
I0812 08:33:19.257366 26953 sgd_solver.cpp:106] Iteration 29850, lr = 0.01
I0812 08:33:37.661783 26953 solver.cpp:228] Iteration 29860, loss = 1.88811
I0812 08:33:37.661875 26953 solver.cpp:244]     Train net output #0: loss = 1.88811 (* 1 = 1.88811 loss)
I0812 08:33:39.057466 26953 sgd_solver.cpp:106] Iteration 29860, lr = 0.01
I0812 08:33:57.468199 26953 solver.cpp:228] Iteration 29870, loss = 1.94216
I0812 08:33:57.468442 26953 solver.cpp:244]     Train net output #0: loss = 1.94216 (* 1 = 1.94216 loss)
I0812 08:33:58.872195 26953 sgd_solver.cpp:106] Iteration 29870, lr = 0.01
I0812 08:34:17.207666 26953 solver.cpp:228] Iteration 29880, loss = 1.95956
I0812 08:34:17.207746 26953 solver.cpp:244]     Train net output #0: loss = 1.95956 (* 1 = 1.95956 loss)
I0812 08:34:18.608321 26953 sgd_solver.cpp:106] Iteration 29880, lr = 0.01
I0812 08:34:36.996821 26953 solver.cpp:228] Iteration 29890, loss = 1.90612
I0812 08:34:36.997053 26953 solver.cpp:244]     Train net output #0: loss = 1.90612 (* 1 = 1.90612 loss)
I0812 08:34:38.385150 26953 sgd_solver.cpp:106] Iteration 29890, lr = 0.01
I0812 08:34:56.225646 26953 solver.cpp:337] Iteration 29900, Testing net (#0)
I0812 08:34:56.823823 26953 solver.cpp:404]     Test net output #0: accuracy = 0.502
I0812 08:34:56.823921 26953 solver.cpp:404]     Test net output #1: loss = 2.17572 (* 1 = 2.17572 loss)
I0812 08:34:57.384874 26953 solver.cpp:228] Iteration 29900, loss = 1.93179
I0812 08:34:57.384954 26953 solver.cpp:244]     Train net output #0: loss = 1.93179 (* 1 = 1.93179 loss)
I0812 08:34:58.789906 26953 sgd_solver.cpp:106] Iteration 29900, lr = 0.01
I0812 08:35:17.185230 26953 solver.cpp:228] Iteration 29910, loss = 1.9557
I0812 08:35:17.185428 26953 solver.cpp:244]     Train net output #0: loss = 1.9557 (* 1 = 1.9557 loss)
I0812 08:35:18.576689 26953 sgd_solver.cpp:106] Iteration 29910, lr = 0.01
I0812 08:35:36.969485 26953 solver.cpp:228] Iteration 29920, loss = 1.73159
I0812 08:35:36.969568 26953 solver.cpp:244]     Train net output #0: loss = 1.73159 (* 1 = 1.73159 loss)
I0812 08:35:38.364599 26953 sgd_solver.cpp:106] Iteration 29920, lr = 0.01
I0812 08:35:56.759454 26953 solver.cpp:228] Iteration 29930, loss = 1.92166
I0812 08:35:56.759713 26953 solver.cpp:244]     Train net output #0: loss = 1.92166 (* 1 = 1.92166 loss)
I0812 08:35:58.153053 26953 sgd_solver.cpp:106] Iteration 29930, lr = 0.01
I0812 08:36:16.498705 26953 solver.cpp:228] Iteration 29940, loss = 1.96607
I0812 08:36:16.498785 26953 solver.cpp:244]     Train net output #0: loss = 1.96607 (* 1 = 1.96607 loss)
I0812 08:36:17.902871 26953 sgd_solver.cpp:106] Iteration 29940, lr = 0.01
I0812 08:36:36.326289 26953 solver.cpp:228] Iteration 29950, loss = 1.88467
I0812 08:36:36.326524 26953 solver.cpp:244]     Train net output #0: loss = 1.88467 (* 1 = 1.88467 loss)
I0812 08:36:37.722434 26953 sgd_solver.cpp:106] Iteration 29950, lr = 0.01
I0812 08:36:56.097862 26953 solver.cpp:228] Iteration 29960, loss = 2.01674
I0812 08:36:56.097934 26953 solver.cpp:244]     Train net output #0: loss = 2.01674 (* 1 = 2.01674 loss)
I0812 08:36:57.516373 26953 sgd_solver.cpp:106] Iteration 29960, lr = 0.01
I0812 08:37:15.954596 26953 solver.cpp:228] Iteration 29970, loss = 1.98099
I0812 08:37:15.954758 26953 solver.cpp:244]     Train net output #0: loss = 1.98099 (* 1 = 1.98099 loss)
I0812 08:37:17.354707 26953 sgd_solver.cpp:106] Iteration 29970, lr = 0.01
I0812 08:37:35.774631 26953 solver.cpp:228] Iteration 29980, loss = 1.95222
I0812 08:37:35.774701 26953 solver.cpp:244]     Train net output #0: loss = 1.95222 (* 1 = 1.95222 loss)
I0812 08:37:37.190414 26953 sgd_solver.cpp:106] Iteration 29980, lr = 0.01
I0812 08:37:55.572752 26953 solver.cpp:228] Iteration 29990, loss = 1.9802
I0812 08:37:55.572926 26953 solver.cpp:244]     Train net output #0: loss = 1.9802 (* 1 = 1.9802 loss)
I0812 08:37:56.960039 26953 sgd_solver.cpp:106] Iteration 29990, lr = 0.01
I0812 08:38:14.819089 26953 solver.cpp:454] Snapshotting to binary proto file caffe_alexnet_train_iter_30000.caffemodel
I0812 08:38:30.247908 26953 sgd_solver.cpp:273] Snapshotting solver state to binary proto file caffe_alexnet_train_iter_30000.solverstate
I0812 08:38:30.602288 26953 solver.cpp:337] Iteration 30000, Testing net (#0)
I0812 08:38:31.299248 26953 solver.cpp:404]     Test net output #0: accuracy = 0.522
I0812 08:38:31.299319 26953 solver.cpp:404]     Test net output #1: loss = 2.13746 (* 1 = 2.13746 loss)
I0812 08:38:31.909737 26953 solver.cpp:228] Iteration 30000, loss = 2.06066
I0812 08:38:31.909816 26953 solver.cpp:244]     Train net output #0: loss = 2.06066 (* 1 = 2.06066 loss)
I0812 08:38:33.302517 26953 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I0812 08:38:51.623917 26953 solver.cpp:228] Iteration 30010, loss = 1.96791
I0812 08:38:51.623986 26953 solver.cpp:244]     Train net output #0: loss = 1.96791 (* 1 = 1.96791 loss)
I0812 08:38:53.028394 26953 sgd_solver.cpp:106] Iteration 30010, lr = 0.01
I0812 08:39:11.353420 26953 solver.cpp:228] Iteration 30020, loss = 1.94301
I0812 08:39:11.353706 26953 solver.cpp:244]     Train net output #0: loss = 1.94301 (* 1 = 1.94301 loss)
I0812 08:39:12.758934 26953 sgd_solver.cpp:106] Iteration 30020, lr = 0.01
I0812 08:39:31.130651 26953 solver.cpp:228] Iteration 30030, loss = 1.97235
I0812 08:39:31.130712 26953 solver.cpp:244]     Train net output #0: loss = 1.97235 (* 1 = 1.97235 loss)
I0812 08:39:32.547133 26953 sgd_solver.cpp:106] Iteration 30030, lr = 0.01
I0812 08:39:50.912183 26953 solver.cpp:228] Iteration 30040, loss = 2.0197
I0812 08:39:50.912400 26953 solver.cpp:244]     Train net output #0: loss = 2.0197 (* 1 = 2.0197 loss)
I0812 08:39:52.308648 26953 sgd_solver.cpp:106] Iteration 30040, lr = 0.01
I0812 08:40:10.697791 26953 solver.cpp:228] Iteration 30050, loss = 1.99056
I0812 08:40:10.697856 26953 solver.cpp:244]     Train net output #0: loss = 1.99056 (* 1 = 1.99056 loss)
I0812 08:40:12.106788 26953 sgd_solver.cpp:106] Iteration 30050, lr = 0.01
I0812 08:40:30.446918 26953 solver.cpp:228] Iteration 30060, loss = 2.07029
I0812 08:40:30.447053 26953 solver.cpp:244]     Train net output #0: loss = 2.07029 (* 1 = 2.07029 loss)
I0812 08:40:31.864892 26953 sgd_solver.cpp:106] Iteration 30060, lr = 0.01
I0812 08:40:50.260994 26953 solver.cpp:228] Iteration 30070, loss = 2.04496
I0812 08:40:50.261071 26953 solver.cpp:244]     Train net output #0: loss = 2.04496 (* 1 = 2.04496 loss)
I0812 08:40:51.645576 26953 sgd_solver.cpp:106] Iteration 30070, lr = 0.01
I0812 08:41:10.062126 26953 solver.cpp:228] Iteration 30080, loss = 1.97117
I0812 08:41:10.062304 26953 solver.cpp:244]     Train net output #0: loss = 1.97117 (* 1 = 1.97117 loss)
I0812 08:41:11.464073 26953 sgd_solver.cpp:106] Iteration 30080, lr = 0.01
I0812 08:41:29.825964 26953 solver.cpp:228] Iteration 30090, loss = 1.99003
I0812 08:41:29.826040 26953 solver.cpp:244]     Train net output #0: loss = 1.99003 (* 1 = 1.99003 loss)
I0812 08:41:31.227222 26953 sgd_solver.cpp:106] Iteration 30090, lr = 0.01
I0812 08:41:49.052382 26953 solver.cpp:337] Iteration 30100, Testing net (#0)
I0812 08:41:49.653702 26953 solver.cpp:404]     Test net output #0: accuracy = 0.52
I0812 08:41:49.653780 26953 solver.cpp:404]     Test net output #1: loss = 2.04798 (* 1 = 2.04798 loss)
I0812 08:41:50.231597 26953 solver.cpp:228] Iteration 30100, loss = 1.84291
I0812 08:41:50.231689 26953 solver.cpp:244]     Train net output #0: loss = 1.84291 (* 1 = 1.84291 loss)
I0812 08:41:51.606050 26953 sgd_solver.cpp:106] Iteration 30100, lr = 0.01
I0812 08:42:09.972534 26953 solver.cpp:228] Iteration 30110, loss = 1.91815
I0812 08:42:09.972604 26953 solver.cpp:244]     Train net output #0: loss = 1.91815 (* 1 = 1.91815 loss)
I0812 08:42:11.369920 26953 sgd_solver.cpp:106] Iteration 30110, lr = 0.01
I0812 08:42:29.727356 26953 solver.cpp:228] Iteration 30120, loss = 1.97042
I0812 08:42:29.727560 26953 solver.cpp:244]     Train net output #0: loss = 1.97042 (* 1 = 1.97042 loss)
I0812 08:42:31.143230 26953 sgd_solver.cpp:106] Iteration 30120, lr = 0.01
I0812 08:42:49.515894 26953 solver.cpp:228] Iteration 30130, loss = 2.01299
I0812 08:42:49.515967 26953 solver.cpp:244]     Train net output #0: loss = 2.01299 (* 1 = 2.01299 loss)
I0812 08:42:50.908004 26953 sgd_solver.cpp:106] Iteration 30130, lr = 0.01
I0812 08:43:09.338917 26953 solver.cpp:228] Iteration 30140, loss = 1.82501
I0812 08:43:09.339153 26953 solver.cpp:244]     Train net output #0: loss = 1.82501 (* 1 = 1.82501 loss)
I0812 08:43:10.747807 26953 sgd_solver.cpp:106] Iteration 30140, lr = 0.01
I0812 08:43:29.092564 26953 solver.cpp:228] Iteration 30150, loss = 2.05492
I0812 08:43:29.092645 26953 solver.cpp:244]     Train net output #0: loss = 2.05492 (* 1 = 2.05492 loss)
I0812 08:43:30.516957 26953 sgd_solver.cpp:106] Iteration 30150, lr = 0.01
I0812 08:43:48.899866 26953 solver.cpp:228] Iteration 30160, loss = 1.97772
I0812 08:43:48.900121 26953 solver.cpp:244]     Train net output #0: loss = 1.97772 (* 1 = 1.97772 loss)
I0812 08:43:50.303035 26953 sgd_solver.cpp:106] Iteration 30160, lr = 0.01
I0812 08:44:08.715279 26953 solver.cpp:228] Iteration 30170, loss = 1.95413
I0812 08:44:08.715351 26953 solver.cpp:244]     Train net output #0: loss = 1.95413 (* 1 = 1.95413 loss)
I0812 08:44:10.131009 26953 sgd_solver.cpp:106] Iteration 30170, lr = 0.01
I0812 08:44:28.531708 26953 solver.cpp:228] Iteration 30180, loss = 2.0365
I0812 08:44:28.531952 26953 solver.cpp:244]     Train net output #0: loss = 2.0365 (* 1 = 2.0365 loss)
I0812 08:44:29.923421 26953 sgd_solver.cpp:106] Iteration 30180, lr = 0.01
I0812 08:44:48.352862 26953 solver.cpp:228] Iteration 30190, loss = 1.85721
I0812 08:44:48.352934 26953 solver.cpp:244]     Train net output #0: loss = 1.85721 (* 1 = 1.85721 loss)
I0812 08:44:49.752452 26953 sgd_solver.cpp:106] Iteration 30190, lr = 0.01
I0812 08:45:07.550012 26953 solver.cpp:337] Iteration 30200, Testing net (#0)
I0812 08:45:08.138276 26953 solver.cpp:404]     Test net output #0: accuracy = 0.516
I0812 08:45:08.138342 26953 solver.cpp:404]     Test net output #1: loss = 2.1894 (* 1 = 2.1894 loss)
I0812 08:45:08.730742 26953 solver.cpp:228] Iteration 30200, loss = 1.97899
I0812 08:45:08.730805 26953 solver.cpp:244]     Train net output #0: loss = 1.97899 (* 1 = 1.97899 loss)
I0812 08:45:10.100625 26953 sgd_solver.cpp:106] Iteration 30200, lr = 0.01
I0812 08:45:28.542047 26953 solver.cpp:228] Iteration 30210, loss = 1.84141
I0812 08:45:28.542104 26953 solver.cpp:244]     Train net output #0: loss = 1.84141 (* 1 = 1.84141 loss)
I0812 08:45:29.941354 26953 sgd_solver.cpp:106] Iteration 30210, lr = 0.01
I0812 08:45:48.310511 26953 solver.cpp:228] Iteration 30220, loss = 2.08324
I0812 08:45:48.310796 26953 solver.cpp:244]     Train net output #0: loss = 2.08324 (* 1 = 2.08324 loss)
I0812 08:45:49.716028 26953 sgd_solver.cpp:106] Iteration 30220, lr = 0.01
I0812 08:46:08.053051 26953 solver.cpp:228] Iteration 30230, loss = 1.93576
I0812 08:46:08.053130 26953 solver.cpp:244]     Train net output #0: loss = 1.93576 (* 1 = 1.93576 loss)
I0812 08:46:09.451920 26953 sgd_solver.cpp:106] Iteration 30230, lr = 0.01
I0812 08:46:27.810003 26953 solver.cpp:228] Iteration 30240, loss = 1.9609
I0812 08:46:27.810268 26953 solver.cpp:244]     Train net output #0: loss = 1.9609 (* 1 = 1.9609 loss)
I0812 08:46:29.202818 26953 sgd_solver.cpp:106] Iteration 30240, lr = 0.01
I0812 08:46:47.659780 26953 solver.cpp:228] Iteration 30250, loss = 1.95498
I0812 08:46:47.659839 26953 solver.cpp:244]     Train net output #0: loss = 1.95498 (* 1 = 1.95498 loss)
I0812 08:46:49.072662 26953 sgd_solver.cpp:106] Iteration 30250, lr = 0.01
I0812 08:47:07.391825 26953 solver.cpp:228] Iteration 30260, loss = 1.99573
I0812 08:47:07.391973 26953 solver.cpp:244]     Train net output #0: loss = 1.99573 (* 1 = 1.99573 loss)
I0812 08:47:08.785811 26953 sgd_solver.cpp:106] Iteration 30260, lr = 0.01
I0812 08:47:27.152586 26953 solver.cpp:228] Iteration 30270, loss = 2.05981
I0812 08:47:27.152667 26953 solver.cpp:244]     Train net output #0: loss = 2.05981 (* 1 = 2.05981 loss)
I0812 08:47:28.556601 26953 sgd_solver.cpp:106] Iteration 30270, lr = 0.01
I0812 08:47:46.952988 26953 solver.cpp:228] Iteration 30280, loss = 2.12812
I0812 08:47:46.953146 26953 solver.cpp:244]     Train net output #0: loss = 2.12812 (* 1 = 2.12812 loss)
I0812 08:47:48.351487 26953 sgd_solver.cpp:106] Iteration 30280, lr = 0.01
I0812 08:48:06.744833 26953 solver.cpp:228] Iteration 30290, loss = 2.07682
I0812 08:48:06.744904 26953 solver.cpp:244]     Train net output #0: loss = 2.07682 (* 1 = 2.07682 loss)
I0812 08:48:08.162580 26953 sgd_solver.cpp:106] Iteration 30290, lr = 0.01
I0812 08:48:25.928467 26953 solver.cpp:337] Iteration 30300, Testing net (#0)
I0812 08:48:26.522718 26953 solver.cpp:404]     Test net output #0: accuracy = 0.518
I0812 08:48:26.522784 26953 solver.cpp:404]     Test net output #1: loss = 2.2471 (* 1 = 2.2471 loss)
I0812 08:48:27.106444 26953 solver.cpp:228] Iteration 30300, loss = 1.98037
I0812 08:48:27.106531 26953 solver.cpp:244]     Train net output #0: loss = 1.98037 (* 1 = 1.98037 loss)
I0812 08:48:28.474015 26953 sgd_solver.cpp:106] Iteration 30300, lr = 0.01
I0812 08:48:46.908731 26953 solver.cpp:228] Iteration 30310, loss = 1.93633
I0812 08:48:46.908800 26953 solver.cpp:244]     Train net output #0: loss = 1.93633 (* 1 = 1.93633 loss)
I0812 08:48:48.311800 26953 sgd_solver.cpp:106] Iteration 30310, lr = 0.01
I0812 08:49:06.690417 26953 solver.cpp:228] Iteration 30320, loss = 2.00673
I0812 08:49:06.690675 26953 solver.cpp:244]     Train net output #0: loss = 2.00673 (* 1 = 2.00673 loss)
I0812 08:49:08.099016 26953 sgd_solver.cpp:106] Iteration 30320, lr = 0.01
I0812 08:49:26.498035 26953 solver.cpp:228] Iteration 30330, loss = 2.03259
I0812 08:49:26.498106 26953 solver.cpp:244]     Train net output #0: loss = 2.03259 (* 1 = 2.03259 loss)
I0812 08:49:27.898779 26953 sgd_solver.cpp:106] Iteration 30330, lr = 0.01
I0812 08:49:46.315064 26953 solver.cpp:228] Iteration 30340, loss = 2.06212
I0812 08:49:46.315193 26953 solver.cpp:244]     Train net output #0: loss = 2.06212 (* 1 = 2.06212 loss)
I0812 08:49:47.729595 26953 sgd_solver.cpp:106] Iteration 30340, lr = 0.01
I0812 08:50:06.086442 26953 solver.cpp:228] Iteration 30350, loss = 2.02873
I0812 08:50:06.086511 26953 solver.cpp:244]     Train net output #0: loss = 2.02873 (* 1 = 2.02873 loss)
I0812 08:50:07.478227 26953 sgd_solver.cpp:106] Iteration 30350, lr = 0.01
I0812 08:50:25.878443 26953 solver.cpp:228] Iteration 30360, loss = 1.96696
I0812 08:50:25.878588 26953 solver.cpp:244]     Train net output #0: loss = 1.96696 (* 1 = 1.96696 loss)
I0812 08:50:27.274690 26953 sgd_solver.cpp:106] Iteration 30360, lr = 0.01
I0812 08:50:45.702062 26953 solver.cpp:228] Iteration 30370, loss = 1.90416
I0812 08:50:45.702132 26953 solver.cpp:244]     Train net output #0: loss = 1.90416 (* 1 = 1.90416 loss)
I0812 08:50:47.103416 26953 sgd_solver.cpp:106] Iteration 30370, lr = 0.01
I0812 08:51:05.480500 26953 solver.cpp:228] Iteration 30380, loss = 2.01599
I0812 08:51:05.480830 26953 solver.cpp:244]     Train net output #0: loss = 2.01599 (* 1 = 2.01599 loss)
I0812 08:51:06.881305 26953 sgd_solver.cpp:106] Iteration 30380, lr = 0.01
I0812 08:51:25.304766 26953 solver.cpp:228] Iteration 30390, loss = 2.11841
I0812 08:51:25.304849 26953 solver.cpp:244]     Train net output #0: loss = 2.11841 (* 1 = 2.11841 loss)
I0812 08:51:26.703816 26953 sgd_solver.cpp:106] Iteration 30390, lr = 0.01
I0812 08:51:44.499351 26953 solver.cpp:337] Iteration 30400, Testing net (#0)
I0812 08:51:45.089015 26953 solver.cpp:404]     Test net output #0: accuracy = 0.53
I0812 08:51:45.089081 26953 solver.cpp:404]     Test net output #1: loss = 2.04417 (* 1 = 2.04417 loss)
I0812 08:51:45.657050 26953 solver.cpp:228] Iteration 30400, loss = 1.75788
I0812 08:51:45.657114 26953 solver.cpp:244]     Train net output #0: loss = 1.75788 (* 1 = 1.75788 loss)
I0812 08:51:47.021545 26953 sgd_solver.cpp:106] Iteration 30400, lr = 0.01
I0812 08:52:05.392280 26953 solver.cpp:228] Iteration 30410, loss = 2.14968
I0812 08:52:05.392344 26953 solver.cpp:244]     Train net output #0: loss = 2.14968 (* 1 = 2.14968 loss)
I0812 08:52:06.786768 26953 sgd_solver.cpp:106] Iteration 30410, lr = 0.01
I0812 08:52:25.179726 26953 solver.cpp:228] Iteration 30420, loss = 2.02772
I0812 08:52:25.179951 26953 solver.cpp:244]     Train net output #0: loss = 2.02772 (* 1 = 2.02772 loss)
I0812 08:52:26.578574 26953 sgd_solver.cpp:106] Iteration 30420, lr = 0.01
I0812 08:52:44.977813 26953 solver.cpp:228] Iteration 30430, loss = 1.84501
I0812 08:52:44.977880 26953 solver.cpp:244]     Train net output #0: loss = 1.84501 (* 1 = 1.84501 loss)
I0812 08:52:46.389112 26953 sgd_solver.cpp:106] Iteration 30430, lr = 0.01
I0812 08:53:04.745708 26953 solver.cpp:228] Iteration 30440, loss = 1.8579
I0812 08:53:04.745919 26953 solver.cpp:244]     Train net output #0: loss = 1.8579 (* 1 = 1.8579 loss)
I0812 08:53:06.147060 26953 sgd_solver.cpp:106] Iteration 30440, lr = 0.01
I0812 08:53:24.614189 26953 solver.cpp:228] Iteration 30450, loss = 1.843
I0812 08:53:24.614258 26953 solver.cpp:244]     Train net output #0: loss = 1.843 (* 1 = 1.843 loss)
I0812 08:53:26.008991 26953 sgd_solver.cpp:106] Iteration 30450, lr = 0.01
I0812 08:53:44.374095 26953 solver.cpp:228] Iteration 30460, loss = 1.92375
I0812 08:53:44.374330 26953 solver.cpp:244]     Train net output #0: loss = 1.92375 (* 1 = 1.92375 loss)
I0812 08:53:45.790105 26953 sgd_solver.cpp:106] Iteration 30460, lr = 0.01
I0812 08:54:04.151103 26953 solver.cpp:228] Iteration 30470, loss = 2.13881
I0812 08:54:04.151177 26953 solver.cpp:244]     Train net output #0: loss = 2.13881 (* 1 = 2.13881 loss)
I0812 08:54:05.543799 26953 sgd_solver.cpp:106] Iteration 30470, lr = 0.01
I0812 08:54:23.961189 26953 solver.cpp:228] Iteration 30480, loss = 1.7526
I0812 08:54:23.961437 26953 solver.cpp:244]     Train net output #0: loss = 1.7526 (* 1 = 1.7526 loss)
I0812 08:54:25.348304 26953 sgd_solver.cpp:106] Iteration 30480, lr = 0.01
I0812 08:54:43.706316 26953 solver.cpp:228] Iteration 30490, loss = 2.05199
I0812 08:54:43.706377 26953 solver.cpp:244]     Train net output #0: loss = 2.05199 (* 1 = 2.05199 loss)
I0812 08:54:45.113448 26953 sgd_solver.cpp:106] Iteration 30490, lr = 0.01
I0812 08:55:02.879544 26953 solver.cpp:337] Iteration 30500, Testing net (#0)
I0812 08:55:03.472244 26953 solver.cpp:404]     Test net output #0: accuracy = 0.512
I0812 08:55:03.472326 26953 solver.cpp:404]     Test net output #1: loss = 2.10549 (* 1 = 2.10549 loss)
I0812 08:55:04.046119 26953 solver.cpp:228] Iteration 30500, loss = 1.90528
I0812 08:55:04.046183 26953 solver.cpp:244]     Train net output #0: loss = 1.90528 (* 1 = 1.90528 loss)
I0812 08:55:05.422508 26953 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I0812 08:55:23.807771 26953 solver.cpp:228] Iteration 30510, loss = 1.93481
I0812 08:55:23.807842 26953 solver.cpp:244]     Train net output #0: loss = 1.93481 (* 1 = 1.93481 loss)
I0812 08:55:25.202488 26953 sgd_solver.cpp:106] Iteration 30510, lr = 0.01
I0812 08:55:43.594584 26953 solver.cpp:228] Iteration 30520, loss = 2.07388
I0812 08:55:43.594893 26953 solver.cpp:244]     Train net output #0: loss = 2.07388 (* 1 = 2.07388 loss)
I0812 08:55:45.001934 26953 sgd_solver.cpp:106] Iteration 30520, lr = 0.01
I0812 08:56:03.372756 26953 solver.cpp:228] Iteration 30530, loss = 2.00726
I0812 08:56:03.372823 26953 solver.cpp:244]     Train net output #0: loss = 2.00726 (* 1 = 2.00726 loss)
I0812 08:56:04.771312 26953 sgd_solver.cpp:106] Iteration 30530, lr = 0.01
I0812 08:56:23.209570 26953 solver.cpp:228] Iteration 30540, loss = 1.84853
I0812 08:56:23.209808 26953 solver.cpp:244]     Train net output #0: loss = 1.84853 (* 1 = 1.84853 loss)
I0812 08:56:24.604056 26953 sgd_solver.cpp:106] Iteration 30540, lr = 0.01
I0812 08:56:42.947090 26953 solver.cpp:228] Iteration 30550, loss = 2.0918
I0812 08:56:42.947160 26953 solver.cpp:244]     Train net output #0: loss = 2.0918 (* 1 = 2.0918 loss)
I0812 08:56:44.347867 26953 sgd_solver.cpp:106] Iteration 30550, lr = 0.01
I0812 08:57:02.734311 26953 solver.cpp:228] Iteration 30560, loss = 1.85366
I0812 08:57:02.734472 26953 solver.cpp:244]     Train net output #0: loss = 1.85366 (* 1 = 1.85366 loss)
I0812 08:57:04.142346 26953 sgd_solver.cpp:106] Iteration 30560, lr = 0.01
I0812 08:57:22.528918 26953 solver.cpp:228] Iteration 30570, loss = 1.82325
I0812 08:57:22.528977 26953 solver.cpp:244]     Train net output #0: loss = 1.82325 (* 1 = 1.82325 loss)
I0812 08:57:23.938380 26953 sgd_solver.cpp:106] Iteration 30570, lr = 0.01
I0812 08:57:42.336525 26953 solver.cpp:228] Iteration 30580, loss = 1.87153
I0812 08:57:42.336697 26953 solver.cpp:244]     Train net output #0: loss = 1.87153 (* 1 = 1.87153 loss)
I0812 08:57:43.736224 26953 sgd_solver.cpp:106] Iteration 30580, lr = 0.01
I0812 08:58:02.124575 26953 solver.cpp:228] Iteration 30590, loss = 1.95772
I0812 08:58:02.124639 26953 solver.cpp:244]     Train net output #0: loss = 1.95772 (* 1 = 1.95772 loss)
I0812 08:58:03.530627 26953 sgd_solver.cpp:106] Iteration 30590, lr = 0.01
I0812 08:58:21.350028 26953 solver.cpp:337] Iteration 30600, Testing net (#0)
I0812 08:58:21.938453 26953 solver.cpp:404]     Test net output #0: accuracy = 0.556
I0812 08:58:21.938527 26953 solver.cpp:404]     Test net output #1: loss = 2.07196 (* 1 = 2.07196 loss)
I0812 08:58:22.515563 26953 solver.cpp:228] Iteration 30600, loss = 1.94619
I0812 08:58:22.515661 26953 solver.cpp:244]     Train net output #0: loss = 1.94619 (* 1 = 1.94619 loss)
I0812 08:58:23.897743 26953 sgd_solver.cpp:106] Iteration 30600, lr = 0.01
I0812 08:58:42.239970 26953 solver.cpp:228] Iteration 30610, loss = 1.87524
I0812 08:58:42.240043 26953 solver.cpp:244]     Train net output #0: loss = 1.87524 (* 1 = 1.87524 loss)
I0812 08:58:43.631786 26953 sgd_solver.cpp:106] Iteration 30610, lr = 0.01
I0812 08:59:01.967089 26953 solver.cpp:228] Iteration 30620, loss = 1.99612
I0812 08:59:01.967306 26953 solver.cpp:244]     Train net output #0: loss = 1.99612 (* 1 = 1.99612 loss)
I0812 08:59:03.371630 26953 sgd_solver.cpp:106] Iteration 30620, lr = 0.01
I0812 08:59:21.750103 26953 solver.cpp:228] Iteration 30630, loss = 1.9211
I0812 08:59:21.750167 26953 solver.cpp:244]     Train net output #0: loss = 1.9211 (* 1 = 1.9211 loss)
I0812 08:59:23.161026 26953 sgd_solver.cpp:106] Iteration 30630, lr = 0.01
I0812 08:59:41.570135 26953 solver.cpp:228] Iteration 30640, loss = 2.15239
I0812 08:59:41.573276 26953 solver.cpp:244]     Train net output #0: loss = 2.15239 (* 1 = 2.15239 loss)
I0812 08:59:42.962105 26953 sgd_solver.cpp:106] Iteration 30640, lr = 0.01
I0812 09:00:01.359913 26953 solver.cpp:228] Iteration 30650, loss = 1.93133
I0812 09:00:01.359980 26953 solver.cpp:244]     Train net output #0: loss = 1.93133 (* 1 = 1.93133 loss)
I0812 09:00:02.762508 26953 sgd_solver.cpp:106] Iteration 30650, lr = 0.01
I0812 09:00:21.125083 26953 solver.cpp:228] Iteration 30660, loss = 2.0114
I0812 09:00:21.125347 26953 solver.cpp:244]     Train net output #0: loss = 2.0114 (* 1 = 2.0114 loss)
I0812 09:00:22.515882 26953 sgd_solver.cpp:106] Iteration 30660, lr = 0.01
I0812 09:00:40.916437 26953 solver.cpp:228] Iteration 30670, loss = 1.95232
I0812 09:00:40.916498 26953 solver.cpp:244]     Train net output #0: loss = 1.95232 (* 1 = 1.95232 loss)
I0812 09:00:42.316373 26953 sgd_solver.cpp:106] Iteration 30670, lr = 0.01
I0812 09:01:00.715718 26953 solver.cpp:228] Iteration 30680, loss = 1.88321
I0812 09:01:00.715916 26953 solver.cpp:244]     Train net output #0: loss = 1.88321 (* 1 = 1.88321 loss)
I0812 09:01:02.119346 26953 sgd_solver.cpp:106] Iteration 30680, lr = 0.01
I0812 09:01:20.527675 26953 solver.cpp:228] Iteration 30690, loss = 1.88062
I0812 09:01:20.527740 26953 solver.cpp:244]     Train net output #0: loss = 1.88062 (* 1 = 1.88062 loss)
I0812 09:01:21.938035 26953 sgd_solver.cpp:106] Iteration 30690, lr = 0.01
I0812 09:01:39.744223 26953 solver.cpp:337] Iteration 30700, Testing net (#0)
I0812 09:01:40.335973 26953 solver.cpp:404]     Test net output #0: accuracy = 0.546
I0812 09:01:40.336037 26953 solver.cpp:404]     Test net output #1: loss = 2.03694 (* 1 = 2.03694 loss)
I0812 09:01:40.900686 26953 solver.cpp:228] Iteration 30700, loss = 1.86179
I0812 09:01:40.900744 26953 solver.cpp:244]     Train net output #0: loss = 1.86179 (* 1 = 1.86179 loss)
I0812 09:01:42.289268 26953 sgd_solver.cpp:106] Iteration 30700, lr = 0.01
I0812 09:02:00.646584 26953 solver.cpp:228] Iteration 30710, loss = 1.82198
I0812 09:02:00.646646 26953 solver.cpp:244]     Train net output #0: loss = 1.82198 (* 1 = 1.82198 loss)
I0812 09:02:02.045161 26953 sgd_solver.cpp:106] Iteration 30710, lr = 0.01
I0812 09:02:20.453969 26953 solver.cpp:228] Iteration 30720, loss = 1.98066
I0812 09:02:20.454161 26953 solver.cpp:244]     Train net output #0: loss = 1.98066 (* 1 = 1.98066 loss)
I0812 09:02:21.849268 26953 sgd_solver.cpp:106] Iteration 30720, lr = 0.01
I0812 09:02:40.255199 26953 solver.cpp:228] Iteration 30730, loss = 1.92707
I0812 09:02:40.255260 26953 solver.cpp:244]     Train net output #0: loss = 1.92707 (* 1 = 1.92707 loss)
I0812 09:02:41.666892 26953 sgd_solver.cpp:106] Iteration 30730, lr = 0.01
I0812 09:03:00.029255 26953 solver.cpp:228] Iteration 30740, loss = 1.8578
I0812 09:03:00.029464 26953 solver.cpp:244]     Train net output #0: loss = 1.8578 (* 1 = 1.8578 loss)
I0812 09:03:01.429934 26953 sgd_solver.cpp:106] Iteration 30740, lr = 0.01
I0812 09:03:19.836737 26953 solver.cpp:228] Iteration 30750, loss = 2.05145
I0812 09:03:19.836807 26953 solver.cpp:244]     Train net output #0: loss = 2.05145 (* 1 = 2.05145 loss)
I0812 09:03:21.242940 26953 sgd_solver.cpp:106] Iteration 30750, lr = 0.01
I0812 09:03:39.690919 26953 solver.cpp:228] Iteration 30760, loss = 2.16747
I0812 09:03:39.691159 26953 solver.cpp:244]     Train net output #0: loss = 2.16747 (* 1 = 2.16747 loss)
I0812 09:03:41.093492 26953 sgd_solver.cpp:106] Iteration 30760, lr = 0.01
I0812 09:03:59.535749 26953 solver.cpp:228] Iteration 30770, loss = 1.858
I0812 09:03:59.535821 26953 solver.cpp:244]     Train net output #0: loss = 1.858 (* 1 = 1.858 loss)
I0812 09:04:00.945837 26953 sgd_solver.cpp:106] Iteration 30770, lr = 0.01
I0812 09:04:19.318269 26953 solver.cpp:228] Iteration 30780, loss = 2.07319
I0812 09:04:19.318907 26953 solver.cpp:244]     Train net output #0: loss = 2.07319 (* 1 = 2.07319 loss)
I0812 09:04:20.726774 26953 sgd_solver.cpp:106] Iteration 30780, lr = 0.01
I0812 09:04:39.078980 26953 solver.cpp:228] Iteration 30790, loss = 1.92009
I0812 09:04:39.079064 26953 solver.cpp:244]     Train net output #0: loss = 1.92009 (* 1 = 1.92009 loss)
I0812 09:04:40.492601 26953 sgd_solver.cpp:106] Iteration 30790, lr = 0.01
I0812 09:04:58.369602 26953 solver.cpp:337] Iteration 30800, Testing net (#0)
I0812 09:04:58.963358 26953 solver.cpp:404]     Test net output #0: accuracy = 0.538
I0812 09:04:58.963423 26953 solver.cpp:404]     Test net output #1: loss = 2.18877 (* 1 = 2.18877 loss)
I0812 09:04:59.557885 26953 solver.cpp:228] Iteration 30800, loss = 1.91952
I0812 09:04:59.557967 26953 solver.cpp:244]     Train net output #0: loss = 1.91952 (* 1 = 1.91952 loss)
I0812 09:05:00.921937 26953 sgd_solver.cpp:106] Iteration 30800, lr = 0.01
I0812 09:05:19.388941 26953 solver.cpp:228] Iteration 30810, loss = 2.11644
I0812 09:05:19.389019 26953 solver.cpp:244]     Train net output #0: loss = 2.11644 (* 1 = 2.11644 loss)
I0812 09:05:20.796509 26953 sgd_solver.cpp:106] Iteration 30810, lr = 0.01
I0812 09:05:39.182848 26953 solver.cpp:228] Iteration 30820, loss = 1.90269
I0812 09:05:39.183032 26953 solver.cpp:244]     Train net output #0: loss = 1.90269 (* 1 = 1.90269 loss)
I0812 09:05:40.574965 26953 sgd_solver.cpp:106] Iteration 30820, lr = 0.01
I0812 09:05:58.940074 26953 solver.cpp:228] Iteration 30830, loss = 1.9039
I0812 09:05:58.940150 26953 solver.cpp:244]     Train net output #0: loss = 1.9039 (* 1 = 1.9039 loss)
I0812 09:06:00.334408 26953 sgd_solver.cpp:106] Iteration 30830, lr = 0.01
I0812 09:06:18.737026 26953 solver.cpp:228] Iteration 30840, loss = 1.86791
I0812 09:06:18.737287 26953 solver.cpp:244]     Train net output #0: loss = 1.86791 (* 1 = 1.86791 loss)
I0812 09:06:20.127799 26953 sgd_solver.cpp:106] Iteration 30840, lr = 0.01
I0812 09:06:38.531762 26953 solver.cpp:228] Iteration 30850, loss = 1.9332
I0812 09:06:38.531827 26953 solver.cpp:244]     Train net output #0: loss = 1.9332 (* 1 = 1.9332 loss)
I0812 09:06:39.936039 26953 sgd_solver.cpp:106] Iteration 30850, lr = 0.01
I0812 09:06:58.336544 26953 solver.cpp:228] Iteration 30860, loss = 2.01443
I0812 09:06:58.336786 26953 solver.cpp:244]     Train net output #0: loss = 2.01443 (* 1 = 2.01443 loss)
I0812 09:06:59.744753 26953 sgd_solver.cpp:106] Iteration 30860, lr = 0.01
I0812 09:07:18.167778 26953 solver.cpp:228] Iteration 30870, loss = 1.99444
I0812 09:07:18.167852 26953 solver.cpp:244]     Train net output #0: loss = 1.99444 (* 1 = 1.99444 loss)
I0812 09:07:19.570324 26953 sgd_solver.cpp:106] Iteration 30870, lr = 0.01
I0812 09:07:37.955595 26953 solver.cpp:228] Iteration 30880, loss = 1.89593
I0812 09:07:37.955837 26953 solver.cpp:244]     Train net output #0: loss = 1.89593 (* 1 = 1.89593 loss)
I0812 09:07:39.331919 26953 sgd_solver.cpp:106] Iteration 30880, lr = 0.01
I0812 09:07:57.699010 26953 solver.cpp:228] Iteration 30890, loss = 1.95203
I0812 09:07:57.699079 26953 solver.cpp:244]     Train net output #0: loss = 1.95203 (* 1 = 1.95203 loss)
I0812 09:07:59.103783 26953 sgd_solver.cpp:106] Iteration 30890, lr = 0.01
I0812 09:08:16.873369 26953 solver.cpp:337] Iteration 30900, Testing net (#0)
I0812 09:08:17.472261 26953 solver.cpp:404]     Test net output #0: accuracy = 0.53
I0812 09:08:17.472344 26953 solver.cpp:404]     Test net output #1: loss = 1.99932 (* 1 = 1.99932 loss)
I0812 09:08:18.052461 26953 solver.cpp:228] Iteration 30900, loss = 2.02922
I0812 09:08:18.052553 26953 solver.cpp:244]     Train net output #0: loss = 2.02922 (* 1 = 2.02922 loss)
I0812 09:08:19.414417 26953 sgd_solver.cpp:106] Iteration 30900, lr = 0.01
I0812 09:08:37.814254 26953 solver.cpp:228] Iteration 30910, loss = 1.78816
I0812 09:08:37.814332 26953 solver.cpp:244]     Train net output #0: loss = 1.78816 (* 1 = 1.78816 loss)
I0812 09:08:39.214186 26953 sgd_solver.cpp:106] Iteration 30910, lr = 0.01
I0812 09:08:57.637886 26953 solver.cpp:228] Iteration 30920, loss = 1.99109
I0812 09:08:57.638110 26953 solver.cpp:244]     Train net output #0: loss = 1.99109 (* 1 = 1.99109 loss)
I0812 09:08:59.021255 26953 sgd_solver.cpp:106] Iteration 30920, lr = 0.01
I0812 09:09:17.400986 26953 solver.cpp:228] Iteration 30930, loss = 2.00518
I0812 09:09:17.401057 26953 solver.cpp:244]     Train net output #0: loss = 2.00518 (* 1 = 2.00518 loss)
I0812 09:09:18.796281 26953 sgd_solver.cpp:106] Iteration 30930, lr = 0.01
I0812 09:09:37.220785 26953 solver.cpp:228] Iteration 30940, loss = 1.92502
I0812 09:09:37.220955 26953 solver.cpp:244]     Train net output #0: loss = 1.92502 (* 1 = 1.92502 loss)
I0812 09:09:38.619678 26953 sgd_solver.cpp:106] Iteration 30940, lr = 0.01
I0812 09:09:57.001989 26953 solver.cpp:228] Iteration 30950, loss = 2.02168
I0812 09:09:57.002059 26953 solver.cpp:244]     Train net output #0: loss = 2.02168 (* 1 = 2.02168 loss)
I0812 09:09:58.384528 26953 sgd_solver.cpp:106] Iteration 30950, lr = 0.01
I0812 09:10:16.815762 26953 solver.cpp:228] Iteration 30960, loss = 2.14243
I0812 09:10:16.815944 26953 solver.cpp:244]     Train net output #0: loss = 2.14243 (* 1 = 2.14243 loss)
I0812 09:10:18.216337 26953 sgd_solver.cpp:106] Iteration 30960, lr = 0.01
I0812 09:10:36.614776 26953 solver.cpp:228] Iteration 30970, loss = 2.06363
I0812 09:10:36.614846 26953 solver.cpp:244]     Train net output #0: loss = 2.06363 (* 1 = 2.06363 loss)
I0812 09:10:38.026810 26953 sgd_solver.cpp:106] Iteration 30970, lr = 0.01
I0812 09:10:56.431999 26953 solver.cpp:228] Iteration 30980, loss = 2.01148
I0812 09:10:56.432246 26953 solver.cpp:244]     Train net output #0: loss = 2.01148 (* 1 = 2.01148 loss)
I0812 09:10:57.829260 26953 sgd_solver.cpp:106] Iteration 30980, lr = 0.01
I0812 09:11:16.232648 26953 solver.cpp:228] Iteration 30990, loss = 2.07288
I0812 09:11:16.232717 26953 solver.cpp:244]     Train net output #0: loss = 2.07288 (* 1 = 2.07288 loss)
I0812 09:11:17.644358 26953 sgd_solver.cpp:106] Iteration 30990, lr = 0.01
I0812 09:11:35.424336 26953 solver.cpp:337] Iteration 31000, Testing net (#0)
I0812 09:11:36.025393 26953 solver.cpp:404]     Test net output #0: accuracy = 0.48
I0812 09:11:36.025475 26953 solver.cpp:404]     Test net output #1: loss = 2.23406 (* 1 = 2.23406 loss)
I0812 09:11:36.591150 26953 solver.cpp:228] Iteration 31000, loss = 1.9148
I0812 09:11:36.591253 26953 solver.cpp:244]     Train net output #0: loss = 1.9148 (* 1 = 1.9148 loss)
I0812 09:11:37.965365 26953 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I0812 09:11:56.397219 26953 solver.cpp:228] Iteration 31010, loss = 1.88507
I0812 09:11:56.397280 26953 solver.cpp:244]     Train net output #0: loss = 1.88507 (* 1 = 1.88507 loss)
I0812 09:11:57.804996 26953 sgd_solver.cpp:106] Iteration 31010, lr = 0.01
I0812 09:12:16.146319 26953 solver.cpp:228] Iteration 31020, loss = 1.91579
I0812 09:12:16.146476 26953 solver.cpp:244]     Train net output #0: loss = 1.91579 (* 1 = 1.91579 loss)
I0812 09:12:17.557883 26953 sgd_solver.cpp:106] Iteration 31020, lr = 0.01
I0812 09:12:35.923908 26953 solver.cpp:228] Iteration 31030, loss = 2.03723
I0812 09:12:35.923974 26953 solver.cpp:244]     Train net output #0: loss = 2.03723 (* 1 = 2.03723 loss)
I0812 09:12:37.323735 26953 sgd_solver.cpp:106] Iteration 31030, lr = 0.01
I0812 09:12:55.705148 26953 solver.cpp:228] Iteration 31040, loss = 1.90862
I0812 09:12:55.705364 26953 solver.cpp:244]     Train net output #0: loss = 1.90862 (* 1 = 1.90862 loss)
I0812 09:12:57.121022 26953 sgd_solver.cpp:106] Iteration 31040, lr = 0.01
*** Aborted at 1471007593 (unix time) try "date -d @1471007593" if you are using GNU date ***
PC: @     0x7fff33173a3d (unknown)
*** SIGTERM (@0x3e900007912) received by PID 26953 (TID 0x7f0374db6700) from PID 30994; stack trace: ***
    @     0x7f47b8d032f0 (unknown)
    @     0x7fff33173a3d (unknown)
    @     0x7f47b8de338d (unknown)
    @     0x7f4799df82be (unknown)
    @     0x7f47997ad7ab (unknown)
    @     0x7f479978ae33 (unknown)
    @     0x7f479978af89 (unknown)
    @     0x7f47996fec87 (unknown)
    @     0x7f47996d70c2 (unknown)
    @     0x7f47ba724d90 (unknown)
    @     0x7f47ba75c1fd (unknown)
    @     0x7f47bac2f46f caffe::P2PSync<>::on_gradients_ready()
    @     0x7f47bac1cd0e caffe::Solver<>::Step()
    @     0x7f47bac2e9a7 caffe::P2PSync<>::InternalThreadEntry()
    @     0x7f47bac5e355 caffe::InternalThread::entry()
    @     0x7f47b230109a (unknown)
    @     0x7f47ae0686aa start_thread
    @     0x7f47b8dd4eed (unknown)
    @                0x0 (unknown)
Terminated
